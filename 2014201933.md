一、图像处理
  1.caffe使用
      由于之前并没有接触过类似的实验，所以在安装及使用caffe上费了很多的时间。由于显卡的限制，安装过程中Ubuntu崩溃了几次，最后使用的也是没有gpu的简化版本，处理速度上较慢，但是基本还是可以使用的。

 2.图像处理（普通网络）
    图像集使用的是caffe自带的cifar-10数据集，一开始选择的处理手段就是cifar-10中自带的quick.sh，处理使用的是一个只有三个卷积层的5000次迭代模型，最后得到的处理结果是百分之七十多，如果使用full.sh对应的是一个几万次迭代的卷积层数更多的模型，据了解通过这个方式训练出来的准确度接近百分之九十，但是由于受不能使用gpu这一客观条件的限制，并没有实际运行。
 
 3.图像处理（简单改进）
  简单改进的思路是对于已经给出的quick.sh进行改变，通过改变参数和其中的卷积层来实现对于网络结构的改善。通过简单的实验基本得出了以下结论：1）单纯的增加层数并不能够优化网络，只是将网络导向收敛。2）按照一定方式增加卷积层数，确实能在一定程度上增加分类的精确度，但是效果很有限。3）改变训练权重参数，确实对于最终结果有着较大的影响，可以影响在同一个条件下的收敛情况。//但有时也会有负面影响。

4.最终处理（resnet）
何凯明的论文中也提到像刚才说到的简单的增加卷积层的办法其实是不太现实的，因为较少的层数可能并不明显，但是如果层数很多的情况之下，会出现所谓梯度消失或是梯度爆炸的情况，在那种情况下精确度会受很大的影响，为了应对这种情况，我们使用resnet结构网络。
resnet比普通的网络多的主要是快捷通道-即从每一层都有直接下之后的层传输数据的途径，这样可以减少传输过程中出现的误差，而在处理的卷积层之中实际传输的是一个残差数据。我使用的是一个十几层的resnet网络，在运行了4000次迭代之后，尚未收敛就已经达到了百分之八十以上的准确率。

二、文本分类
1.文本分类问题
文本分类问题主要是基于scigen生成的假论文和实际由人所撰写的真论文的区分。在查看网络查询结果后可以发现，scigen主要是将所有可以在对应学科的论文中出现的词语进行分类，之后利用算法使用上下文无关文法生成那些看起来没什么问题，但是一点实际意义都没有的论文。所以对应生成的假论文有两个较为明显的缺点:1)假论文对于中心的强调不够，也就是说假论文更多的时候是在讲与主题无关的东西，所以通过分析关键词出现的频率基本就可以判断2）假论文缺乏逻辑，通过上下文无关文法生成的论文虽然没有语法问题，但是词语搭配与正常的论文差距很大，通过分析正常论文的词语逻辑，再与假论文进行比对就可判断。

2.word2vec和lstm
这一点其实是有点失败的，因为本来认为这个方式是确实可行的，但是在实际做的时候遇到了一些问题，最后并没有完全实现。这个思路就是首先利用word2vec将论文处理成词向量，这在开源的tensorflow下还是很好实现的，然后再利用循环神经网络训练。最终通过较多的真论文训练出一个模型，当我们将一个论文放在模型中运行时，模型通过之前训练的结果对下一个词进行预估，然后根据是否相同给出判断，最终输出1（真）或是-1（假）。但是在找lstm模型时还是出了问题，有的是处理的方向不一样，有的是输入不合适，只能说在这方面还是学的没那么好，所以也就止步于词向量了。

3.cnn
既然输入输出会出问题，那么干脆就直接将论文输入，输出结果就行了，所以我使用了cnn网络训练，cnn相较lstm还有一定不足，但是在处理的时候看还是很好的，将每一句输入之后，cnn对每一句话进行训练。在通过了10000次迭代后，基本上就已经收敛了，但是可能由于数据处理的问题，毕竟从pdf转成txt文件还是有较大误差的，中间分词和图像处理还是不尽如人意，导致准确率没能达到1。然后另一个限制就是对于训练集的要求很高，我是用的是一个30真30假的训练集，之后对于一个在训练集中的真假论文准确率有接近96%，但是对于一个新的论文就90%左右，数据集的大小以及处理出来的数据是否规范影响了最终的准确率，如果有更多更好的数据，最后分析的准确率应该会更高。