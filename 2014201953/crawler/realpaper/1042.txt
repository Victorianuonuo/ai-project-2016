Performance Analysis of Online Anticipatory Algorithms

for Large Multistage Stochastic Integer Programs

Luc Mercier and Pascal Van Hentenryck

Brown University

{mercier,pvh}@cs.brown.edu

Abstract

Despite signiﬁcant algorithmic advances in recent
years, ﬁnding optimal policies for large-scale, mul-
tistage stochastic combinatorial optimization prob-
lems remains far beyond the reach of existing meth-
ods. This paper studies a complementary approach,
online anticipatory algorithms, that make decisions
at each step by solving the anticipatory relaxation
for a polynomial number of scenarios. Online an-
ticipatory algorithms have exhibited surprisingly
good results on a variety of applications and this
paper aims at understanding their success. In par-
ticular, the paper derives sufﬁcient conditions under
which online anticipatory algorithms achieve good
expected utility and studies the various types of er-
rors arising in the algorithms including the antic-
ipativity and sampling errors. The sampling error
is shown to be negligible with a logarithmic num-
ber of scenarios. The anticipativity error is harder
to bound and is shown to be low, both theoretically
and experimentally, for the existing applications.

1 Introduction
Online stochastic algorithms for solving large multistage
stochastic integer programs have attracted increasing interest
in recent years. They are motivated by applications in which
different types of requests arrive dynamically, and it is the
role of the algorithm to decide which requests to serve and
how. Unlike traditional online algorithms, these applications
assume that the uncertainty is stochastic and that distributions
of the requests are given.

Consider the packet scheduling problem from [Chang et
al., 2000]. A router receives a set of packets at each time step
and must choose which packet to serve. Packets can be served
only for a limited time and they are characterized by a value.
The goal is to maximize the values of the served packets. The
packet distributions are speciﬁed by Markov models whose
states specify arrival frequencies for the packet type.

Online reservation systems [Benoist et al., 2001] are an-
other such application. Customers place requests in real time
for some service at a ﬁxed date. The resources are modeled by
a multiknapsack constraint. (Think of tour operators request-
ing rooms in hotels for a group: the choice of a speciﬁc hotel

is not pertinent for the group but all group members must be
allocated to the same hotel). Customers must be immediately
notiﬁed of acceptance or rejection of their requests, and ac-
cepted requests must be satisﬁed. Accepted requests must
also be assigned to a speciﬁc resource at reservation time and
this choice cannot be reconsidered. The goal is to maximize
the proﬁt of the served requests which come from different
types with different characteristics and arrival frequencies.

Online multiple vehicle routing with time windows [Bent
and Van Hentenryck, 2003] captures an important class of ap-
plications arising in transportation and distribution systems.
In these problems, a ﬂeet of vehicles serve clients which are
located in many different locations and place request for ser-
vice in real-time in speciﬁc time windows. Clients must be
immediately notiﬁed of acceptance or rejection of their re-
quests, and all accepted requests must be satisﬁed. Routing
decisions however can be delayed if necessary. The goal is to
maximize the number of satisﬁed requests.

All these problems share several characteristics. First, they
can be modeled as multistage integer stochastic programs.
Second, the number of stages is large.
In packet schedul-
ing, time is discrete by nature, and experiments were made
with 200,000 stages. For the two other applications, time
is continuous but a reasonable discretization of time would
require 200 stages. Third, the set of feasible decisions at
each stage is ﬁnite. Finally, these applications require fast
decision-making. These characteristics prohibit the use of a
priori methods for (Partially Observable) Markov Decision
Processes and for Stochastic Programs. Indeed, [Chang et al.,
2000] and [Benoist et al., 2001] have shown that (PO)MDPs
do not scale on these applications. Moreover, successful algo-
rithms for 2-stage stochastic optimization, such as the Sample
Average Approximation method, are shown to require a num-
ber of samples exponential in the number of stages [Shapiro,
2006], precluding their use on these applications.

Interestingly, high-quality solutions to these applications
have been obtained by online algorithms that relax the non-
anticipativity constraints in the stochastic programs. These
online anticipatory algorithms make decisions online at a
time t in three steps:

1. sample the distribution to obtain scenarios of the future;

2. optimize each scenario for each possible decision;

3. select the best decision over all scenarios.

IJCAI-07

1979

It is clear that this strategy is necessarily suboptimal, even
with many scenarios. However, experimental results have
been surprisingly good, especially with the Regret algorithm
[Bent and Van Hentenryck, 2004; Hentenryck et al., 2006]
which is an efﬁcient way of implementing step 2. Our goal
in this paper is to demystify these results by providing a the-
oretical analysis of these algorithms. Section 2 describes the
model and the algorithm. Section 3 analyses the performance
of the online anticipatory algorithm and isolates two funda-
mental sources of error: a sampling error and a quantity called
the global anticipatory gap which is inherent to the problem.
Section 4 shows how to bound the anticipatory gap theoreti-
cally and experimentally. Section 5 analyzes the effect of ap-
proximating the optimization problem. Section 6 compares
the anticipatory gap to the expected value of perfect informa-
tion. Section 7 presents directions for future research.

2 Model and Algorithm
We consider ﬁnite stochastic integer programs of the form

(cid:2)

(cid:2)

(cid:3)(cid:3)

Q = max

x1∈X (s1)

E

max

x2∈X (s2)

E

. . . max

xT ∈X (sT )

f (x, ξ)

,

where ξ is a stochastic process, with ξt being the observation
at time t, (with ξ1 being deterministic), st = (x1..t−1, ξ1..t)
is the state at time t, X maps states to non-empty subsets of
a ﬁnite set X of decisions (so the max’s are well-deﬁned),
and f is the utility function bounded by Fmax. We denote
respectively x and ξ the vectors x1..T and ξ1..T .

A decision process is a stochastic process x such that ∀t :
xt ∈ X (st). We can assume that the computation of each xt
requires exactly one random variable γt. These variables are
independent and independent of ξ.

In practice, decisions cannot be made based on future ob-
servations. A decision process x is non-anticipative if xt
is a deterministic function of γ1..t and ξ1..t (that is, if x is
adapted to the ﬁltration Ft = σ(γ1..t, ξ1..t)). We can rewrite
the stochastic program as

Q = max {E [f (x, ξ)] | x non-anticip. dec. proc.} .

A scenario is a realization of the process ξ. The ofﬂine prob-
lem is the problem a decision maker would face if, in a given
state st, the future observations are revealed; we deﬁne
O(st, xt, ξ) = max {f (y, ξ) | y dec. proc., y1..t = x1..t} ,

O(st, ξ) = max {f (y, ξ) | y dec. proc., y1..t−1 = x1..t−1}

= max

x∈X (st)

O(st, x, ξ).

Note that these two problems are deterministic.

Finally, the expected value of the clairvoyant (EVC ) is de-
ﬁned as the expected utility of a clairvoyant decision maker,
that is, EVC = E [O(s
1 , ξ)]. The problems discussed in the
introduction all ﬁt in this model: in particular, the utility is
bounded thanks to capacity constraints. The model can also
be generalized to the case in which f (x, ξ) has ﬁnite ﬁrst and
second moments for every x.

The anticipatory algorithm studied here is Algorithm
MakeDecision, parametrized by the number of scenarios
m, whose successive decisions form a non-anticipative pro-
cess:

Function MakeDecision(st, γt)
Use γt to compute scenarios ξ1 . . . ξm where ξi
foreach x ∈ X (st) do

(cid:4)

1..t = ξ1..t

g(x) ← 1

m

m

i=1 O(st, x, ξi)

xt ← argmaxx∈X (st) g(x)

3 Analysis of the Anticipatory Algorithm
We compare the performance of the anticipatory algorithm
with the ofﬂine, a posteriori solution in the expected sense, as
is typically done in online algorithms [Borodin and El-Yaniv,
1998]. In other words, for the decision process x produced
by the anticipatory algorithm, we bound EVC − E [f (x , ξ)],
which we call the expected global loss (EGL).

3.1 Local and Global Losses
We ﬁrst show that the EGL is the sum of the expected losses
of the stages.
Deﬁnition 1 Let st be a state. The expected local loss of
decision x ∈ X (st) is deﬁned as

Δ(st, x) = E [O(st, ξ) − O(st, x, ξ) |st ] .

Note that conditioning on a state st does not provide any
information on γt: when reading an expression of the
form E [. . . |st], keep in mind that there is uncertainty on
ξt+1, . . . , ξT and on γt, . . . , γT .
Lemma 1 (Global Loss = Sum of Local Losses) For
decision process x,

any

T(cid:5)

EVC − E [f (x , ξ)] =

E [Δ(s

t , x

t )]

t=1

Proof. Let Ct be the random variable O(st, xt, ξ) and At =
E [Ct − f (x, ξ)]. Then AT = 0 and, for t < T ,

At = E [Ct − Ct+1 + Ct+1 − f (x, ξ)]

= E [Ct − Ct+1] + At+1
= E [Δ(st+1, xt+1)] + At+1.

The last equality comes from decomposing and re-assembling
Finally EVC −
amongst all possible values of xt.
E [f (x , ξ)] = E [C
0 .
0

− f (x , ξ)] = A

2

3.2 Decomposition of the Local Loss
We now show that the local loss at a state st consists of a
sampling error and the anticipatory gap.
Deﬁnition 2 The anticipatory gap of a state st is deﬁned as

Δg(st) = min

x∈X (st)

Δ(st, x).

The choice error of x wrt st is deﬁned as

Δc(st, x) = Δ(st, x) − Δg(st).

The anticipatory gap is inherent to the problem and indepen-
dent of the decision process x. An equivalent deﬁnition is

(cid:2)

max

x∈X (st)

E [O(st, x, ξ)|st] − E

max

x∈X (st)

O(st, x, ξ)

This expression shows that this gap can be interpreted as the
cost of commuting of E and max. We now bound Δc(st, x).

(cid:6)(cid:6)(cid:6)(cid:6)st
(cid:3)

.

IJCAI-07

1980

Lemma 2 (Sampling Error) Let xt be computed by the an-
ticipatory algorithm using m samples per decision. Let st be
a state and x(cid:2) be argmax E [O(st, x, ξ) |st ] (break ties arbi-
trarily). Then

(cid:7)

E [Δc(st, xt) |st ] ≤

Δc(st, x) exp

(cid:8)

,

−mΔc(st, x)2

2σ(st, x)2

(cid:5)

x∈X (st)

where σ(st, x) is the standard deviation of O(st, x, ξ) −
O(st, x(cid:2), ξ) given st.
Proof. Here all probabilities and expectations are implicitly
conditional on st. The left-hand side can be decomposed as

(cid:5)

E [Δc(st, xt)] =

Δc(st, x)P(xt = x).

x∈X (st)

Due to the argmax in MakeDecision, the event xt = x
implies ∀x(cid:3) ∈ X (st), g(x(cid:3)) ≤ g(x). Therefore P (xt = x) ≤
Since f is bounded, O(st, x, ξ) −
P (g(x) ≥ g(x(cid:2))).
O(st, x(cid:2), ξ) has a ﬁnite expectation and variance. Now,

(cid:10)

g(x) − g(x(cid:2)) =

1
m

O(st, x, ξi) − O(st, x(cid:2), ξi)

and, by the central limit theorem, this difference is normally
distributed for m large enough, with mean −Δc(st, x) and
. Finally, if X ∼ N (μ, σ2) with μ < 0,
variance
then P (X ≥ 0) ≤ exp

m σ(st, x)2

(Chernoff bound).

− μ

2

1

2

2σ2

(cid:10)

m(cid:5)

(cid:9)

i=1

(cid:9)

3.3 Performance of the Algorithm
We now assemble the previous results.

Deﬁnition 3 The Global Anticipatory Gap of the problem is

Once again, this quantity is inherent to the problem.

Theorem 1 The expected global loss of the anticipatory al-
gorithm satisﬁes

EGL ≤ GAG + O

e −Km

where m is the number of samples per decision and

K = min

st,x∈X (st)
Δc(st,x)>0

Δc(st, x)2
2σ(st, x)2 .

Proof. We have

T(cid:5)

EGL =

E [Δ(s

t=1

T(cid:5)

The term GAG comes from

(cid:9)
T(cid:5)

t=1

t , x

t )] ≤

(cid:17)

T(cid:5)

g (s

t )] + E [Δ

E [Δ

(cid:18)

(cid:17)

T(cid:5)

(cid:10)

.

t )]

(cid:18)

c(s

t , x

E [Δg(st)] = E

Δg(st)

≤ E

t=1
and the global sampling error satisﬁes

t=1

max
x1..T

t=1

Δg(st)

,

E [Δc(st, xt)] ≤ 2T |X| Fmaxe−Km.

T(cid:5)

t=1

GAG = E

⎡⎣ max

x1..T

xi∈X (si)

T(cid:5)

⎤⎦ .

Δ

g (s

t=1

t )

(cid:15)

(cid:16)

An important consequence of this theorem is that the sam-
pling error can be made smaller than some constant a by
choosing m ≥ 1/K log (2/aT |X| Fmax). [Shapiro, 2006] ar-
gues that the SAA method does not scale to multistage prob-
lems, because the number of samples to achieve a given accu-
racy grows exponentially with T . The anticipatory algorithm
only requires m to grow logarithmically with T |X|, which
makes it highly scalable. Of course, it only produces high-
quality decisions when the anticipatory gap is small.

4 Bounding the Global Anticipatory Gap

This section provides theoretical and experimental results on
the anticipatory gap, explaining why anticipatory algorithms
are effective in the applications mentioned in the introduction.

4.1 Theoretical Proof on Packet Scheduling
We ﬁrst show how to compute an upper bound on GAG for a
simpliﬁed version of the packet scheduling problem. Suppose
that there are k types of packets whose values are v1 < . . . <
vk respectively. At each step from 1 to T − 1, a packet of
type i arrives with probability pi. All these random variables
are independent. Each packet has a lifetime of 2, meaning a
packet received at time t can be scheduled either at time t or
at time t + 1. The utility is the sum of scheduled packets over
the T stages. All packets take a single time step to serve. For
convenience, we introduce a packet type 0 with value v0 = 0
and probability p0 = 1. It should be clear that this problem
satisﬁes all assumptions above.
In particular, the utility is
bounded (0 ≤ f ≤ T vk).

Why is the GAG small on this problem? We show that
Δg is rarely high, inducing a small GAG. For st a state and
x, y ∈ X (st), we say that x dominates y if O(st, x, ξ) ≥
O(st, y, ξ) almost surely given st. Studying Δg(st) only re-
quires to focus on non-dominated decisions: there are at most
two non-dominated decisions for a given state, which consists
of scheduling

• the most valuable packet, of type i, received at time t− 1

and not already scheduled; or

• the most valuable packet, of type j, received at time t.

Moreover, if i ≥ j, then choosing j is dominated, since i is
more valuable and will be lost if not chosen now. Also, if
i < j but the second most valuable packet received at t is of
type k ≥ i, then choosing i is dominated. If one of these two
conditions holds, a decision dominates all the other ones, and
thus Δg(st) = 0.

Suppose now that st does not satisfy any of them. By the
dominance property, scenarios can be partitioned into those
where scheduling i (resp. j) is the unique ofﬂine, optimal de-
cision and those on which there is a tie. Introduce the random
variable yt, taking values i, j or ⊥ in these three respective
cases. We then have
Δ(st, i) = E [O(st, ξ) − O(st, i, ξ) |st ]

= E [O(st, ξ) − O(st, i, ξ) |st, yt = j ] P (yt = j)

and symmetrically
Δ(st, j) = E [O(st, ξ) − O(st, j, ξ) |st ]

2

= E [O(st, ξ) − O(st, j, ξ) |st, yt = i ] P (yt = i) .

IJCAI-07

1981

Now, if i is scheduled and the optimal ofﬂine solution was
to schedule j, then the loss cannot exceed vj − vi, since the
rest of the optimal ofﬂine schedule is still feasible. Hence
E [O(st, ξ) − O(st, i, ξ) |st, yt = j ] ≤ vj − vi. Moreover,
for the optimal ofﬂine schedule to choose j at time t, it is
necessary to have a packet of value greater than vi arriving at
t + 1 and thus P (yt = j) ≤ 1 −
k>i qk where qk = 1 − pk.
Finally, we ﬁnd

(cid:19)
(cid:20)

Δ(st, i) ≤ (vj − vi)

1 −

(cid:22)

(cid:21)

qk

.

k>i

The other case is harder to study, but a trivial upper bound is
Δ(st, j) ≤ vi. Now it remains to bound the expectation of
Δg(st) = min(Δ(st, i), Δ(st, j)) by enumerating the possi-
ble values of i and j and weighting each case with its proba-
bility of occurrence. This weight is, in fact, bounded by the
product of the probabilities of the 3 following events:

• a packet of type i arrived at time t − 1;
• the most valuable packet arrived at t is of type j;
• no packet of type i ≤ k < j arrived at time t.

Here is a numerical example. Suppose there are 4 types of
packets, with the following values and emission probabilities:

type
value
prob

0
0
1.

1
1
.60

2
2
.30

3
4
.20

4
8
.10

The upper bound on Δg depending on i and j, is

(j)

1
2
3
4

.496
1.00
1.00

1

.560
1.68

2

.400

3

4 (i)

We ﬁnd that E [Δg(st)] ≤ .125. On the other hand, a simple
lower bound on the EVC is the expectation of the value of the
most valuable packet arriving at each stage multiplied by the
number of stages. In this case, that leads to EVC ≥ 2 .25T .
As a result, the ratio of GAG over EVC on this problem is
less than 5.55%. Because this analysis is not tight – espe-
cially the lower bound of the EVC –, the anticipatory algo-
rithm is likely to have an even better expected global loss.
This analysis also hints at why online anticipatory algorithms
are so effective on packet scheduling and why they outper-
form competitive algorithms on these instances.

4.2 Discussion on Practical Problems
The previous section shows how to bound the GAG on a par-
ticular problem: study dominance properties between the de-
cisions, bound the loss of making a non-optimal (in the ofﬂine
sense) decision, and bound the probability of this event. We
are currently applying this method on more complex prob-
lems but proofs quickly become very cumbersome. As an
alternative, we discuss another, empirical way to argue that
the GAG of a problem is small.

We have emphasized in the theoretical discussion the
the cho-
We call

importance of bounding the probability that
sen decision is not a posteriori optimal.

P (O(st, xt, ξ) = O(st, ξ) |st ) the consensus rate.
This
quantity can be estimated easily during the computation of
an anticipatory algorithm. It sufﬁces to count how many sce-
narios make the same decision, i.e.,

(cid:6)(cid:6)O(st, x, ξi) = O(st, xt, ξi)

i ∈ {1, . . . , m}

(cid:24)(cid:6)(cid:6) .

(cid:6)(cid:6)(cid:23)

1
m

[Hentenryck et al., 2006] kindly gave us some of these statis-
tics on online reservation systems: they depict the consensus
rate (min/max/avg) as a function of the number of scenarios.

t
n
e
m
e
e
r
g
A
%

 

100

80

60

40

20

0

Max

Average

Min

m  (#Scenarios / decision)

0

25

50

75

100

On this class of instances, there are 6 possible decisions in
each state. Therefore, one could expect an average consen-
sus rate of 20%, but it is actually much higher, at about 80%.
Moreover the maximal ofﬂine loss of a bad decision can eas-
ily be bounded in this problem. By Markov inequality, the
GAG is low. Similar observations were made in the packet
scheduling problem, where the measured average consensus
was about 90%, and in the vehicle routing problem, where the
rate varies among the stages, exhibiting an increasing trend
from 65 to 100%. This argument, however, would be useless
when Fmax is high, e.g. problems with high penalty states.

More generally, the following theorem gives a way to mea-

sure the anticipatory gap of a state.

Theorem 2 Let st be a state. Deﬁne

(cid:22)

max

x∈X (st)

O(st, x, ξi) − max
x∈X (st)

O(st, x, ξi)

,

(cid:20)

m(cid:5)

1
m

i=1

(cid:7)

(cid:25)Δg(st) as
m(cid:5)
(cid:6)(cid:6)(cid:6)(cid:6) st

(cid:8)

i=1

(cid:25)Δg(st) = Δg(st)

then this is a strongly consistent estimator of Δg(st), i.e.,

P

lim

m→+∞

= 1.

Proof. Apply the strong law of large numbers to O(st, x, ξ)
for all x and conclude with the ﬁniteness of X (st).

(cid:25)Δg can be computed by the online anticipatory algorithm at

2

no additional cost.

(cid:26)O. This is the case for the

5 Approximating the Ofﬂine Problem
Theorem 1 explains why the anticipatory algorithm provides
good results when the GAG is small. However, practical im-
plementations use a variant of Algorithm 1 in which O is re-
placed by a fast approximation
three applications mentioned earlier which use an approxi-
mating technique called Regret [Bent and Van Hentenryck,
2004; Hentenryck et al., 2006]. The Regret algorithm can be
seen as a discrete version of sensitivity analysis: instead of
computing O(st, x, ξ) for each for each x ∈ X (st), the idea
is to compute x∗ = argmaxx(O(st, x, ξi)) ﬁrst and then to
compute a vector of approximations

(cid:10)
(cid:9)(cid:26)O(st, x, ξi)

x∈X (st)

IJCAI-07

1982

maxx(O(st, x, ξi)). See [Bent et al., 2005] for a discussion
on the complexity of computing this approximated vector.

using x∗. Each entry in this vector is derived by approx-
imating the loss of selecting a speciﬁc x in X (st) instead
of the optimal decision x∗. As a result, the Regret algo-

rithm ensures (i) (cid:26)O ≤ O and (ii) maxx((cid:26)O(st, x, ξi)) =
thus measured the empirical distribution of O − (cid:26)O on on-
2006]. The difference O − (cid:26)O is zero in 80% of the cases and

It is not easy to provide tight theoretical bounds on the
expected global loss for the Regret approximation. We

line stochastic reservation systems from [Hentenryck et al.,

its mean is very small (around .2 while the typical values of
O are in the range [400,500]), although it can occasionally be
large. This intuitively justiﬁes the quality of Regret, whose
expected global loss is not signiﬁcatively different from the
anticipatory algorithm for the same sample size.

(cid:4)
(cid:4)

m

m
i=1

Finally, recall that, on online reservation systems,

(cid:26)O(st, x(cid:2), ξi) of decision x(cid:2) may only exhibit

the
Let x(cid:2) =
consensus rate is very high on average.
i=1 O(st, x, ξi) and let the consensus rate be
argmaxx
α. By properties (i) and (ii) of Regret, the approximated
“score”
errors in (1 − α)m scenarios and hence will be very close to
i=1 O(st, x(cid:2), ξi). Moreover, other decisions have an ap-
proximated score where (almost all) the terms of the sum has
a negative error. Therefore the approximated decision is bi-
ased toward consensual decisions and a high consensus rate

(cid:4)
tends to hide the approximation errors O − (cid:26)O of Regret.

αm

In summary, a high consensus rate not only makes the AG
small but also allows Regret to produce decisions close in
quality to the exact anticipatory algorithm. This does not
mean that a brutal Regret approximation, e.g., assigning zero
to each non-optimal decision, would be as effective [Bent and
Van Hentenryck, 2004].

6 GAG Versus EVPI
This section studies the relationships between the anticipatory
gap and the expected value of perfect information (EVPI ).
Since these concepts are seemingly close, it is useful to ex-
plain how they differ and why we chose to introduce the no-
tion of anticipatory gap.

Consider the following two maps assigning values to
states: the ofﬂine value and the online value of state st, re-
spectively denoted by φ(st) and π(st) and deﬁned by
φ(st) = max {E [f (x, ξ)|st] | x dec. proc.}
π(st) = max {E [f (x, ξ)|st] | x non-anticip. dec. proc.} .
Note that φ(st) ≥ π(st) for all state st. The difference

η(st) = φ(st) − π(st).

is the (local) expected value of perfect information (EVPI ).
The expected value of perfect information of the problem is
η(s1), that is, the advantage, in the expected sense, of a clair-
voyant over a non-clairvoyant (both with inﬁnite computa-
tional resources). The next lemma relates the ofﬂine problem
and φ and shows that the operators max and E commute for
clairvoyant decision processes.
Lemma 3 For any state st, φ(st) = E [O(st, ξ)|st] .

Figure 1: low EVPI but high Global Anticipatory Gap

Let x(cid:2) be a decision process maximizing
Proof.
E [f (x, ξ)|st]. Then for all ξ, O(st, ξ) ≥ f (x(cid:2), ξ), and, as
E is non-decreasing, E [O(st, ξ)|st] ≥ E [f (x(cid:2), ξ)|st)] =
Inversely, let xξ be a decision process maximizing
φ(st).
f (x, ξ) with xξ
1..t−1 = x1..t−1. Deﬁne x(cid:2) by aggrega-
tion: x(cid:2) does the same thing as xξ on the scenario ξ. Then
φ(st) ≥ E [f (x(cid:2), ξ)|st] = E [O(st, ξ)|st].
2
In two-stage stochastic programming, a low EVPI makes
the problem much easier because an optimal decision is also
a good one for each speciﬁc scenario [Birge and Louveaux,
1997, ch. 4]. However, this is no longer true in the multistage
case. Consider the three-stage problem depicted in Figure 1.
Black dots represent decisions variables x1 and x2. Stochas-
tic variables ξ1 and ξ2 have no inﬂuence and are not repre-
sented. The white dot represents ξ3 which take values 0 and
1 with equal probability. Leaves are tagged with their utilities
and a is large positive number. The value of the EVPI and
the anticipatory gap Δg for each state are the following:

state
Δg
η

root state

0
ε

x1 = 0

1/2(ε + a)
1/2(ε + a)

On this problem, the EVPI is ε: an optimal solution has a
score of ε, whatever the scenario. The expected value of the
optimal policy is zero. However, the online anticipatory algo-
rithm always chooses x1 = 0 and thus has an expected utility
of 1/2(ε − a). Therefore anticipatory algorithms may behave
poorly even with a low EVPI . Moreover, in this case, the
inequality of Theorem 1 is tight when m converges to +∞,
since the GAG equals 1/2(ε + a).

The phenomenon comes from the fact that the EVPI of
the problem is low although the EVPI of the node (x1 = 0)
is ε − 1/2(ε − a) = 1/2(ε + a) and thus much larger. This
does not contradict the super-martingale property of [Demp-
ster, 1998] because Dempster considers optimal decision pro-
cesses, which is not the case of anticipatory algorithms. As
a result, the expected global loss of the anticipatory algo-
rithm cannot be bounded by the root EVPI . The example
may suggest that the maximum of the EVPIs at each node of
the tree gives an upper bound of the EGL, but this is not true
either. Figure 2 presents a stochastic program, where ‘Sub’
are clones of the problem in Figure 1, with variables indices
shifted. On this problem, the optimal solutions to the scenar-
ios have an expected expected utility of ε, and those of the
anticipatory algorithm (with m = ∞) have expected utility
1/4(−3a+ ε); the EGL thus equals 3/4(a+ ε). By Theorem 1,
the GAG is not smaller than the EGL (m = ∞: no sampling
error). As a result, the GAG is greater than the maximum of
the EVPI over all nodes, which is equal to 1/2(ε + a).

IJCAI-07

1983

Figure 2: GAG higher than max of the EVPIs

Finally, the following theorem gives one more reason why

the concept of anticipatory gap is of interest.
Theorem 3 For any state st, we have η(st) ≥ Δg(st) and
there exist cases in which the inequality is strict.
Proof. η(st) = φ(st) − π(st). Recall that π(st) is the op-
timal expected utility of a non-anticipative decision process
given st. Because of non-anticipativity and because X (st) is
ﬁnite, there exists an optimal decision x(cid:2) ∈ X (st) such that
π(st) = E [π(st+1) |st, xt = x(cid:2) ]. Now

max

x∈X (st)

E [O(st, x, ξ) |st ] ≥ E [O(st, x(cid:2), ξ) |st ]

≥ E [π(st+1) |st, xt = x(cid:2) ] .

and thus, using lemma 3,

η(st) ≥ E [O(st, ξ) |st ] − max
x∈X (st)

E [O(st, x, ξ) |st ]

≥ Δg(st).

Indeed, because the estimation of φ(st) obtained by relaxing
non-anticipativity constraints is an upper bound of its online
value π(st) with high probability, a RTDP approach can pro-
duce increasingly tighter approximations of the optimal pol-
icy until decision time. Despite negative complexity results
([Kearns et al., 1999]), we believe that, if the GAG is not too
large, high-quality decisions could be obtained in reasonable
time. Indeed, since the far future is unlikely to be as impor-
tant as the near future for the current decision, we may hope
that small trees will be sufﬁcient for many applications.

Acknowledgments
This research is partly supported by NSF Award DMI-
0600384 and ONR DEPSCOR Award N000140610607.
Thanks to the reviewers for their interesting suggestions.

References
[Barto et al., 1995] A.G. Barto, S.J. Bradtke, and S.P. Singh.
Learning to act using real-time dynamic programming. Ar-
tiﬁcial Intelligence, 72(1):81–138, 1995.

[Benoist et al., 2001] T. Benoist, E. Bourreau, Y. Caseau,
and B. Rottembourg. Towards stochastic constraint pro-
gramming: A study of online multi-choice knapsack with
deadlines. In CP’01, 2001.

[Bent and Van Hentenryck, 2003] R. Bent and P. Van Hen-
tenryck. Dynamic Vehicle Routing with Stochastic re-
quests. IJCAI’03.

This proves the inequality. The second part of the theorem is
proven by the example of Figure 1, on which the root node s1
satisﬁes η(s1) = ε > 0 = Δg(s1).
2

[Bent and Van Hentenryck, 2004] R. Bent and P. Van Hen-
tenryck. Regrets only! online stochastic optimization un-
der time constraints. In AAAI’04, 2004.

7 Conclusion and Research Perspectives
Anticipatory algorithms have been shown experimentally to
be successful in tackling a variety of large multistage stochas-
tic integer programs which were outside the scope of a priori
methods such as (PO)MDPs and multistage stochastic pro-
gramming. This paper studied the performance of anticipa-
tory algorithms in terms of their sampling error and the antic-
ipatory gap of the problems. It showed that, whenever the
anticipatory gap is small, anticipatory algorithms are scal-
able and provide high-quality solutions in the expected sense
with a logarithmic number of samples in the problem size.
The paper also studied how to bound the anticipatory gap
both theoretically and experimentally, showing that a simple
packet scheduling problem admits a small anticipatory gap
and providing experimental evidence on several large multi-
stage stochastic programs. Finally, the paper indicated that
the anticipatory gap is an important concept and studied its
relationships with the expected value of perfect information.
There are many research directions opened by this re-
search. First, It is desirable to to deepen the understanding
of the problem features (both combinatorial and statistical)
which lead to small (or large) anticipatory gaps. Second, it
is also important to study novel anticipatory algorithms for
applications with non-negligible anticipatory gaps. Here an
interesting direction is to borrow ideas from Real-Time Dy-
namic Programming [Barto et al., 1995; Paquet et al., 2005].

[Bent et al., 2005] R. Bent, I. Katriel, and P. Van Henten-

ryck. Sub-Optimality Approximation. In CP’05, 2005.

[Birge and Louveaux, 1997] J.R. Birge and F. Louveaux. In-

troduction to Stochastic Programming. Springer Verlag.

[Borodin and El-Yaniv, 1998] A. Borodin and R. El-Yaniv.
Online Computation and Competitive Analysis. Cam-
bridge University Press, 1998.

[Chang et al., 2000] H. Chang, R. Givan, and E. Chong. On-
line Scheduling Via Sampling. Artiﬁcial Intelligence Plan-
ning and Scheduling (AIPS’00), pages 62–71, 2000.

[Dempster, 1998] M. A. H. Dempster. Sequential importance
sampling algorithms for dynamic stochastic programming.
Annals of Operations Research, 84:153–184, 1998.

[Hentenryck et al., 2006] P. Van Hentenryck, R. Bent, and
In

Y. Vergados. Online stochastic reservation systems.
CPAIOR’06, Springer, 2006.

[Kearns et al., 1999] M. Kearns, Y. Mansour, and A. Ng. A
Sparse Sampling Algorithm for Near-Optimal Planning in
Large Markov Decision Processes. In IJCAI’99, 1999.

[Paquet et al., 2005] S. Paquet, L. Tobin, and B. Chaib-draa.
Real-Time Decision Making for Large POMDPs. In 18th
Canadian Conference on Artiﬁcial Intelligence, 2005.

[Shapiro, 2006] A. Shapiro. On complexity of multistage

stochastic programs. Oper. Res. Lett, 34(1):1–8, 2006.

IJCAI-07

1984

