An Adaptive Context-based Algorithm for Term Weighting

Application to Single-Word Question Answering

Marco Ernandes, Giovanni Angelini, Marco Gori, Leonardo Rigutini, Franco Scarselli

Dipartimento di Ingegneria dell’Informazione

Universit`a di Siena, Siena - Italy

{ernandes,angelini,marco,rigutini,franco}@dii.unisi.it

Abstract

Term weighting systems are of crucial importance
in Information Extraction and Information Re-
trieval applications. Common approaches to term
weighting are based either on statistical or on nat-
ural language analysis. In this paper, we present a
new algorithm that capitalizes from the advantages
of both the strategies by adopting a machine learn-
ing approach. In the proposed method, the weights
are computed by a parametric function, called Con-
text Function, that models the semantic inﬂuence
exercised amongst the terms of the same context.
The Context Function is learned from examples,
allowing the use of statistical and linguistic infor-
mation at the same time. The novel algorithm was
successfully tested on crossword clues, which rep-
resent a case of Single-Word Question Answering.

1 Introduction
Term weighting is an important task in many areas of Infor-
mation Retrieval (IR), including Question Answering (QA),
Information Extraction (IE) and Text Categorization. The
goal of term weighting is to assign to each term w found in a
collection of text documents a speciﬁc score s(w) that mea-
sures the importance, with respect to a certain goal, of the
information represented by the word. For instance, Passage
Retrieval systems weigh the words of a document in order to
discover important portions of text and to discard irrelevant
ones. This is the case of applications as QA, Snippet Extrac-
tion, Keyword Extraction, Automatic Summarization.

Common approaches to term weighting can be roughly di-
vided into two groups: statistical and linguistic techniques.
The methods in the former group are based on a statistical
analysis that extracts, from a document collection, features
as word frequencies or information-theoretical measures.
TFIDF [Salton and McGill, 1986] is a popular statistically-
inspired method currently used in many IR systems to mea-
sure the importance of words. A major assumption in this
approach is that the words of a document can be consid-
ered as unordered and independent elements. Such assump-
tion is shared by many other measures as Information Gain,
Gain Ratio, Best-Match (e.g. BM25) or the Chi-Square func-
tion [Manning and Schtze, 1999]. Even if the literature
presents several interesting adaptations of TFIDF for speciﬁc

problems (e.g. [Debole and Sebastiani, 2003] ), to the best of
our knowledge there has been no attempt to compute TFIDF-
like term weights that make use of relationships among terms.
Latent Semantic Indexing (LSI) [Deerwester et al., 1990]
is a statistical approach that does not suffer from the word-
independence assumption. LSI tries to measure the principal
associative patterns between sets of words and concepts using
the Singular Value Decomposition technique, without taking
into account word order. Unfortunately LSI cannot be em-
ployed in many practical problems. This is the case of QA,
because LSI projects document words into a non-linguistic
space, whereas QA requires answers in natural language.

On the other side, techniques that are more deeply inspired
by natural language theories and applications [Voorhees,
1999], as morphological and syntax analysis, naturally ex-
ploit the information provided by word contexts. But their
design is very difﬁcult and require a large human effort.

In this paper, we present a novel algorithm for term weight-
ing that aims to combine the advantages of both statistical
and linguistic strategies by adopting a machine learning ap-
proach. Our method exploits the relationships (i.e. order,
distance, etc.) among the words of a document in order to
evaluate their semantic relevance to a given question. The
intuition behind the proposed model is that the relevance of
a term can be computed recursively as the combination of
its intrinsic relevance and the relevance of the terms that ap-
pear within the same context. The inﬂuence exercised by a
word on another one is computed using a parametric func-
tion, called Context Function. This function is trained by
examples, thus it is well suited for using together statistical
(e.g. term frequency) and linguistic information (morpholog-
ical, syntactical, lexical), requiring no pre-designed rules.

The main idea underlining the proposed approach is tightly
related to the TextRank algorithm [Mihalcea and Tarau, 2004]
that has been succesfully applied to keyword extraction and
text summarization. More precisely, the context-based algo-
rithm extends TextRank, by allowing a more general mod-
elling of the word relationships and by providing a learning
algorithm to deﬁne the strength of those relationships.

The Context-based algorithm has been evaluated on a spe-
ciﬁc problem, i.e. Single-Word Question Answering, where
the goal is to ﬁnd the single correct word that answers a given
question. Single-Word QA is particularly suited to evaluate a
term weighting algorithm, since it directly exploits the rank

IJCAI-07

2748

produced by the weights. The proposed method has been ap-
plied to improve the performances of a particular answering
system (WebCrow [Ernandes et al., 2005]), designed to ad-
dress crossword clues. The results show that the approach is
viable for the Single-Word QA problem and suggest that it
could be extended to other ﬁelds of Text Processing.

Section 2 describes the Context-based term weighting al-
gorithm. Section 3 presents the experimental environment
used to evaluate the proposed method. In Section 4 we report
the experimental results obtained by the system in the Single-
Word QA problem. Section 5 provides our conclusions.

2 Context-based term weighting
The proposed method exploits the contexts of words. A word
context primarily consists of the text surrounding a given
word, but could also include other features, as document ti-
tles, hyper-linked documents, and so on. The idea is that, in
order to measure the relevance of a word with respect to a
certain goal (e.g. a query, a document category), the features
of the context in which the term appears are important as well
as the features of the word itself. Roughly speaking, a word
is important not just when this is statistically strong, but also
when the words that belong to its context are important too.

This recursive deﬁnition recalls that of social net-
works [Seeley, 1949], where the status of a person depends
on the status of the persons that are somehow related to it.
We assume that a text document can be represented by a so-
cial network, where the importance of the words can be com-
puted on the basis of its neighbors. More precisely, the weight
s(w) of the word w is computed as

(cid:2)

s(w) = (1 − λ)dw + λ

s(u)cw,u ,

(1)

u∈r(w)

where dw is the default score of w, r(w) is the set of words
that belong to the context of w, cw,u is a real number mea-
suring the inﬂuence exercised by u over w, and λ ∈ [0, 1] is
a damping factor. Thus, the score of a word will result from
(cid:3)
the combination of the default score dw and its context score

u∈r(w) s(u)cw,u.
The real numbers dw and cw,u can be calculated using in-
formation about the occurrences and the context of the words
(the frequency and the linguistic role of a word, the distance
between two words, and so on). The functions used to com-
pute these values can be either predeﬁned or learned by exam-
ples in a machine learning fashion. In our work, we assume
that dw is given by an initial scoring system (e.g. TFIDF).
We then learn a parametric function for calculating the cw,u
whose goal is to improve the initial values.

Since the dw can be provided by external informative
sources, the algorithm is well suited to exploit the weights
produced by other algorithms in order to improve their per-
formances. It is worth to notice that both dw and cw,u can be
computed exploiting statistical and linguistic features. From
this point of view our method represents a mechanism to in-
tegrate both kinds of information.

In order to implement the proposed approach, the follow-
ing problems have to be addressed: how to deﬁne a Context
Function that computes the cw,u values, how to compute the
term weights s(w) using Eq.(1), how to automatically learn

the Context Function from a set of examples and how to eval-
uate the performances of the system. These issues will be
considered in the following sub–sections.

2.1 Context Functions

A document set contains multiple instances of words and each
instance (a word-occurrence) is affected by a different con-
text. Therefore, we distinguish between words (that we shall
represent with w) and word occurrences (represented with a
hat, ˆw). Here we assume that cw,u can be computed as the
sum of the contributions of all the occurrences of w and u

(cid:2)

(cid:2)

cw,u =

Cp( ˆw, ˆu).

(2)

ˆw∈occ(w)

ˆu∈ict( ˆw,u)

(cid:4)

Here, occ(w) is the set of instances of word w, and ict( ˆw, u)
is the set of the occurrences of u that belong to the context
of ˆw, i.e. ict( ˆw, u) = occ(u)
ctxt( ˆw), where ctxt( ˆw) is
the context of ˆw. Moreover, given a set of parameters p,
Cp( ˆw, ˆu) is the parametric Context Function that establishes
the strength of the inﬂuence between the instances ˆw (the
word under evaluation) and ˆu (the context word). In our work
this function is learned by examples1.

The context of a word occurrence ˆw can be deﬁned as the
set of words that are contained in the same document and
within the surround of ˆw with dimensions kL + kR (left mar-
gin and right margin). Thus, if “ . . . ˆu−kl −1 ˆu−kl
. . . ˆu−1 ˆw ˆu1
ˆukr +1 . . .(cid:2)(cid:2) is a text passage of any document, then
. . . ˆukr
ctxt( ˆw) = {ˆu−kl
} holds. In this formula-
tion we introduce the strong assumption that direct semantic
relations between words can be registered only within their
surrounds. This assumption is plausible and widely adopted
(e.g. snippets in search engines). On the other hand, the ap-
proach is easily extended to the cases when the context in-
cludes other features as the document title, the section title,
the text of the anchors pointing to the document, and so on.

, ..., ˆu−1, ˆu1, ..., ˆu+kr

The most delicate point of the system is the deﬁnition of
the function Cp( ˆw, ˆu). This establishes how word couples
can inﬂuence one another on the basis of features extracted
from the words and from the relationships between words.
Theoretically, the inﬂuence function can exploit any sort of
information related to ˆw and ˆu: information-theoretical (e.g.
in text categorization: information gain, gain ratio), morpho-
logical (i.e. part-of-speech classes of w and u), syntactical
(i.e. syntax role of w and u) or lexical (e.g. WordNet dis-
tance between w and u). The features that have been used
in our preliminary experiments are exclusively statistical (see
Tab. 1). Interestingly, even with this reduced list of basic fea-
tures, the system displays notable performances.

Moreover, how do we merge all this information into one
single output? The most general approach consists of imple-
menting Cp( ˆw, ˆu) by a modeling tool that has the universal
approximation property, i.e. it allows to realize any function
with any desired degree of precision. These tools include neu-
ral networks, polynomials, and rationales. While we plan to

1The novelty of our approach with respect to TextRank [Mihal-
cea and Tarau, 2004] consists of the introduction of the context func-
tion and the learning algorithm. In fact, TextRank uses an equation
similar to (1) to deﬁne the word scores, but the inﬂuence factors cw,u
are predeﬁned values computed using word co-occurrences.

IJCAI-07

2749

use neural networks in the future, for the introductory scope
of this paper we preferred to exploit a simpler approach both
for the implementation of Cp( ˆw, ˆu) and for the learning algo-
rithm. Such a simpliﬁcation allows to evaluate the proposed
method on the term weighting problem, avoiding that the re-
sults are altered by the complexity of the system.

We deﬁned the inﬂuence function as

i=n(cid:5)

Cp( ˆw, ˆu) =

σ(αixi + βi) ,

(3)

i=0

the αi, βi

is the value associated with the i-th fea-
where xi
are the model parameters, p =
ture,
[α1, . . . , αn, β1, . . . , βn], and σ is the logistic sigmoid func-
tion σ(x) = 1/(1 + e−x). Notice that the logistic sigmoid
is a monotone increasing function that approaches 0, when
x → −∞, and approaches 1, when x → ∞. Thus, each
term σ(αixi + βi) of Eq. (3) is a sort of soft switch related
to the i-th feature and controlled by the parameters αi and βi.
When αi > 0, the switch is “ON” (i.e. close to 1), if xi is
large and positive and it is “OFF” (i.e. close to 0), if xi is
large and negative. More precisely, the parameter αi controls
the steepness and the direction of the soft switch, while βi
controls the point where the switch assumes a medium value
1/2. Finally, the whole function Cp( ˆw, ˆu) can be described
as a simple boolean AND operation which is “ON” only if all
the switches are “ON”.

](cid:3)

S = (1 − λ)D + λCS ,

2.2 Computing and Learning Context Weights
For a correct deﬁnition of the weights, System (1) must have
a unique solution. Stacking all the variables, Eq. (1) can be
written as

(4)
where {w1, ..., wn} is the set the words of the dictionary,
S = [s(w1), ..., s(wn)](cid:3)
is the vector of the weights, D =
, and C = {cw,u} is a square matrix contain-
[dw1
ing the word inﬂuence factors cw,u.

, ..., dwn

It can be easily proved that, provided (cid:5)λC(cid:5) < 1 holds for
any matrix norm (cid:5) · (cid:5), Eq. (4) has a unique solution which can
be computed iterating the system2 St+1 = (1 − λ)D+ λCSt
,
i.e. S = limt→∞ St for any initial S0.
In practice, the
computation can be stopped when the difference between the
scores at iteration t + 1 and iteration t are below a speciﬁed
small value : ||St+1 − St|| < . The method is called Ja-
cobi algorithm [Golub and Loan, 1996] for the solution of
linear systems. It is worth to mention that this technique is
extremely efﬁcient and can be applied even on sparse matri-
ces containing billions of variables [Page et al., 1998].

The learning procedure can be implemented by any op-
timization algorithm that minimizes an error function ep,
where p = [p1, . . . , pn] denotes the set of parameters of the
Context Function Cp( ˆw, ˆu). The function ep measures the
performance of the weighting system on a given dataset and
it will be discussed in details in the following section. In our
method the training algorithm repeats the following two steps
for a predeﬁned number of times:

(cid:3)t−1

1. compute the gradient

δep
δp of the error function with re-

spect to the parameters;

2. adapt the parameters p by resilient method [Riedmiller

and Braun, 1993].

The resilient parameter adaptation is a technique that allows
to update the parameters using the signs of the partial deriva-
tives of the error function. It has been experimentally proved
that resilient is often more efﬁcient than common gradient
descent strategies [Riedmiller and Braun, 1993].

δep
δpi

The gradient is approximated by a simple brute force al-
is given by
gorithm. Each component of the gradient
the corresponding incremental ratio, which requires to calcu-
late the error function for n + 1 times at each training epoch.
It is worth to mention that the proposed learning algorithm
is a simpliﬁed version of the one described in [Gori et al.,
2005]. The latter procedure can be used efﬁciently even for
models having a large number of parameters. Such a fact is
important, since it guarantees that our implementation of the
context function Cp( ˆw, ˆu) can be efﬁciently replaced by more
complex and general models as, e.g. neural networks.

In our implementation we decided to learn, along with the
set of parameters p, the damping factor λ (see Eq. (4)), which,
intuitively, establishes the level of conﬁdence attributed by
the system to the information extracted from the context.
With this incorporation, a couple of improvements are ex-
pected. Firstly, the experiments that would be required to
establish the best λ are avoided. Secondly, the new weights
S are guaranteed not to be outperformed by the default scor-
ing value D. In fact, if the Context Function turns out to be
deleterious for term ranking, λ can be set to 0 and hence the
weighting system replicates the ranking performances of D.
During the experiments this case has not been observed.

2.3 Evaluating term weighting performances
The criterion to evaluate a term weighting system depends
on the speciﬁc task that is addressed by the application. In
QA-like problems, as the one proposed in this paper, the
performance of the system depends on the position that the
correct answer assumes in the candidate answer list. Two
positional and cumulative measures can be used for QA
evaluation:
the Mean Reciprocal Rank of correct answers
(MRR), which is a standard evaluation measure in the QA
community, and the Success Rate (SR) at N, in which we
annotate the probability of ﬁnding a correct answer within
the ﬁrst N candidates. Formally, given a set of questions
Q = {quest(1), ..., quest(q), ..., quest(n)} and denoted by
pos(aq) the position of the correct answer aq
for question
quest(q), we have

MRR(Q) =

q=n(cid:2)

1

1
n

SR(Q, N ) =

1
n

pos(aq)

Θ(N − pos(aq)) ,

q=1

q=n(cid:2)

q=1

(5)

(6)

2In fact, St = (1−λ)

λkCkD+λtCtS0 holds by simple
algebra. Thus, by power series convergence theorems, if (cid:2)λC(cid:2) < 1
is fulﬁlled, then limt→∞ St = (1 − λ)(I − λC)−1D, which is the
solution of Eq. (4), where I is the identity matrix.

k=0

where Θ is Heaviside function deﬁned by Θ(x) = 1, if x ≥ 0,
and Θ(x) = 0, otherwise.

The above performance measures can be used both for
evaluating the weighting system and for implementing the

IJCAI-07

2750

learning procedure. A drawback of using positional mea-
sures is that they are discrete functions and thus non differ-
entiable. In fact the values of MRR and SR change abruptly
when the positions of two words are exchanged. A possi-
ble approach could be to adopt a learning scheme robust to
discrete environments, e.g. simulated annealing or genetic al-
gorithms. However, a major problem of these algorithms is
their stochastic nature that makes the convergence very slow.
In order to adopt a differentiable error function, we deﬁned
a differentiable function sof t pos that replaces the concept
of position pos

(cid:2)

sof t pos(a) =

σ (γ(s(w) − s(a))) ,

(7)

w∈W, w(cid:6)=a

where W is the set of words considered by the weighting al-
gorithm, a is the word whose position value has to be calcu-
lated, and γ is a predeﬁned parameter. Moreover, σ is a sig-
moid function, i.e. a monotone increasing differentiable func-
tion such that limx→∞ σ(x) = 1 and limx→−∞ σ(x) = 0.

Each term contained in the sum of Eq. (7) compares the
score of word a with the score of another word w. If γs(w)
is very larger than γs(a), then the term assumes a value close
to 1, and, in the converse case when γs(w) is very smaller
than γs(a), the term approaches 0. Thus, for large γ, each
terms approaches a Heaviside function and sof t pos(a) ap-
proximates pos(a).

Based on Eq. (5) and (7) we deﬁned a differentiable evalu-

ation function which approximates MRR:

sof tMRR(Q)=

1
|Q|

q=Q(cid:2)

1/

i=|w|(cid:2)

q=0

i=0

σ (γ(s(wi) − s(wa)))

(8)
Once the system is trained using this soft function, the evalu-
ations can be done using the standard MRR (or SR).

3 Experimental Setup

3.1 The Single-Word QA problem

The problem on which the proposed approach was applied
is a special case of Question Answering.
In Single-Word
QA each question has to be answered with a single correct
word, given a number of documents related to the question.
Since the target answer is a unique correct word the perfor-
mance evaluations, unlike standard QA, do not require any
human refereeing. To the best of our knowledge no standard
dataset is available for the task of Single-Word QA, but a very
popular and challenging example is provided by crosswords.
Since crossword clues are intrinsically ambiguous and open-
domain, they represent an very challenging reference point.
It is worth mentioning that Single-Word QA was used as a
testbed since it is particularly suited to evaluate term weight-
ing. Actually, the answers of the QA system are directly de-
pendent on the ranking produced by term weights.

The aim of our experiments is to show that the Context-
based algorithm improves the ranking quality of the candidate
answers provided by WebCrow [Ernandes et al., 2005]. Web-
Crow is a Web-based QA system designed to tackle cross-
word clues for crossword cracking. At the core of this system
there is a web search module, which, given a clue, retrieves

Name
FS-A
FS-B
FS-B*

Feature Set
idf (w), idf (u), dist( ˆw, ˆu)
idf (w), idf (u), dist( ˆw, ˆu), dist(ˆu, Q)
idf (w), idf (u), dist( ˆw, ˆu), dist(ˆu, Q), sw-list

Table 1: The set of features inserted in the Context Functions used
for the experiments. dist( ˆw, ˆu) is the number of separating words
between occurrence ˆw and ˆu. dist(ˆu, Q) is the number of separating
words between ˆu and the closest occurrences of the words of query
Q. sw-list indicates that a stopword list is used in order to avoid the
presence of stopwords within the context window.

useful documents using a search engine (currently Google)
and extracts the candidate answers. These words are then
ranked using statistical and morphological information.

In the experiments we extended WebCrow with the addi-
tion of the the Context-based algorithm. The results show
that the ranking of the correct answers is improved.

Our dataset consisted of 525 Italian crossword clues3 ran-
domly extracted from the archive in [Ernandes et al., 2005].
The dataset has been divided into two subsets. On one side,
NE-questions (165 examples), whose answers are exclusively
factoid Named Entities, e.g. ≺Real-life comic played in
ﬁlm by Dustin Hoffman: lennybruce(cid:8). On the other side,
nonNE-questions (360 examples), whose answers are non-
Named Entities (common nouns, adjectives, verbs, and so on,
e.g. ≺Twenty four hours ago: yesterday(cid:8)).

3.2 Weighting techniques under comparison

In order to assess the effectiveness of the Context-based al-
gorithm we compared its ranking performances with three
different weighting techniques. The ﬁrst is TFIDF, which
gives a statistical evaluation of the importance of a word
to a document. The other two techniques, WebCrow-S and
WebCrow-SM, represent two ranking methods adopted by
WebCrow. WebCrow-S exploits only statistical information
of the words, the documents and the queries. This weighting
scheme is a modiﬁed version of the one presented in [Kwok
et al., 2001]. WebCrow-SM additionally uses a morpholog-
ical analysis of the documents joined with a morphological
Answer Type classiﬁcation of the clues. For all the details
about WebCrow, see [Ernandes et al., 2005].

4 Experimental Results

Train Set and Test Set. The two subsets (NE and nonNE-
questions) were randomly divided into a train set and a test
set, containing 40% and 60% of the examples respectively.
The experiments were repeated 3 times for each conﬁgura-
tion. Each example of the data set contained:
i) a ques-
tion/answer couple; ii) a set of H documents retrieved by
Google (the documents are selected in Google’s order); iii)
the vector of ranked terms W (the candidate answer list) ex-
tracted from the H documents. In our experiments W con-
tains words of any length.

Features. Several Context Functions were trained, each one
with a different set of features. Table 1 presents the list of
feature combinations adopted in the experiments. To fairly

3The dataset is available on http://webcrow.dii.unisi.it.

IJCAI-07

2751

0.36

0.34

0.32

R
R
M

0.3

0.28

0.26
0

Learning Curves (MRR)

WebCrow−S + context | Train−Set
WebCrow−S + context | Test−Set
Baseline (WebCrow−S) | Train−Set
Baseline (WebCrow−S) | Test−Set

50

EPOCHS

100

150

1

0.8

0.6

0.4

0.2

e

t

a
R
 
s
s
e
c
c
u
S

0
0

10

20

Success Rate at N

TF−IDF
TF−IDF+context
WebCrow−S
WebCrow−S + context
WebCrow−SM + context

40

30
70
N (max lookdown position)

50

60

80

90

100

Figure 1: Learning curve of the Context Function on the NE-
question problem with sof tMRR and the FS-B feature conﬁgu-
ration. WebCrow-S is outperformed after 34 epochs. After 60/70
epochs no sensible improvement can be observed.

Figure 2: Success Rate at N for the NE-questions test set. The
curves depict the probability (X-axis) of ﬁnding the correct an-
swer to a question within the ﬁrst N candidate answers (Y-axis).
For clarity, the curve of WebCrow-SM is not reported.

Default TW
TFIDF
TFIDF + context
WebCrow-S
WebCrow-S + context
WebCrow-S + context
WebCrow-SM
WebCrow-SM + context

Feature Set

FS-A

FS-B
FS-B*

FS-B*

NE
0.216
0.233
0.290
0.346
0.355
0.293
0.345

nonNE
0.071
-
-
-
-
0.104
0.121

Table 2: MRR performance.The results of the three baseline algo-
rithms are given in bold. Column Default TW denotes the algorithm
used for the default term weights dw, Feature Set speciﬁes the Fea-
ture Set of the Context Function. The last two columns contain the
MRR values obtained by the system on the two subsets of the testset.
“context” indicates that the context weighting algorithm is used.

compare the Context-based weighting with the other tech-
niques the features were restricted to those effectively used by
each algorithm under comparison. For example, to reweight
TFIDF scores we adopted a feature set, called FS-A (Tab. 1,
ﬁrst row), that exploits no information about the question. In
this work no morphological information was integrated in the
Context Functions. Nevertheless, these were able to improve
also WebCrow-SM’s performances, which adopts morpho-
logical analysis. For simplicity we chose 20 as a ﬁx dimen-
sion for the context window, with kL = 10 and kR = 10.

Initialization and stop policy. The parameters of the Con-
text Functions were initialized with small random weights,
with the only exception of λ, that was initialized to 0.5. Each
training session was stopped after 75 epochs. This stop policy
was suggested by a prior observation of the variation curves
over both the learning set and the test set (see Fig. 1). The
resilient learning scheme guaranteed a fast convergence, re-
quiring less than 60/70 epochs to reach good local minima.

fault scores provided by WebCrow-S, produced a 22.3% in-
crement of the MRR (from 0.29 to 0.355, row 5).

An insightful resume of the performance improvements
is provided by the Success Rate curve (Fig. 2), that shows
the probability of ﬁnding the correct answer within the ﬁrst
N words of W. Each weighting scheme under compar-
ison appears consistently below the curve of its Context-
In particular, with N = 50, the ob-
based reweighting.
served success rate was: TFIDF, 60.4%; TFIDF+context,
63.4%; WebCrow-S, 66.7%; WebCrow-S+context, 79.3%;
WebCrow-SM, 75%; WebCrow-SM+context, 83.3%.

EXP 2: Answering nonNE-questions. Since the nonNE-
questions represent a more difﬁcult task, all the Context Func-
tions were trained and tested with a higher number of doc-
uments, H = 10. The improvement (Tab. 2) of the rank-
ing quality provided by the Context-based algorithm was less
evident than on the NE subset, but still clear. This phe-
nomenon depends on the different nature of these questions,
which make improbable a strong increment of the MRR using
exclusively statistical features, as revealed by the poor perfor-
mance of the TFIDF measure (ﬁrst row). The reweighting of
the term scores provided by WebCrow-SM lead to a 16.3%
increment of the MRR (from 0.104 to 0.121, row 6 and 7).
EXP 3: Varying the number of the Web documents (H).
An interesting feature to evaluate is the ability of the Context
Function to work with a number of documents that differs
from that used in the learning phase. For this reason we tested
the ranking quality of the Context Functions trained over the
NE subset, with dw given by WebCrow-SM (last two rows
of Table 2), varying H. The Context-based algorithm proved
to be robust to the changes of H, constantly outperforming
WebCrow-SM (Fig. 3). With H = 20, the addition of the
context increased the MRR by 15% (from 0.355 to 0.408).

EXP 1: Answering NE-questions. For the NE-questions
problem the Context Functions were trained and tested using
H = 5 as the number of documents used for extracting the
word candidates. The results are presented in Table 2, which
shows the performances in terms of MRR. The ranking per-
formances of the compared methods are given in bold at row
1 (TFIDF), 3 (WebCrow-S) and 6 (WebCrow-SM).

The Context-based algorithm outperformed the compared
weighting methods. In particular, the reweighting of the de-

An example. An example can help to better illustrate these
promising results. WebCrow-SM answered the question:
≺La paura nella folla: panico(cid:8) ( ≺Fear among the crowd:
panic(cid:8)), with the correct answer in 16-th position. With the
addition of the Context-based weighting, panic jumped to 2-
nd position, and other related words appeared among the ﬁrst
20 candidates, as: collective, multitude, emergency
and irrational. A passage extracted from one of the docu-
ments may explain why the context information can result ef-

IJCAI-07

2752

MRR varying the Number of Documents

Convergence of the algorithm

R
R
M

0.5

0.45

0.4

0.35

0.3

0.25

0.2

MRR − WebCrow−SM

MRR − WebCrow−SM + context

1

3

5
15
Number of Documents (H)

10

20

Figure 3: The MRR performance of the Context-based algorithm
over NE-questions, in comparison with WebCrow-SM, varying the
number of docs used in the test set.

fective: “...the panic is an irrational behavior
of the crowd ...”. It is clear that the words panic and
irrational can be strongly reinforced by the contextual
presence of other relevant words, like behavior and crowd.

4.1 Computational Cost

The main drawback of the Context-based weighting method
is due to the additional time cost introduced by the learning
step, that is linear in the number of examples and in the num-
ber of iterations required for learning convergence. Neverthe-
less the training of the Context Functions can be successfully
obtained with a small set of examples, as proved in the pre-
vious paragraphs, noticing that the dimension of the training
set is independent with respect to the test set. The latter could
be several order of magnitudes larger without requiring an in-
crement of the learning set.

Leaving aside the learning phase and the initialization of
the data used by the Context Function (i.e. word distances,
idf, etc.), the theoretical computational requirement of the
Context-based weighting algorithm is O(| ˆW|×(kl+kr)×T ),
where | ˆW| is the total number of word occurrences in the
document set, (kl + kr) provides the dimension of the context
window and T is the number of iterations that are required by
the system to converge.
In theory, the convergence of the
Jacobian algorithm (Sec. 2.2) is exponential. We experimen-
tally observed (Fig. 4) that the system converges in a small
number of iterations, often requiring less than four steps to
reach a maximum weight modiﬁcation (cid:5)St − St−1(cid:5)∞ infe-
rior to 10−5

. Thus, T does not introduce a great overhead.

5 Conclusions and Further work
In this paper we have proposed a novel term weighting
method that exploits the information provided by the contexts
in which the terms are found. We have deﬁned a parametric
function, called Context Function, that models the inﬂuence
exercised by a word on another one that participates in the
same context. Furthermore, we have presented a learning en-
vironment that allows us to adapt the parameters of the Con-
text Function to the training data. The approach has been
proved to be effective on the problem of Single-Word Ques-
tion Answering, improving the answer-ranking performances
of three different term weighting schemes. Future matter of
research includes the application of the Context-based term
weighting to other ﬁelds, as Document Classiﬁcation and In-
formation Extraction and the use of more complex implemen-
tation of the context functions.

1.0E−2

1.0E−4

1.0E−6

1.0E−8

1.0E−10

1.0E−12

||St−St−1||1

||St−St−1||∞

0

5

10

Number of Iterations

15

20

Figure 4: The convergence of the algorithm, a straight line on a
log scale, is exponential. We report both 1-norm and ∞-norm of the
score difference, between two subsequent iterations.

References
[Debole and Sebastiani, 2003] F. Debole and F. Sebastiani.
Supervised term weighting for automated text categoriza-
tion. In Proc. of SAC ’03, Melbourne, USA, 2003.

[Deerwester et al., 1990] S. C. Deerwester, S. T. Dumais,
T. K. Landauer, G. W. Furnas, and R. A. Harshman. Index-
ing by latent semantic analysis. Journal of the American
Society of Information Science, 41(6):391–407, 1990.

[Ernandes et al., 2005] M. Ernandes, G. Angelini,

and
M. Gori. Webcrow: A web-based system for crossword
solving. In Proc. of AAAI ’05, Pittsburgh, USA, 2005.

[Golub and Loan, 1996] G. H. Golub and C. F. Van Loan.
Matrix computations (3nd ed.). Johns Hopkins University
Press, Baltimore, MD, USA, 1996.

[Gori et al., 2005] M. Gori, G. Monfardini, and F. Scarselli.
A new model for learning in graph domains. In Proc. of
IJCNN ’05, Montreal, Canada, 2005.

[Kwok et al., 2001] C. Kwok, O. Etzioni, and D. S. Weld.
Scaling question answering to the web. ACM Trans. Inf.
Syst., 19(3):242–262, 2001.

[Manning and Schtze, 1999] C. D. Manning and H. Schtze.
Foundations of statistical natural language processing.
MIT Press, Cambridge, USA, 1999.

[Mihalcea and Tarau, 2004] R. Mihalcea, and P. Tarau. Text-
Rank: Bringing Order into Texts. In Proc. of EMNLP ’04,
Barcelona, Spain, July 2004.

[Page et al., 1998] L. Page, S. Brin, R. Motwani, and T.
Winograd. The pagerank citation ranking: Bringing order
to the web. In Proc. of ASIS ’98, Pittsburgh, USA, 1998.

[Riedmiller and Braun, 1993] M. Riedmiller and H. Braun.
A direct adaptive method for faster backpropagation learn-
ing: The RPROP algorithm. In Proc. of ICNN ’93, San
Francisco, USA, 1993.

[Salton and McGill, 1986] G. Salton and M. J. McGill. In-
troduction to Modern Information Retrieval. McGraw-
Hill, Inc., New York, NY, USA, 1986.

[Seeley, 1949] J. R. Seeley. The net of reciprocal inﬂuence.

Canadian Journal of Psychology, 3(4):234–240, 1949.

[Voorhees, 1999] E. Voorhees. Natural language processing
and information retrieval. In Proc. of SCIE ’99, Frascati,
Italy, 1999.

IJCAI-07

2753

