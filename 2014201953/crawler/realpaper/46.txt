Optimal Refutations for Constraint Satisfaction Problems

Tudor Hulubei and Barry O’Sullivan
Cork Constraint Computation Centre

Department of Computer Science, University College Cork, Ireland

tudor@hulubei.net, b.osullivan@cs.ucc.ie

Abstract

Variable ordering heuristics have long been an im-
portant component of constraint satisfaction search
algorithms. In this paper we study the behaviour of
standard variable ordering heuristics when search-
ing an insoluble (sub)problem. We employ the
notion of an optimal refutation of an insoluble
(sub)problem and describe an algorithm for ob-
taining it. We propose a novel approach to empir-
ically looking at problem hardness and typical-case
complexity by comparing optimal refutations with
those generated by standard search heuristics. It is
clear from our analysis that the standard variable
orderings used to solve CSPs behave very differ-
ently on real-world problems than on random prob-
lems of comparable size. Our work introduces a po-
tentially useful tool for analysing the causes of the
heavy-tailed phenomenon observed in the runtime
distributions of backtrack search procedures.

1 Introduction
The conventional wisdom in systematic backtrack search
is that a variable ordering heuristic should be chosen so
that if a bad assignment is made, and search enters an
insoluble (sub)tree, the heuristic will prefer variables that
have a high likelihood of proving quickly that
the cur-
rent (sub)tree is indeed unproductive. This property of
a variable ordering heuristic is often referred to as fail-
ﬁrstness [Haralick and Elliott, 1980]. Fail-(cid:2)rstness can be
seen as an explanation for why particular variable order-
ing heuristics are better than others for solving CSPs, and it
has received considerable attention from the research com-
munity [Smith and Grant, 1998; Beck et al., 2004]. Various
ways of explaining the quality of variable ordering heuris-
tics in terms of fail-(cid:2)rstness have been proposed. Some au-
thors argue that heuristics that minimise branching depth are
best [Haralick and Elliott, 1980], while others argue that such
a policy can cause an increase in branching factor which
can have the effect of increasing the size of the resultant
(sub)tree [Smith and Grant, 1998].

A search algorithm enters an insoluble search tree either
because the problem itself is insoluble, or because the current
partial solution has just been extended with an assignment

that cannot lead to a complete solution. In either case, the
ideal is that insolubility can be proven with the least amount
of effort. In this paper we will measure such effort by the
number of nodes visited to prove that an insoluble (sub)tree
has no solution. We can evaluate variable ordering heuristics
by comparing the number of nodes that they visit to prove the
insolubility of a (sub)problem with the minimum number of
nodes required to draw the same conclusion.

By comparing optimal refutations with those generated by
MAC [Sabin and Freuder, 1994], when combined with vari-
ous standard variable ordering heuristics, we show empiri-
cally that there is a signi(cid:2)cant difference between the perfor-
mance of heuristics on typical random problems and those
found in the real world. We also suggest that small-to-
medium sized random binary CSPs are of limited value when
studying and developing variable ordering heuristics. While
this has been the intuition amongst constraints researchers,
our analysis shows empirically that this is indeed the case and
gains insights into the nature of the difference in behaviour
between random and real-world problems. Finally, we discuss
how our results may provide further insights into the causes
of the heavy-tailed phenomenon observed in the runtime dis-
tributions of backtrack search procedures. For example, by
focusing on the distributions of actual and optimal refutations
we can study whether heavy-tailedness is present because of
the variable ordering heuristic, the value ordering heuristic, or
is more fundamentally related to the structure of the problem.

2 Preliminaries
Deﬁnition 1 (Constraint Satisfaction Problem). We deﬁne
a CSP as a 3-tuple P ^= hV; D; Ci where V is a ﬁnite set of
n variables V ^= fV1; : : : ; Vng, D is a set of ﬁnite domains
D ^= fD(V1); : : : ; D(Vn)g such that D(Vi) is the ﬁnite set of
possible values for Vi, and C is a ﬁnite set of constraints such
that each Cij 2 C is a subset of D(Vi) (cid:2) D(Vj) specifying
the combinations of values allowed between Vi and Vj, where
i < j. We say that P is arc-consistent (AC) if 8vk 2 D(Vi)
and 8j such that Cij 2 C, 9vl 2 D(Vj ) with (vk; vl) 2 Cij.
An assignment Aik ^= hVi = vki represents a reduction of
D(Vi) to fvkg (cid:18) D(Vi). A solution to P is a set of distinct
assignments S ^= fAl1k1 ; : : : ; Alnknj(vki ; vkj ) 2 Cijg.

Deﬁnition 2 (Search Algorithm). A search algorithm (cid:2) ^=
h(cid:3); (cid:1); (cid:30)V ; (cid:30)vi is a combination of a branching method (cid:3), a

consistency enforcement method (cid:1), a variable ordering (cid:30)V
and a value ordering (cid:30)v, both of which can be either static
or dynamic.

Deﬁnition 3 (Search Tree). A search tree T for a problem
P is a set of nodes and arcs. Each node corresponds to a set
of assignments, N ^= fAl1k1 ; : : : ; Alp(cid:0)1kp(cid:0)1 ; Alpkpg, totally
ordered by a dynamic variable ordering heuristic (cid:30)V . The
root of the search tree is a special node R ^= ;. Two nodes
N1 and N2 are connected by an arc if 9Aij such that N2 =
N1 [ Aij, in which case we say that N1 is the parent of N2,
and N2 is the child of N1. For every node N, its children are
totally ordered by a dynamic value ordering heuristic (cid:30)v.

Search trees are de(cid:2)ned in the context of a speci(cid:2)c search
algorithm. For a particular CSP instance P , and search algo-
rithm (cid:2), a one-to-one mapping exists between the nodes in
the search tree T and the assignments made by (cid:2).

Deﬁnition 4 (Mistake Point). For a soluble problem P , a
mistake point M is a node identiﬁed by a set of assignments
M ^= fAl1k1 ; :::; Alp(cid:0)1kp(cid:0)1 ; Alpkpg, totally ordered by (cid:30)V ,
for which 9S 2 S such that M n fAlpkpg (cid:26) S, but :9S 2 S
such that M (cid:26) S. Since an insoluble problem does not admit
any solutions, we deﬁne the mistake point associated with an
insoluble problem as the root of its search tree.

Informally, a mistake point corresponds to an assignment
that, given past assignments, cannot lead to a solution even
though, in the case of a soluble problem, a solution exists.
Whenever the value ordering heuristic makes such a mis-
take, the role of the variable ordering heuristic is to guide
the search out of that insoluble search tree as quickly as pos-
sible. However, it is important to realise that the actual set of
mistake points encountered during search is also dependent
on the variable ordering heuristic used.

For a soluble problem P , let PM ^= fVM; DM; CMg be
the insoluble (sub)problem corresponding to M, where VM ^=
V n fVl1 ; :::; Vlpg, CM ^= fCij jVi; Vj 2 VM; Cij 2 Cg, and
DM is the set of current domains after arc-consistency has
been restored to re(cid:3)ect the domain reductions due to M. If P
is insoluble, as a notational convenience, we de(cid:2)ne M ^= ;
and PM as the arc-consistent version of P . For brevity, we
will refer to the insoluble (sub)tree rooted at a mistake point
and its corresponding insoluble (sub)problem interchange-
ably.

Deﬁnition 5 (Refutations). Given a search algorithm (cid:2), a
refutation for a given insoluble (sub)problem PM, rooted at
mistake point, M, is simply the corresponding search tree
TM. We will refer to jTMj, the number of nodes in TM, as
the size of the refutation.

We study the refutations found using a version of MAC
that uses AC-3 [Mackworth, 1977] for consistency enforce-
ment and selects values randomly. Our goal is to determine
how close to optimality are the refutations obtained when
well known variable ordering heuristics, with randomly bro-
ken ties, are substituted for (cid:30)V . For each heuristic (cid:30)V we
(cid:2)rst collect the mistake points it generates when using MAC

(note that each variable ordering heuristic will generate a dif-
ferent set of mistake points). When we analyse MAC in con-
junction with a certain (cid:30)V on a mistake point M, we will
refer to the refutation for the (sub)problem PM as the actual
refutation. We will contrast the actual refutation with the opti-
mal refutation for PM, obtained by replacing (cid:30)V with a new
variable ordering heuristic (cid:30)V such that jTMj is minimised.
Sometimes, rather than using the optimal refutation, we
compare against the quasi-optimal, de(cid:2)ned as the smallest
refutation whose depth does not exceed that of the actual. By
selecting variables based on a depth-(cid:2)rst traversal of the tree
of minimum size, (cid:30)V causes MAC to generate the smallest
possible search tree proving insolubility for PM. In our ex-
perience it is extremely rare that the quasi-optimal refutation
is larger than the optimal. By accepting quasi-optimality we
can use the depth of the actual refutation as an upper bound,
dramatically speeding-up search for better refutations.
Deﬁnition 6 (Improvement Ratios). For a given mistake
point, the refutation improvement ratio is the ratio between
the size of the actual refutation and that of the optimal refuta-
tion. The overall refutation improvement ratio is simply the
ratio between the total number of nodes in all the actual refu-
tations and the total number of nodes in all their correspond-
ing optimal refutations encountered when ﬁnding the ﬁrst so-
lution or proving insolubility.

3 Analysing Refutations
Our focus here is only on how a variable ordering heuristic
behaves when trying to prove insolubility for a (sub)problem.
We are not interested in focusing on how often a variable or-
dering heuristic enters an insoluble (sub)tree. Therefore, our
analysis is centered around (cid:2)nding optimal refutations for all
the mistake points in a search tree. Unfortunately, this is a
herculean task, as we have to search through all the possible
permutations of assignments, i.e. consider all possible search
trees rooted at each mistake point. Without clever optimisa-
tions, this would not be feasible for anything but the tiniest
problems.
3.1 Basic Algorithm
Given a problem instance, a search algorithm (MAC in our
case) and the variable ordering heuristic to be evaluated, we
begin by searching for a solution, with the goal of identify-
ing all the mistake points. The mistake points represent the
roots of the insoluble (sub)trees the search algorithm happens
to encounter before (cid:2)nding the (cid:2)rst solution. For each such
mistake point we compute both the actual refutation, by re-
running MAC on the current (sub)problem using the heuristic
we are evaluating, and the optimal refutation, by considering
all the possible permutations of assignments to the variables
involved in that (sub)problem. Note that insoluble instances
are just a special case where the only mistake point is before
the (cid:2)rst assignment. Furthermore, when analysing insoluble
problems, it is important to realise that the optimal refutation
is independent of the heuristic used; in other words no other
ordering could possibly prove insolubility more quickly.

Both the search algorithm with the variable ordering
heuristics being analysed and the exhaustive search for the

optimal refutation use the same method of enforcing consis-
tency (AC in our case). Failure to do so would make the refu-
tation improvement ratio a function of both the variable or-
dering and the level of consistency enforced, thus being detri-
mental to our goal of analysing variable ordering heuristics.
The version of MAC that we use employs k-way branch-
ing [Smith and Sturdy, 2004], rather than binary branching,
so that selecting a variable Vi creates jD(Vi)j branches in the
search tree. Thus, we make sure that refutation sizes are not
in(cid:3)uenced by the value ordering.
3.2 Optimisations
There are a number of optimisations that we have applied.

Firstly, we can easily maintain an upper bound on the size
of the optimal refutation by initially setting it to the size of
the actual refutation, then updating it as smaller refutations
are found. Therefore, the search for the optimal refutation can
be implemented as a branch-and-bound procedure.

Secondly, we can improve the search by looking ahead
to avoid choices that cannot improve on the current small-
est refutation. Whenever a variable Vi is selected at a certain
depth all the values in its domain have to be tried, and they all
have to fail for the current (sub)problem to be proved insolu-
ble. Consequently, we know that by selecting Vi, the size of
the current partial refutation will increase by at least a number
of nodes equal to jD(Vi)j. We call this a 1-level look-ahead.
By temporarily assigning to Vi, in turn, every value v in
its domain, and by attempting to restore arc-consistency after
every such assignment, we can associate with each v a mini-
mum contribution to the size of the refutation. If the assign-
ment makes the subproblem arc-inconsistent, v’s contribution
will be 1, given by the node corresponding to the assignment
itself. However, if arc-consistency can be restored after the
assignment, at least one more variable will have to be consid-
ered before the current subproblem can be proved insoluble.
Therefore, v will carry a minimum contribution equal to the
smallest domain size amongst all the remaining unassigned
variables. We call this a 2-level look-ahead.

In general, Vi’s selection would increase the size of the cur-
rent partial refutation by at least the sum of the minimum con-
tributions of all the values in its domain. If that would cause
the current partial refutation to exceed the size of the small-
est refutation found so far, Vi will be skipped at the current
depth. This dramatically reduces the search space and brings
reasonable size problems within reach.

4 Experiments
The basic experiment we run is this: for each variable order-
ing heuristic we (cid:2)rst (cid:2)nd all the mistake points that MAC vis-
its when (cid:2)nding the (cid:2)rst solution or proving insolubility; for
each mistake point, we (cid:2)nd MAC’s actual refutation (still with
the same heuristic); using the size of the actual refutation as
an upper bound, we (cid:2)nd the (quasi-)optimal refutation. This
approach was adopted because different variable orderings
generate potentially different sets of mistake points.

We have performed experiments1 on random binary
problems, various
the n-queens problem
1 Code freely available with source at http://hulubei.net/tudor/csp.

instances of

for varying values of n, and a subset of
the RL-
FAP Celar Scen11 [Cabon et al., 1999]. We have stud-
ied the following dynamic variable ordering heuris-
tics: min-domain [Haralick and Elliott, 1980], max-degree,
min(domain/degree) [Bessi(cid:30)ere and Regin, 1996], and bre-
laz [Br·elaz, 1979]; their corresponding anti-heuristics; and
random variable selection. These are regarded as the standard
general-purpose variable ordering heuristics used in the CSP
literature. Ties were broken randomly. Throughout our exper-
iments we have used a dynamic random value ordering.

Note that for heuristics we report the optimal refutations
for random problems and n-queens, and the quasi-optimal
refutations for RLFAP. For anti-heuristics we always com-
pute quasi-optimal refutations. While the true optimal refu-
tations for RLFAP may be smaller than those reported, based
on our observations the difference is not signi(cid:2)cant. Limit-
ing the search to quasi-optimal proofs allowed us to gather
signi(cid:2)cantly more data for this problem.

4.1 Random and n-Queens Problems
Due to the extreme computational requirements of the search
for optimal refutations, we had to limit our experiments to
random problems with 15 variables and uniform domain sizes
of 10 values. We generated 800 instances for each tightness
point using a random problem generator that conforms to the
Model-B speci(cid:2)cation [Gent et al., 2001].

We selected instances at the highest peak of dif(cid:2)culty for
these problems, found to pass through a plane corresponding
to density 0.95. Tightness was varied along this plane. Specif-
ically, we identify a distinct tightness at which we move from
generating a set of problem instances that are all soluble to
generating instances that are all insoluble. In Figure 1 this
transition occurs at a tightness of 0:3. We indicate the range
of tightness for which all problems were soluble (resp. insol-
uble) with a (cid:147)high(cid:148) (resp. (cid:147)low(cid:148)) line.

 3
 2.8
 2.6
 2.4
 2.2
 2
 1.8
 1.6
 1.4
 1.2
 1
 0.8

 5
 4.5
 4
 3.5
 3
 2.5
 2
 1.5
 1
 0.5

brelaz
max-degree
min-domain
min-domain/degree
random
HIGH=solution found, LOW=no solution 

 0

 0.1

 0.2

 0.3

 0.4

 0.5

 0.6

 0.7

 0.8

 0.9

 1

anti-brelaz
max-domain
max-domain/degree
min-degree
HIGH=solution found, LOW=no solution

 0

 0.1

 0.2

 0.3

 0.4

 0.5

 0.6

 0.7

 0.8

 0.9

 1

Fig. 1: Mean overall improvement ratios (y-axis) for random prob-
lems as a function of tightness (x-axis). Heuristics (anti-heuristics)
are in the top (bottom) plot. Median plots are virtually identical.

In Figure 1 we present the results associated with each of
the variable ordering heuristics studied. Note that we are not
ranking heuristics, but are simply studying how close their
actual refutation sizes are to optimality. The overall refuta-
tion improvement ratio peaks at 1.8 for min(domain/degree)
at a tightness of about 0.24, meaning that for the set of mis-
take points encountered when solving these problems using
min(domain/degree) there does not exist a variable ordering
that could decrease the number of nodes in the corresponding
refutations by more than that factor, on the average. Since at
the peak of dif(cid:2)culty proving insolubility accounts for most of
the time spent in search, this result suggests that no improve-
ment in the ordering of variables, for the problems we have
studied, would ever lead to an order of magnitude speedup.
Indeed, in the soluble region we can see that at best we can
hope to halve the time taken by max-degree. In theory, how-
ever, for soluble problems heuristics could do better by failing
less.

Once we move through the phase-transition to insoluble
problems, all heuristics offer improvement ratios less than
2.2 for max-degree and less than 1.6 for all other heuris-
tics, except random. In the case of min(domain/degree) we
see that when using MAC at the peak of dif(cid:2)culty the ra-
tio is approximately 1.4. This is an interesting result since
is demonstrates that for proving insolubility no variable or-
dering heuristic exists, for these problems, that can improve
upon min(domain/degree) by more than a factor of 1.4 at the
peak of dif(cid:2)culty.

Figure 2 presents a plot of the distribution of actual refuta-
tion sizes against optimal, per mistake point, for the random
and min(domain/degree) variable ordering heuristics. Of in-
terest here is the apparent linear relationship between actual
versus optimal refutation size. A similar linear relationship
was observed for all other heuristics and anti-heuristics stud-
ied. When we discuss the performance of variable ordering
heuristics on a real-world problem in the next section we will
see that this linear relationship does not hold and that for very
large refutations found by a heuristic, the optimal refutation
can be many orders of magnitude smaller.

 600

 500

 400

 300

 200

 100

 0

random

 0

 20  40  60  80  100  120  140  160

 600

 500

 400

 300

 200

 100

 0

min-domain/degree

 0

 20  40  60  80  100  120  140  160

Fig. 2: Refutation sizes for mistake points in random problems when
using random and min(domain/degree) variable orderings: actual (y-
axis) as a function of optimal (x-axis).

The performance of a random variable ordering is of com-
parable quality to that of a good variable ordering heuristic in
this problem class. From Figure 1 we see that the improve-
ment ratio of the random heuristic is approximately 2.7 at the
phase transition, close to that of standard heuristics.

Finally, in Figure 3 we present, for each variable ordering
heuristic, the distribution of insoluble (sub)trees in the data-
set as a function of the improvement ratio. We see that almost
all ratios were close to 1, meaning that almost all of the time
the standard variable ordering heuristics performed very close
to perfection. We also see that for the random ordering heuris-
tic ratios of 10 are found less that 0.01% of the time and that
there does not exist a single insoluble (sub)tree that provides
an opportunity to make improvements of more than an order
of magnitude over current heuristics.

In experiments performed over a large data-set of insolu-
ble subtrees generated from problems ranging from 8 to 22
queens we have observed similarly small refutation improve-
ment ratios for n-queens, only slightly bigger than those ob-
served for random problems. Also, the linear relationship be-
tween actual and optimal refutation size was observed, as well
as a similar distribution of ratios.

 1

 0.1

 0.01

 0.001

 1e-04

 1e-05

 1

brelaz
max-degree
min-domain
min-domain/degree
random

 2

 3

 4

 5

 6

 7

 8

 9

 10

Fig. 3: Probability of an insoluble (sub)tree in the data-set for ran-
dom problems (y-axis) having an improvement ratio greater than a
certain value (x-axis).

4.2 RLFAP Celar Scen11
The small improvement ratios obtained for random prob-
lems and n-queens, and estimated in [Li and G·erard, 2000]
for hard random unsatis(cid:2)able 3-SAT, do not seem to hold for
real-world problems. A popular benchmark for binary CSPs,
RLFAP Celar Scen11 was an obvious candidate for our analy-
sis. Unfortunately, at 680 variables, we could not analyse the
entire problem. Instead, we extracted a subset of the original
problem made up of 22 variables that were part of the back-
door set [Williams et al., 2003] over which MAC backtracked
while solving the original problem. We analysed all the mis-
take points found when solving this subset of RLFAP over 500
times for all variable ordering heuristics.

Refutation improvement ratios of 20 and over were ob-
served, even when using the best heuristics, as seen in Fig-
ures 4 and 5, while they were non-existent for random and n-
queens problems. Comparing Figures 2 and 4 we can clearly
see that heuristics behaves very differently on this problem
than on the random problems presented earlier. Speci(cid:2)cally,
we can see that actual refutations correlate very poorly with
quasi-optimal and that no linear relationship exists; note that
a log-scale had to be used on the y-axis of the left plot in
Figure 4 due to the spread of actual refutation sizes for each
quasi-optimal point on the x-axis.

However, of particular interest in this problem is the pattern
we observe in Figure 5. While the vast majority of refutations

 1e+07

 1e+06

 100000

 10000

 1000

 100

 10

 1

random

 0

 200

 400

 600

 800

 1000

 1200

 10000
 9000
 8000
 7000
 6000
 5000
 4000
 3000
 2000
 1000
 0

min-domain/degree

 0

 400

 800

 1200

 1600

Fig. 4: Refutation sizes for mistake points in the RLFAP data-set
when using random and min(domain/degree) variable orderings: ac-
tual (y-axis) as a function of quasi-optimal (x-axis).

offer small improvement ratios, it is possible to (cid:2)nd subtrees
on which the standard heuristics perform very poorly. For ex-
ample, we can see that in a small number of subtrees max-
degree did 100 times worse than quasi-optimal, while the
other heuristics, except min(domain/degree), sometimes did
50 times worse than quasi-optimal. Clearly, the behaviour of
standard variable orderings is signi(cid:2)cantly different on real-
world problems than on the random problems that many re-
searchers use as a basis for studying these heuristics. In the
case of a random variable ordering, we observed a very small
number of subtrees where the refutation found was more than
a factor of 105 worse than quasi-optimal, and that in the vast
majority of cases it performed more than an order of magni-
tude worse than quasi-optimal.

 1

 0.1

 0.01

 0.001

 1e-04

 1

brelaz
max-degree
min-domain
min-domain/degree
random

 10

 100

 1000

 10000

 100000

 1e+06

Fig. 5: Probability of an insoluble subtree in the RLFAP data-set (y-
axis) having an improvement ratio greater than a certain value (x-
axis).

Therefore, our standard heuristics behave very differently,
indeed much worse, on real-world problems than on random
and n-queens problems. In particular, they can be less robust
in the sense that they can sometime waste signi(cid:2)cant amounts
of time (cid:2)nding refutations for insoluble (sub)trees that are far
worse than optimal.

5 Discussion
It is clear from our analysis that the standard variable or-
derings used to solve CSPs behave very differently on real-
world problems than on random problems of comparable
size, which are frequently used to study the performance of
heuristics in the research literature. Our results demonstrate
that there are considerable opportunities to improve search
performance on real-world problems. Some researchers

have already begun developing the necessary infrastruc-
ture needed to study real-world problems in a systematic
way [Gomes et al., 2000; Walsh, 1999; Walsh, 2001]. There
have also been some recent successful results demonstrat-
ing that one can bene(cid:2)t considerably from developing vari-
able ordering heuristics that can exploit characteristics one
encounters in real-world problems [Boussemart et al., 2004;
Dubois and Dequen, 2001; Refalo, 2004].

It is not known whether the linear relationship between ac-
tual and optimal refutations is preserved as the size of ran-
dom problems increases. Recent work on studying the per-
formance of variable ordering heuristics on very large CSPs
has shown that there can be orders of magnitude differences
between heuristics [Bessi(cid:30)ere et al., 2001]. However, those re-
sults do not contradict the results presented in this paper with
respect to the relative performance of standard variable order-
ings on random and non-random problems.

Our analysis is related to the work of Li and Gerard
on studying the limits of branching heuristics for random
3-SAT [Li and G·erard, 2000]. However, our interests here
are in studying the limits of variable ordering heuristics
in a constraint satisfaction context. Furthermore, our anal-
ysis is capable of (cid:2)nding exact optimal refutations, rather
than approximating them, and focuses on the differences
observed between random and real-world problems. Our
work is also closely related to the theoretical analysis of
proof complexity for satis(cid:2)ability and constraint satisfac-
tion [Beame et al., 1998; Mitchell, 2003].

 1

 0.1

 0.01

 0.001

 1e-04

 1e-05

 1

 1

 0.1

 0.01

 0.001

 1e-04

 1e-05

 1

brelaz
max-degree
min-domain
min-domain/degree
random

 10

 100

 1000

1e+4

1e+5

1e+6

1e+7

brelaz
max-degree
min-domain
min-domain/degree
random

 10

 100

 1000

1e+4

1e+5

1e+6

1e+7

Fig. 6: Probability of an insoluble subtree in the RLFAP data-set (y-
axis) being greater than an optimal/actual (top/bottom) refutation of
a given size (x-axis).

In this paper we introduce a potentially useful tool for
analysing the causes of the heavy-tailed phenomenon ob-
served in the runtime distributions of backtrack search pro-
cedures [Gomes et al., 2000]. Figures 5 and 6 show, for RL-
FAP, a very small percentage of insoluble (sub)problems for
which standard variable ordering heuristics will (cid:2)nd refuta-
tions that are signi(cid:2)cantly larger than optimal, leading to a

long runtime. Furthermore, it is also interesting to note from
Figure 5 that the vast majority of actual refutations are very
close to being optimal, with the exception of those found with
a random variable ordering heuristic.

Gomes et al. [2004] report a high correlation between the
distribution of the depth of mistake points and the runtime
distribution, e.g. the presence of heavy-tails. We can further
extend this analysis by also considering the size of optimal
refutations rooted at these mistake points. This may provide a
way of isolating the causes of heavy-tailed behaviour by mak-
ing a distinction between the effects of the algorithm and its
components (propagation method, variable and value order-
ings), versus the effects of the inherent structure of the prob-
lem [Walsh, 1999; Walsh, 2001]. As part of our future work
in this area we will study optimal refutations for problems
that are well known to exhibit heavy-tail behaviour.

6 Conclusions
In this paper we have proposed a novel approach to empiri-
cally looking at problem hardness and typical-case complex-
ity by comparing optimal refutations with those generated
by standard search heuristics. We have compared refutations
of insoluble (sub)trees found using well known variable or-
dering heuristics combined with a standard CSP search algo-
rithm against optimal refutations. Our results show that there
is a signi(cid:2)cant difference between the performance of heuris-
tics on typical random problems and those found in the real-
world. We suggest that small-to-medium sized random binary
CSPs are of limited value to constraints researchers and intro-
duced a potentially useful tool for analysing the causes of the
heavy-tailed phenomenon observed in the runtime distribu-
tions of backtrack search procedures.

Acknowledgments
This material is based on work supported by Science Foun-
dation Ireland under Grant 00/PI.1/C075. We would like to
thank Barbara M. Smith, Eugene C. Freuder, Nic Wilson,
Chris Beck, Bart Selman, Carla Gomes and Susan Epstein
for their comments and suggestions, and to John Morrison
and the Boole Centre For Research in Informatics for provid-
ing access to their Beowulf cluster.

References
[Beame et al., 1998] P. Beame, R. Karp, T. Pitassi, and M. Saks. On
the complexity of unsatis(cid:2)ability of random k-cnf formulas. In
Proceedings of ACM STOC-1998, pages 561(cid:150)571, 1998.

[Beck et al., 2004] J.C. Beck, P. Prosser, and R.J. Wallace. Trying
again to fail-(cid:2)rst. In Proceedings of CSCLP-2004, LNCS 3419,
pages 41(cid:150)55, 2004.

[Bessi(cid:30)ere and Regin, 1996] C. Bessi(cid:30)ere and J-C. Regin. MAC and
combined heuristics: two reasons to forsake FC (and CBJ?) on
hard problems. In Proceedings of CP-1996, LNCS 1118, pages
61(cid:150)75, 1996.

[Bessi(cid:30)ere et al., 2001] C. Bessi(cid:30)ere, A. Chmeiss, and L. Sais.
Neighbourhood-based variable ordering heuristics for the con-
straint satisfaction problem (long version). Available from:
http://www.lirmm.fr/˜bessiere/pubs , 2001.

[Boussemart et al., 2004] F. Boussemart, F. Hemery, C. Lecoutre,
and L. Sais. Boosting systematic search by weighting constraints.
In Proceedings of ECAI-2004, pages 146(cid:150)150, 2004.

[Br·elaz, 1979] D. Br·elaz. New methods to color the vertices of a

graph. Communications of the ACM, 22(4):251(cid:150)256, 1979.

[Cabon et al., 1999] B. Cabon, S. Givry, L. Lobjois, T. Schiex, and
J.P. Warners. Radio link frequency assignment. Constraints,
4(1):79(cid:150)89, 1999.

[Dubois and Dequen, 2001] O. Dubois and G. Dequen.

A
backbone-search heuristic for ef(cid:2)cient solving of hard 3-SAT for-
mulae. In Proceedings of IJCAI-2001, pages 248(cid:150)253, 2001.

[Gent et al., 2001] I.P. Gent, E. MacIntyre, P. Prosser, B.M. Smith,
and T. Walsh. Random constraint satisfaction: Flaws and struc-
ture. Constraints, 6(4):345(cid:150)372, 2001.

[Gomes et al., 2000] C.P. Gomes, B. Selman, N. Crato, and
H. Kautz. Heavy-tailed phenomena in satis(cid:2)ability and constraint
satisfaction problems. Automated Reasoning, 24(1/2):67(cid:150)100,
2000.

[Gomes et al., 2004] C.P. Gomes, C. Fern·andez, B. Selman, and
C. Bessi(cid:30)ere. Statistical regimes across constrainedness regions.
In Proceedings of CP-2004, LNCS 3258, pages 32(cid:150)46, 2004.

[Haralick and Elliott, 1980] R.M. Haralick and G.L. Elliott.

In-
creasing tree search ef(cid:2)ciency for constraint satisfaction prob-
lems. Artiﬁcial Intelligence, 14(3):263(cid:150)313, 1980.

[Li and G·erard, 2000] C.M. Li and S. G·erard. On the limit of
branching rules for hard random unsatis(cid:2)able 3-sat. In Proceed-
ings of ECAI-2000, pages 98(cid:150)102, 2000.

[Mackworth, 1977] A.K. Mackworth. Consistency in networks of

relations. Artiﬁcial Intelligence, 8(1):99(cid:150)118, 1977.

[Mitchell, 2003] D.G. Mitchell. Resolution and constraint satisfac-
tion. In Proceedings of CP-2003, LNCS 2833, pages 555(cid:150)569,
2003.

[Refalo, 2004] P. Refalo.

Impact-based search strategies for con-
straint programming. In Proceedings of CP-2004, LNCS 3258,
pages 557(cid:150)571, 2004.

[Sabin and Freuder, 1994] D. Sabin and E.C. Freuder. Contradict-
ing conventional wisdom in constraint satisfaction. In Proceed-
ings of ECAI-1994, pages 125(cid:150)129, 1994.

[Smith and Grant, 1998] B.M. Smith and S.A. Grant. Trying harder
to fail (cid:2)rst. In Proceedings of ECAI-1998, pages 249(cid:150)253, 1998.
[Smith and Sturdy, 2004] B.M. Smith and P. Sturdy. An empirical
investigation of value ordering for (cid:2)nding all solutions. In Work-
shop on Modelling and Solving Problems with Constraints, 2004.
[Walsh, 1999] T. Walsh. Search in a small world. In Proceedings

of IJCAI-1999, pages 1172(cid:150)1177, 1999.

[Walsh, 2001] T. Walsh. Search on high degree graphs. In Proceed-

ings of IJCAI-2001, pages 266(cid:150)271, 2001.

[Williams et al., 2003] R. Williams, C.P. Gomes, and B. Selman.
Backdoors to typical case complexity. In Proceedings of IJCAI-
2003, pages 1173(cid:150)1178, 2003.

