Conditional Planning in the Discrete Belief Space

Jussi Rintanen∗

Albert-Ludwigs-Universit¨at Freiburg, Institut f¨ur Informatik

Georges-K¨ohler-Allee, 79110 Freiburg im Breisgau

Germany

Abstract

Probabilistic planning with observability restric-
tions, as formalized for example as partially ob-
servable Markov decision processes (POMDP), has
a wide range of applications, but it is computation-
ally extremely difﬁcult. For POMDPs, the most
general decision problems about existence of poli-
cies satisfying certain properties are undecidable.
We consider a computationally easier form of plan-
ning that ignores exact probabilities, and give an al-
gorithm for a class of planning problems with par-
tial observability. We show that the basic backup
step in the algorithm is NP-complete. Then we pro-
ceed to give an algorithm for the backup step, and
demonstrate how it can be used as a basis of an ef-
ﬁcient algorithm for constructing plans.

Introduction

1
When the sequence of states that will be visited during plan
execution cannot be exactly predicted, for example because of
nondeterminism, it is necessary to produce plans that apply
different actions depending on how the plan execution has
proceeded so far. Such plans are called conditional plans.

Construction of conditional plans is particularly difﬁcult
when there is no full observability; that is, when during plan
execution it is not possible to uniquely determine what the
current state of the world is. Planning problems having this
property are said to be partially observable, and their solution
requires that the sets of possible current world states – the be-
lief states – are (implicitly) maintained during plan execution
and (implicitly) represented by a plan.

The earliest work on planning with partial observability
was in the framework of partially observable Markov decision
processes (POMDPs) [Smallwood and Sondik, 1973; Kael-
bling et al., 1998]. Planning with POMDPs is computation-
ally difﬁcult. For unbounded horizon lengths an unbounded
number of probability distributions corresponding to belief
states needs to be considered, and ﬁnding optimal plans is not
in general solvable [Madani et al., 1999]. A natural approach
for easing the computational difﬁculty of POMDP planning
is to consider horizons of a bounded length [Mundhenk et
∗This research was partly supported by DFG grant RI 1177/2-1.

al., 2000]. A second approach which has been pursued
with algorithms for conditional planning [Weld et al., 1998;
Bonet and Geffner, 2000; Bertoli et al., 2001], ignores prob-
abilities and hence directly yields a ﬁnitary problem. Main
decision problems related to non-probabilistic planning with
partial observability are 2-EXP-complete [Rintanen, 2004a].
A main difference between POMDPs and corresponding
non-probabilistic problems is that the latter do not use proba-
bilistic notions like success probability or expected cost, and
require that a plan must reach the goals with certainty. An
implication of success probability 1 is that uncertainty about
observations and sensing can be ignored: if an observation is
correct with a probability strictly less than 1 then it is as good
as no observation at all.

For this planning problem we present an iterative algorithm
that has some resemblance to iterative algorithms for solving
POMDPs. The algorithm maintains a data structure repre-
senting those belief states for which a conditional plan has
been shown to exist. Initially this data structure represents
those belief states consisting of goal states only. Then this
data structure is repeatedly extended by performing search
backwards from the goal belief states.

The structure of the paper is as follows. Section 2 deﬁnes
the planning problem. Sections 3 and 4 respectively describe
the formal framework and analyze its properties. Section 5
proposes a planning algorithm and Section 6 presents exper-
imental results obtained with an implementation of the algo-
rithm. Section 7 concludes the paper.

2 The Planning Problem
In this section we present a formalization of planning in
which states are atomic objects without internal structure.

Deﬁnition 1 A problem instance is hS, I, O, G, Pi where S
is the set of states, I ⊆ S is the set of initial states, O
is the set of actions o ⊆ S × S, G ⊆ S is the set of
goal states and P = (C1, . . . , Cn) is a partition of S into
classes of observationally indistinguishable states satisfying
1 ≤ i < j ≤ n.

S{C1, . . . , Cn} = S and Ci ∩ Cj = ∅ for all i, j such that

Making an observation tells which set Ci the current state
belongs to. Distinguishing states in a given Ci is not possible.

An action is a relation between states and their successor
states. An action o is applicable in a state s if sos0 for some
s0 ∈ S. Deﬁne the image of a set B of states with respect to an
action o as imgo(B) = {s0 ∈ S|s ∈ B, sos0}. The preimage
is preimgo(B) = {s ∈ S|∅ 6= imgo({s}) ⊆ B}, consisting
of those states from which o is guaranteed to reach a state in
B. An action o is deterministic if it is a partial function.

Plans are directed graphs with two kinds of nodes: action

nodes and observation nodes.
Deﬁnition 2 Let hS, I, O, G, (C1, . . . , Cn)i be a problem in-
stance. A plan is a triple hN, b, li where

where C =S{C0

• N is a ﬁnite set of nodes,
• b ∈ N is the initial node,
• l : N → (O×N)∪22S×N is a function that assigns each
node an action and a successor node ho, ni ∈ O × N
or a set of states and successor nodes hC, ni ∈ 22S×N
m} for some {C0
m} ⊆
1, . . . , C0
{C1, . . . , Cn}.
In the ﬁrst case the node is an action
node and in the second an observation node.
For all n ∈ N and {hC, mi,hC0, m0i} ⊆ l(n) the ob-
servations C and C0 may not intersect: C ∩ C0 = ∅.
Nodes with l(n) = ∅ are terminal.

1, . . . , C0

We restrict to acyclic plans. Acyclicity means that the
graph hN, Ei, where hn, n0i ∈ E iff l(n) = ho, n0i for some
o or hC, n0i ∈ l(n) for some C, is acyclic.1
Plan execution starts from the initial node b and any of the
initial states. For an action node with label ho, ni in state s
execute o and continue from n and a state in imgo(s). For an
observation node identify hC, ni in the node label so that s ∈
C, and then continue from n and s. A plan solves a problem
instance if all of its executions terminate in a terminal node
and a goal state. Execution of an acyclic plan can have at
most as many steps as there are nodes in the plan.

3 Problem Representation
Now we introduce the representation for sets of state sets for
which a plan for reaching goal states exists.

In the following example states are viewed as valuations
of state variables, and the observational classes correspond to
valuations of those state variables that are observable.

Example 3 Consider the blocks world with the state vari-
ables clear(X) observable, allowing to observe the top-
most block of each stack. With three blocks there are
7 observational classes because there are 7 valuations of
{clear(A), clear(B), clear(C)} with at least one block clear.

Consider the problem of trying to reach the state in which
all blocks are on the table. For each block there is an action
for moving it onto the table from wherever it was before. If

1Construction of cyclic plans requires looking at more global
properties of transition graphs than what is needed for acyclic plans.
The difﬁculties of cyclic plans in our framework are similar to those
in the MDP/POMDP framework when using average rewards in-
stead of ﬁnite horizons or discounted rewards [Puterman, 1994].

a block cannot be moved nothing happens. Initially we only
have the empty plan for the goal states.

Then we compute the preimages of this set with actions
that respectively put the blocks A, B and C onto the table, and
split the resulting sets to the different observational classes.

Now for these 7 belief states we have a plan consisting of
one or zero actions. But we also have plans for sets of states
that are only represented implicitly. These involve branching.
For example, we have a plan for the state set consisting of the
four states in which respectively all blocks are on the table,
A is on C, A is on B, and B is on A. This plan ﬁrst makes
observations and branches, and then executes the plan asso-
ciated with the belief state obtained in each case. Because 3
observational classes each have 2 belief states, there are 23
maximal state sets with a branching plan. From each class
only one belief state can be chosen because observations can-
not distinguish between belief states in the same class.

We can ﬁnd more belief states that have plans by comput-
ing preimages of existing belief states. Let us choose the be-
lief states in which respectively all blocks are on the table, B
is on C, C is on B, and C is on A, and compute their union’s
preimage with A-onto-table. The preimage intersected with
the observational classes yields new belief states: for the class
with A and B clear there is a new 2-state belief state covering
both previous belief states in the class, and for the class with
A clear there is a new 2-state belief state.

Computation of further preimages yields for each observa-
tional class a belief state covering all the states in that class,
(cid:4)
and hence a plan for every belief state.

The above example shows how the exponential number of
state sets (corresponding to the Cartesian product of the ob-
servational classes) considered by Rintanen [2002] is repre-
sented only implicitly. The algorithm by Rintanen [2002] ex-

CABCAB??C??B??A??BC??AC??BACABABC??C??B??A??BC??AC??BAABCABCABCABCABCCABpreimage of A−onto−tablepreimage of B−onto−tablepreimage of C−onto−tableCAB??C??B??A??BC??AC??BAABCABCABCCABABCABCABCABCABCplicitly generates the state sets, the number of which in many
cases is very high. With the new representation the computa-
tional complexity is shifted from the size of the representation
to the time it takes to ﬁnd a combination of belief states hav-
ing a useful preimage. This shift is useful for two reasons.
First, much of the space complexity (and the time complexity
it implies) is traded to time complexity only: the state sets are
not represented explicitly (except in the unobservable special
case.) Second, the succinct representation allows much better
control on which belief states to produce, and although ﬁnd-
ing one new belief state and plan still takes worst-case expo-
nential time, this may be performed by clever algorithms and
be further sped up by heuristics.

Next we formalize the framework in detail.

Deﬁnition 4 (Belief space) Let P = (C1, . . . , Cn) be a par-
tition of the set of all states. Then a belief space is an n-tuple
hG1, . . . , Gni where Gi ⊆ 2Ci for all i ∈ {1, . . . , n} and
B 6⊂ B0 for all i ∈ {1, . . . , n} and {B, B0} ⊆ Gi.

Notice that in each component of a belief space we only
have set-inclusion maximal belief states. The simplest belief
spaces are obtained from sets B of states as B(B) = h{C1 ∩
B}, . . . ,{Cn ∩ B}i. A belief space is extended as follows.

Deﬁnition 5 (Extension) Let P = (C1, . . . , Cn) be the par-
tition of all states, G = hG1, . . . , Gni a belief space, and T a
set of states. Deﬁne G⊕ T as hG1 d (T ∩ C1), . . . , Gn d (T ∩
Cn)i where the operation d adds the latter set of states to the
former set of sets of states and eliminates sets that are not set-
inclusion maximal, deﬁned as U d V = {R ∈ U ∪ {V }|R 6⊂
K for all K ∈ U ∪ {V }}.

A belief space G = hG1, . . . , Gni represents the set of
sets of states ﬂat(G) = {B1 ∪ ··· ∪ Bn|Bi ∈ Gi for all i ∈
{1, . . . , n}} and its cardinality is |G1| · |G2| · . . . · |Gn|.

4 Complexity of Basic Operations
The basic operations on belief spaces needed in planning al-
gorithms are testing the membership of a set of states in a
belief space, and ﬁnding a set of states whose preimage with
respect to an action is not contained in the belief space. Next
we analyze the complexity of these operations.

Theorem 6 For belief spaces G and state sets B, testing
whether there is B0 ∈ ﬂat(G) such that B ⊆ B0, and com-
puting G ⊕ B takes polynomial time.
Proof: Idea: A linear number of set-inclusion tests sufﬁces.
(cid:3)

Our algorithm for extending belief spaces by computing
the preimage of a set of states (Lemma 8) uses exhaustive
search and runs in worst-case exponential time. This asymp-
totic worst-case complexity is very likely the best possible
because the problem is NP-hard. Our proof for this fact is a
reduction from SAT: represent each clause as the set of liter-
als that are not in it, and then a satisfying assignment is a set
of literals that is not included in any of the sets, corresponding
to the same question about belief spaces.

Theorem 7 Testing if for belief space G there is R ∈ ﬂat(G)
such that preimgo(R) 6⊆ R0 for all R0 ∈ ﬂat(G) is NP-
complete. This holds even for deterministic actions o.
Proof: Membership is easy: For G = hG1, . . . , Gni choose
nondeterministically Ri ∈ Gi for every i ∈ {1, . . . , n}, com-
pute R = preimgo(R1∪···∪Rn), and verify that R∩Ci 6⊆ B
for some i ∈ {1, . . . , n} and all B ∈ Gi. Each of these steps
takes only polynomial time.
Let T = {c1, . . . , cm} be a set of clauses over propositions
A = {a1, . . . , ak}. We deﬁne a belief space based on states
{a1, . . . , ak, ˆa1, . . . , ˆak, z1, . . . , zk, ˆz1, . . . , ˆzk}. The states ˆa
represent negative literals. Deﬁne
i = (A\ci) ∪ {ˆa|a ∈ A,¬a 6∈ ci} for i ∈ {1, . . . , m},
c0
m},{{z1},{ˆz1}}, . . . ,{{zk},{ˆzk}}i ,
G = h{c0
o = {hai, zii|1 ≤ i ≤ k} ∪ {hˆai, ˆzii|1 ≤ i ≤ k}.
We claim that T is satisﬁable if and only if there is B ∈

ﬂat(G) such that preimgo(B) 6⊆ B0 for all B0 ∈ ﬂat(G).
Assume T is satisﬁable, that is, there is M such that
M |= T . Deﬁne M0 = {zi|ai ∈ A, M |= ai} ∪ {ˆzi|ai ∈
A, M 6|= ai}. Now M0 ⊆ B for some B ∈ ﬂat(G) because
from each class only one of {zi} or {ˆzi} is taken. Let M00 =
preimgo(M0) = {ai ∈ A|M |= ai} ∪ {ˆai|ai ∈ A, M 6|= ai}.
6⊆ B for all B ∈ ﬂat(G). Take any
We show that M00
i ∈ {1, . . . , m}. Because M |= ci, there is aj ∈ ci ∩ A such
that M |= aj (or ¬aj ∈ ci, for which the proof goes simi-
larly.) Now zj ∈ M0, and therefore aj ∈ M00. Also, aj 6∈ c0
j.
As there is such an aj (or ¬aj) for every i ∈ {1, . . . , m},
6⊆ B for all
M00 is not a subset of any c0
B ∈ ﬂat(G).
Assume there is B ∈ ﬂat(G) such that D = preimgo(B) 6⊆
B0 for all B0 ∈ ﬂat(G). Now D is a subset of A ∪ {ˆa|a ∈ A}
with at most one of ai and ˆai for any i ∈ {1, . . . , k}. Deﬁne
a model M such that for all a ∈ A, M |= a if and only if
a ∈ D. We show that M |= T . Take any i ∈ {1, . . . , m}
(corresponding to a clause.) As D 6⊆ B for all B ∈ ﬂat(G),
i. Hence there is aj or ˆaj in D\c0
D 6⊆ c0
i. Consider the
case with aj (ˆaj goes similarly.) As aj 6∈ c0
i, aj ∈ ci. By
deﬁnition of M, M |= aj and hence M |= ci. As this holds
for all i ∈ {1, . . . , m}, M |= T .
(cid:3)

1, . . . , c0

i, and hence M00

5 Planning Algorithms
Based on the problem representation in the preceding section,
we devise a planning algorithm that repeatedly identiﬁes new
belief states (and associated plans) until a plan covering the
initial states is found. The algorithm in Figure 2 tests for
plan existence; further book-keeping is needed for outputting
a plan. The size of the plan is proportional to the number of it-
erations the algorithm performs, and outputting the plan takes
polynomial time in the size of the plan. The algorithm uses
the subprocedure ﬁndnew (Figure 1) for extending the belief
space (this is the NP-hard subproblem from Theorem 7). Our
implementation of the subprocedure orders sets f1, . . . , fm
by cardinality in a decreasing order: bigger belief states are
tried ﬁrst. We also use a simple pruning technique for deter-
ministic actions o: If preimgo(fi) ⊆ preimgo(fj) for some i
and j such that i > j, then we may ignore fi.

PROCEDURE ﬁndnew(o,A,F ,H);
IF F = hi AND preimgo(A) 6⊆ B for all B ∈ ﬂat(H)
THEN RETURN A;
IF F = hi THEN RETURN ∅;
F is h{f1, . . . , fm}, F2, . . . , Fki for some k ≥ 1;
FOR i := 1 TO m DO

B := ﬁndnew(o,A ∪ fi,hF2, . . . , Fki,H);
IF B 6= ∅ THEN RETURN B;

END;
RETURN ∅

Figure 1: Algorithm for ﬁnding new belief states

PROCEDURE plan(I,O,G);
H := B(G);
progress := true;
WHILE progress and I 6⊆ I0 for all I0 ∈ ﬂat(H) DO

progress := false;
FOR EACH o ∈ O DO

B := ﬁndnew(o,∅,H,H);
IF B 6= ∅ THEN

BEGIN

H := H ⊕ preimgo(B);
progress := true;

END;

END;

END;
IF I ⊆ I0 for some I0 ∈ ﬂat(H) THEN RETURN true
ELSE RETURN false;

Figure 2: Algorithm for planning with partial observability

Lemma 8 Let H be a belief space and o an action. The pro-
cedure call ﬁndnew(o,∅,F, H) returns a set B0 of states such
that B0 = preimgo(B) for some B ∈ ﬂat(F ) and B0 6⊆ B00
for all B00 ∈ ﬂat(H), and if no such belief state exists it re-
turns ∅.

Sketch: The procedure goes through the ele-
Proof:
ments hB1, . . . , Bni of F1 × ··· × Fn and tests whether
preimgo(B1 ∪ ··· ∪ Bn) is in H. The sets B1 ∪ ··· ∪ Bn are
the elements of ﬂat(F ). The traversal through F1 × ··· × Fn
is by generating a search tree with elements of F1 as children
of the root node, elements of F2 as children of every child of
the root node, and so on, and testing whether the preimage is
in H. The second parameter of the procedure represents the
state set constructed so far from the belief space, the third pa-
rameter is the remaining belief space, and the last parameter
is the belief space that is to be extended, that is, the new belief
(cid:3)
state may not belong to it.

The correctness proof of the procedure plan consists of the
following lemma and theorems. The ﬁrst lemma simply says
that extending a belief space H is monotonic in the sense that
the members of ﬂat(H) can only become bigger.

Lemma 9 Assume T is any set of states and B ∈ ﬂat(H).
Then there is B0 ∈ ﬂat(H ⊕ T ) so that B ⊆ B0.

The second lemma says that if we have belief states in dif-
ferent observational classes such that each is included in a
belief state of a belief space H, then there is a set in ﬂat(H)
that includes all these belief states.

Lemma 10 Let B1, . . . , Bn be sets of states so that for every
i ∈ {1, . . . , n} there is B0
i, and
there is no observational class C such that for some {i, j} ⊆
{1, . . . , n} both i 6= j and Bi∩ C 6= ∅ and Bj ∩ C 6= ∅. Then
there is B0 ∈ ﬂat(H) such that B1 ∪ ··· ∪ Bn ⊆ B0.

i ∈ ﬂat(H) such that Bi ⊆ B0

The proof of the next theorem shows how the algorithm
is capable of ﬁnding any plan by constructing it bottom up
starting from the leaf nodes. The construction is based on
ﬁrst assigning a belief state to each node in the plan, and then
showing that the algorithm reaches that belief state from the
goal states by repeated computation of preimages.

1, . . . , n0

(Z(nm))∪ (Z(n0

Theorem 11 Whenever there exists a ﬁnite acyclic plan for a
problem instance, the algorithm in Figure 2 returns true.
Proof: Assume there is a plan hN, b, li for a problem instance
hS, I, O, G, Pi. Label all nodes of the plan as follows. The
root node b is labeled with I, that is, Z(b) = I. When all
parent nodes of a node n have a label, we assign a label to n.
Let l(n1) = ho1, ni, . . . , l(nm) = hom, ni for action nodes
n1, . . . , nm that have n as the child node, and let l(n0
1) =
k) = {hCk, ni, . . .} for all observation
{hC1, ni, . . .}, . . . , l(n0
nodes n0
k with n as one of the children. Then Z(n) =
1)∩ C1)∪···∪
imgo1(Z(n1))∪···∪ imgom
k)∩ Ck). If the above labeling does not assign anything
(Z(n0
to a node n, then assign Z(n) = ∅. Each node is labeled with
those states that are possible in that node on some execution.
We show that if plans for Z(n1), . . . , Z(nk) exist, where
n1, . . . , nk are children of a node n in a possible plan, then
the algorithm determines that a plan for Z(n) exists as well.
Induction hypothesis: For each plan node n such that all
paths to a terminal node have length i or less, its label B =
Z(n) is a subset of some B0 ∈ ﬂat(H) where H is the value
of the program variable H after the while loop exits and H
could not be extended further.
Base case i = 0: Terminal nodes of the plan are labeled
with subsets of G. By Lemma 9, there is G0 such that G ⊆ G0
and G0 ∈ ﬂat(H) because initially H = B(G) and thereafter
it was repeatedly extended.
Inductive case i ≥ 1: Let n be a plan node. By the induc-
tion hypothesis for all children n0 of n, Z(n0) ⊆ B for some
B ∈ ﬂat(H).
If n is an observation node with children n1, . . . , nk and
respective observations C1, . . . , Ck, then Z(n) ∩ C1, . . .,
Z(n) ∩ Ck all occupy disjoint observational classes and su-
perset of Z(n) ∩ Ci for every i ∈ {1, . . . , k} is in ﬂat(H).
Hence by Lemma 10 Z(n) ⊆ B for some B ∈ ﬂat(H).
If n is an action node with action o and child node n0,
then imgo(Z(n)) ⊆ Z(n0), and by the induction hypothe-
sis Z(n0) ⊆ B0 for some B0 ∈ ﬂat(H). We have to show that
Z(n) ⊆ B00 for some B00 ∈ ﬂat(H). Assume that there is
no such B00. But now by Lemma 8 ﬁndnew(o,∅,H,H) would
return B000 such that preimgo(B000) 6⊆ B for all B ∈ ﬂat(H),

and the while loop could not have exited with H, contrary to
(cid:3)
our assumption about H.

Theorem 12 Let Π = hS, I, O, G, Pi be a problem instance.
If plan(I,O,G) returns true, then Π has a solution plan.

ﬂat(Hi) for which a plan reaching G exists.

Proof: Let H0, H1, . . . be the sequence of belief spaces H
produced by the algorithm. We show that for all i ≥ 0, for
every B ∈ ﬂat(Hi) there is a plan that reaches G.
Induction hypothesis: Hi contains only such state sets B ∈
Base case i = 0: H0 = B(G), and the only state set in H0
Inductive case i ≥ 1: Hi+1 is obtained as Hi⊕preimgo(B)
Because by Lemma 8 B ∈ ﬂat(Hi), by induction hypothe-
sis there is a plan π for B. The plan that executes o followed
by π reaches G from preimgo(B).

is G. The empty plan reaches G from G.
where B = ﬁndnew(o,∅,Hi,Hi).

Let B be any member of ﬂat(Hi+1). We show that for B
there is a plan for reaching G. The plan for B starts by a
branch2. We show that for every possible observation, cor-
responding to one observational class, there is a plan that
reaches G. Let Cj be the jth observational class. When ob-
serving Cj, the current state is in Bj = B ∩ Cj. Now for
Bj there is B0
j where Hi+1,j is the
jth component of Hi+1. Now by induction hypothesis there
j ∈ Hi+1,j\Hi,j,
is a plan for B0
then for the branch corresponding to Cj we use the plan for
(cid:3)
preimgo(B), as B0

j ∈ Hi+1,j with Bj ⊆ B0
j if B0
j must be preimgo(B) ∩ Cj.

j ∈ Hi,j, and if B0

Until now we have used only one partition of the state
space to observational classes. However,
it is relatively
straightforward to generalize the above deﬁnitions and algo-
rithms to the case in which several partitions are used, each
for a different set of actions. This means that the possible
observations depend on the action that has last been taken.

6 Experimentation with an Implementation
We have implemented the algorithm from the previous sec-
tion and call the resulting planning system BBSP. The only
heuristic is the one described in the preceding sections: ﬁnd-
new chooses bigger belief states ﬁrst. The implementa-
tion is based on representing sets of states and actions as
BDDs [Burch et al., 1994]. There is a small improvement
in the belief space representation with BDDs: all components
of a belief space consisting of one belief state only are repre-
sented by one BDD.

We carried out a comparison to the MBP planner [Bertoli
et al., 2001] which uses forward-search together with some
heuristics for restricting branching. MBP starts search from
the initial states, and proceeds forward by taking actions,
leading to another set of states, or by using observations to
split the current state set to several smaller ones. Different
choices of actions and observations induce a search tree.

2Some branches might not be needed, and if the intersection of B
with only one observational class is non-empty the plan could start
with an action node instead of a degenerate observation node.

problem
BTCS1601
BTCS1701
BTCS1801
BTCS1901
BTCS2001
medical18
medical20
medical22
medical24
medical26
emptyroom07
emptyroom08
emptyroom10
emptyroom15
emptyroom20
ring03
ring04
ring05
ring06
ring07
ring08
ring09
ring10
BW03fo
BW04fo
BW05fo
BW06fo
BW03pfo
BW04pfo
BW05pfo
BW06pfo
BW03po
BW04po
BW05po
BW06po

|S|
MBP
0.60
98
0.79
104
1.01
110
1.22
116
1.44
122
7.34
148
24.13
164
180
60.53
196 > 20 m
212 > 20 m
0.09
49
0.12
64
0.16
100
0.37
225
0.62
400
0.09
162
0.38
648
1.99
2430
13.12
8748
94.73
30618
104976
744.90
354294 > 20 m
1180980 > 20 m
13
32.64
73 > 20 m
501 > 20 m
4051 > 20 m
0.13
13
73
90.15
501 > 20 m
4051 > 20 m
0.08
0.71
13.49
394.21

runtime in seconds
BBSP
1.21
1.38
2.08
2.28
2.52
2.49
2.91
3.48
4.11
6.61
0.38
0.63
1.56
9.60
25.58
0.16
0.44
1.03
1.63
2.41
3.34
5.55
7.06
0.14
0.67
6.43
133.14
0.12
0.69
6.29
133.88
0.12
0.64
6.41
198.85

13
73
501
4051

iterations
BBSP
32
34
36
38
40
21
23
25
27
29
41
53
81
198
243
11
19
23
27
31
35
39
43
9
22
46
64
9
22
46
64
9
22
46
64

Table 1: Runtime comparison BBSP vs. MBP

Some of the MBP runtimes given by Bertoli et al. [2001]
are much better than given by us in this paper (speciﬁcally on
the medical and ring problems) because the branching heuris-
tic used by Bertoli et al. works well on their formulations of
the benchmarks: branch only on one observable state variable
if possible. We used a slightly different formulation where
one many-valued observation is replaced by a small number
of Boolean observations.

Runtimes of the planners are given in Table 1. The runs
were on a 360 MHz Sun Sparcstation under Solaris. The
problem instances are the same as in [Rintanen, 2002] where
MBP was shown in almost all cases to be faster than GPT
[Bonet and Geffner, 2000] and much faster than the YK ¨A
planner [Rintanen, 2002] on most of the problems except the
blocks worlds problems with full or almost full observability.
BTCS is the bomb-in-the-toilet problem with sensing. In the
medical problems patients are cured by performing tests and
medicating. The emptyroom problems are about navigating
from an unknown location to the center of the room. The ring
problems are about closing and locking all the windows of
a building consisting of a cycle of rooms. BW is the blocks

world with increasing number of blocks with the goal to ar-
range them into one stack from any initial conﬁguration under
different degrees of observability: fo is full observability, pfo
is with the on relation observable, and po is partial observ-
ability (clear and ontable are observable). The problems are
solvable under partial observability because moving a block
only requires that it is clear and a move action is applicable
no matter where the block is.

The rightmost column gives the number of iterations BBSP
needs for ﬁnding a plan. MBP runtimes in some cases grow
faster because it performs more search. This is most obvi-
ous in some of the problems with more observations as the
number of possible ways of branching becomes astronomi-
cal. In our algorithm, the dynamic programming character of
plan generation better avoids this explosion in the number of
belief states to be considered.

In forward search there is an inherent conﬂict between
A) keeping the size of plans and search trees down by not
branching on all possible observations and B) branching
enough to be able to ﬁnd a plan. In MBP a number of heuris-
tics is used for controlling branching, and for these bench-
marks the heuristics in most cases work very well. For back-
ward plan construction no similar conﬂict exists, and plan
construction by a form of dynamic programming leads to ef-
fective reuse of already constructed belief states and plans,
and there is no separate problem of deciding how to branch.

7 Conclusions and Future Work
We have presented a novel framework for non-probabilistic
conditional planning with partial observability, proposed a
backward search algorithm for ﬁnding plans, and shown that
the basic backup step of the algorithm is NP-hard. We have
also demonstrated how an efﬁcient implementation of the
backup step leads to competitive planning.

For future work we propose considering the problem of
ﬁnding plans with quality guarantees, for example, plans with
optimal execution length, as well as planning under more gen-
eral inﬁnite-horizon executions. Also, the use of more sophis-
ticated heuristics for driving the planning algorithm should
be considered, for example the ones proposed by Rintanen
[2004b] generalized to partially observable problems.

References
[Bertoli et al., 2001] Piergiorgio

Bertoli,

Alessandro
Cimatti, Marco Roveri, and Paolo Traverso. Planning
in nondeterministic domains under partial observability
via symbolic model checking. In Bernhard Nebel, editor,
Proceedings of the 17th International Joint Conference on
Artiﬁcial Intelligence, pages 473–478. Morgan Kaufmann
Publishers, 2001.

[Bonet and Geffner, 2000] Blai Bonet and H´ector Geffner.
Planning with incomplete information as heuristic search
in belief space. In Steve Chien, Subbarao Kambhampati,
and Craig A. Knoblock, editors, Proceedings of the Fifth
International Conference on Artiﬁcial Intelligence Plan-
ning Systems, pages 52–61. AAAI Press, 2000.

[Burch et al., 1994] J. R. Burch, E. M. Clarke, D. E. Long,
K. L. MacMillan, and D. L. Dill. Symbolic model check-
ing for sequential circuit veriﬁcation. IEEE Transactions
on Computer-Aided Design of Integrated Circuits and Sys-
tems, 13(4):401–424, 1994.

[Kaelbling et al., 1998] Leslie Pack Kaelbling, Michael L.
Littman, and Anthony R. Cassandra. Planning and act-
ing in partially observable stochastic domains. Artiﬁcial
Intelligence, 101(1-2):99–134, 1998.

[Madani et al., 1999] Omid Madani, Steve Hanks, and Anne
Condon. On the decidability of probabilistic planning
and inﬁnite-horizon partially observable Markov decision
problems. In Proceedings of the 16th National Conference
on Artiﬁcial Intelligence (AAAI-99) and the 11th Confer-
ence on Innovative Applications of Artiﬁcial Intelligence
(IAAI-99), pages 541–548. AAAI Press, 1999.

[Mundhenk et al., 2000] Martin Mundhenk,

Judy Gold-
smith, Christopher Lusena, and Eric Allender. Complexity
of ﬁnite-horizon Markov decision process problems. Jour-
nal of the ACM, 47(4):681–720, 2000.

[Puterman, 1994] M. L. Puterman. Markov decision pro-
cesses: discrete stochastic dynamic programming. John
Wiley & Sons, 1994.

[Rintanen, 2002] Jussi Rintanen. Backward plan construc-
tion under partial observability. In Malik Ghallab, Joachim
Hertzberg, and Paolo Traverso, editors, Proceedings of the
Sixth International Conference on Artiﬁcial Intelligence
Planning Systems, pages 173–182. AAAI Press, 2002.

[Rintanen, 2004a] Jussi Rintanen. Complexity of planning
with partial observability.
In Shlomo Zilberstein, Jana
Koehler, and Sven Koenig, editors, ICAPS 2004. Proceed-
ings of the Fourteenth International Conference on Auto-
mated Planning and Scheduling, pages 345–354. AAAI
Press, 2004.

[Rintanen, 2004b] Jussi Rintanen. Distance estimates for
planning in the discrete belief space. In Proceedings of the
18th National Conference on Artiﬁcial Intelligence (AAAI-
2004) and the 13th Conference on Innovative Applica-
tions of Artiﬁcial Intelligence (IAAI-2004), pages 525–
530. AAAI Press, 2004.

[Smallwood and Sondik, 1973] Richard D. Smallwood and
Edward J. Sondik. The optimal control of partially observ-
able Markov processes over a ﬁnite horizon. Operations
Research, 21:1071–1088, 1973.

[Weld et al., 1998] Daniel S. Weld, Corin R. Anderson, and
David E. Smith. Extending Graphplan to handle uncer-
tainty and sensing actions. In Proceedings of the 15th Na-
tional Conference on Artiﬁcial Intelligence (AAAI-98) and
the 10th Conference on Innovative Applications of Artiﬁ-
cial Intelligence (IAAI-98), pages 897–904. AAAI Press,
1998.

