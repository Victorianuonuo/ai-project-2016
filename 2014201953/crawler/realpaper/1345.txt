Session  24  Perception  for  Robots 

THOUGHTS ABOUT A VISUALL 

GUIDED GRASP REFLEX 

Richard  L, 
Department  of  Mathematics 
Colorado  State 
Fort  Collins, 

Didday 
and  Computer  Science 
University 
Colorado 

Abstract 

Animal  visual  orientinq  reflexes 

This  paper  describes  a  preliminary  attempt  to 

apply  organizational  principles  taken  from  animal  per(cid:173)
ceptual  processes  to  the  problem  of  providing  a  robot 
visual  qrasp  reflex.  The  goal  is  to  provide  a  cheap, 
rapid  mechanism  for  directinq  a  hand/arm  to  grasp  one 
of  several  arbitrarily  shaped  objects  in  the  visual 
scene.  A  proqram  which  implements  a  simple  form  of 
such  a  reflex  is  described. 

Introduction 

The  structure  of  animal  nervous  systems  was  f i r st 

analyzed  in  terms  of  reflexes.  A  reflex  is  sometimes 
thought  of  as  a  response  which  involves  only  a  few 
synaptic  delays  and  which  is  independent  of  higher 
centers  of  the  brain.  Thus  the  doctor's  hammer  strik-
ing  (and  stretchinq)  the  tendon  just  below  the  kneecap 
results  in  a  reflexive  kick  no  matter  what  we  may  be 
thinklnq  about  at  the  time.  However,  more  current 
notions  hold  that  reflexes  are  to  be  thought  of  as 
part  of  a  hierarchical  control  scheme,  functioninq  to 
carry  out  incompletely  specified  commands  from  above. 
Thus,  we  find  that  the  familiar  knee  jerk  reflex  does 
not  occur  when  the  knee's  owner  is  in  free  fall9 
While  this  particular  reflex  is  adequate  and  appro(cid:173)
priate  in  some  cases  (especially  locomotion),  it  is 
under  the  control  of  other  reqions  of  the  brain.  And 
so  it  goes: 
archically,  we  can  discover  layer  upon  layer  of 
relatively  autonomous  subsystems  controlling  and  con(cid:173)
trolled  by  others. 

if  we  look  at  the  nervous  system  hier(cid:173)

The visual  orientinq  reflex  has  received  a  sub(cid:173)
stantial  amount  of  attention  in  a  wide  ranqe  of 
animals.  Attempts  to  model  it  have  led  me  throuqh  a 
number  of  concepts  which  I  thouqht  would  be  interest-
inq  to  apply  to  the  robot  problem.  The  main  notion 
is  that  this  system  is  a  rapid,  parallel  device  which 
typically  needs  to  know  remarkably  l i t t le  about  an 
object  to  respond  appropriately  to  i t.  Thus,  it 
seems  to  me,  a  robot  grasp  reflex  could  be  constructed 
which  could  appropriately  grasp  an  object  in  the 
visual  scene  quickly  and  cheaply  upon  a  very  crude 
command  (i.e.  without  beinq  told  the  object's  exact 
location,  orientation  or  shape). 

The  next  section  of  this  paper  provides  a  brief 
review  of  midbrain  mechanisms  which  mediate  the  vis(cid:173)
ual  orienting  response.  The  last  section  describes 
a  rather  brief  and  superficial  effort  at  applying 
notions  from  the  nervous  system  to  the  problem  of 
usinq  a  serial  computer  to  control  a  robot  hand  in  a 
simple  environment.  Finally  there  are  some  suqqes-
tions  for  generalizinq  to  a  more  realistic  case. 

Author's  address  as  of  September,  1973: 

R.  L.  Didday 
Information  and  Computer  Science 
Applied  Sciences  Buildinq 
University  of  California 
Santa  Cruz,  California  95060 

658 

The  optic  tectum  (or  superior  colllculus  as  this 
midbrain  structure  is  called  in  mammals)  is  common  to 
vertebrates  and  is  implicated  in  visual  localizing 
responses. 
In  the  frog,  it  mediates  visual  approach 
responses  (snapping  and  orienting),  while  in  humans 
it  produces  reflex  eye  movements.  Let  us  look  at  its 
structure  in  the  frog. 

The  optic  tectum  stands  between  sensory  and  motor 
systems.  There  is  an  orderly,  somatotopic  mappinq  of 
points  on  the  retina  onto  the  tectum  and  from  tectum 
to  motor  response.  This  is  illustrated  by  microelec-
trode  recordlnqs  and  by  electrical  stimulation  of  the 
tectum—such  experiments  show  that  a  particular  region 
of  the  tectum  can  produce  a  motor  response  which  is 
"aimed"  at  the  same  region  of  visual  space  which  pro(cid:173)
jects 

that  spot  on 

tectum.  8 

the 

to 

An  early  paper  by  Pitts  and  McCulloch  orovides 
a  provocative  framework  for  describinq  the  operation 
of  the  frog.  tectum.  Picture  the  retina  and  its  pro(cid:173)
cesses  as  sendinq  a  spatially  arrayed  somatotopically 
mapped  representation  of  the  visual  scene  through  the 
ganalion  cell  axons  to  the  tectum.  Regions  of  this 
array  which  are  highly  excited  correspond  to  regions 
of  the  visual  scene  containing  visual  details  which 
" f i t"  the  feature  detecting  processes  of  the  retina. 
We  might  then  imagine  that  each  locus  of  excitation 
on  the  tectum  triggers  a  motor  command  aimed  at  the 
corresponding  point  in  space  so  that  the  summated 
effect  of  all  the  muscle  commands  yields  a  response 
to  the  "average"  location—the  "feature  center  of 
gravity"  (see  Didday4  for  a  more  detailed  discussion). 
This  scheme  would  predict  proper  behavior  when  faced 
by  one  "prey  object",  but  would  nredict  responses  to 
the  average  spatial  location  of  a  number  of  visual 
stimuli.  'Surprisinqly  enouqh,  this  does  sometimes 
occur  in  the  frog6,  but  usually  response  is  made  to 
only  one  of  those  objects  present-  The  basic  Pitts-
McCulloch  scheme  does  not  predict  this,  usually  more 
appropriate,  type  of  resnonse. 

The  notion  that  the  image  of  an  object  can  direct(cid:173)

ly  lead  to  the  proper  combination  of  muscle  contrac(cid:173)
tions  required  to  deal  with  it  is  very  appealing. 
It 
offers  a  rapid  way  to  deal  with  the  problem  of  orient-
ina  the  body  with  respect  to  objects  in  the  environ(cid:173)
ment.  One  possible  way  to  allow  for  responses  to  only 
one  of  several  stimuli  present  while  maintaining  the 
feature  of  allowing  the  stimulus  to  shape  the  response 
directly  is  to  alter  the  Pitts-NcCulloch  scheme  by 
dividinq  the  incoming  information  into  overlapping 
regions  and  providina  a  mechanism  to  select  one  re(cid:173)
gion.  The  "super-position"  effect  which  uses  an 
object's  image  to  tailor  the  response  then  works  with(cid:173)
in  the  chosen  region.  The  more  rare  responses 
"between"  two  stimuli  would  then  respresent  failure 
of  the  selection  mechanism. 

Clearly,  there  are  a  great  number  of  ways  to 

implement  such  a  function,  and  three  different  imple(cid:173)
mentations  are  contrasted  in  Didday4.  One  implemen(cid:173)
tation  utilizes  cells  which  function  much  like  the 
"newness"  and  "sameness"  cells  described  by  Lettvin, 
et.  a l . '. 

Arbib  and  Didday1  describe  how  this  basic  frame-
work  might  be  used  as  a  locallzina  reflex  which  acts 
in  conjunction  with  recognition  mechanisms  to  form  a 
percelvlna  system  capable  of  using  memory  to  interact 
with  a  complex  environment. 

The  basic  organization  provides  a  means  of  using 

features 

to  control  motor  behavior  which  must 
visual 
be  accurately  tailored  to  local  details  of  an  object 
In  the  visual  scene.  Behavior  which  depends  on  de(cid:173)
t a i l ed  analysis  and  knowledge  of  more  subtle  aspects 
of  the  objects 
( c o r t i c al  visual  centers  in  mammals).  The  optic  tec(cid:173)
tum  or  superior  colliculus 
is  seen  as  performing 
a  reflexive 

is  carried  out  by  other  reqions 

l o c a l i z i nq  r o l e. 

thus 

A  grasp  reflex  f or  robots 

This  section  describes  a  f i r st  attemot  to  define 

a  system  which  is  organized  like  the  visual  mechan(cid:173)
isms  depicted  in  the  previous  section.  The  motor 
behavior  which  the  system  is  to  control 
is  arm  and 
hand  movement. 

I  have  made  a  number  of  assumptions  in  what 

f o l l o w s,  many  of  them  with  an  eye  to  simplifyinq  the 
problem.  Many  of  them  could  be  relaxed  with  present 
knowledge  and  further  e f f o r t.  Some  thoughts  on  such 
expansions  of  the  power  of  the  reflex  are  described 
l a t e r. 
The  most  serious  simplifying  assumption  is 
that  the  world  may  be  treated  as  two-dimensional. 

One  of  the  principal  notions  put  f o r th  by  Arbib 

and  Didday1  was  that  the  qoal  of  perception  is  in 
determining  appropriate  motor  behavior.  This 
the  idea  that  the  task  of  perception  is  not  to  con(cid:173)
struct  a  delicately  detailed  internal  reconstruction 
of  the  input  scene  but  rather  to  help  choose  possible 
motor  responses.  Thus  we  find  sensory  feature  detec(cid:173)
tors  elegantly  matched  to  possible  motor  response 
(or  perhaps  vice  versa).  The  feature  detectors  soon 
to  be  described  owe  t h e ir  details  to  the  hand  they 
are  to  help  c o n t r o l. 

led  to 

The  hand  is  assumed  to  consist  of  two  "fingers" 

on  a  palm  as  shown  in  Fig.  1.  Details  of  the  hand 
which  are  reflected 
in  the  desiqn  of  the  feature 
detectors  are  the  length  and  width  of  the  fingers 
and  the  maximum  opening  distance  of  the  fingers.  As 
seems  to  be  the  case  in  animal  nervous  systems,  motor 
programs  (are  assumed  to)  exist  which,  when  given  the 
appropriate  parameters,  can  direct  the  hand  so  that 
the  palm  lies  over  point  (x,  y}  at  an  angle  O  and 
with  the  fingers  w  units  apart. 
It  is  then  the  task 
of  the  grasp  reflex  to  analyze  the  visual  scene  and 
produce  values  of  these  four  parameters  which  are 
appropriate  for  graspino  some  object  in  the  scene. 
Four  parameters  suffice  because  the  system  to  be 
described  functions 

two  dimensions  only. 

in 

Further  simplifications  arise  from  the  assump(cid:173)

input  is  ob(cid:173)

t i on  t h at  the  two-dimensional  visual 
tained  from  "above"  the  real  world  scene  and  in  such 
a  way  that  a ll  objects  are  seen  from  the  same  dis(cid:173)
tance.  Thus  an  object's  size  is  immediately  recov(cid:173)
erable  from  the  size  of  i ts  retinal 
Finally 
I  have  assumed  that  a ll  objects  are  darker  than  the 
surround. 

image. 

Figure  2  provides  an  outline  of  the  conceptual 
organization  of  the  system.  The  implementation  is 
for  a  serial  computer,  thus  where  layers  of  parallel 
this 
operating  c e ll 
implementation  simply  maintains  l i s ts  of  the  loca(cid:173)
t i o n,  orientation  and  level  of  excitation  of  active 
" c e l l s ".  The  terminology  from  nervous  systems  is 
used  throughout,  however. 

types  would  exist  in  animals, 

There  are  f i ve  classes  of  " c e l l s"  which  process 

the  visual  scene  to  produce  a  specific  motor  command. 
All  are  " d i r e c t i o n a l ".  The  f i r st  two  are  sensory 
feature  detectors  which  receive 
inputs  from  local 
regions  of  the  retina  and  detect  "tongues"  (class  a) 
and  "Inward  boundedness"  (class  b).  These  somewhat 
obscure  descriptions  are  ellucidated  in  Fig.  3a  and 
b.  There 
is  already  a  larqe  amount  of  detail  of  the 
nature  of  the  hand  included  at  this  l e v e l.  The  max(cid:173)
imum  opening  width  of  the  hand  determines  the  width 

of  the  excitatory  region  of  the  class  a  c e l l s.  The 
lenqth  of  the  class  b  cells  corresponds  to  the  length 
of  the  hand,  and  the  width  of  the  i n h i b i t o ry  cell  row 
in  the  class  b  cells  corresponds 
to  the  widths  of  the 
fingers.  All 
these  would  change  1f  a  d i f f e r e nt  hand 
were  to  be  used. 

In  a  nervous  system  implementation,  there  would 

be  some  number  of  overlapping  cells  of  both  classes 
for  each  point  on  the  r e t i n a,  and  the  outnuts  of  these 
feature  detectors  would  l ie  in  some  topographically 
mapped  region. 
a  l i st  is  created  with  an  element  for  each  class  a 
c e ll  which  has  a  non-zero  level  of  e x c i t a t i o n,  and 
s i m i l a r ly  for  class  b. 

In  the  current,  serial 

implementation, 

Class  d  cells  are  excited  by  the  concurrence  of 
a  class  a  cell  at  angle  e  and  a  class  b  c e ll  at  the 
same  anole  in  a  reaion  "to  the  l e ft  of"  the  class  a 
c e l l.  Thus  a  class  d  cell  siqnals  the  j o i nt  existence 
of  a  "tonque"  and  a  reaion  appropriate  for  the  l e ft 
finoer  to  occuny.  Class  e  cells  do  the  same  but  for 
the  r i g ht 

finger. 

Class  c  cells  are  excited  by  concurrent  class  d 
and  class  e  excitation  which  is  centered  on  the  same 
class  a  c e l l.  Thus  class  c  excitation  sinnals  an 
appropriate  angle  and  position  for  the  nalm  of  the 
hand  to  occupy. 

The  selection  mechanism  operates  on  the  t o t a l i ty 
of  class  c  e x c i t a t i o n,  and  selects  that  spatial  region 
which  has  maximal  class  c  e x c i t a t i o n,  j u st  as  the 
selection  mechanism  in  the  froq  model  selects 
that 
reqion  which  has  maximal  "foodness"  potency.  Since 
an  object  which 
is  small  enough  to  f it  e n t i r e ly  within 
the  opened  hand  could  be  qrasped  equally  well  from  any 
d i r e c t i o n,  there  w i ll 
in  general  be  many  class  c  cells 
excited.  To  aid  the  selection  mechanism  in  such  cases, 
a  bias  is  applied  to  those  class  c  f i r i nq  levels  which 
result  in  arm  positions  which  are  less  "awkward"  beinq 
favored.  That  i s,  hand  orientations 
for  the 
least  deviation  from  the  hand/arm  startinq  position 
are  preferred. 

that  c a ll 

Once  a  region  has  been  chosen,  the  class  c,  class 

in  that  reqion  are 

d  and  class  e  excitation  levels 
used  to  derive  the  motor  command  (the  positional  par(cid:173)
ameters  for  the  hand).  The  hand  position  and  orien(cid:173)
tation  command  is  obtained  by  computing  the  sum  of 
the  x  and  y  coordinates  and  angle  for  each  class  e 
cell 
each  c e l l. 
this  weighting  process  which  allows 
the  determination  of  position  and  angle  to  a  greater 
precision  than  the  spacing  of  the  c e l l s.  The  command 
for  finger  width  is  computed  in  a  similar  manner  from 
class  d  and  class  e  c e l ls  within  the  chosen  region. 

in  the  region  weighted  by  the  Firing  rate  of 

It  is 

Figs.  4-6  show  three  visual  scenes  on  which  the 

simulated  mechanism  has  been  tested.  The  input  scene 
is  a  50  x  50  array  of  squares.  The  actual 
incut  to 
the  program  is  an  array  which  for  each  square  has  a 
number  corresponding  to  the  proportion  of  that  square 
which  is  dark.  Fig.  4  i l l u s t r a t es  a  blob  shaped  ob(cid:173)
j e ct  which  has  a  lobe  to  the  r i g ht  which  (qiven  the 
feature  detectors  used) 
is  good  for  grasping.  This 
region  produced  maximal  class  c  e x c i t a t i o n,  so  the 
parameters  are  tailored  to  qrasp  the  object  there. 
The  "hand"  is  sketched  in  the  chosen  orientation. 

Fig.  5a  i l l u s t r a t es  an  object  which  is  squared 
o ff  at  one  end  and  pointed  at  the  other  and  which  is 
at  an  angle  with  respect  to  the  coordinates  of  the 
input  g r i d.  Fig.  5b  i l l u s t r a t es  the  regions  corre-
spondinq  to  those  class  a  cells  which  were  excited. 
The  response  is  made  up  of  weighted  sums  of  this 
information,  and  so  is  appropriate  to  the  position  of 
the  object  even  though  no  cell 
is  oriented  colinearly 
with  any  side  of  i t. 

Fig.  6  I l l u s t r a t es 

the  a b i l i ty  of  the  mechanism 
to  choose  one  of  several  objects  present.  Given  the 
forms  of  the  class  a  and  class  b  c e l l s,  a  squared 
o ff  end 
is  a 

is  more  appropriate  for  graspino  than 

659 

References 

1  Arbib,  M.  A.  and  Pidday,  R.  L.  (1971).  The  organi(cid:173)
zation  of  action  oriented  memory  for  a  perceivina 
system.  Part  I:  The  basic  model..  J.  Cybernet(cid:173)
ics,  1,  3. 

2  Didday,  R.  L.  (1970).  The  simulation  and  modelina 
of  distributed  information  processing  in  the  frog 
visual  system.  Stanford  University  Inform. 
Systems  Lab.  Tech.  Rep.,  6112. 

3  Didday,  R.  L.  (1971).  Simulatina  distributed  com(cid:173)
Int.  J.  Man-Machine 

putation  in  nervous  systems. 
Studies,  3,  99. 

4  Didday,  R.  L.  (1972),  Structural  models  of  simple 
Int.  J.  Man-Machine 

sensory-motor  coordination. 
Studies,  4,  439. 

5  Guzman,  A.  (1967).  Some  aspects  of  pattern  recog(cid:173)

nition  by  computer.  MAC  TR  37,  MIT. 

6 

Inole,  D,  (1970),  Visumotor  functions  of  the  froo 

optic  tectum.  Brain  Behav.  Evol.  3,  57. 

7  Lettvin,  J.  Y.,  Maturana,  H.  R., McCulloch, W.  S. 

and  Pitts,  W.  H.  (1961).  Two  remarks  on  the 
visual  system  of  the  froq. 
tion.  Ed.  W.  W.  Rosenblith,  pp.  757-776. 
Cambridge,  Mass,  :  MIT  Press. 

In  Sensory  Communica(cid:173)

2  Pitts,  W.  H.  and  McCulloch,  W.  S.  (1947).  How  we 
know  universals:  The  perception  of  auditory  and 
visual  forms.  Bull.  math.  Biophys.,  9,  127. 
This  paper  is  reprinted  in  McCulloch,  W.  5. 
(1965).  Embodiments  of  Mind.  Cambridoe,  Mass.  : 
MIT  Press, 

9  Roberts,  T.  D.  M.  (1967).  Neurophysiology  of 
postural  mechanisms.  Butterworths,  n.  66. 

blob,  so  the  upper  object  is  chosen.  The  approach 
from  the  right  was  chosen  due  to  the  bias  toward 
smaller  arm  movement. 

Conclusion 

In  its  current,  preliminary  form,  the  grasp  re(cid:173)

flex  carries  out  the  operation  "go  get  the  best  look-
inq  thinq  to  grasp".  What  is  "best"  is  determined  by 
the  two  classes  of  feature  detection  units  operating 
on  the  input  scene.  Another  layer  of  feature  detec(cid:173)
tors  which  process  the  scene  before  it  gets  to  the 
qrasp  reflex  could  bias  what  is  "best".  This  new 
layer  (which  would  be  under  program  control)  could 
serve  to  enrich  the  power  of  the  grasp  reflex  by 
allowing  different  sorts  of  things  to  be  "best"  at 
different  times. 
I f,  for  example,  "handles"  have 
some  particular  feature  characteristics,  appropriate 
settings  of  this  new  layer  could  cause  the  reflex  to 
pick  an  object  up  by  the  handle  (for  using  it)  one 
time,  and  pick  it  up  by  some  other  appropriate  part 
(for  givinq  the  object  to  someone  else)  the  next. 
Like  any  reflex,  the  mechanism  has  a  f a i r ly 

narrow  range  in  which  it  can  function  appropriately. 
I f,  for  example,  the  reflex  chooses  to  grasp  an  ob(cid:173)
ject  which  turns  out  to  be  too  heavy  to  move,  some 
higher  level  function  which  makes  a  more  sophisticated 
analysis  of  the  situation  will  have  to  be  alerted. 
In 
cases  when  the  grasp  reflex  is  adequate,  it  can  serve 
to  perform  the  task  of  orienting  the  hand  very  rapidly 
at  very  l i t t le  computational  effort. 

The  scheme  must  be  further  enlarged  to  incor(cid:173)
porate  "neqative"  sorts  of  information,  e.g.  excita(cid:173)
tion  caused  by  objects  not  in  the  chosen  region  could 
be  used  to  prevent  those  motor  responses  which  would 
bump  into  other  objects.  Also,  negative  information 
could  be  used  to  allow  picking  up  an  object  with  the 
finqertips  when  it  is  shaped  so  that  a  f u ll  hand  qrip 
is  impossible.  More  importantly,  negative  information 
is  needed  when  the  object  is  so  small  that  it  can  be 
picked  up  from  any  orientation. 
In  this  case,  even 
weighting  in  favor  of  minimal  arm  movements  will  not 
preclude  the  possibility  that  the  average  location  nf 
excitation  lies  within  the  boundaries  of  the  object-
thus  producinq  a  command  which  would  tend  to  place 
the  hand  on  top  of  the  chosen  object.  One  other  pos(cid:173)
s i b i l i ty  that  shows  promise  here  is  to  use  information 
from  the  object  to  alter  the  size  and  shape  of  the 
regions  used  by  the  selection  mechanism. 

The  most  important  alteration  would  be  to  have 

the  system  function  in  a  three  dimensional  world. 
Feature  detectors  responsive  to  visual  features  such 
as  those  Guzman5  utilized  might  prove  helpful  here. 
Most  of  Guzman's  features  are  local  in  nature—if  com-
plex  global  features  prove  to  be  necessary  then  the 
reflex  organization  becomes  unattractive—the  reflex 
is  of  value  only  if  it  is  extremely  fast. 

It  is  conceivable  that  the  organization  described 
here  is  really  only  appropriate  to  the  parallel  nature 
of  the  brain.  Much  of  the  efforts  in  the  analysis  of 
Didday2,4  were  concerned  with  the  problems  of  global 
versus  local  information  flow. 
In  the  brain,  global 
functions  are  very  costly  (require  many  interconnec(cid:173)
tions)--in  a  serial  computer  they  are  somewhat  more 
expensive  than  local  ones  due  to  the  combinatorics 
Involved. 
of  organization  from  the  brain  is  of  use  to  robots. 
Perhaps  the  organization  into  hierarchically  con(cid:173)
trolled  reflexes  will  provide  less  direct  insights 
than  those  suggested  here,  but  it  seems  to  have  been 
so  universally  employed  in  brains  as  to  be  of  some 
basic  value-

It  remains  to  be  seen  whether  takinq  ideas 

660 

Fig.  2  A  visualization  of  the  scheme  for  determining  the 
x,  y  ,  o  position  of  the  hand.  Cell  firing  is  in(cid:173)
dicated  by  a  small  arrow  whose  orientation  corre(cid:173)
sponds  to  the  orientation  of  the  receptive  field 
of  the  cell.  The  selection  mechanism  chooses  the 
region  containing  maximal  excitation. 

Fig.  3  The  receptive  fields  of 

typical  class  a  and 
class  b  cells.  Visual  inputs  to  squares  narked 
" i"  have  an  inhibitory  effect,  those  falling  on 
squares  marked  "e"  have  an  excitatory  effect. 
There  is  a  class  a  and  a  class  b  "cell"  for 
each  point  in  the  visual  scene  and  in  each  o r i(cid:173)
entation  0°,  45°,  90°,  135°,  180°,  225°,  270° 
and  315  .  Combinations  of  cells  at  these 
orientations  and  having  differing  firing  rates 
can  deal  with  visual  events  lying  at  any  angle. 

Class  a  cells  detect  "tongues"  --  i.e. 
places  that  are  not  too  wide  for  the  hand  to 
grasp.  Class  b  cells  detect  regions  which  a 
finger  could  f it  around. 

661 

F1g.  4  A  blob.  The  hand  parameters  chosen  would 
In 

place  the  hand  in  the  position  shown. 
this  computer  run,  eleven  different  excited 
class  c  cells  were  in  the  chosen  region. 

662 

Fig.  5a  An  object  oriented  at  about  256°.  Weighted 
combinations  of  class  c  cells  at  angles  100  , 
225°,  270°  and  315°  combined  to  specify  the 
appropriate  hand  angle. 

Fig.  5b  Details  of  the  process  showing  the  class  a 
regions  which  participated  in  making  up  the 
class  c  firing  which  in  turn  tailored  the 
motor  command.  Amount  of  overlap  with  the 
object  determines  firing  rate. 

663 

