Gossip-Based Aggregation of Trust in Decentralized Reputation Systems

Ariel D. Procaccia and Yoram Bachrach and Jeffrey S. Rosenschein

School of Engineering and Computer Science

The Hebrew University of Jerusalem

{arielpro,yori,jeff}@cs.huji.ac.il

Abstract

Decentralized Reputation Systems have recently
emerged as a prominent method of establishing
trust among self-interested agents in online envi-
ronments. A key issue is the efﬁcient aggregation
of data in the system; several approaches have been
proposed, but they are plagued by major shortcom-
ings.
We put forward a novel, decentralized data man-
agement scheme grounded in gossip-based algo-
rithms. Rumor mongering is known to possess al-
gorithmic advantages, and indeed, our framework
inherits many of their salient features: scalabil-
ity, robustness, globality, and simplicity. We also
demonstrate that our scheme motivates agents to
maintain a sparkling clean reputation, and is inher-
ently impervious to certain kinds of attacks.

1 Introduction

In open multiagent environments, self-interested agents are
often tempted to employ deceit as they interact with others.
Fortunately, dishonest agents can expect their victims to re-
taliate in future encounters. This “shadow of the future” mo-
tivates cooperation and trustworthiness.

However, as the size of the system grows, agents have an
increasingly small chance of dealing with another agent they
already know; as a consequence, building trust in domains
teeming with numerous agents becomes much harder. Repu-
tation systems address this problem by collecting and spread-
ing reports among agents, so that agents may learn from oth-
ers’ experience. To put it differently, agents are intimidated
by the “shadow of the future” today, even though tomorrow
they are most likely to meet total strangers.

Reputation systems can be decomposed into two major
components: 1) the trust model, which describes whether an
agent is trustworthy, and 2) the data management scheme.
The latter component poses some interesting questions, since
it is imperative to efﬁciently aggregate trust-related informa-
tion in the system. A simple solution is maintaining a central
database that contains the feedback gathered from past trans-
actions. Unfortunately, this solution is inappropriate in dis-
tributed environments where scalability is a major concern, as

the database soon becomes a bottleneck of the system. More-
over, this approach is not robust to failures. Previous work
on decentralized reputation schemes suffered from their own
major problems: agents have to maintain complex data struc-
tures, evaluation of trust is based only on local information,
or there are restrictive assumptions on the trust model.1

We approach this hornets’ nest by designing a novel
method of trust aggregation (i.e., a reputation system’s data
management scheme). The method is demonstrated in this
paper for a simple trust model, but it can be extended to more
complex models.

The roots of our gossip-based approach can be traced to a
seminal paper by Frieze and Grimmett [1985]: a rumor starts
with one agent; at each stage, each agent that knows the ru-
mor spreads it to another agent chosen uniformly at random.
The authors show that the rumor reaches all agents quickly
(a result that coincides with real life). We directly rely on
more recent results, surveyed in the next section. It has been
shown that aggregate information, such as averages and sums
of agents’ inputs, can be calculated using similar methods of
uniform gossip in a way that scales gracefully as the number
of agents increases. Furthermore, the approach is robust to
failures, and the results hold even when one cannot assume a
point-to-point connection between any two agents (as is the
case in peer-to-peer [P2P] networks).

In our setting, each agent merely keeps its private evalua-
tion of the trustworthiness of other agents, based on its own
interactions.2 When an agent wishes to perform a transaction
with another, it obtains the average evaluation of the other’s
reputation from all agents in the system, using a gossip-based
technique. Although the presented algorithms estimate the
average reputation, they can be easily adapted to estimating
whether a certain agent has a high reputation in the eyes of
the majority of the agents, or certain other similar metrics.
Thus, the framework we advocate for aggregating reputation
information accommodates more sophisticated trust models.
Some advantages are immediately self-evident. Each agent
stores very little information, which can be simply and efﬁ-
ciently organized, and evaluation of trust is based on global
information. Additionally, this framework inherits the advan-

1The “or” is not exclusive.
2The question of how agents set this valuation is outside the

scope of this paper.

IJCAI-07

1470

tages of gossip-based algorithms: scalability, robustness to
failure, decentralization, and as a consequence, applicability
in peer-to-peer networks.

We show that our scheme has two other major advantages.
An important desideratum one would like a reputation sys-
tem to satisfy is motivating agents to maintain an untarnished
reputation, i.e., to be absolutely trustworthy (as opposed to,
say, being generally trustworthy but occasionally cheating).
We show that our data management scheme, together with an
extremely simple trust model, satisﬁes this property. We also
demonstrate that our scheme is inherently resistant to some
attacks (with no assumptions on the trust model). This is a
positive side effect of the exponential convergence rates of
the algorithms we use.

In this paper we do not address the problem of designing
a trust model. Rather, we suggest an approach for agents to
aggregate distributed trust information so as to decide with
whom to carry out transactions.

2 Gossip-Based Information Aggregation
In this section, we survey the relevant results of Kempe, Do-
bra and Gehrke [Kempe et al., 2003]. These algorithms allow
us to estimate the average of values held at network nodes (in
our case, these values will be the reputation values concern-
ing a particular agent). [Kempe et al., 2003] also shows how
to calculate other functions over these values, such as the ma-
jority function and sum. Thus our algorithms can be adapted
for other, more sophisticated models of trust.

We begin by describing a simple algorithm, PUSH-SUM, to
compute the average of values at nodes in a network. There
are n nodes in the system, and each node i holds an input
xi ≥ 0. At time t, each node i maintains a sum st,i and a
weight wt,i. The values are initialized as follows: s0,i = xi,
w0,i = 1. At time 0, each node i sends the pair s0,i, w0,i to
itself; at every time t > 0, the nodes follow the protocol given
as Algorithm 1.

Algorithm 1

(cid:2)
(cid:2)

1: procedure PUSH-SUM
2:
3:
4:
5:
6:

Let {(ˆsl, ˆwl)}l be all the pairs sent to i at time t − 1
st,i ←
wt,i ←
Choose a target ft(i) uniformly at random
wt,i) to i and to ft(i)
Send the pair ( 1
2
st,i
wt,i is the estimate of the average at time t

l ˆsl
l ˆwl

st,i, 1
2

7:
8: end procedure

Let U (n, δ, ) (the diffusion speed of uniform gossip) be an
upper bound on the number of turns PUSH-SUM requires so
that for all t ≥ U (n, δ, ) and all nodes i,

(cid:3)(cid:3)(cid:3)(cid:3)(cid:3) st,i

wt,i

1(cid:2)

·

k xk

(cid:3)(cid:3)(cid:3)(cid:3)(cid:3) ≤ 

xk

(cid:4)

k

− 1
n

(the relative error is at most ) with probability at least 1 − δ.
Theorem 1 ([Kempe et al., 2003]).
1. U (n, δ, ) = O(log n + log 1

δ + log 1

 ).

2. The size of all messages sent at time t by PUSH-SUM is
O(t + maxi bits(xi)), where bits(xi) is the number of
bits in the binary representation of xi.

A major advantage of gossip-based algorithms is their ro-
bustness to failures: the aggregation persists in the face of
failed nodes, permanent communication failures, and other
unfortunate events. Further, no recovery action is required.
The assumption is that nodes can detect whether their mes-
sage has reached its destination; PUSH-SUM is modiﬁed so
that if a node detects its target failed, it sends its message to
itself.
Theorem 2 ([Kempe et al., 2003]). Let μ < 1 be an upper
bound on the probability of message loss at each time step,
and let U (cid:2)
be the diffusion speed of uniform gossip with faults.
Then:

U (cid:2)(n, δ, ) =

2

(1 − μ)2

U (n, δ, ).

(cid:2)

In several types of decentralized networks, such as P2P net-
works, point-to-point communication may not be possible. In
these networks, it is assumed that at each stage nodes send
messages to all their neighbors (ﬂooding). When the under-
lying graph is an expander, or at least expected to have good
expansion, results similar to the above can be obtained. Fortu-
nately, it is known that several peer-to-peer topologies induce
expander graphs [Pandurangan et al., 2001].

(cid:3)(cid:3)(cid:3) st,i

In the rest of the paper, we have xi ≤ 1, and in particular
i xi ≤ n. Therefore, it is possible to redeﬁne U to be an
upper bound on the number of turns required so that for all
k xk
t ≥ U and all nodes i, the absolute error
is at most  with conﬁdence 1 − δ, and it still holds that
U (n, δ, ) = O(log n + log 1
 ). Hereinafter, when
we refer to U we have this deﬁnition in mind.
Remark 1. The protocol PUSH-SUM is presented in terms of
a synchronized starting point, but this assumption is not nec-
essary. A node that poses the query may use the underlying
communication mechanism to inform all other nodes of the
query; convergence times are asymptotically identical.

δ + log 1

(cid:2)

− 1
n

(cid:3)(cid:3)(cid:3)

wt,i

3 Our Framework
Let the set of agents be N = {1, . . . , n}. Each agent i ∈ N
holds a number rj
i ∈ [0, 1] for each agent j ∈ N (including
itself). This number represents j’s reputation with respect to
i, or to put it differently, the degree to which i is willing to
trust j. As agents interact, these assessments are repeatedly
updated. We do not in general concern ourselves with how
agents set these values.

When an agent i is deliberating whether to deal with an-
other agent j, i wishes to make an informed evaluation of the
other’s reputation. Let ¯rj =
be the average of j’s rep-
utation with respect to all agents. Knowledge of ¯rj
would
give i a good idea of how trustworthy j is (this is, of course,
a simple model of trust).

rj
k

P

k
n

We show that in this scenario, agents can use gossip-based
algorithms to decide with whom to carry out transactions.
Also, in such a setting, agents are encouraged to keep a com-
pletely untarnished reputation. Similar results can be ob-
tained for more complex trust models.

IJCAI-07

1471

Algorithm 2
1: procedure EVAL-TRUST(i, j, δ, ) (cid:4) i evaluates ¯rj

with

accuracy , conﬁdence 1 − δ

2:
3:

for all k ∈ N do

xk ← rj
k

(cid:4) Inputs to PUSH-SUM are j’s

reputation w.r.t. agents

end for
run PUSH-SUM for U = U (n, δ, ) stages
return

4:
5:
sU,i
6:
wU,i
7: end procedure

A simple way to compute the average trust

is via

PUSH-SUM.

− ¯rj

(cid:3)(cid:3)(cid:3) st,i

The protocol EVAL-TRUST is given as Algorithm 2.
PUSH-SUM is executed for U = U (n, δ, ) stages. At time
U , it holds for all k ∈ N , and in particular for agent i, that

(cid:3)(cid:3)(cid:3) ≤ , with probability 1 − δ. In other words, the

wt,i
algorithm returns a very good approximation of j’s average
reputation.

In practice, when two agents i and j interact, i may eval-
uate j’s reputation (and vice versa) by calling EVAL-TRUST.
The protocol quickly returns the approximation of ¯rj
, based
on the values rj
k at the time EVAL-TRUST was called. Each
agent i keeps different values st,i and wt,i for every differ-
ent query that was issued by some other agent in the system,
and updates these values repeatedly according to PUSH-SUM.
Thus, at any stage every agent participates in many parallel
executions of PUSH-SUM.

A possible cause for concern is the amount of communi-
cation each agent has to handle at every turn. However, the
quick convergence of PUSH-SUM guarantees that the burden
will not be too great. Indeed, it is plausible to assume that
the number of new interactions at each turn is bounded by a
constant c (or at worst is very small compared to n). Each
such new interaction results in at most two new executions
of EVAL-TRUST, but the execution lasts at most U turns. To
conclude the point, each agent sends at most c·U = O(log n)
messages per turn.
Remark 2. The size of messages depends on how the rj
i are
calculated, and as mentioned above, this issue is outside the
scope of this paper. Nevertheless, there would usually be a
constant number of reputation levels (say, for instance, ri
j ∈
{0, 0.1, 0.2, . . . , 1}), so the message size would normally be
constant.

As the above method of aggregating an agent’s average
reputation relies on the gossip-based algorithm PUSH-SUM,
it inherits all the latter’s beneﬁts, in particular robustness to
failure and applicability in peer-to-peer networks.

4 The Beneﬁt of an Unstained Reputation
It is very desirable (indeed, crucial) that a reputation system
be able to induce truthfulness in agents. Naturally, an agent
with a stained reputation would be shunned by its peers, while
an agent with a good reputation would easily solicit deals
and transactions. A further step in this direction is motivat-
ing agents never to cheat. Indeed, an agent with a generally

good reputation, that only occasionally cheats, would proba-
bly be able to win the conﬁdence of peers; there is seemingly
no reason why an agent should not play false now and again.
Nevertheless, we consider in this section an extremely simple
and general trust model, and show that with the data manage-
ment scheme that we have presented, there is a social beneﬁt
to having a very high reputation: the higher the agent’s repu-
tation, the shorter the time required to close deals.

i

We consider a model in which each agent i has a reputa-
tion threshold rthr
(similar to [Xiong and Liu, 2003]) and a
conﬁdence level δi: agent i is willing to deal with an agent
j iff i knows that j’s average reputation is at least rthr
, with
conﬁdence 1 − δi. i evaluates j’s reputation as above, us-
ing EVAL-TRUST. Recall that when the algorithm terminates,
st,i
agent i only has an -close approximation of ¯rj
wt,i is very
close to rthr
Remark 3. We still do not commit to the way the values ri
j
are determined and updated, so the above trust model is quite
general.

, i would have to increase the accuracy.

. If

i

i

Algorithm 3
1: procedure DECIDE-TRUST(i, j) (cid:4) i decides if it wants

(cid:4) Initialization

to deal with j
 ← 1/2
k1 ← 0
loop

2:
3:
4:
5:
6:

A total of k2 stages

7:
8:
9:
10:
11:
12:
13:
14:
15: end procedure

end if
k1 ← k2
 ← /2

end loop

k2 ← U (n, δi, )
run EVAL-TRUST(j) for another k2 − k1 stages (cid:4)

if st,i/wt,i < rthr

i −  then

return false

else if st,i/wt,i > rthr

i +  then

return true

The procedure DECIDE-TRUST, given as Algorithm 3, is
a straightforward method of determining whether ¯rj ≥ rthr
.
Agent i increases the accuracy of the evaluation by repeatedly
halving , until it is certain of the result. In this context, a
stage of EVAL-TRUST corresponds to a stage of PUSH-SUM.
Proposition 3. Let i, j ∈ N , and Δij = |¯rj − rthr
|. With
probability at least 1 − δi, DECIDE-TRUST correctly decides
whether agent j(cid:2)s reputation is at least rthr
after O(log n +
i
log 1
Δij ) stages of EVAL-TRUST.3

δi + log 1

i

i

Proof. Assume w.l.o.g. that rthr
, and that the algorithm
reached a stage t0 where  < Δij/2. At this stage, it holds

i < ¯rj

3The probability is the chance that the algorithm will answer in-

correctly; the bound on the number of stages is always true.

IJCAI-07

1472

that | st,i
wt,i

− ¯rj | ≤  (with probability 1 − δi), and therefore:

st,i
wt,i

≥ ¯rj − 

= rthr
> rthr

i + Δij − 
i + .

Hence, the algorithm surely terminates when  < Δij/2.
Now the proposition follows directly from the fact that
U (n, δi, Δij ) = O(log n + log 1

δi + log 1

Δij ).

To conclude, Proposition 3 implies that there is a beneﬁt for
agent j in maintaining a high reputation: for any agent i with
a reasonable threshold, Δij is signiﬁcant, and this directly
affects the running time of DECIDE-TRUST.

Remark 4. The result is limited, though, when the number of
agents n is large, as the time to evaluate an agent’s reputation
is also proportional to log n.

5 Resistance to Attacks

We have seen that information about an agent’s reputation
can be efﬁciently propagated, as long as all agents consis-
tently follow EVAL-TRUST. However, with reputation sys-
tems we are usually dealing with self-interested agents. In
our context, a manipulative agent may artiﬁcially increase or
decrease the overall evaluation of some agent’s reputation by
deviating from the protocol.

In the framework we have presented, trust is evaluated on
the basis of global knowledge, i.e., the average of all repu-
tation values in the system. Therefore, any small coalition
cannot signiﬁcantly change the average reputation of some
agent j by setting their own valuations rj
i to legal values in
[0, 1], and then following the protocol EVAL-TRUST.4

wants to ensure that for all i,

This is, of course, not the case when a manipulator is al-
lowed to set its reputation value arbitrarily. As a simple mo-
tivating example, consider a setting where agents propagate
agent j’s average reputation (xi = rj
i for all i), and a ma-
st,i
nipulator im
wt,i converges to
a high value as the time t increases. At some stage t0, the
manipulator updates st0,im to be n, but except for this harsh
deviation follows the protocol to the letter. In particular, the
manipulator might initially set rj
im = xim = n. We refer to
st,i
this strategy as Strategy 1. Clearly, for all i,
wt,i eventually
converges to a value that is at least 1.

Despite the apparent effectiveness of Strategy 1, it is easily
detected. Indeed, unless for all i (cid:6)= im
it holds that st0,i = 0
at the time t0 when the manipulator deviated by assigning
st,i
st0,im = n, the expressions
wt,i would eventually converge
to a value that is strictly greater than 1; this would clearly
unmask the deceit. It is of course possible to update st0,im to
be less than n, but it is difﬁcult to determine a priori which
value to set without pushing the average reputation above 1.
We now consider a more subtle way to increase the val-
st,i
wt,i , a deceit that is indeed difﬁcult to detect; we call this

ues

4In fact, this holds for every coalition that does not constitute a

sizable portion of the entire set of agents.

(cid:2)

(cid:2)

strategy Strategy 2. For the ﬁrst T stages of the algorithm, the
manipulator im
follows PUSH-SUM as usual, with the excep-
tion of the updates of st,im : after updating wt,im =
l ˆwl
(as usual), im
updates: st,im = wt,im . In other words, the
st,im
manipulator sets its personal evaluation of the average
wt,im
to be 1 at every stage t = 1, . . . , T . For time t > T , the ma-
nipulator abides by the protocol. Using this strategy, it always
≤ 1 for all i. In addition, for all t, it still holds
holds that
i wt,i = n. Therefore, without augmenting the system
that
with additional security measures, this manipulation is difﬁ-
cult to detect. We shall presently demonstrate formally that
st,i
wt,i converges
the manipulation is effective in the long run:
to 1 for all i.
Proposition 4. Under Strategy 2, for all i ∈ N ,
in probability.

T →∞−→ 1

s2T ,i
w2T ,i

st,i
wt,i

(cid:2)

i st,i is monotonic increasing in
Proof. We ﬁrst notice that
stage t. Moreover, as noted above, it holds that at every stage,

i wt,i = n, as for all i ∈ N :

st,i
wt,i

≤ 1, and thus:

(cid:2)
(cid:4)

(cid:4)

st,i ≤

wt,i = n.

i

i

Let , δ > 0. We must show that it is possible to choose
T large enough such that for all t ≥ 2T and all i ∈ N ,
Pr[

≥ 1 − ] ≥ 1 − δ.

st,i
wt,i
Assume that at time t it holds that:

(cid:2)

< 1 − /2.

i st,i
n
≥ 1 − /4}, w(It) =

(cid:2)

i∈It

(1)

wt,it . It

Let It = {i ∈ N :
holds that:

st,i
wt,i

(cid:4)
(cid:4)
(cid:4)

i∈It

i∈N

n(1 − /2) ≥

≥

≥

st,i

st,i

wt,i · (1 − /4)

i∈It

= w(It)(1 − /4).

It follows that w(It) ≤ n · 1−/2

1−/4 . The total weight of
agents in N \ It is at least n − w(It). There must be an agent
it ∈ N \ It with at least a 1/n-fraction of this weight:

wt,it

≥

n − w(It)

n

≥



4 − 

.

(2)

In order for the choice of it to be well-deﬁned, assume it is
the minimal index that satisﬁes Equation (2).

Now, let s(cid:2)

t,im be the manipulator’s sum had it updated it
l ˆsl for all messages
. With probability 1/n (and independently of other

according to the protocol, i.e., s(cid:2)
l sent to im
stages), ft(it) = im

; if this happens, it holds that:

t,im =

(cid:2)

s(cid:2)
t+1,im ≤ (wt+1,im − 1/2 · wt,it ) + 1/2 · st,it

≤ (wt+1,im − 1/2 · wt,it )
· (1 − /4).

+ 1/2 · wt,it

(3)

IJCAI-07

1473

For all stages t it holds that

i st,i =
t+1,im , as the manipulator is the only agent that
i st,i. Therefore, in the conditions of Equa-

i st+1,i −

(cid:2)

st+1,im − s(cid:2)
might change

tion (3), (cid:4)

(cid:4)

st+1,i −

i

i

st,i = st+1,im − s(cid:2)

t+1,im

E

is also true for t = 0), so it is enough to consider messages at
time t from all i (cid:6)= im

.

Therefore, for all stages t, it holds that:

(cid:8)

(cid:4)

(cid:4)

(cid:7)(cid:4)

st+1,i −

st,i

=

(Pr[ft(i) = im

]

(cid:2)

(cid:2)

= wt+1,im − st+1,im
≥ 1/2 · wt,it



·

4

≥

2

32 − 8

= Δ(w).

(cid:2)

(cid:2)

tion (1) holds and ft(it) = im

So far, we have shown that for each stage t where Equa-
i st+1,i −
times
before Equation (1) no longer holds, or to put it differently,

i st,i ≥ Δ(w). This can happen at most

, it is the case that

n(1−/2)

Δ(w)

P

before

i st,i
n ≥ 1 − /2.

Let Xt be i.i.d. binary random variables, that are 1 iff
It holds that for all t where Equation (1) is

ft(it) = im
true, E[Xt] = 1/n. By Chernoff’s inequality, it holds that:

.

(cid:2)

T1(cid:4)

t=1

Pr[

1
T1

Xt ≤ 1

2n ] ≤ e− T1

2n2 .

E

i sT1,i
n

i

i

i(cid:6)=im

st,i))

wt,i − 1
2

1
2
(wt,i − st,i)

· (

(cid:4)
(cid:4)
(cid:4)

i(cid:6)=im

i(cid:6)=im

i∈N

wt,i

wt,i

=

1
2n

≤ 1
2n

≤ 1
2n

=

.

1
2

The last equality follows from the fact that for all t,
i wt,i = n.
P
As ¯rj =
obtain that

, and from the linearity of expectation, we

s0,i
i
n

(cid:12)(cid:8)

(cid:9)(cid:2)

(cid:10)

(cid:11)(cid:4)
(cid:7)
T1−1(cid:4)
(cid:7)(cid:4)
T1−1(cid:4)

t=0

i

E

st+1,i −

(cid:4)
(cid:4)

i

st,i

(cid:8)

− ¯rj

=

=

1
n

1
n

st+1,i −

st,i

i

i

E

t=0
T1 · 1
2

.

≤ 1
n

δ + log 1

In particular, since U (n, δ, ) = O(log n + log 1

 ),
PUSH-SUM is executed O(log n) stages, and thus the differ-
ence in the average is at most O( log n
n ), which is quite insub-
stantial.
Remark 5. It is not guaranteed at time T1 that each
is close to ¯rj
during the execution of PUSH-SUM.

st,i
wt,i
, because the inputs were dynamically changed

Remark 6. The above discussion focused on a setting where
the manipulator attempts to increase the average reputation of
an agent. It is likewise possible for a manipulator to decrease
an agent’s average reputation, or indeed set it eventually to
any value it wants.

6 Related Work
P2PRep [Cornelli et al., 2002] and Xrep [Damiani et al.,
2002] are P2P reputation systems that can be piggybacked
onto existing P2P protocols (such as Gnutella). P2PRep
allows peers to estimate trustworthiness of other peers by
polling. No guarantees are given with respect to computa-
tional efﬁciency and scalability.

Aberer and Despotovic [2001] introduce a reputation sys-
tem that consists of both a semantic model and a data manage-
ment scheme. The latter relies on P-Grid [Aberer, 2001], and

i

i

P

ST1,i
n

(cid:2)

It is possible to choose T1 to be large enough such that this
2n · T1 ≥ n(1−/2)
expression is at most δ/2, and in addition 1
.
Δ(w)
ST1,i
Therefore, at time T1, the average
≥ 1 − /2 with
n
probability 1 − δ/2.

Recall that after T stages (where im

tocol), it still holds that
P

deviated from the pro-
i wT,i = n. Assume that indeed
≥ 1 − /2. By modifying the proof of Theorem
3.1 from [Kempe et al., 2003], it is possible to show that
after another T2 = T2(n, δ, ) stages where all agents ob-
serve the protocol, it holds with probability 1 − δ/2 that for
all i,
t ≥ T1 + T2,
The proof
max{T1, T2}.

−
st,i
wt,i
is completed by simply choosing T =

(cid:3)(cid:3)(cid:3) < /2, and thus for all i and

> 1 −  with probability 1 − δ.

(cid:3)(cid:3)(cid:3) sT1 +T2,i

wT1+T2,i

ST1,i
n

P

i

Proposition 4 implies that Strategy 2 poses a provably acute
problem, when PUSH-SUM is run a large number of turns.
Fortunately, PUSH-SUM converges exponentially fast, and
thus it is usually the case that the manipulator is not able to
signiﬁcantly affect the average reputation, as the following
proposition demonstrates.
Proposition 5. Let T1 ≤ T . Under Strategy 2 it holds that
E

(cid:5) P

(cid:6)

i

ST1,i
n

− ¯rj

≤ T1
2n .

(cid:2)

Proof. Let {ˆsl, ˆwl} be the messages that the manipulator
received at time t + 1. The manipulator sets st+1,im =
l ˆwl. Essentially, this is equivalent to setting
wt+1,im =
for all l ˆsl = ˆwl, or in other words, raising each ˆsl by ˆwl − ˆsl.
At turn t it was already true that st,im = wt,im (w.l.o.g. this

IJCAI-07

1474

uses distributed data structures for storing trust information;
the associated algorithms scale gracefully as the number of
agents increases. This approach, however, suffers from sev-
eral shortcomings compared to ours. Agents in this scheme
assess others’ reputation only on the basis of complaints ﬁled
in the past; the framework is generally limited to such binary
trust information. In addition, trust is evaluated only accord-
ing to referrals from neighbors, whereas in our approach the
evaluation is based on all the information in the system.

Xiong and Liu [2003] presented a sophisticated framework
speciﬁcally applicable in P2P networks, where the decision
whether to trust a peer is based on ﬁve metrics: satisfaction,
number of transactions, credibility of feedback, transaction
context, and community context. [Srivatsa et al., 2005] ex-
tended this work. Both papers focus on the trust model, and
generally do not elaborate on the data management scheme.
Speciﬁcally, in [Xiong and Liu, 2003] a P-Grid [Aberer,
2001] is used. Thus, this work is in a sense orthogonal but
complementary to ours. Dewan and Dasgupta [2004] propose
self-certiﬁcation and IP-Based safeguards as ways of induc-
ing trust; this work also complements ours.

Finally, gossip-based algorithms5 have many applications
in other domains, for instance replicated database mainte-
nance [Demers et al., 1987].

7 Conclusions

It is scalable:

We have presented a data management scheme built on
gossip-based algorithms, and have demonstrated that it pos-
sesses several interesting features. Our method is decentral-
ized, and uses no central database.
It is also applicable in
networks where point-to-point communication cannot be as-
sumed.
the time to evaluate an agent’s av-
erage reputation with conﬁdence 1 − δ and accuracy  is
O(log n + log 1
 ). The evaluation of trust is global,
and based on all relevant information in the system, rather
than only local information. We have used simple data struc-
tures: each agent merely keeps an assessment of the agents
with which it personally interacted. Our method motivates
absolute truthfulness, as the time to close deals may decrease
as reputation increases. It is also resistant to some attacks,
such as carefully tampering with the updates performed by
PUSH-SUM.

δ + log 1

We have focused on the data management scheme, and
have largely ignored the trust model. However, we believe
that many existing trust models can be integrated with our
framework. A simple example is the binary trust model
of [Aberer and Despotovic, 2001], where agents can ﬁle com-
plaints against other agents. In our framework, each agent i
sets its value rj
i to be 0 if it wishes to ﬁle a complaint against
j; otherwise, the value is 1. More sophisticated models may,
however, require modiﬁcations to the framework. For exam-
ple, an agent may give higher credibility to agents that have a
high reputation (in its opinion), and weight their estimations
accordingly. An interesting direction for further work would
be to use gossip techniques to take even such considerations
into account.

5Also called epidemic algorithms.

8 Acknowledgment

This work was partially supported by grant #039-7582 from
the Israel Science Foundation.

References
[Aberer and Despotovic, 2001] K. Aberer and Z. Despo-
tovic. Managing trust in a peer-2-peer information sys-
tem. In Proceedings of the Tenth International Conference
on Information and Knowledge Management, pages 310–
317, 2001.

[Aberer, 2001] K. Aberer. P-grid: A self-organizing access
structure for P2P information systems. In Proceedings of
the 9th International Conference on Cooperative Informa-
tion Systems, pages 179–194, 2001.

[Cornelli et al., 2002] F. Cornelli, E. Damiani, S. De Capi-
tani di Vimercati, S. Paraboschi, and P. Samarati. Choos-
ing reputable servants in a P2P network. In Proceedings of
the 11th International World Wide Web Conference, pages
376–386, 2002.

[Damiani et al., 2002] E. Damiani, S. De Capitani di Vimer-
cati, S. Paraboschi, P. Samarati, and F. Violante. A
reputation-based approach for choosing reliable resources
in peer-to-peer networks. In Proceedings of the 9th ACM
Conference on Computer and Communications Security,
pages 207–216, 2002.

[Demers et al., 1987] A. J. Demers, D. H. Greene, C. Hauser,
Wes Irish, and John Larson. Epidemic algorithms for repli-
cated database maintenance. In Proceedings of the Sixth
Annual ACM Symposium on Principles of Distributed
Computing, pages 1–12, 1987.

[Dewan, 2004] Prashant Dewan. Peer-to-peer reputations. In
Proceedings of the 18th International Parallel and Dis-
tributed Processing Symposium, 2004.

[Frieze and Grimmett, 1985] A. M. Frieze and G. R. Grim-
mett. The shortest-path problem for graphs with ran-
dom arc-lengths. Discrete Applied Mathematics, 10:57–
77, 1985.

[Kempe et al., 2003] D. Kempe, A. Dobra, and J. Gehrke.
Gossip-based computation of aggregate information.
In
Proceedings of the 44th Annual IEEE Symposium on Foun-
dations of Computer Science, pages 482–491, 2003.

[Pandurangan et al., 2001] G. Pandurangan, P. Raghavan,
and E. Upfal. Building low diameter P2P networks.
In
Proceedings of the 42nd Annual IEEE Symposium on
Foundations of Computer Science, pages 492–499, 2001.

[Srivatsa et al., 2005] M. Srivatsa, L. Xiong, and L. Liu.
Trustguard: Countering vulnerabilities in reputation man-
agement for decentralized overlay networks. In Proceed-
ings of the 14th International World Wide Web Conference,
pages 422–431, 2005.

[Xiong and Liu, 2003] L. Xiong and L. Liu. A reputation-
based trust model for peer-to-peer ecommerce communi-
ties. In Proceedings of the 4th ACM Conference on Elec-
tronic Commerce, pages 228–229, 2003.

IJCAI-07

1475

