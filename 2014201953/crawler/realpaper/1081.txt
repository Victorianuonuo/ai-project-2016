Instance-based AMN Classiﬁcation for Improved Object Recognition

in 2D and 3D Laser Range Data

Rudolph Triebel Richard Schmidt

´Oscar Mart´ınez Mozos Wolfram Burgard

Department of Computer Science, University of Freiburg

Georges-Koehler-Alle 79, 79110 Freiburg, Germany

{triebel, rschmidt, omartine, burgard}@informatik.uni-freiburg.de

Abstract

In this paper, we present an algorithm to iden-
tify diﬀerent types of objects from 2D and 3D
laser range data. Our method is a combination
of an instance-based feature extraction similar to
the Nearest-Neighbor classiﬁer (NN) and a collec-
tive classiﬁcation method that utilizes associative
Markov networks (AMNs). Compared to previ-
ous approaches, we transform the feature vectors
so that they are better separable by linear hyper-
planes, which are learned by the AMN classi-
ﬁer. We present results of extensive experiments
in which we evaluate the performance of our algo-
rithm on several recorded indoor scenes and com-
pare it to the standard AMN approach as well as
the NN classiﬁer. The classiﬁcation rate obtained
with our algorithm substantially exceeds those of
the AMN and the NN.

1 Introduction

In this paper, we consider the problem of identifying objects
in 2D and 3D range measurements. We believe that the seg-
mentation of these data into known object classes can be use-
ful in many diﬀerent areas, such as map registration, robot lo-
calization, object manipulation, or human-robot interaction.
For example, a robot that is able to classify the 3D data ac-
quired by a range sensor has a better capability of ﬁnding
corresponding data points in diﬀerent measurements. In this
way, the scan registration can be carried out more reliably.
Other application areas, in which object recognition is impor-
tant, include seek-and-rescue tasks such as the one aimed by
the RoboCup rescue initiative.

What makes the object detection especially hard is the fact
that it involves both, the segmentation and the classiﬁcation
of the segments. To simultaneously solve this segmentation
and classiﬁcation problem, recently collective classiﬁcation
approaches have become a popular approach. They are based
on the assumption that in many real-world domains spatial
neighbors in the data tend to have the same labels. For ex-
ample, Anguelov et al. [2005] formulate the problem of seg-
menting 3D range data into known classes as a supervised
learning task and apply collective classiﬁcation to solve the

task. They use a technique called associative Markov net-
works (AMNs), which combines the concept of relational
learning with collective classiﬁcation.

So far, AMNs have been used only based on the log-linear
model, which means that there is only a linear relationship
between the extracted features and the weight parameters
learned by the algorithm. This results in classiﬁcation algo-
rithms that learn hyper-planes in the feature space to separate
the object classes. However, in many real-world applications
the assumption of the linear separability of the features is of-
ten not justiﬁed. One way to overcome this problem may be
to extend the log-linear model, but this is still subject to ongo-
ing research. In this paper, we propose a diﬀerent approach.
By combining the ideas of instance-based classiﬁcation with
the AMN approach, we obtain a classiﬁer that is more ro-
bust against the error introduced by the linear-separability as-
sumption. We present a way to compute new feature vec-
tors from a given set of standard features, i.e., we transform
the original features, and show that these features are better
suited for classiﬁcation using the AMN approach.

This paper is organized as follows. The next section gives
an overview of the work that has been presented so far in
this area. Then we summarize the concepts of collective clas-
siﬁcation using associative Markov networks and describe
shortly how learning and inference is done in AMNs. Then,
a detailed description of our approach is presented. Finally,
we present the results of experiments, which illustrate that
our method provides better classiﬁcations than previous ap-
proaches.

2 Related Work
The problem of recognizing objects from 3D range data has
been studied intensively in the past. Most of the approaches
can be distinguished according to the features used. One pop-
ular approach are spin images [Johnson, 1997; de Alarc´on
et al., 2002; Frome et al., 2004], which are rotationally and
translationally invariant local descriptors. Spin images are
also used as features in the work presented here. Other types
of 3D features include local tensors [Mian et al., 2004], shape
maps [Wu et al., 2004], and multi-scale features [Li and
Guskov, 2005]. Osada et al. [2001] proposed a 3D object
recognition technique based on shape distributions. Whereas
this approach requires a complete view of the objects, our
method can deal with partially seen objects. Additionally,

IJCAI-07

2225

Huber et al. [2004] present an approach for parts-based object
recognition. This method provides a better classiﬁcation be-
cause nearby parts that are easier to identify than others help
to guide the classiﬁcation. A similar idea of detecting object
components has been presented by Ruiz-Correa et al. [2003],
who introduced symbolic surface signatures. Another ap-
proach to object recognition proposed by Boykov and Hut-
tenlocher [1999] is based on Markov random ﬁelds (MRFs).
They classify objects in camera images by incorporating sta-
tistical relationships between nearby object parts. A rela-
tional approach using MRFs has been proposed by Limketkai
et al. [2005]. The idea here is to exploit the spatial relation-
ship between nearby objects, which in this case consist of 2D
line segments. The work that is mostly related to the approach
described in this paper is presented by Anguelov et al. [2005],
in which an AMN approach is used in a supervised learning
setting to classify 3d range data. In this paper, we combine
this approach with techniques from instance-based classiﬁca-
tion to obtain improved classiﬁcation results.

3 Range Scan Classiﬁcation
Suppose we are given a set of N data points p1, . . . , pN
taken from a 2D or 3D scene and a set of K object classes
C1, . . . , CK. A data point in this context may be a 3D scan
point or a 2D grid cell of an occupancy grid. The following
formulations are identical in these two cases.

For each data point pi, we are also given a feature vector
xi. Later we will describe in detail how the features are de-
ﬁned in the context of this paper. The task is to ﬁnd a label
yi ∈ {1, . . . , K} for each pi so that all labels yi, . . . , yN are
optimal given the features. The notion of optimality in this
context depends on the classiﬁcation method we choose. In
the standard supervised learning approach, we deﬁne a like-
lihood function Pω(y | x) of the labels y given the features x.
Then, the classiﬁcation problem can be subdivided into two
tasks: ﬁrst we need to ﬁnd good parameters ω∗ for the likeli-
hood function Pω(y | x). Then we seek for good labels y∗ that
maximize this likelihood. Assuming we are given a training
data set, in which the labels ˆy have been assigned by hand,
we can formulate the classiﬁcation as follows:
• learning step: ﬁnd ω∗ = argmaxωPω(ˆy | x)
• inference step: ﬁnd y∗ = argmaxyPω∗(y | x)

3.1 Collective Classiﬁcation
In most standard classiﬁcation methods, such as Bayes clas-
siﬁcation, Nearest Neighbor, AdaBoost etc. the classiﬁcation
of a data point only depends on its local features, but not on
the labeling of nearby data points. However, in practice one
often observes a statistical dependence of the labelings asso-
ciated to neighboring data points. For example, if we con-
sider the local planarity of a scan point as a feature, it may
happen that the likelihood P(y | x) of the class label ‘wall’ is
higher than that of the class label ‘door’, although all other
scan points in the vicinity of this point belong to the class
‘door’. Methods that use the information of neighboring data
points are denoted as collective classiﬁcation techniques (see
Chakrabarti and Indyk[1998]). Recently, a collective clas-
siﬁcation approach to classify 3D range scan data has been

presented by Anguelov et al. [2005]. The authors propose
the use of associative Markov networks (AMNs), which are a
special type of Relational Markov Random Fields, described
in Taskar et al.[2002]. In the following we will brieﬂy de-
scribe AMNs.

3.2 Associative Markov Networks

In our case,

An associative Markov network is an undirected graph in
which the nodes are represented by N random variables
y1, . . . , yN .
these random variables are dis-
crete and correspond to the labels of each of the data points
p1, . . . , pN. Each node yi and each edge (yi, y j) in the graph
has an associated non-negative value ϕ(xi, yi) and ψ(xi j, yi, y j)
respectively. These are also known as the potentials of the
nodes and edges. The node potentials reﬂect the fact that for
a given feature vector xi some labels are more likely to be as-
signed to pi than others, whereas the edge potentials encode
the interactions of the labels of neighboring nodes given the
edge features xi j. Whenever the potential of a node or edge
is high for a given label (yi) or a label pair (yi, y j), the con-
ditional probability of these labels given the features is also
high. The conditional probability that is represented by the
network can be expressed as

P(y | x) =

N(cid:2)

i=1

1

Z

(cid:2)

ϕ(xi, yi)

ψ(xi j, yi, y j).

(1)

(i j)∈E

(cid:4)

(cid:3)
y(cid:4)

(cid:4)

Here, Z denotes the partition function which by deﬁnition is
given as Z =

ψ(xi j, y

ϕ(xi, y

, y

(i j)∈E

N
i=1

(cid:4)
i

(cid:4)
j).

(cid:4)
i )

It remains to describe the node and edge potentials ϕ and
ψ.
In Taskar et al.[2004], the potentials are deﬁned using
the log-linear model. In this model, a weight vector wk is
introduced for each class label k = 1, . . . , K. The node po-
· xi where
tential ϕ is then deﬁned so that log ϕ(xi, yi) = wk
n
k = yi. Accordingly, the edge potentials are deﬁned as
log ψ(xi j, yi, y j) = wk,l
· xi where k = yi and l = y j. Note
∈ Rde
that there are diﬀerent weight vectors wk
n
for the nodes and edges.

∈ Rdn and wk,l

e

e

For the purpose of convenience we use a slightly diﬀerent

notation for the potentials, namely
K(cid:5)

log ϕ(xi, yi) =

log ψ(xi j, yi, y j) =

(wk
n
K(cid:5)

k=1

K(cid:5)

k=1

l=1

· xi)yk
i

(2)

(wk,l

e

· xi j)yk

i yl

j

,

(3)

where yk
label k and 0, otherwise.

i is an indicator variable which is 1 if point pi has

e

= 0 for k (cid:2) l and wk,k

the constraints wk,l
sults in ψ(xi j, k, l) = 1 for k (cid:2) l and ψ(xi j, k, k) = λk
λk
i j

In a further reﬁnement step of our model, we introduce
≥ 0. This re-
i j, where
≥ 1. The idea here is that edges between nodes with dif-
ferent labels should be penalized over edges between equally
labeled nodes. This last speciﬁcation of AMNs makes it pos-
sible to run the inference step eﬃciently using graph cuts
(see [Boykov et al., 1999; Taskar, 2004]).

e

IJCAI-07

2226

4 Learning and Inference with AMNs
In this section, we describe how learning and inference can be
carried out with AMNs. First, we reformulate Equation (1) as
the conditional probability Pw(y | x) where the parameters
ω are expressed by the weight vectors w = (wn, we). By
plugging in Equations (2) and (3) we obtain that log Pw(y | x)
equals
K(cid:5)
N(cid:5)

(cid:5)

K(cid:5)

(wk
n

· xi)yk
i

+

(wk,k
e

i=1

k=1

(i j)∈E

k=1

· xi j)yk

i yk

j

− log Zw(x).

(4)

Note that the partition function Z only depends on w and x,
but not on the labels y.

4.1 Learning
As mentioned above, in a standard supervised learning task
the goal is to maximize Pw(y | x). However, the problem
that arises here is that the partition function Z depends on
the weights w. This means that when maximizing log Pw(ˆy |
x), the intractable calculation of Z needs to be done for each
w. However, if we instead maximize the margin between the
optimal labeling ˆy and any other labeling y deﬁned by

log Pω(ˆy | x) − log Pω(y | x),

(5)

the term Zw(x) cancels out and the maximization can be done
eﬃciently. This method is referred to as maximum margin
optimization. The details of this formulation are omitted here
for the sake of brevity. We only note that the problem is re-
duced to a quadratic program (QP) of the form:

min

1

2

(cid:6)w(cid:6)2 + cξ

(6)

N(cid:5)

i=1

αi ≥ N; we ≥ 0;

s.t. wXˆy + ξ −

(cid:5)

αi −

αk
i j

− wk
n

· xi ≥ −ˆyk
i

, ∀i, k;

i j, ji∈E

αk
i j

+ αk
ji

− wk
e

· xi j ≥ 0, αk
i j

, αk
ji

≥ 0, ∀i j ∈ E, k

Here, the variables that are solved for in the QP are the
weights w = (wn, we), a slack variable ξ and additional vari-
ables αi, αi j and α ji. We refer to Taskar et al.[2004] for de-
tails.

Inference

4.2
Once the optimal weights w have been calculated, we can
perform inference on an unlabeled test data set. This is done
by ﬁnding the labels y that maximize log Pw(y | x). As men-
tioned above, Z does not depend on y so that the maximiza-
tion in equation (4) can be carried out without considering
the last term. With the constraints imposed on the variables
yk
i this leads to a linear program of the form

N(cid:5)

K(cid:5)

(cid:5)

K(cid:5)

max

i=1

k=1

(wk
n

+

· xi)yk
i
K(cid:5)

i j∈E

k=1

(wk
e

· xi j)yk
i j

(7)

s.t. yk
i

≥ 0, ∀i, k;

yi = 1, ∀i

yk
i j

≤ yk
i

, yk
i j

k=1
≤ yk
j

, ∀i j ∈ E, k

x2
 
e
r
u
t
a
e
F

 1.3
 1.2
 1.1
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0

training set class 1
training set class 2
test set class 1
test set class 2

 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1

Feature x1

t2
 
e
r
u
t
a
e
F

 0.5

 0.4

 0.3

 0.2

 0.1

 0

 0

class 1
class 2

 0.1

Feature t1

 0.2

 0.3

Figure 1: Example of the feature transform τ for a two-class
problem with two features. Left: Training data and test data
with ground truth labeling. Right: Test data after applying τ.

Here, we introduced variables yk
i j representing the labels of
two points connected by an edge. The last two inequality
conditions are a linearization of the constraint yk
i j

∧ yk
j.

= yk
i

In our current implementation, we perform the learning and
inference step by solving the quadratic and linear program
from Equations (6) and (7). The implementation is based on
the C++ library OOQP [Gertz and Wright, 2003]. As men-
tioned above, the inference step can be performed more ef-
ﬁciently using graph-cuts. However, in our application, in
which the data sets were comparably small, the linear pro-
gram solver turned out to be fast enough.

5 Instance-based Extension

The main drawback of the AMN classiﬁer, which is based
on the log-linear model, is that it separates the classes lin-
early. This assumes that the features are separable by hyper-
planes, which is not justiﬁed in all applications. This does
not hold for instance-based classiﬁers such as the nearest-
neighbor (NN) classiﬁer. In NN classiﬁcation, a query data
point ˜p is assigned to the label that corresponds to the train-
ing data point p whose features x are closest to the features
˜x of ˜p. In the learning step, the NN classiﬁer simply stores
the entire training data set and does not compute a reduced
set of training parameters, which is why it is also called lazy
classiﬁcation.

The idea now is to combine the advantage of instance-
based NN classiﬁcation with the AMN approach to obtain a
collective classiﬁer that is not restricted to the linear separa-
bility requirement. This will be presented in the next section.

5.1 The Transformed Feature Vector

Suppose we are given a general K-class classiﬁcation prob-
lem where for each training data point ˆp we are given a fea-
ture vector ˆx of length L and a label ˆy ∈ {1, . . . , K}. Now,
if we assume that the correct label for a new query feature
∗ of its closest training ex-
vector ˜x corresponds to the label ˆy
ample x∗ in feature space, then the NN algorithm yields the
optimal classiﬁcation. Of course, this assumption is not valid
∗ will be
in general, but we can at least say that the label ˆy
more likely than any other label. As an example, consider the
two-class problem with two features depicted in the left part
of Fig. 1. The two-dimensional feature space is deﬁned by
the training data shown as boxes. Now, the true labels of an

IJCAI-07

2227

(a) Training data

(b) Test data (ground truth)

(c) NN

(d) AMN

(e) iAMN

Figure 2: Results on 2D data of an occupancy grid map.

arbitrary test data set, here shown as triangles, will be related
to the labels of their closest training feature points. In our
example, the probability of the label ˜y ∈ {1, 2} corresponding
to ˜x is proportional to a Gaussian distribution N(μk, σ) with
μk = d(˜x, ˆxk) and k ∈ {1, 2}. Here, ˆxk denotes the training ex-
ample with label k that is closest to ˜x and d(·, ·) the distance
in feature space. The variance σ is set to 0.03.

From the left side of Fig. 1, we can see that any attempt
to separate the classes using hyperplanes (in this case lines)
will lead to severe classiﬁcation errors. However, if we in-
troduce a feature transform τ : RL → RK in such a way that
τ(˜x) = (d(˜x, ˆx1), . . . , d(˜x, ˆxK)), then the transformed features
˜t := τ(˜x) are more easily separable by hyperplanes. This is
illustrated on the right side of Fig. 1. The reason for this is
that the NN classiﬁer always chooses the label corresponding
to the smallest component of ˜t. This means, that the set Tk
of all transformed feature points t = (t1, . . . , tK) that will be
assigned the label k can be described by
Tk = {t ∈ RK |tk < t1 ∧ · · · ∧ tk < tk−1 ∧ tk < tk+1 ∧ · · · ∧ tk < tK }.
As can be seen from this equation, the border of the set Tk
is described by K − 1 hyperplanes passing through the ori-
gin. In the case of our two-class example, the only separating
hyperplane (line) is described by the equation t1 = t2.

5.2 M Nearest Neighbors
One problem of the NN classiﬁer is that the assignment of
a label to a query point ˜p only depends on the labeling of
one instance in the training set, namely the one whose feature
vector is closest to ˜x. However, it is possible that the features
of other training instances are also very close to ˜x, although
they are labeled diﬀerently. For example, suppose that the
distances of ˜x to the two closest training features ˆx1 and ˆx2
are very similar, and the corresponding labels ˆy1 and ˆy2 are
diﬀerent, the decision of assigning the label ˆy1 to ˜p may be
wrong, especially in the presence of noise. Therefore we pro-
ceed as follows: For the feature vector ˜x that corresponds to ˜p
we compute the M nearest training instances in each of the K
classes C1, . . . , CK and the corresponding distances d(˜x, ˆxm
k )
where k = 1, . . . , K and m = 1, . . . , M. These are used to
deﬁne the transformed feature vector τM(˜x) as

τM (˜x) = (. . . , d(˜x, ˆx1

k), . . . , d(˜x, ˆxM

k ), . . . )

(8)

Experiments show that higher values of M increase the clas-
siﬁcation rate, but for large M the improvement is very small.
In our experiments, M = 5 turned out to be a good choice.

6 Experimental Results

We performed a series of experiments with 2D and 3D data
to compare our instance–based AMN (iAMN) algorithm with
the NN and the AMN classiﬁer. The results of these experi-
ments demonstrate that the iAMN outperforms the two other
algorithms, independent of the features used.

6.1

Implementation Details

To speed up the learning process, we need to represent all
feature vectors such that the nearest neighbor search in the
feature space can be performed eﬃciently. To this end, we
use kD-trees K1, . . . , KK to store the training feature vectors
of each class C1, . . . , CK. This way, the computational eﬀort
of the nearest neighbor lookup becomes logarithmic in the
number of the stored instances.

Thus, the training step consists of computing the features
for the training data, transforming these features according to
Eq. 8 and assigning the transformed features to the nodes of
the AMN. The edge features of the AMN consist of a constant
scalar value, as described by Anguelov et al. [2005]. After
solving the quadratic program we obtain the weight vectors
wk. Then, in the inference step, we use the transformed fea-
tures τM(x) of the test data as node features for the AMN.
Again, the edge features are constant.

Feature Computation Depending on the input data used,
we computed diﬀerent types of features for the data points.
In the case of the 2D grid data, each point in the map is rep-
resented by a set of geometrical features which are extracted
from a laser range scan covering 360o ﬁeld of view. Each
laser is simulated and centered at each point in the map rep-
resenting a free space [Mozos et al., 2005]. Because the num-
ber of geometrical features is huge (more than 300) we select
the best ones using the AdaBoost algorithm.

For the 3D data set we computed spin images [Johnson,
1997] with a size of 5 × 10 bins. The spherical neighborhood
for computing the spin images had a radius between 10 and
15cm, depending on the resolution of the input data.

Data Reduction When classifying data sets with many
points, e.g., 3D scans with over 10, 000 scan points, the time
and memory requirements of the AMN classiﬁer grows very
large. In these cases, we perform a data set reduction, again
using kD-trees: after inserting all data points into the tree, we

IJCAI-07

2228

(a) Ground truth

(b) NN

(c) AMN

(d) iAMN

Figure 3: Classiﬁcation results for one scene from the Multi data set

prune the tree at a ﬁxed level λ. All points in the subtrees
below level λ are then merged into one mean point. The spin
image features, however, are still computed on the whole data
set to provide a high density in the feature extraction.

2D Map Annotation

6.2
For the 2D classiﬁcation experiment we used an occupancy
grid map of the interior of a building. The map was annotated
with three diﬀerent labels, namely ’corridor’, ’room’ and
’lobby’. Then the map was divided into two non-overlapping
submaps, one for training and one for testing. Fig. 2(a) shows
the submap used for training and Fig. 2(b) the ground truth
for the classiﬁcation. The results obtained with the NN and
the standard AMN approach are shown in Figs. 2(c) and 2(d),
while Fig 2(e) shows the result of our iAMN algorithm. It can
be seen that the iAMN approach gives the best result. The
classiﬁcation rate of the NN is with 92.2% higher than that of
the standard AMN, which was 89.8%, but the classiﬁcation
is very noisy. In contrast, the iAMN result is more consistent
wrt. neighboring data points and has the highest classiﬁcation
rate with 95.5%.

3D Scan Point Classiﬁcation

6.3
Furthermore, we evaluated the classiﬁcation algorithms on
three diﬀerent 3D data sets with an overall number of 38
scanned scenes. The scans were obtained with a 3D laser
range scanner. The ﬁrst data set is called Human and con-
sists of 11 recorded scenes with two humans in varying poses.
The scans were labeled into the four classes ’head’, ’torso’,
’legs’, and ’arms’. The second data set named Single con-
sists of 20 diﬀerent 3D scans of the object classes ’chair’,
’table’, ’screen’, ’fan’, and ’trash can’. Each scan in the Sin-
gle data set contains just one object of each class, apart from
tables, which may have screens standing on top of them. The
last data set is named Multi and consists of seven scans with
multiple objects of the same types as in the Single data set.

The Human and Single data sets were evaluated using cross
validation. For the Multi data set we used the object instances

from the Single set for training, because those were not oc-
cluded by other objects. The classiﬁcation was performed on
the complete scans.

Fig. 3 shows a typical classiﬁcation result for a scan from
the Multi test set. We can see that NN assigns wrong labels to
diﬀerent points while their neighbors are classiﬁed correctly.
The AMN results show that areas of points tend to be clas-
siﬁed with the same label. However, due to the restriction
to linearly separable data, many object parts are misclassi-
ﬁed, especially in complex objects like chairs and fans. The
results obtained with iAMN are better even in these complex
objects, because the transformed feature vectors computed by
iAMN are better suited for a classiﬁcation based on separat-
ing hyper-planes. Table 1 shows the resulting classiﬁcation
rates. We can see that the iAMN classiﬁer outperforms both
of the others in all three data sets.

A statistical analysis using a t-student test with a signiﬁ-
cance level of 0.05 is shown in Fig. 5. As can be seen, for
the Multi set our algorithm performs signiﬁcantly better than
both the NN and the standard AMN. A detailed analysis of
the classiﬁcation results is depicted in Fig. 4 wchich demon-
strates that our iAMN yields highly accurate results for all
three data sets.

Data set NN AMN iAMN

Human

75% 69%

Single

81% 72%

Multi

63% 62%

80%

89%

76%

Table 1: Classiﬁcation results for all three data sets

7 Conclusions

In this paper we proposed an algorithm that combines as-
sociative Markov networks with an instance-based approach
similar to the nearest neighbor classiﬁer for identifying ob-

IJCAI-07

2229

NN
AMN
inst. AMN

 100

 80

 60

 40

%
n

 

i
 

e

t

a
r
 

n
o

i
t

a
c
i
f
i
s
s
a

l

 20C

 0

1 2 3 4 5 6 7 8 9 10 11

(a) Data set Human

%
n

 

i
 

e

t

a
r
 

n
o

i
t

a
c
i
f
i
s
s
a
C

l

 100

 80

 60

 40

 20

 0

1

NN
AMN
inst. AMN

3

2

5
(b) Data set Single

4

%
n

 

i
 

e

t

a
r
 

n
o

i
t

a
c
i
f
i
s
s
a
C

l

 100

 80

 60

 40

 20

 0

6

NN
AMN
inst. AMN

1

2

3

4

5

6

7

(c) Data set Multi

Figure 4: Individual classiﬁcation rates for all scenes.

%
n

 

i
 

e

t

a
r
 

n
o

i
t

a
c
i
f
i
s
s
a
C

l

 100

 90

 80

 70

 60

 50

 40

NN
AMN
inst. AMN

References
[Anguelov et al., 2005] D. Anguelov, B. Taskar, V. Chatalbashev, D. Koller, D. Gupta,
G. Heitz, and A. Ng. Discriminative learning of markov random ﬁelds for seg-
mentation of 3d scan data. In Proc. of the Conf. on Computer Vision and Pattern
Recognition (CVPR), pages 169–176, 2005.

[Boykov and Huttenlocher, 1999] Y. Boykov and D. Huttenlocher. A new Bayesian

approach to object recognition. In Proc. of IEEE CVPR, 1999.

[Boykov et al., 1999] Y. Boykov, O. Veksler, and R. Zabih. Fast approximate energy
minimization via graph cuts. In Proc. of the Int. Conf. on Computer Vision (ICCV),
pages 377–384, 1999.

[Chakrabarti and Indyk, 1998] S. Chakrabarti and P. Indyk. Enhanced hypertext cate-

HUMAN

SINGLE

MULTI

gorization using hyperlinks. In Proc. of the ACM SIGMOD, 1998.

Figure 5: Results of a t-student test with signiﬁcance level
0.05 on the three diﬀerent 3D data sets. For the Multi data set
we obtain a signiﬁcant improvement over NN and standard
AMN classiﬁcation.

jects in 3D range data. In contrast to the approach suggested
by Anguelov et al. [2005], our method is able to classify more
complex objects with a diverse set of features per class. By
using the distances of features to their nearest neighbors, the
transformed feature space becomes more easily linearly sepa-
rable. Accordingly, it improves the performance of the AMN
training step. While the AMN inference task can be solved
using graph-cuts, the drawback of our approach is, that by
storing instances the resulting classiﬁer becomes a lazy clas-
siﬁcation method. The inference step requires to compute
the distance between the instance to be classiﬁed and the
known training instances. This is computational expensive
in general. However, by utilizing eﬃcient data structures like
kD-Trees the computational eﬀort becomes logarithmic in the
number of stored instances.

Despite these encouraging results, there are several aspects
that warrant future research. One way to improve the ap-
proach presented here could be to classify the objects on a
lower complexity level, i.e., by classifying object parts fol-
lowing the idea by Huber et al. [2004]. As features of less
complex objects are distributed more compactly in the fea-
ture space, they might be easier to separate.

Acknowledgments

This work has partly been supported by the German Research
Foundation under contract number SFB/TR8 and by the Eu-
ropean Union under contract number FP6-004250-CoSy.

[de Alarc´on et al., 2002] P. A. de Alarc´on, A. D. Pascual-Montano, and J. M. Carazo.
Spin images and neural networks for eﬃcient content-based retrieval in 3d object
databases. In Proc. of the Int. Conf. on Image and Video Retrieval (CIVR), 2002.

[Frome et al., 2004] A. Frome, D. Huber, R. Kolluri, T. Bulow, and J. Malik. Recog-
nizing objects in range data using regional point descriptors. In Proc. of the Europ.
Conf. on Computer Vision (ECCV), 2004.

[Gertz and Wright, 2003] E. M. Gertz and S. J. Wright. Object-oriented software for
quadratic programming. ACM Trans. on Mathematical Software, pages 58–81, 2003.

[Huber et al., 2004] D. Huber, A. Kapuria, R. Rao Donamukkala, and M. Hebert.
Parts-based 3d object classiﬁcation. In Proc. of the Conf. on Computer Vision and
Pattern Recognition (CVPR), 2004.

[Johnson, 1997] A. Johnson. Spin-Images: A Representation for 3-D Surface Match-

ing. PhD thesis, Robotics Institute, Carnegie Mellon Univ., Pittsburgh, PA, 1997.

[Li and Guskov, 2005] X. Li and I. Guskov. Multiscale features for approximate align-
ment of point-based surfaces. In Symp. on Geometry Processing, pages 217–226,
2005.

[Limketkai et al., 2005] B. Limketkai, L. Liao, and D. Fox. Relational object maps
for mobile robots. In Proc. of the Int. Joint Conf. on Artiﬁcial Intelligence (IJCAI),
pages 1471–1476, 2005.

[Mian et al., 2004] Ajmal S. Mian, Mohammed Bennamoun, and Robyn A. Owens.
In Proc. of the

Matching tensors for automatic correspondence and registration.
Europ. Conf. on Computer Vision (ECCV), 2004.

[Mozos et al., 2005] O. Martinez Mozos, C. Stachniss, and W. Burgard. Supervised
In Proc. of the Int. Conf. on

learning of places from range data using adaboost.
Robotics & Automation (ICRA), 2005.

[Osada et al., 2001] R. Osada, T. Funkhouser, B. Chazelle, and D. Dobkin. Matching
3D models with shape distributions. In Shape Modeling International, pages 154–
166, 2001.

[Ruiz-Correa et al., 2003] S. Ruiz-Correa, L. G. Shapiro, and M. Meila. A new
In Proc. of the Int.

paradigm for recognizing 3-d object shapes from range data.
Conf. on Computer Vision (ICCV), pages 1126–1133, 2003.

[Taskar et al., 2002] B. Taskar, P. Abbeel, and D. Koller. Discriminative probabilistic
models for relational data. In Eighteenth Conf. on Uncertainty in Artiﬁcial Intelli-
gence (UAI02), 2002.

[Taskar et al., 2004] B. Taskar, V. Chatalbashev, and D. Koller. Learning associative

markov networks. In Proc. of the Int. Conf. on Machine Learning (ICML), 2004.

[Taskar, 2004] Ben Taskar. Learning Structured Prediction Models: A Large Margin

Approach. PhD thesis, Stanford University, Stanford, CA, December 2004.

[Wu et al., 2004] Z. Wu, Y. Wang, and G. Pan. 3D face recognition using local shape
map. In Proc. of IEEE Intern. Conf. on Image Processing, pages 2003–2006, 2004.

IJCAI-07

2230

