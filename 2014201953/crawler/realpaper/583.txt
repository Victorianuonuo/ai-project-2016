Action representation and partially observable planning using epistemic logic 

F-31062 Toulouse Cedex 

F-31062 Toulouse Cedex 

Andreas Herzig 

IRIT/UPS 

France 

herzig@irit.fr 

Jerome Lang 

IRIT/UPS 

France 

lang@irit.fr 

Pierre Marquis 

CRIL/Universite d'Artois 

F-62307 Lens Cedex 

France 

marquis@cril.univ-artois.fr 

Abstract 

We  propose  a  purely  logical  framework  for plan(cid:173)
ning in partially observable environments.  Knowl(cid:173)
edge states are expressed in a suitable fragment of 
the epistemic logic S5.  We show how to lift the ef(cid:173)
fects of actions (both physical actions and sensing 
actions) from the state level to the epistemic level. 
We show how progression, regression and plan gen(cid:173)
eration can be achieved in our framework. 

Introduction 

1 
Planning under incomplete knowledge and partial observabil(cid:173)
ity is a tricky issue in AI, because of its computational (tem(cid:173)
poral  and  spatial)  hardness. 
Partially  obsewable  Markov 
decision processes (POMDP) are the mainstream approach to 
partially  observable  planning.  Nevertheless,  the  applicabil(cid:173)
ity of the POMDP approach is limited from the practical side 
as soon as the set of states has a strong combinatorial struc(cid:173)
ture, rendering the number of states much too high for an ex(cid:173)
plicit representation of actions, preferences, and policies.  On 
the other hand, logical approaches to planning under incom(cid:173)
plete knowledge allow for much more compact encodings of 
planning problems than POMDPs; most of them deal with an 
incomplete  initial  state  and/or nondeterministic  actions,  but 
either they do not handle partial observability, or at least they 
do it in a very simple way, by assuming for instance that the 
set  of variables  is  partitioned  between  (directly)  observable 
and unobservable variables. 

To  fill  the gap between POMDPs and logical  approaches, 
an abstraction of the POMDP model (leaving aside probabili(cid:173)
ties and expected utility) can be considered. It should account 
at least for the following elements:  a set S of states;  a set 
of belief states built from S  ;  a set 
of actions,  where each 
action  is  associated  with  a  transition  model  between  states 
and/or belief states;  some  preference structure  (e.g.,  a  sim(cid:173)
ple goal  or a utility  function);  and  a set 
of  observations, 
together with  some  correlation  function  between  states  and 
observations. 

While  policies  for a  fully  observable MDP map  states  to 
actions,  the  output of such  an  abstract POMDP  is  a  policy 
mapping belief states to  actions;  indeed,  a  POMDP can  be 
viewed as a fully observable MDP over the set of belief states 

(this is a classical way of understanding POMDPs - and even 
to solve them). 

In  this paper,  we present a rich logical framework that in(cid:173)
stantiates the abstraction above, views a partially observable 
process as a fully observable process over belief states,  and 
allows for expressing actions and policies in a compact way. 
The framework has a fairly good level of generality (since it 
avoids for instance to commit to a particular action language, 
see Section 3.1) and is therefore modular enough to be easily 
adapted or extended. 

The  simplest  and  best-known  way  of  distinguishing  be(cid:173)
tween  truths  and  beliefs  in  logic  consists  in  expressing  the 
problem in  an epistemic or doxastic  logic.  To make the ex(cid:173)
position simpler,  we assume that the agent has accurate be(cid:173)
liefs,  i.e.,  all  she  believes  is  true  in  the  actual  world.  This 
means  that  we  identify  belief and  knowledge  (since  knowl(cid:173)
edge  is  usually  viewed  as  true  belief);  therefore our frame(cid:173)
work is based on the logic S5 and instead of belief we use the 
term  knowledge  throughout  the  paper.]  S5  is  computation(cid:173)
ally no more complex than classical logic:  S5 satisfiability is 
NP-complete [Ladner, 19771. 

In  Section  2  we  define  two  notions  of knowledge  states: 
simple  knowledge  states  (for  on-line  plan  execution)  and 
complex  knowledge  states  (for  off-line  reasoning  about  the 
effects  of a  plan).  In  Section  3  we  show  how  a  knowledge 
state evolves when an action is performed. Then we show in 
Section  4  how  to  perform  goal  regression,  and  we  show  in 
Section 5 how it can be used so as to implement a sound and 
complete plan generator. Section 6 discusses related work. 

2  Knowledge states 
The language 
of propositional  logic  S5  is built  up from 
a  finite  set  of propositional  variables  VAR,  the  usual  con(cid:173)
nectives, 
and  the  epistemic 
modality  K.  S5  formulas  are denoted  by  capital  Greek  let(cid:173)
etc.  An  S5  formula is  objective (or modality-free) 
ters 
iff it does  not contain  any occurrence of K  (i.e.,  it  is  a clas(cid:173)
sical propositional formula).  Objective formulas are denoted 

the  logical  constants 

and 

1 Alternatively, we could have chosen to work with beliefs, using 
the  doxastic  logic  KD45,  which  is  very  similar  to  S5  except  that 
beliefs may be wrong, that is, 
is not an axiom. The techni(cid:173)
cal issues developed in this paper would have been almost identical. 
Now,  choosing  another logic  than  S5  or KD45  would  induce  a  lot 
of complications, including an important complexity gap. 

REASONING ABOUT ACTIONS AND CHANGE 

1067 

by  small  Greek  letters  
formulas  from  

is denoted  by 

etc.  and  the  set  of all  objective 

A  fundamental property of S5  is  that nested  modalities col(cid:173)

is  equivalent  to 

lapse,  i.e., 
for this  reason,  we  assume  without  loss  of generality  that  the 
scope  of  each  occurrence  of  modality  K  in  formula  
is  an 
objective  formula. 

An  epistemic atom  is  an  S5  formula of the  form  
where 
is  objective.  An  epistemic formula  is  a  formula  built  up 

from  epistemic  atoms  and  usual  connectives: 

is an epistemic formula,  while  

is  not.  An 
epistemic  formula is positive  iff it  does  not contain  any  occur(cid:173)
rence of K  in  the  scope of a  negation: 
is not positive,  while 

called  states.  States  are  denoted  by  s,  s'  etc. 
jective  formula,  we  let  

,  also 
is  the  set  of  all  interpretations  of  
is  an  ob(cid:173)
If  
is  a  model  of 

A  structure2  for  S5  is  defined  as  a  nonempty  set  of states 
M 
S.  Rather  than  "structure",  we  call  M  a  knowledge 
state  (SKS).  Intuitively,  it  represents  all  the  states  the  agent 
considers  possible.  The  satisfaction  of  an  S5  formula  by  an 
SKS  M  for a  state  s   M  is  defined  inductively  by: 

A  complex  knowledge  state  (CKS)  is  a  positive  epistemic 
formula,3  generated  by  epistemic  atoms  and  the  connectives 
2This  semantics  is  equivalent  (and  simpler  for  our  purpose)  to 
the usual  semantics by means of Kripke models <W, wa/, R)  where 
W  is a set of worlds, val a valuation function and R an equivalence 
relation.  Sec for instance [Fagin et al.,  19951. 

3We  restrict  the  syntax  of CKS  to  positive  epistemic  formulas 
because for almost all problems, ignorance can already be expressed 
by  the  fact  that  positive  knowledge  is  not  provable  from  the  cur(cid:173)
rent  CKS.  This  way  of generating  explicit  ignorance  from  implicit 
is a kind of Epistemic Closed World Assumption, already at work in 
[Reiter,  2001]  and  reminiscent  of autoepistemic  logic;  its principle 
can be roughly be stated as  "if I cannot  prove that I know 
then  I 
.  However,  for the purpose of this paper,  we do not 
don't  know 
need this completion because the set of valid plans from a CKS and 
the set of valid plans from its completion coincide. 

3  Actions and progression 
In general, actions have both  physical  (or otitic)  and epistemic 
effects,  i.e.,  they  are  meant  to  change  both  the  state  of  the 
world  and  the  agent's  knowledge  state,  but  without  loss  of 
generality we  assume  (as  usually  in  A I)  that  any  "mixed"  ac(cid:173)
tion can  be decomposed into two actions,  the  first  one  having 
only  ontic  effects  and  the  second  one  only  epistemic  effects. 
For  instance,  the  action  of tossing  a coin  is  decomposed  into 
a  bJ  i n d - t o ss  action  followed  by  a  s ee  action  telling  the 
agent  whether the  coin  has  landed on  h e a ds  or on  t a i l s. 

in  a  prepositional  action 

3.1  O n t ic  actions 
Ontic  actions  are  meant  to  have  effects  on  the  world  outside 
the  agent,  especially physical effects  such  as  moving  a  block, 
switching  the  light,  moving  etc.  They  are  assumed  to  be de(cid:173)
language  (allowing  or  not 
scribed 
for  nondeterminism,  for  ramifications/causality).  Any  action 
language 
can  be chosen,  provided that  it  is  propositional 
and  that  it  expresses  the  effects  of  an  action  a  within  a  for(cid:173)
involving  atoms  labelled by  t  and atoms  labelled  by 
mula 
(the  former for the  state  before the  action  is  performed, 
the  latter  for  the  state  after  it  is  performed).  Among  candi(cid:173)
date  languages  we  find  those  of  the  
family  [Gelfond  and 
Lifschitz,  1993],  "propositionalized"  situation  calculus  [Lin, 
2000]  and causality  languages  [McCain  and Turner,  1998].4 

of  an  action  

The  description 

allows  for  comput(cid:173)
ing  the  successor  state  of  a  state  s  (or  the  set  of  successor 
is  nondeterministic).  This  set  is  represented  by 
states  if 
any  objective  formula  prog  
(whose  models  form  the 
set  of  successor  states).  This  definition  extends  to  sets  of 
initial  states,  or  equivalently  to  propositional  formulas,  by 

4The  common  core  of these  languages  is  the  use  of explicit  or 
implicit successor state axioms.  These languages coincide for deter(cid:173)
ministic,  ramification-free  actions  and  differ  in  the  way  they  treat 
nondeterminism  (using  for  instance  exogeneous  variables  or  Re(cid:173)
l e a se statements), ramifications, etc. 

1068 

REASONING ABOUT ACTIONS AND CHANGE 

before  performing  

then  she  still  knows  it  after)  and  re(cid:173)

liability  (if  the  agent  observes  
after  observing  it).  These  three 
holds,  so  that  she  knows  
properties  imply  that  the  effects  of an  epistemic  action  asso(cid:173)
ciated  with  the  outcome  set  
by  the  following  progression  operator: 

after  performing 

can  be  represented 

then 

The  problem  with  the  latter  definition  is  that  the  CKS  has 
to  be  put  in  E D NF  first.  This  does  not  induce  any  loss  of ex(cid:173)
pressivity  but  the  transformation  may  be  exponentially  large 
so  that  we  may  want  to  compute  the  successor  CKS  directly 
from a CKS  expressed in  any form, such as  in  Example  1. 

We now give a more elegant way  of computing progression 
via  an  extension  of  variable forgetting  to  S5  formulas.  We 
recall first from  [Lin  and Reiter,  1994] the inductive definition 

4  Regression 
The problem is  stated as follows:  given a  CKS  
(represent(cid:173)
ing a goal knowledge state)  and  an  (ontic or epistemic) action 

characterize  the  weakest  CKS  denoted  by  R e gin 

which  performing  

leads to  a CKS  satisfying 

7Note  that  actions  that  may  fail  to  be  informative  can  only  be 
expressed  here by  the occurrence  of a  tautology  in their outcomes. 
In this case,  unfortunately,  we get that  Prog 
because 

as soon as 

for some 

8This docs  not  induce  any  loss of generality,  because  any  epis(cid:173)
temic  action  can  be  rewritten  equivalently  into  a  logarithmic  se(cid:173)
quence  of binary  tests,  together  with  the  addition  of some  domain 
constraints. 

REASONING ABOUT ACTIONS AND CHANGE 

1069 

5  Plan generation 
Definition 6 (planning problems)  A  planning  problem 
w.r.t.  a  propositional  action  language 
consists  of  an 
SKS 
init describing the initial knowledge state of the 
agent, a finite set of actions. 
{ontic)(epistemic) 
and a CKS T describing the goal. Effects of ontic actions are 
described in 

The  reason  why 

is  a  CKS  is  that  it  is  not  sufficient 
to  reach  the  goal,  it  must  also  be  the  case  that  the  goal  is 
known to be reached,  may be purely epistemic goal such as 
i.e., an agent may have the ultimate goal to know 

whether  holds or not. 

Plans are defined inductively as follows: 
• 
•  any action (ontic or epistemic) is a plan; 

the empty plan 

is a plan; 

sistent with 

and built up from variables of 

, only. 
The latter abductive characterization of ontic actions is in(cid:173)
dependent of the action language chosen - and it now allows 
for characterizing the regression of complex epistemic  states 
by an ontic action. 

4.2  Regression  for epistemic  actions 

Therefore, a plan can be seen as a program without loops, 
whose branching conditions are epistemic formulas: the agent 
can decide whether she knows that a given objective formula 
is  true (whereas she  is not always  able to decide whether a 
given objective formula is true in the actual world). 

While CKS are relevant for off-line planning, i.e., for rea(cid:173)
soning about the possible effects of a plan, they are no longer 
relevant  for  representing  knowledge  during  plan  execution, 
. since at each time step the agent is in exactly one knowledge 
state. 

} 

Sketch of proof. We give it in the latter case only (the proof 
for  the  general  case  is  similar).  We  abbreviate  Reg 
by 
We  first  establish  (the  proof  is  omitted)  that 
necessarily a CKS, 

Now, 

is 

At  that stage, we make use of the following lemma:  for any 
objective formulas A, B  and  C, 
(KB  V  KC)  is  valid 
is then 
is valid. 
is valid or 
(in  S5)  iff  

1070 

REASONING ABOUT ACTIONS AND CHANGE 

Definition 8 (valid plans)  A  plan  
is 
planning problem  V  if and only  if  Prog 
Initially,  the agent does not know the 
Exemple 2 (cont'd) 
values  of  and 
and 
her goal is to reach a belief state where she knows the value 

(her  initial  knowledge  state  is 

^alid  plan for  the 

and compute 

A valid plan can be computed by the following backward 
algorithm  based  on  goal  regression  which  is  reminiscent  of 
dynamic  programming.  The  current goal 
expressed  in 
Then we nondeterministically pick 
EDNF, is initialized as 
The  current goal  is 
an action 
then  updated  by 
The  process 
or  it  is  not  possible  to  im(cid:173)
is  iterated  until 
anymore. Since there is a finite number of possible 
prove 
belief  states,  the  algorithms  stop  and  returns 
valid  plan, 
if such  a  plan  exists.  An  ordered  list  L  is  constantly  up(cid:173)
dated,  initialized by 

where '. 

each time a new disjunct (i.e.,  not sub(cid:173)

sumed  by  any  previous disjunct  of 
after regressing by action a, the pair 

is added to 
is added to L. 
There are two slightly different possible outputs:  (1) either 
the  output  is just  L,  i.e.,  an  ordered knowledge-based pro(cid:173)
gram (or decision list):  at execution time, when observations 
are made, the new knowledge state is computed, then we look 
for the  leftmost 
is true in the cur(cid:173)
rent  knowledge  state and 
is  performed;  (2)  or the  output 
is  a  ready-to-use conditional plan  computed by  "simulating" 
possible executions from 

in L such that 

6  Related work 
Knowledge-based  programs  In  the  planning  community, 
the  idea  of  using  explicit  knowledge  preconditions  for  ac(cid:173)
tions  and plans comes back to  [Moore,  1985; Morgenstern, 
1987J.  Developed  in  a different perspective  (agent design), 
knowledge-based programs  [Fagin  et  al,  1995;  Brafman  et 
al,  1998; Herzig et al, 2000; Reiter,  2001]  are high-level pro(cid:173)
tocols that describe the actions an agent should perform as a 
function of her knowledge. Thus, in a knowledge-based pro(cid:173)
gram,  branching  conditions  are  epistemically  interpretable, 
and  plans  explicitly  involve  deduction  tasks  during  on-line 
execution (just like in our framework). Actually, the output of 
our plan  generation  process  is  a  knowledge-based program. 
Therefore,  our  work  can  be  seen  as  an  upstream  task  that 
generates a valid knowledge-based program from a compact 
specification of action effects and goals. 

Action  languages  A  number of works have extended  action 
languages so as to handle explicit knowledge and partial ob(cid:173)
servability,  especially  [Lobo  et  al.,  1997;  de  Giacomo  and 
Rosati,  1999;  Baral  and  Son,  2001].  Knowledge  is  repre(cid:173)
sented in all cases by an explicit or implicit epistemic modal(cid:173)
ity  (plus  a  "minimal  knowledge" semantics  in  [de  Giacomo 
and  Rosati,  1999]).  The  line  of work  most  related  to  ours 
is of [Baral  and Son,  2001];  indeed, not only they represent 
epistemic  actions  with  an  epistemic  modality  but  they  also 
allow  for conditional  plans  with  epistemic  branching condi(cid:173)
tions.  Our work can  be  seen  as  an  extension of theirs:9  (i) 
our formalism is general enough to accept any propositional 
action  language  (including  those  handling  causal  rules)  for 
representing  the  effects  of ontic  actions);  (ii)  our  syntax  is 
less  restricted,  since  we  allow  for  any  and-or  combination 
of SKS  (i.e.,  CKSs)  while  they  consider  SKS  only;  as  ar(cid:173)
gued in  Section  3,  this makes the representation more com(cid:173)
pact,  when reasoning at planning time about the future con(cid:173)
sequences of actions; (Hi) our progression and regression op(cid:173)
erators have significant computational characterizations (e.g., 
ontic regression has an abductive characterization); lastly, we 
have a sound and complete algorithm for plan generation. 
Planning under partial observability There is a number of 
recent approaches for logic-based plan generation under par(cid:173)
tial observability. 

[Bonet and Geffner,  1998]  give a  high-level  language for 
describing  action  effects  on  both  the  world  and  the  agent's 
beliefs.  Their language is a decidable fragment of first-order 
logic.  By  describing  ontic  actions  with  successor  state  ax(cid:173)
ioms,  they  allow  for  handling  the  frame  problem  and  ram(cid:173)
ification  problems.  After  a  problem  has  been  represented 
in  their  language,  its  description  is  automatically  translated 
into  a  POMDP  model  and  solved  by  using  POMDP  algo(cid:173)
rithms, so that there is no need to define progression and re(cid:173)
gression directly in  the logic, nor to have an explicit knowl(cid:173)
edge modality: this is the main difference with our approach, 
where the compact logical  representation  is kept and propa(cid:173)
gated throughout the process. 

The next three approaches solve the plan generation prob(cid:173)
lem directly in a high-level language but, on the other hand, 
they all make important restrictions that lead to a loss of ex(cid:173)
pressivity.  These  restrictions  imply  that  none  of  these  ap(cid:173)
proaches makes use of action languages, while ours can ben(cid:173)
efit  from  the  huge  amount of work  in  this  area and  accord(cid:173)
ingly, can handle the frame problem as well  as ramification 
and causality in the best possible way while maintaining com(cid:173)
putational complexity at a reasonable level. 

[Bacchus and  Petrick,  1998; Petrick and Bacchus,  2002], 
like  us,  use  an  epistemic  modality.  Apart  from  the  repre(cid:173)
sentation  of ontic  actions  (less  expressive  than  ours  due  to 
the abovementioned point10), they restrict the syntax of epis-

9Actually, only of the first part of [Baral and Son, 2001], since 
the second half of their paper gives a detailed study of sound and 
efficient approximations of their formalism.  We plan to integrate 
similar approximations in our framework. 

,0On the other hand, they use a fragment of first-order logic which 
allows for expressing some actions (such as value tests) elegantly, 
and they motivate their expressivity restrictions by efficiency con(cid:173)
siderations, so that their approach is a good trade-off between effi-

REASONING ABOUT ACTIONS AND CHANGE 

1071 

temic formulas (for instance,  simple disjunctive beliefs such 
as K(aV6) cannot be expressed) and consequently, as they no(cid:173)
tice, their algorithm sometimes fails to discover a valid plan. 
„. The approaches [Sertoli et  al.,  2001; Rintanen, 2002] do 
not  make  use  of an  epistemic  modality,  and  therefore  can(cid:173)
not explicitly express disjunctions of belief states (i.e., CKSs) 
or complex  knowledge-based  programs.  The  representation 
of  belief  states  in  both  approaches  uses  BDDs,  which  al(cid:173)
low for a compact representation but not as space efficient as 
DAG-based propositional formulas.  While the algorithm in 
[Bertoli et al, 2001 ] uses progression (based on model check(cid:173)
ing),  [Rintanen, 2002]  has a regression operator, and, inter(cid:173)
estingly enough, his combination operator 
between belief 
states  (which  aims at computing, given  two  belief states  B\ 
and B2,  the maximal belief states  in  which,  after observing 
the values of observable variables, leads to know that the true 
state is  in  51  or to know that the true state is in  B2) can be 
reformulated using  our epistemic  regression (Section 4.2)11 
and  thus epistemic  logic  helps  understanding how  and  why 
this operator works.12 
Situation  calculus  [Scherl  and  Levesque,  1993]  represent 
sensing  actions  in  the  situation calculus by  means of an  ex(cid:173)
plicit  accessibility relation  between  situations (which means 
that  knowledge is  treated  as  an  ordinary  fluent)  which  cor(cid:173)
responds exactly to  the  semantics  of our epistemic  modality 
(once  situations  have  been  identified  with  states).  Our  ap(cid:173)
proach  expresses  the  problem  at  the  formula  level  and  en(cid:173)
ables thus a more concise representation and can benefit from 
existing complexity and automated deduction results for S5. 
Levesque  [Levesque,  1996]  builts  on  the  above  framework 
towards a general theory of planning with  sensing, handling 
complex plans  involving,  like ours,  nondeterminism, obser(cid:173)
vations and branching (and also loops). 

Acknowledgements 
The  third  author  has  been  partly  supported  by  the  IUT  de 
Lens,  the  Universite  d'Artois,  the  Region  Nord  /  Pas-de-
Calais  under  the  TACT-TIC  project,  and  by  the  European 
Community FEDER Program. 

References 
[Bacchus and Pctrick, 1998]  F. Bacchus and R. Petrick. Modelling 
an agent's incomplete knowledge during planning and execution. 
In KR-98, pages 432-443, 1998. 

[Baral and Son, 2001]  C. Baral and T. Son.  Formalizing sensing 
actions - a transition function based approach.  Artificial Intelli(cid:173)
gence, 125(1-2):19-91,2001. 

ciency and expressivity. 

11 Indeed, introducing the action observe performed systemati(cid:173)
cally after any ontic action (Rintanen docs not consider real epis(cid:173)
temic actions but assumes instead automatic observability: there is a 
set of variables whose value is observed after any action) and giving 
the truth value of each observable variable 
can be iden(cid:173)
for(B) 
tified with Reg(observe, 
is a propositional  formula such that  Mod(for(B)) 
More 
then Kfor(B)  is one of the disjuncts of 
precisely, if 
Reg(observe,  Kfor(B\)  V  Kfor(B2))  after  minimization. 

where 

12Note also that all approaches discussed in this section pay at(cid:173)
tention to efficiency (which may explain the restrictions made) and 
all of them have been implemented and report experimental results. 

[Bertoli et al, 2001]  P.  Bertoli,  A.  Cimatti,  M.  Roveri,  and 
P. Traverse  Planning in nondeterministic domains  under partial 
In  IJCAI-OI,  pages 
observability  via  symbolic  model  checking. 
473-478,2001. 

[Bonet and Geffner,  1998]  B.  Bonet  and  H.  Geffncr. 

High-
level  planning  and  control  with  incomplete  information  using 
POMDPs.  In  AAAI  Fall Symposium om POMDPs,  1998. 

[Brafman et al,  1998]  R. Brafman, J. Halpern, and Y. Shoham.  On 
the  knowledge  requirements  of tasks.  Artificial  Intelligence,  98, 
1998. 

[de Giacomo and Rosati,  1999]  G. de Giacomo and R. Rosati. Min(cid:173)
imal  knowledge  approach  to  reasoning  about  actions  and  sens(cid:173)
ing.  Electronic  Transactions  on Artificial Intelligence,  3  (section 
C):l-18,  1999. 

[Fagine/a/., 1995]  R.  Fagin,  J.  Halpcn,  Y.  Moses,  and  M.  Vardi. 

Reasoning about Knowledge.  MIT Press,  1995. 

[Gelfond and Lifschitz,  1993]  M. Gelfond and V. Lifschitz.  Repre(cid:173)
senting  action  and  change  by  logic  programs.  Journal  of Logic 
Programming,  17:301-322,  1993. 

[Herzig et al, 2000]  A. Herzig, J. Lang, D. Longin, and Th. Polac-
sek.  A  logic for planning under partial observability.  In AAAl-00, 
pages 768-773, 2000. 

[Ladner,  1977]  R.E.  Ladner.  The  computational  complexity  of 
provability in systems of modal propositional logics. SI AM Jour(cid:173)
nal of Computing,  6:467-AM,  1977. 

[Levesque,  1996]  H. Levesque.  What is planning in the presence of 

sensing?  In AAAI-96, pages  1139-1146,  1996. 

[Lin and Reiter,  1994]  F. Lin and  R. Reiter.  Forget it!  In AAAl Fall 
Symposium on Relevance, pages 154-159, New Orleans, 1994. 
[Lin, 2000]  F Lin.  From causal theories to successor state axioms 

and STRIPS-like systems.  In AAAl-00, pages 786-791, 2000. 

[Lobo et al.,  1997]  J. Lobo, G.  Mendcz, and S. R. Taylor.  Adding 
In  AAAI-97, 

knowledge  to  the  action  description  language  A. 
pages 454-459,  1997. 

[McCain and Turner,  1998]  N. McCain and H. Turner. Satisfiability 
planning with causal theories.  In KR-98, pages 212-223,  1998. 
[Moore,  1985]  R.C.  Moore.  A  formal  theory  of knowledge  and 
action,  chapter  Formal  Theories  of  the  Commonscnse  World. 
Ablex,  1985. 

[Morgenstcrn,  1987]  L. Morgenstern.  Knowledge preconditions for 

actions and plans.  In IJCAI-87, pages 867-874,  1987. 

[Pctrick and Bacchus, 2002J  R.  Pctrick  and  F.  Bacchus. 

A 
knowledge-based approach to planning with incomplete informa(cid:173)
tion and sensing.  In AIPS-02, pages 212-221, 2002. 

[Reiter,  1993]  R. Reiter.  The frame problem in the situation calcu(cid:173)
lus:  a simple solution (sometimes) and a completeness result for 
goal  regression.  In V.  Lifschitz,  editor, Artificial Intelligence and 
Mathematical  Theory  of Computation:  Papers  in  Honor  of John 
McCarthy, pages 359-380.  Academic Press,  1993. 

[Reiter, 2001]  R.  Reiter.  Knowledge  in  Action:  Logical  Founda(cid:173)
tions for Specifying  and Implementing  Dynamical  Systems.  MIT 
Press, 2001. 

[Rintanen, 2002]  J. Rintanen. Backward plan construction for plan(cid:173)
ning with partial observability. In AIPS-02, pages  173-182, 2002. 
[Scherl and Levesque,  1993]  R. B. Scherl and H. J. Levesque.  The 
frame  problem  and  knowledge-producing  actions.  In  AAA  1-93, 
pages 698-695,  1993. 

1072 

REASONING ABOUT ACTIONS AND CHANGE 

