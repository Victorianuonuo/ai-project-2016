Fast Algorithm for Connected Row Convex Constraints∗

Yuanlin Zhang

Texas Tech University

Computer Science Department

yzhang@cs.ttu.edu

Abstract

Many interesting tractable problems are identiﬁed
under the model of Constraint Satisfaction Prob-
lems. These problems are usually solved by forcing
a certain level of local consistency. In this paper,
for the class of connected row convex constraints,
we propose a novel algorithm which is based on
the ideas of variable elimination and efﬁcient com-
position of row convex and connected constraints.
Compared with the existing work including ran-
domized algorithms, the new algorithm has better
worst case time and space complexity.

Introduction

1
Constraint satisfaction techniques have found wide applica-
tions in combinatorial optimisation, scheduling, conﬁgura-
tion, and many other areas. However, Constraint Satisfaction
Problems (CSP) are NP-hard in general. One active research
area is to identify tractable CSP problems and ﬁnd efﬁcient
algorithms for them.

An interesting class of row convex constraints was iden-
tiﬁed by van Beek and Dechter (1995). It is known that if
a problem of row convex constraints is path consistent, it is
tractable to ﬁnd a solution for this problem. However, when
the problem is not path consistent, path consistency enforcing
might not lead to global consistency due to the possibility that
the row convexity of some constraints is destroyed. Deville
et al. (1997) restrict row convexity to connected row convex-
ity (CRC). In fact, the scene labeling problem and constraint
based grammar examples given in [van Beek and Dechter,
1995] are CRC constraints. One can ﬁnd a solution of CRC
constraints by enforcing path consistency. Deville et al. also
provide an algorithm more efﬁcient than the general path con-
sistency algorithm by making use of certain properties of row
convexity. The algorithm has a worst case time complexity
of O(n3d2) with space complexity of O(n2d) where n is
the number of variables, d the maximum domain size. Re-
cently, Kumar (2006) has proposed a randomized algorithm
for CRC constraints with time complexity of O(γn2d2) and
space complexity O(ed) (personal communication) where e

∗

The research leading to the results in this paper was funded in

part by NASA-NNG05GP48G.

is the number of constraints and γ the maximum degree of
the constraint graph.

In this paper, making use of the row convexity and connect-
edness of constraints, we propose a new algorithm to solve
CRC constraints with time complexity of O(nσ2d + ed2)
where σ is the elimination degree of the triangulated graph of
the given problem. We observe that the satisﬁability of CRC
constraints is preserved when a variable is eliminated with
proper modiﬁcation of the constraints on the neighbors of the
eliminated variable. The new algorithm simply eliminates the
variables one by one until it reaches a special problem with
only one variable.

A key operation in the elimination algorithm is to com-
pose two constraints. The properties of connectedness and
row convexity of the constraints make it possible to get a fast
composition algorithm with time complexity of O(d).

In this paper, we present the elimination algorithm after
the preliminaries on CRC constraints. The methods to com-
pute composition of row convex and connected constraints
are then proposed. We examine the elimination algorithm on
problems with sparse constraint graphs before we conclude
the paper.

2 Preliminaries
A binary constraint satisfaction problem (CSP) is a triple
(V, D, C) where V is a ﬁnite set of variables, D ={Dx | x ∈
V and Dx is the ﬁnite domain of x}, and C is a ﬁnite set of
binary constraints over the variables of V . As usual, we as-
sume there is only one constraint on a pair of variables. We
use n, e, and d to denote the number of variables, the number
of constraints, and the maximum domain size of a CSP prob-
lem. We use i, j, . . . and x, y, . . . to denote variables in this
paper. The constraint graph of a problem (V, D, C) is a graph
with vertices V and edges E = {{i, j} | cij ∈ C}. A CSP
is satisﬁable if there is an assignment of values to variables
such that all constraints are satisﬁed.

Assume there is a total ordering on each domain of D.
When necessary, we introduce head and tail for each variable
domain such that head (tail respectively) is smaller (larger
respectively) than any other value of the domain. Func-
tions succ(u, Di) (u ∈ Di ∪ {head}) and pred(u, Di)
(u ∈ Di ∪ {tail}) denote respectively the successor and pre-
decessor of u in the current domain Di∪ {head, tail}. The
domain Di is omitted when it is clear from the context.

IJCAI-07

192

Given a constraint cij and a value a ∈ Di, the extension
set cij[a] is {b ∈ Dj | (a, b) ∈ cij}. cij[a] is also called the
image of a with respect to cij. Clearly cij[head] = cij[tail] =
∅. Standard operations of intersection and composition can
be applied to constraints. The composition of cix and cxj
is denoted by cxj ◦ cix.
It is convenient to use a Boolean
matrix to represent a constraint cij. The rows and columns
are ordered by the ordering of the values of Di and Dj.

A constraint cij is arc consistent (AC) if every value of
Di has a support in Dj and every value of Dj has a support
in Di. A CSP problem is arc consistent if all its constraints
are arc consistent. A path x, . . . , y of a constraint graph is
consistent if for any assignments x = a and y = b such that
(a, b) ∈ cxy, there is an assignment for each of other variables
in the path such that all constraints over the path are satisﬁed
by the assignments. A constraint graph is path consistent if
every path of the graph is consistent. A CSP is path consistent
if the completion of its constraint graph is path consistent. A
CSP is partially path consistent if its constraint graph is path
consistent [Bliek and Sam-Haroud, 1999].

A constraint cij is row convex if there exists a total order-
ing on Dj such that the 1’s are consecutive in each row of
the matrix of cij. The reduced form of a constraint cij, de-
noted by c∗
ij, is obtained by removing from Di (and Dj re-
spectively) those values whose image with respect to cij (cji
respectively) is empty. For a row convex constraint cij, the
image of a ∈ Di can be represented as an interval [u, v]
where u is the ﬁrst and v is the last value of Dj such that
(a, u), (a, v) ∈ cij. A row convex constraint cij is connected
if the images [a, b] and [a(cid:3), b(cid:3)] of any two consecutive rows
(and columns respectively) of cij are not empty and satisfy
(cid:8)= ∅.
[a, b]∩ [ pred(a(cid:3)), b(cid:3)]
Note that, for our purposes, the deﬁnition of connectedness
here is stronger than that by Deville et al. (1997). If a con-
straint is row convex and connected, it is arc consistent. A
constraint cij is connected row convex if its reduced form is
row convex and connected. The constraints obtained from the
intersection or composition of two CRC constraints are still
connected row convex. The transposition of a CRC constraint
is still connected row convex. Enforcing path consistency on
a CSP of CRC constraints will make the problem globally
consistent [Deville et al., 1997].

(cid:8)= ∅ or [a, b]∩ [a(cid:3), succ(b(cid:3))]

The consistency property on row convex constraints is due
to some nice property on convex sets. Given a set U and a
total ordering ≤ on it, a set A ⊆ U is convex if its elements
are consecutive under the ordering, that is

A = {v ∈ U | min A ≤ v ≤ max A}.

Consider a collection of sets S = {E1, . . . , Ek} and an or-
dering ≤ on ∪i=1..kEi where every Ei(1 ≤ i ≤ k) is convex.
The intersection of the sets of S is not empty if and only if
the intersection of every pair of sets of S is not empty [van
Beek and Dechter, 1995; Zhang and Yap, 2003].

(V −{x}, D, C(cid:3)) where C(cid:3) = C ∪{cxj ◦ cix ∩ cij | cjx, cix ∈
Rx and i (cid:8)= j} − Rx. In the elimination, when composing
cix and cxj, if cij /∈ C we simply take cij as a universal
constraint, i.e., Di × Dj.

Theorem 1 Consider an arc consistent problem P =(V, D, C)
of CRC constraints and a variable x ∈ V .
Let
P (cid:3)=(V (cid:3), D(cid:3), C(cid:3)) be the problem after x is eliminated. P is
satisﬁable iff P (cid:3) is satisﬁable.

Proof We ﬁrst prove if P is satisﬁable, so is P (cid:3). Let s be
a solution of P , sx an assignment of x by s, and s¯x be the
restriction of s to V (cid:3). We only need to show that s¯x satisﬁes
ij ∈ C(cid:3) for all cix, cxj ∈ C. Since s is a solution of P , s¯x
c(cid:3)
satisﬁes cix, cjx and cij. Hence, s¯x satisﬁes c(cid:3)
ij.
Next we prove if P (cid:3) is satisﬁable, so is P . Let t be a solu-
tion of P (cid:3). We will show that t is extensible consistently to
x in P . Let Vx be {i | cix ∈ Rx}. For each i ∈ Vx, let the
assignment of i in t be ai. Let S = {cix[ai] | i ∈ Vx}. Since
all constraints of P are row convex and P is arc consistent,
the sets of S are convex and none of them is empty.
Consider any two sets cix[ai], cjx[aj] ∈ S. Since t is a
solution of P (cid:3), (ai, aj) ∈ c(cid:3)
ij is a constraint of P (cid:3).
ij = cxj ◦ cix ∩ cij, where cij is either in C
The fact that c(cid:3)
or universal, implies that there exists a value b ∈ Dx such
that ai, aj and b satisfy cix, cjx and cij. Hence, cix[ai] ∩
cjx[aj] (cid:8)= ∅. By the property on the intersection of convex
sets, the intersection of the sets of S is not empty. For any
v ∈ ∩E∈SE, it is easy to verify that (t, v) is a solution of P .
Therefore, P is satisﬁable.

2
Based on Theorem 1, we can reduce a CSP with CRC con-
straints by eliminating the variables one by one until a trivial
problem is reached.

ij where c(cid:3)

consistent ← false, return

consistent ← true
C(cid:2) ← C, C(cid:2)(cid:2) ← ∅, L ← V
while L (cid:5)= ∅ do

// (V, D, C) is a CSP problem, s is a stack
enforce arc consistency on (V, D, C)
if some domain of D becomes empty then

Algorithm 1: Basic elimination algorithm for CRC con-
straints
eliminate (inout(V, D, C), out consistent, s)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21

select and remove a variable x from L
C(cid:2)
x ← {cyx | cyx ∈ C(cid:2)}
foreach cix, cjx ∈ C(cid:2)
x where i < j do
c(cid:2)
ij ← cxj ◦ cix
if cij ∈ C(cid:2)
ij ← c(cid:2)
then c(cid:2)
ij ∩ cij
C(cid:2) ← (C(cid:2) − {cij}) ∪ {c(cid:2)
ij}
collect to Q the values not valid under c(cid:2)

remove from the domains the values in Q and propagate the removals
if some domain becomes empty then
consistent ← false, return

C(cid:2) ← C(cid:2) − C(cid:2)
C(cid:2)(cid:2) ← C(cid:2)(cid:2) ∪ C(cid:2)
s.push (x)

x

x

ij

C ← C(cid:2)(cid:2)

, consistent ← true

3 Variable elimination in CRC
Consider a problem (V, D, C) and a variable x ∈ V . The rele-
vant constraints of x, denoted by Rx, are the set of constraints
{ cyx | cyx ∈ C}. To eliminate x is to transform (V, D, C) to

The procedure eliminate((V, D, C), consistent, s) in Al-
gorithm 1 eliminates the variables of (V, D, C). When it
returns, consistent is false if some domain becomes empty
and true otherwise; the eliminated variables are pushed to the

IJCAI-07

193

stack s in order and C will contain only the “removed” con-
straints associated with the eliminated variables. Most parts
of the algorithm are clear by themselves. The body of the
while loop (lines 7 – 20) eliminates the variable x. Line 18
discards from C(cid:3) the constraints incident on x, i.e., C(cid:3)
x. and
Line 19–20 push x to the stack and put the constraints C(cid:3)
x,
which are associated to x, into C(cid:3)(cid:3). After eliminate, the
stack s, D (revised in lines 2, 15), and C will be used to ﬁnd
a solution of the original problem.

On top of the elimination algorithm, it is rather straightfor-
ward to design an algorithm to ﬁnd the solutions of a prob-
lem of CRC constraints (Algorithm 2). L (line 5) represents
the assigned variables. Cx in line 8 contains only those con-
straints that involve x and an instantiated variable. In line 10,
when Cx is empty, the domain Dx is not modiﬁed.

// (V, D, C) is a CSP problem
create an empty stack s
eliminate ( (V, D, C), consistent, s)
if not consistent then return
L ← ∅
while not s.empty () do

Algorithm 2: Find a solution of CRC constraints
solve (in (V, D, C), out consistent)
1
2
3
4
5
6
7
8
9
10
11
12
13

x ← s.pop ()
Cx ← {cix | cix ∈ C, i ∈ L}
for each i ∈ L, let bi the assignment of i
Dx ← ∩cix∈Cx cix[bi]
choose any value a of Dx as the assignment of x
L ← L ∪ {x}

output the assignment of the variables of L

Theorem 2 Assume the time and space complexity of the
composition (and intersection respectively) of two constraints
are O(α) and O(1). Further assume the time and space com-
plexity of enforcing arc consistency are O(ed2) and O(β).
Given a CRC problem P =(V, D, C), a solution of the prob-
lem can be found in O(n3α) with working space O(n + β).

Assume the constraint graph of P is complete. For every
variable, there are at most n neighbors. So, to eliminate a
variable (line 10–14) takes O(n2α). Totally, n variables are
removed. So, the complexity of eliminate is O(n3α). The
procedure eliminate dominates the complexity of solve
and thus to ﬁnd a solution of P takes O(n3α + ed2) where
ed2 is the cost (amortizable) of removing values and its prop-
agation. Working space here excludes the space for the rep-
resentation of the constraints and the new constraints created
by elimination. It is useful to distinguish the existing non-
randomized algorithms. Throughout this paper, space com-
plexity refers to working space complexity by default. A
stack s and a set L are used by solve and eliminate to
hold variables. They need O(n) space. The total space used
by solve is O(n+β) where β is the space cost (amortizable)
of removing values and its propagation.
2

4 Composing two CRC constraints
In this section, we consider only constraints that are row con-
vex and connected. These constraints are arc consistent in
accordance with our deﬁnition. Remember that our deﬁnition

of connectedness is stronger than the original deﬁnition. The
following property is clear and useful across this section.

Property 1 Given two row convex and connected constraints
cix and cxj, let cij be their composition. For any u ∈ Di,
cij[u] is not empty.

To compose two constraints cix and cxj, one can simply
multiply their matrices, which amounts to the complexity of
O(d3) . We will present fast algorithms to compute the com-
position in this section. Constraints here can use an interval
representation deﬁned below. For every cij ∈ C and u ∈ Di,
cij[u].min is used for min{v | (u, v) ∈ cij}, and cij[u].max
for max{v | (u, v) ∈ cij}.
4.1 Basic algorithm to compute composition
With the interval representation, we have procedure compose
in Algorithm 3. For any value u ∈ Di and v ∈ Dj, lines 6–8
compute whether (u, v) ∈ cxj ◦ cix. By Property 1, min ≤
max is always true for line 10.

u ← succ (head, Di)
while u (cid:5)= tail do

v ← succ (head, Dj )
min ← tail, max ← head
while v (cid:5)= tail do

Algorithm 3: Basic algorithm for computing the composition
of two constraints
compose (in cix, cxj , out cij )
1
2
3
4
5
6
7
8
9
10
11
disjoint (in cix[u], cjx[v])
12
13
14

cij [u].min ← min, cij [u].max ← max
u ← succ (u, Di)

return true
else return false

if not disjoint (cix[u], cjx[v]) then

if v > max then max ← v
if v < min then min ← v

v ← succ (v, Dj )

if (cix[u].min > cjx[v].max) or (cix[u].max < cjx[v].min) then

Proposition 1 The procedure of compose has a time com-
plexity of O(d2) and space complexity is O(1).

O(d2).

The two while loops (lines 2, 5) give a time complexity of
2
We emphasize that, due to the interval representation of
constraints, for any cix and cxj we need to call compose
twice to compute cij and cji separately. This does not af-
fect the complexity of those algorithms using compose. For
example, for eliminate to use compose we need to change
i < j (line 10 of Algorithm 1) to i (cid:8)= j.
4.2 Remove values without support
Although composition does not lead to the removal of values
under our assumption, the intersection will inevitably cause
the removal of values. In this case, to maintain the row con-
vexity and connectedness, we need to remove values without
support from their domains. The algorithm removeValues,
listed in Algorithm 4, makes use of the interval representation
(line 6–11) to propagate the removal of values. If a domain
becomes empty (line 13), we let the program involving this
procedure exit with an output indicating inconsistency.

IJCAI-07

194

take and delete a value (u, x) from Q
foreach variable y such that cyx ∈ C do

foreach value v ∈ Dy do

Algorithm 4: Remove values
removeValues (in (V, D, C), Q)
1
// Q is a queue of values to be removed
while Q (cid:5)= ∅ do
2
3
4
5
6
7
8
9
10
11
12
13

if cyx[v].min = u = cyx[v].max then

Q ← Q ∪ {(v, y)}
else if u = cyx[v].min then

cyx[v].min ← succ (u, Dx)

else if u = cyx[v].max then

cyx[v].max ← pred (u, Dx)

delete u from Dx
if Dx = ∅ then output inconsistency, exit

row that contains at least a 1, cij.l(cid:5) the ﬁrst value u of Di
such that cij[u].min=min, cij.l⊥ the last value v of Di such
that cij[v].min=min, cij.r(cid:5) the ﬁrst value u of Di such that
cij[u].max=max, and cij.r⊥ the last value v of Di such that
cij[v].max=max. If cij is row convex and connected, cij.t
= succ(head, Di) and cij.b = pred(tail, Di). The ﬁelds are
related as follows.

Proposition 3 Given a row convex and connected constraint
cij, for all u ∈ Di such that cij.l(cid:5) ≤ u ≤ cij.l⊥, cij[u].min=
min; for all u such that cij.r(cid:5) ≤ u ≤ cij.r⊥, cij[u].max=
max; and the relation between cij.l(cid:5) (cij.l⊥) and cij.r(cid:5)
(cij.r⊥) can be arbitrary.

(cid:2)

Proposition 2 Given a CSP problem (V, D, C) of CRC con-
straints with an interval representation, the worst case time
complexity of removeValues is O(ed2) with space com-
plexity of O(nd).
Let δi be the degree of variable i ∈ V . To delete a value
(line 4–12), the cost is δid. In the worst case, nd values are
i∈1..n δid × d =
removed. Hence the time complexity is
O(ed2). The space cost for Q is O(nd).
2
Given a problem of CRC constraints that are represented
by matrix, for each constraint cij and u ∈ Di, we setup
cij[u].min and cij[u].max and collect the values of Di with-
out support. Let Q contain all the removed values during the
setup stage, we then call removeValues to make the prob-
lem arc consistent. This process has a time complexity of
O(ed2) with working space complexity O(nd) (due to Q).

By the above process, Theorem 1, and Proposition 2, it
is clear that the procedure solve equipped with compose
and removeValues has the following property. Note that
the time and space cost of removeValues are “amortized”
in eliminate.

Corollary 1 Given a problem of CRC constraints, solve
can ﬁnd a solution in time O(n3d2) with space complexity
O(nd).
4.3 Fast composition of constraints
As one may see, compose makes use of the row convexity to
the minimal degree. In fact, we can do better.

t
l(cid:10)

l⊥
b

............................

............................

............................

............................

..............................................
.............
...............................................
...............
...............
..................
.................
..............
...............................................
...............................................
.........
............................

............................

............................

............................

t
r(cid:10)

r⊥
b

Figure 1: The area of 1’s in the matrix of a CRC constraint
The 1’s in the matrix of a CRC constraint form an ab-
stract shape (the shaded area in Figure 1) where the slant
edges mean monotonicity rather than concrete boundaries.
It is characterised by the following ﬁelds associated with
cij. Let min = min{cij[u].min | u ∈ Di} and max =
max{cij[u].max | u ∈ Di}. The ﬁeld cij.t denotes the
value of Di corresponding to the ﬁrst row that contains at
least a 1, cij.b the value of Di corresponding to the last

t

l2

l2

l3

l3

b

...................................................

\

shape

...................................................
................................................................

l1

...................................................

l4

...................................................
................................................................

.......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

................................

................................................................

................................................................

................................

.......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .

b shape

d shape

.......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .

.......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .

o shape

/ shape

.......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .

.......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .......... .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

................................
q shape

................................

p shape

Figure 2: The possible shapes of the strips of a constraint that
is row convex and connected

Consider a row convex and connected constraint cij. Let
l1, l2, l3, l4 be the sorted values of cij.l(cid:5), cij.r(cid:5), cij.l⊥, and
cij.r⊥. The matrix of cij consists of the following strips. 1)
Top strip denotes the rows from cij.t to l2, 2) middle strip the
rows from l2 to l3, and 3) bottom strip the rows from l3 to
cij.b (b in the diagram).

The row convexity and connectedness of cij implies that
the 1’s in its top strip can be of only ’b’ shape or ’d’ shape, the
1’s in its middle strip of only ’\’ shape, ’o’ shape, or ’/’ shape,
and the 1’s in its bottom strip of only ’q’ shape or ’p’ shape
(see Figure 2). Note that these shapes are abstract shapes and
do not have the ordinary geometrical properties. The strips
and shapes are characterised by the following properties.
Property 2 Top strip: for every u1, u2 ∈ [cij.t, l2] where
u1 ≤ u2, cij[u1] ⊆ cij[u2]. Middle strip:
for ev-
ery u1, u2 ∈ [l2, l3] where u1 = pred(u2), shape ’\’ im-
plies cij[u1].min≤cij[u2].min and cij[u1].max≤cij[u2].max;
shape ’o’ implies cij[u1] = cij[u2]; and shape ’/’ implies
cij[u2].min≤cij[u1].min and cij[u2].max≤cij[u1].max. Bot-
tom strip: for every u1, u2 ∈ [l3, cij.b] where u1 ≤ u2,
cij[u2] ⊆ cij[u1].

Assume cix and cxj are row convex and connected. The
new algorithm to compute cxj ◦ cix, listed in Algorithm 5,
is based on the following two ideas. 1) We ﬁrst compute
cij[u].min for all u ∈ Di (line 2–21), which is called min
phase, and then compute cij[u].max for all u ∈ Di (line
22–41), which is called max phase. 2) In the two phases,
the properties of the shapes and strips of cix are employed to
speed up the computation.

In the min phase, the algorithm starts from the top strip of
cix. Let u = cix.t. Find cij[u].min (line 5) and let it be v.

IJCAI-07

195

if the middle strip is of ’/’ shape then

searchToLeftWrap (cix, cxj , u, l3, v, cij )

searchToLeftWrap (cix, cxj , u, l3, v, cij )

else searchToRight (cix, cxj , u, l3, v, cij )

else searchToRight (cix, cxj , u, l3, v, cij )

if the middle strip is of ’\’ shape then

if v (cid:5)= cjx.t and cix[u].max < cjx[pred(v)].min then

if v (cid:5)= cjx.t and cix[u].min > cjx[pred(v)].max then

u ← l2
while u ≤ l3 do {cij [u].min ← v, u ← succ (u, Di)}

let l1, . . . , l4 be the ascendingly sorted values of l(cid:4), l⊥, r(cid:4), r⊥ of cix
// min phase
// process the top strip of cix
u ← cix.b
ﬁnd from head to tail the ﬁrst v ∈ Dj such that cix[u] ∩ cjx[v] (cid:5)= ∅
cij [u].min ← v
searchToLeft (cix, cxj , u, l2, v, cij )
// process the middle strip
if the middle strip is of ’o’ shape then

Algorithm 5: Fast algorithm for computing the composition
of two constraints
fastCompose (in cix, cxj , out cij )
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42

// bottom strip
searchToRight (cix, cxj , u, cij .b, v, cij )
// max phase
// process the top strip
u ← cix.b
ﬁnd the last v ∈ Dj such that cix[u] ∩ cjx[v] (cid:5)= ∅
cij [u].max ← v
searchToRightMax (cix, cxj , u, l2, v, cij )
// process the middle strip
if the middle strip is of ’o’ shape then

// bottom strip
searchToLeftMax (cix, cxj , u, cij .b, v, cij )
set the ﬁelds of cij : t, b, l(cid:4), l⊥, r(cid:4), r⊥

u ← l2
while u ≤ l3 do {cij [u].max ← v, u ← succ (u, Di)}

if v (cid:5)= cjx.b and cix[u].max < cjx[succ(v)].min then

if v (cid:5)= cjx.b and cix[u].min > cjx[succ(v)].max then

if the middle strip is of ’\’ shape then

else searchToLeftMax (cix, cxj , u, l3, v, cij )

else searchToLeftMax (cix, cxj , u, l3, v, cij )

searchToRightWrap (cix, cxj , u, l3, v, cij )

searchToRightWrap (cix, cxj , u, l3, v, cij )

if the middle strip is of ’/’ shape then

Algorithm 6: Search methods for computing the composition
of two constraints
searchToLeft (inout cix, cxj , u, l, v, cij )
1
2
3

// search to the left of v
while u ≤l do

ﬁnd ﬁrst v1 from v down to head of Dj such that
cix[u] ∩ cjx[pred(v1)] = ∅
cij [u].min = v1, v ← v1, u ← succ (u, Di)

4
searchToLeftWrap (inout cix, cxj , u, l, v, cij )
5
6
7
8

// search to the left of v
wrapToRight ← false
while u ≤l do

ﬁnd ﬁrst v1 from v down to head of Dj such that
cix[u] ∩ cjx[pred(v1)] = ∅ and cix[u] ∩ cjx[v1] (cid:5)= ∅
if v1 does not exist then {wrapToRight ← true, break }
else {cij [u].min ← v1, v ← v1, u ← succ (u, Di)}

if wrapToRight is true and u ≤l then

9
10
11
12
searchToRight (inout cix, cxj , u, l, v, cij )
13
14
15

// search to the right of v
while u ≤l do

searchToRight (cix, cxj , u, l, succ (head, Dj ), cij )

ﬁnd ﬁrst v1 from v to tail of Dj such that
cix[u] ∩ cjx[pred(v1)] = ∅ and cix[u] ∩ cjx[v1]
cij [u].min ← v1, v ← v1, u ← succ (u, Di)

ﬁnd last v1 from v to tail of Dj such that
cix[u] ∩ cjx[succ(v1)] = ∅ and cix[u] ∩ cjx[v1] (cid:5)= ∅
if v1 does not exist then {wrapToLeft ← true, break }
else {cij [u].max = v1, v ← v1, u ← succ (u, Di) }

if wrapToLeft is true then

25
26
27
28
searchToLeftMax (inout cix, cxj , u, l, v, cij )
29
30
31

// search to the left of v
while u ≤l do

ﬁnd ﬁrst v1 from v down to head of Dj such that
cix[u] ∩ cjx[v1] (cid:5)= ∅
cij [u].max ← v1, v ← v1,u ← succ (u, Di)

32

searchToLeftMax (cix, cxj , u, l, pred (tail, Dj ), cij )

ﬁnd last v1 from v to tail of Dj such that cix[u] ∩ cjx[v1] (cid:5)= ∅
cij [u].max ← v1, v ← v1, u ← succ (u, Di)

// search to the right of v
while u ≤l do

16
searchToRightMax (inout cix, cxj , u, l, v, cij )
17
18
19
20
searchToRightWrap (inoutcix, cxj , u, l, v, cij )
21
22
23
24

// search to the right of v
wrapToLeft ← false
while u ≤l do

Due to the property of the top strip, we can ﬁnd cij[u].min for
all u ∈ [cij.t, l2] in order by scanning once from v down to
head of Dj, i.e., searching to the left of v (line 7). The search
procedure searchToLeft is listed in Algorithm 6 where one
needs to note that v is replaced by v1 in line 4. Similarly,
we can process the bottom strip by searching to the right of
v ∈ Dj (line 21). For the middle strip, we have three cases for
the three shapes. By Property 2, lines 9–11 are quite straight-
forward for the ’o’ shape. For the ’\’ shape (line 12–15),
if v is not the ﬁrst column of cxj and cix[u] is “above” the
interval of the column before v of cxj (line 13), we need to
search to the left of v to be sure we do not miss any value
of Dj that is smaller than v but is a support of a ∈ [u, l3].
Due to the property of the ’\’ shape, after we hit the head of
Dj and no support is found, we need to search to the right
until tail if necessary (line 14). This process is implemented
as searchToLeftWrap (line 5–12 of Algorithm 6). The cor-
rectness of this method is assured by the connectedness as
well as row convexity of cix and cxj. The details are not
given here due to space limit. Otherwise (line 15), we only
need to search to the right of v for values in [u, l3]. The pro-
cess for the ’/’ shape is similar to that for the ’\’ shape with
some “symmetrical” differences (line 17).

The max phase is similar. Finally, according to the new cij,
we set the attributes of cij in a proper way (line 42). Clearly,
for each phase, we only need a time cost of O(d).

Proposition 4 The algorithm fastCompose is correct and
composes two constraints in time complexity of O(d) with
space complexity of O(1).

5 CSP’s with sparse constraint graphs
The practical efﬁciency of eliminate is affected by the or-
dering of the variables to be eliminated. Consider a constraint
graph with variables {1, 2, 3, 4, 5} that is shown in the top left
corner of Figure 3. In the ﬁrst row, we choose to eliminate 1
ﬁrst and then 3. In this process, no constraints are composed.
However, if we ﬁrst eliminate 2 and then 4 as shown in the
second row, eliminate needs to make 3 compositions in
eliminating each of variable 2 and 4.

The topology of a constraint graph can be employed to ﬁnd
a good variable elimination ordering. Here we consider trian-
gulated graphs. An undirected graph G is triangulated if for
every cycle of length 4 or more in G, there exists two non-
consecutive vertices of the cycle such that there is an edge
between them in G. Given a vertex x ∈ G, N(x) denotes

IJCAI-07

196

1
2
................................
3

5
................................................................
4

1
2
................................
3

5
................................................................
4

1

..................

5
................................................................
4

2
................................
3

2

..................

.............................................................1
.............................................................

5
................................
4

3

3

4

2

..................

5
................................................................
4

1

5

..................................................................................................................................................................................................................

3

..................

Figure 3: Example on elimination variable ordering

neighbors of x: {y | {x, y} is an edge of G}. A vertex x
is simplicial if the subgraph of G induced by N(x) is com-
plete. A nice property of triangulated graphs is that there is
a simplicial vertex for each triangulated graph and a triangu-
lated graph remains triangulated after a simplicial vertex and
its incident edges are removed from the graph. A perfect ver-
tex elimination order of a graph G=({x1, x2, . . . , xn}, E) is
an ordering (cid:11)y1, y2, . . . , yn(cid:12) of the vertices of G such that for
1 ≤ i ≤ n − 1, yi is a simplicial vertex of the subgraph of G
induced by {yi, yi+1, . . . , yn}.
Given a perfect elimination order (cid:11)y1, y2, . . . , yn(cid:12) of a
graph G, the elimination degree of yi(1 ≤ i ≤ n), denoted by
σi, is the degree of yi in the subgraph of G that is induced by
{yi, yi+1, . . . , yn}. We use σ to denote the maximum elimi-
nation degree of the vertices of a perfect elimination order.

It is well known that, for a graph G that is not complete,
it can be triangulated in time O(n(e + f)) where f is the
number of edges added to the original graph and e the num-
ber of edges of G [Bliek and Sam-Haroud, 1999]. A perfect
elimination order can be found in O(n + e).

For CSP problems whose constraint graph is triangulated,
the elimination algorithm has a better time complexity bound.

in contrast to the randomized algorithms, a deterministic al-
gorithm needs space O(f d) to store newly created constraints
where f is the number of edges needed to triangulate the
sparse graph.

For problems with dense constraint graphs (e = Θ(n2)),
our algorithm (O(n3d + ed2) where e = n2) is better than
the best (O(n3d2)) of the existing algorithms.

For problems with sparse constraint graphs, the traditional
path consistency method [Deville et al., 1997] can not make
use of the sparsity. Bliek and Sam-Haroud (1999) proposed
to triangulate the constraint graph and introduced path con-
sistency on triangulated graphs. For CRC constraints, their
(deterministic) algorithm achieves path consistency on the tri-
angulated graph with time complexity of O(δe(cid:3)d2) and space
complexity of O(δe(cid:3)d) where δ is the maximum degree of
the triangulated graph and e(cid:3) the number of constraints in
the triangulated graph. The randomized algorithm by Ku-
mar (2006) has a time complexity of O(γn2d2) where γ is
the maximum degree of the original constraint graph. Our
algorithm can achieve O(nσ2d + e(cid:3)d2) where σ is the max-
imum elimination degree of the triangulated graph. Since
σ ≤ δ, γ ≤ δ, σ2 ≤ e(cid:3) ≤ n2 ( σ and γ are not compara-
ble), our algorithm is still favorable in comparison with the
others.

It is worth mentioning that, in addition to “determinism”,
a deterministic algorithm has a great efﬁciency advantage
over randomized algorithms when more than one solution is
needed.

We point out that we introduce removeValues just for
simplifying the design and analysis of the composition algo-
rithms. It might be possible to design a reﬁned propagation
mechanism and/or composition algorithms to discard the ed2
component from the time complexity and decrease the space
complexity of the elimination algorithm to O(n).

Theorem 3 Consider a CSP problem P whose constraint
graph G is triangulated. The procedure eliminate equipped
with fastCompose has a time complexity of O(nσ2d + ed2)
and space complexity of O(nd).
Let (cid:11)y1, y2, . . . , yn(cid:12) be a perfect elimination for G. Clearly,
to eliminate yi, eliminate has to compose σ2
i constraints.
Since n − 1 variables are eliminated by eliminate, its
complexity is O(nσ2d + ed2) where O(ed2) is due to
the removeValues. The space complexity is also due to
removeValues.
2

6 Related work and conclusion
We have proposed a simple elimination algorithm to solve
CRC constraints. Thanks to this algorithm, we are able to
focus on developing fast algorithms to compose constraints
that are row convex and connected. We show that the compo-
sition can be done in O(d) time, which beneﬁts from a new
understanding of the properties of row convex and connected
constraints.
In addition to the simplicity, our deterministic
algorithm has some other advantages over the existing ones.
The working space complexity O(nd) of our algorithm is the
best among existing deterministic or randomized algorithms
of which the best is O(ed). However, when a graph is sparse,

References
[Bliek and Sam-Haroud, 1999] Christian Bliek and Djamila
Sam-Haroud. Path consistency on triangulated constraint
graphs. In IJCAI-99, pages 456–461, Stockholm, Sweden,
1999. IJCAI Inc.

[Deville et al., 1997] Y. Deville, O. Barette, and P. Van Hen-
tenryck. Constraint satisfaction over connected row con-
vex constraints. In IJCAI-97, volume 1, pages 405–411,
Nagoya, Japan, 1997. IJCAI Inc.

[Kumar, 2006] T. K. Satish Kumar. Simple randomized al-
gorithms for tractable row and tree convex constraints. In
Proceedings of National Conference on Artiﬁcial Intelli-
gence 2006, page to appear, 2006.

[van Beek and Dechter, 1995] P. van Beek and R. Dechter.
On the minimality and global consistency of row-convex
constraint networks. Journal of The ACM, 42(3):543–561,
1995.

[Zhang and Yap, 2003] Yuanlin Zhang and Roland H. C.
Yap. Consistency and set intersection.
In Proceedings
of International Joint Conference on Artiﬁcial Intelligence
2003, pages 263–268, Acapulco, Mexico, 2003. IJCAI
Inc.

IJCAI-07

197

