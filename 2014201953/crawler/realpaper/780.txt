Semantic Precision and Recall for Ontology Alignment Evaluation

Jérôme Euzenat
INRIA Rhône-Alpes
Monbonnot, France

Jerome.Euzenat@inrialpes.fr

Abstract

In order to evaluate ontology matching algorithms
it is necessary to confront them with test ontologies
and to compare the results with some reference.
The most prominent comparison criteria are pre-
cision and recall originating from information re-
trieval. Precision and recall are thought of as some
degree of correction and completeness of results.
However, when the objects to compare are seman-
tically deﬁned, like ontologies and alignments, it
can happen that a fully correct alignment has low
precision. This is due to the restricted set-theoretic
foundation of these measures. Drawing on previous
syntactic generalizations of precision and recall, se-
mantically justiﬁed measures that satisfy maximal
precision and maximal recall for correct and com-
plete alignments is proposed. These new measures
are compatible with classical precision and recall
and can be computed.

Introduction

1
Ontology matching is an important problem for which many
algorithms have been provided [Euzenat and Shvaiko, 2007].
Given a pair of ontologies, these algorithms compute a set of
correspondences between entities of these ontologies, called
alignment.

In order to evaluate such algorithms, they are confronted
with ontologies to match and the resulting alignment (A) is
compared to a reference alignment (R) based on some crite-
rion. The usual approach for evaluating the returned align-
ments is to consider them as sets of correspondences and to
apply precision and recall originating from information re-
trieval [van Rijsbergen, 1975] and adapted to the matching
task. Precision and recall are the ratio of the number of true
positive (|R ∩ A|) on that of the retrieved correspondences
(|A|) and those expected (|R|) respectively. These criteria are
well understood and widely accepted.

There are problems with using precision and recall in this
context. As reported in [Ehrig and Euzenat, 2005], these mea-
sures have the drawback to be of the all-or-nothing kind. An
alignment may be very close to the expected result and an-
other quite remote from it and both sharing the same precision
and recall values. The reason for this is that the criteria only

compare two sets of correspondences without considering if
these correspondences are close or remote to each other: if
they are not the same exact correspondences, they score zero.
They both score identically low, despite their different qual-
ity.

Moreover, there can be semantically equivalent alignments
which are not identical. A fair measure of alignment quality
should rank these alignments with the same values (or at least,
closer values than non equivalent alignments). It is thus nec-
essary to design semantically grounded alignment measures
instead of measures based on their syntactic equality.

In this paper we investigate some measures that generalize
precision and recall in order to overcome the problems pre-
sented above. We ﬁrst provide the basic deﬁnitions of align-
ments, semantics, precision and recall as well as a motivating
example (§2). We then present the framework for general-
izing precision and recall introduced in [Ehrig and Euzenat,
2005] (§3). From that point we investigate and propose new
semantically justiﬁed evaluation versions of precision and re-
call. We discuss their properties and deﬁne complementary
measures (§4). We show on the motivating example that the
proposed measures improve on previous ones (§5).

2 Foundations
We ﬁrst precisely deﬁne what are alignments through their
syntax (§2.1) and semantics (§2.2) before introducing preci-
sion and recall adapted to alignments (§2.3).

We will consider ontologies as logics. The languages used
in the semantics web such as RDF or OWL are indeed logics.
The semantics of the ontologies are given through their set of
models.

2.1 Alignments
The result of matching, called an alignment, is a set of pairs of
entities (cid:3)e, e(cid:2)(cid:4) from two ontologies o and o(cid:2) that are supposed
to satisfy a certain relation r with a certain conﬁdence n.
Deﬁnition 1 (Alignment, correspondence). Given two on-
tologies o and o(cid:2), an alignment between o and o(cid:2) is a set of
correspondences (i.e., 4-uples): (cid:3)e, e(cid:2), r, n(cid:4) with e ∈ o and
e(cid:2) ∈ o(cid:2) being the two matched entities, r being a relation-
ship holding between e and e(cid:2), and n expressing the level of
conﬁdence in this correspondence.

IJCAI-07

348

For the sake of simplicity, we will here only consider cor-
respondences as triples (cid:3)e, e(cid:2), r(cid:4). The best way to compare
results with conﬁdence is to plot their precision/recall func-
tions. The examples are only provided for simple ontologies,
which are class hierarchies but do not depend on this simple
language.

Figure 1 presents two ontologies together with ﬁve align-
ments R, A1, A2, A3, and A4. R is the reference alignment
and can be expressed by the following equations:

R =

Employee = Worker Accounting = Headquarters
Production ≤ Japan

Marketing ≤ Spain

The other alignments share the ﬁrst two correspondences with
the reference alignment and have additional ones:

Employee = Worker Accounting = Headquarters
Electronics ≤ Japan
Computer ≤ Spain
Employee = Worker Accounting = Headquarters
Electronics ≤ Worker Computer ≤ Worker
Employee = Worker Accounting = Headquarters
Marketing ≥ Saleforce

Optics ≥ Spain

(cid:2)

(cid:2)
(cid:2)
(cid:2)

(cid:3)

A1 =

A3 =

A4 =

A2 =

Alignment A2 contains more correspondences than the oth-
ers, it is made of the following:

Employee ≤ Worker Accounting ≤ Headquarters
Employee ≥ Worker Accounting ≥ Headquarters
Production ≤ Japan

Marketing ≤ Spain

2.2 Semantics of alignments
In the line of the work on data integration [Ghidini and Ser-
aﬁni, 1998], we provide a ﬁrst-order model theoretic seman-
tics. It depends on the semantics of ontologies but does not
interfere with it. In fact, given a set of ontologies and a set
of alignments between them, we can evaluate the semantics
of the whole system in function of the semantics of each in-
dividual ontology. The semantics of an ontology is given by
its set of models.
Deﬁnition 2 (Models of an ontology). Given an ontology o, a
model of o is a function m from elements of o to elements of a
domain of interpretation Δ. The set of models of an ontology
is noted M(o).

Because the models of various ontologies can have differ-
ent interpretation domains, we use the notion of an equalising
function, which helps making these domains commensurate.
Deﬁnition 3 (Equilising function). Given a family of inter-
pretations (cid:3)Io, Δo(cid:4)o∈Ω of a set of ontologies Ω, an equal-
ising function for (cid:3)Io, Δo(cid:4)o∈Ω is a family of functions γ =
(γo : Δo −→ U)o∈Ω from the domains of interpretation to a
global domain of interpretation U. The set of all equalising
functions is called Γ.

When it is unambiguous, we will use γ as a function. The
goal of this γ function is only to be able to (theoretically)
compare elements of the domain of interpretation. It is sim-
pler than the use of domain relations in distributed ﬁrst order

≥

≤

≤
≥

=
≤

≤

≤

=
≥

≤

≤

Employee

Marketing

Computer

Optics

Administration

Accounting

Production

Electronics

≤

Worker

Spain

≥

Saleforce

Headquarters

Japan

R

A1

A2

A3

A4

Figure 1: Five class alignments between two ontologies (only
the classes involved in correspondences are displayed).

logics [Ghidini and Seraﬁni, 1998] in the sense that there is
one function per domain instead of relations for each pair of
domains.

The relations used in correspondences do not necessarily
belong to the ontology languages. As such, they do not have
to be interpreted by the ontology semantics. Therefore, we
have to provide semantics for them.
Deﬁnition 4 (Interpretation of alignment relations). Given
r an alignment relation and U a global domain of inter-
pretation, r is interpreted as a binary relation over U, i.e.,
rU ⊆ U × U.

The deﬁnition of correspondence satisﬁability relies on γ
It requires that in the

and the interpretation of relations.
equalised models, the correspondences be satisﬁed.
Deﬁnition 5 (Satisﬁed correspondence). A correspondence
c = (cid:3)e, e(cid:2), r(cid:4) is satisﬁed for an equalising function γ by two
models m, m(cid:2) of o, o(cid:2) if and only if γo · m ∈ M(o), γo(cid:2) · m(cid:2) ∈
M(o(cid:2)) and

(cid:3)γo(m(e)), γo(cid:2)(m(cid:2)(e(cid:2)))(cid:4) ∈ rU

This is denoted as m, m(cid:2) |=γ c.
are respective models of o and o(cid:2):

For instance, in the language used as example, if m and m(cid:2)

m, m(cid:2) |=γ (cid:3)c, c(cid:2), =(cid:4) iff γo(m(c)) = γo(cid:2)(m(cid:2)(c(cid:2)))
m, m(cid:2) |=γ (cid:3)c, c(cid:2),≤(cid:4) iff γo(m(c)) ⊆ γo(cid:2)(m(cid:2)(c(cid:2)))
m, m(cid:2) |=γ (cid:3)c, c(cid:2),≥(cid:4) iff γo(m(c)) ⊇ γo(cid:2)(m(cid:2)(c(cid:2)))
m, m(cid:2) |=γ (cid:3)c, c(cid:2),⊥(cid:4) iff γo(m(c)) ∩ γo(cid:2)(m(cid:2)(c(cid:2))) = ∅

IJCAI-07

349

Deﬁnition 6 (Satisﬁable alignment). An alignment A of two
ontologies o and o(cid:2) is said satisﬁable if and only if
∃m ∈ M(o),∃m(cid:2) ∈ M(o(cid:2)),∃γ ∈ Γ;∀c ∈ A, m, m(cid:2) |=γ c
Thus, an alignment is satisﬁable if there are models of the
ontologies that can be combined in such a way that this align-
ment makes sense.
Deﬁnition 7 (Models of aligned ontologies). Given two on-
tologies o and o(cid:2) and an alignment A between these on-
tologies, a model of these aligned ontologies is a triple
(cid:3)m, m(cid:2), γ(cid:4) ∈ M(o) × M(o(cid:2)) × Γ, such that A is satisﬁed
by (cid:3)m, m(cid:2), γ(cid:4).

It

In that respect, the alignment acts as a model ﬁlter for the
ontologies. It selects the interpretation of ontologies which
are coherent with the alignments. Note, this allows to transfer
information from one ontology to another since reducing the
set of models will entail more consequences in each aligned
ontology.

In this paper we consider those consequences of aligned

ontologies that are correspondences.
Deﬁnition 8 (α-Consequence of aligned ontologies). Given
two ontologies o and o(cid:2) and an alignment A between these
ontologies, a correspondence δ is a α-consequence of o, o(cid:2)
and A (noted A |= δ) if and only if for all models (cid:3)m, m(cid:2), γ(cid:4)
of o, o(cid:2) and A, m, m(cid:2) |=γ δ (the set of α-consequences is
noted by Cn(A)).
For α-consequences, A2 is strictly equivalent to R (i.e.,
A2 |= R and R |= A2). In fact, the aligned ontologies with
A2 and R have exactly the same models.

is noteworthy that, given an alignment,

the α-
consequences of this alignment can be larger than it. If the
alignment is not satisﬁable, then any correspondence is a α-
consequence of it.

Such a formalism helps deﬁning the meaning of align-
ments: it tells what are the consequences of ontologies with
alignments. It is particularly useful for deciding if delivered
alignments are consistent and for specifying what is expected
from matching algorithms and how they should be designed
or evaluated. It can be naturally extended to distributed sys-
tems in the sense of [Ghidini and Seraﬁni, 1998], i.e., sets of
ontologies and alignments.
2.3 Precision and recall
Precision and recall are commonplace measures in informa-
tion retrieval. They are based on the comparison of an ex-
pected result and the effective result of the evaluated system.
These results are considered as a set of items, e.g., the docu-
ments to be retrieved.

Since these measures are commonly used and well under-
stood, they have been adapted for ontology alignment eval-
uation [Do et al., 2002]. In this case, sets of documents are
replaced by sets of correspondences, i.e., alignments. The
alignment (A) returned by the system to evaluate is compared
to a reference alignment (R).

Like in information retrieval, precision measures the ratio
of correctly found correspondences (true positives) over the
total number of returned correspondences (true positives and

A

C × C(cid:2)

R

True

False
False
negatives
positives
= R − A
= A − R
True negatives = (C × C(cid:2)) − (A ∪ R)

positives
= A ∩ R

Figure 2: Two alignments seen as sets of correspondences
and their relations.

false positives). In logical terms this is supposed to measure
the correctness of the method. Recall measures the ratio of
correctly found correspondences (true positives) over the total
number of expected correspondences (true positives and true
negatives). In logical terms, this is a completeness measure.
This is displayed in Figure 2.
Deﬁnition 9 (Precision and recall). Given a reference align-
ment R, the precision of some alignment A is given by

P (A, R) =

|R ∩ A|

|A|

.

.

and recall is given by

R(A, R) =

|R ∩ A|

|R|

Other measures, such as fallout, F-measure, noise, silence,
etc. can be derived from precision and recall [Do et al., 2002].
For the examples of Figure 1, the two ﬁrst columns of Ta-
ble 1 display precision and recall. As expected, evaluating the
reference against itself yields a maximal precision and recall.
All the other alignments share the two ﬁrst correspondences
with R and miss the two other ones so they have a precision
and recall of 50% (but A2 which is handicapped by having
more than 4 correspondences).

The semantics of alignments has not been taken into ac-
count since an alignment, like A2 equivalent to R score worse
than an incorrect and incomplete alignment, like A4.

3 Generalizing precision and recall
Even if they are well understood and widely accepted mea-
sures, precision and recall have the drawback that whatever
correspondence has not been found is deﬁnitely not consid-
ered. As a result, they do not discriminate between a bad and
a better alignment.

Indeed, when considering the example of Figure 1, align-
ment A4 is arguably worse than the others, because its ad-
ditional correspondences are measurably more different from
the reference ones, but it scores the same as the other align-
ments.

As precision and recall are easily explained measures, it
is useful to maintain the precision and recall structure when
looking for new measures. This also ensures that measures
derived from precision and recall (e.g., F-measure) still can

IJCAI-07

350

be computed easily. [Ehrig and Euzenat, 2005] proposed an
abstract generalization of precision and recall that has been
instantiated with syntactic measures. This allows to take into
account “near misses”, i.e., incorrect correspondences that
are close to the target (and that, for instance, can be more
easily repaired).

Instead of comparing alignments set-theoretically, [Ehrig
and Euzenat, 2005] proposes to measure the proximity of cor-
respondence sets rather than the strict size of their overlap.
Instead of taking the cardinal of the intersection of the two
sets (|R ∩ A|), the natural generalizations of precision and
recall measure their proximity (ω(A, R)).
Deﬁnition 10 (Generalized precision and recall). Given a ref-
erence alignment R and an overlap function ω between align-
ments, the precision of an alignment A is given by

Pω(A, R) = ω(A, R)

|A|

and recall is given by

Rω(A, R) = ω(A, R)

.

|R|

In order, for these new measures to be true generalizations,
ω has to share some properties with |R∩ A|. In particular, the
measure should be positive:

∀A, B, ω(A, B) ≥ 0

(positiveness)

and should not exceed the minimal size of both sets:

∀A, B, ω(A, B) ≤ min(|A|,|B|)

(maximality)

This guarantees that the given values are within the unit in-
terval [0 1]. Further, this measure should only add more ﬂex-
ibility to the usual precision and recall so their values cannot
be worse than the initial evaluation:

∀A, B, ω(A, B) ≥ |A ∩ B|
(boundedness)
Hence, the main constraint faced by the proximity is:

|A ∩ R| ≤ ω(A, R) ≤ min(|A|,|R|)

This is indeed a true generalization because, ω(A, R) =

|A ∩ R| satisﬁes all these properties.
4 Semantic precision and recall and other

measures

Our main goal is to design a generalization of precision and
recall that is semantically grounded. In consequence, those
correspondences that are consequences of the evaluated align-
ments have to be considered as recalled and those that are
consequence of the reference alignments as correct.

For that purpose we will attempt to follow the guidelines
introduced in [Ehrig and Euzenat, 2005] as far as possible.
We add some more constraints to a semantic precision and re-
call which consider correctness and completeness of an align-
ment as their limit:

R |= A ⇒Psem(A, R) = 1
(max-correctness)
A |= R ⇒Rsem(A, R) = 1 (max-completeness)

Cn(A) = Cn(R) iff Psem(A, R) = 1

and Rsem(A, R) = 1 (deﬁniteness)

A

C × C(cid:2)

R

d
a

c

b

Cn(A)

Cn(R)

Figure 3: Two alignments and their relations through the set
of their consequences.

The classical positiveness depends on A = R, it is replaced
here by its semantic counterpart. In addition, we rephrase the
previous properties by applying them to precision and recall
instead of ω (M is any of precision and recall and M(cid:2) its
generalized counterpart):

M(cid:2)(A, R) ≥ 0
M(cid:2)(A, R) ≤ 1
M(cid:2)(A, R) ≥ M(A, R)

(positiveness)
(maximality)
(boundedness)

Ideal model

4.1
The natural semantic extension of these measures consists of
using the set of α-consequences (or deductive closure on the
prover side) instead of |A∩ R|. This corresponds to taking as
ω the size of the set identiﬁed by d instead of that identiﬁed
by a in Figure 3.

In this case, the true positive becomes the correspondences
that are consequences of both alignments and the usual deﬁ-
nitions of true and false positives and negatives are only ex-
tended to alignment consequences.
Deﬁnition 11 (Ideal semantic precision and recall). Given a
reference alignment R, the precision of some alignment A is
given by

Pideal(A, R) =

|Cn(R) ∩ Cn(A)|

|Cn(A)|

and recall is given by

Rideal(A, R) =

|Cn(R) ∩ Cn(A)|

|Cn(R)|

= P (Cn(A), Cn(R))

= R(Cn(A), Cn(R))

This ideal way of dealing with semantic precision and re-
call can be applied to any language with a semantics. It is not
restricted to alignments and as soon as the notion of conse-
quence is deﬁned from an alignment, it can be applied.

These measures are different from the extensions of [Ehrig
and Euzenat, 2005] because the divisor has changed. How-
ever, for a language with a well-deﬁned semantics this mea-
sure is a natural extension of precision and recall. Most of the
required properties are satisﬁed by these ideal measures:

IJCAI-07

351

Property 1. Pideal and Rideal satisfy:

– positiveness;
– maximality;
– completeness-maximality;
– correctness-maximality;
– deﬁniteness;

Pideal and Rideal do not necessarily satisfy boundedness.

This extension has two drawbacks: (1) both numerator and
divisor could be inﬁnite, yielding an undeﬁned result, and (2)
contrary to the objective of [Ehrig and Euzenat, 2005], these
measures do not guarantee to provide better results than pre-
cision and recall in general, i.e., we do not have P (A, R) ≤
Pideal(A, R) nor R(A, R) ≤ Rideal(A, R). This is because
there is no direct relation between the size of an alignment (or
a set of axioms) and the size of its α-consequences.
4.2 Semantic precision and recall
In order to deal with the problems raised by the inﬁnite char-
acter of the set of α-consequences, a natural way would be
to compare the deductive reductions instead of the deductive
closures. Unfortunately, the deductive reduction is usually
not unique. We thus propose to use the deductive closure
bounded by a ﬁnite set so that the result is ﬁnite. It is based
on different sets of true positives as :

T PP (A, R) = {δ ∈ A; R |= δ} = A ∩ Cn(R)

and

T PR(A, R) = {δ ∈ R; A |= δ} = Cn(A) ∩ R

These two sets correspond respectively to the sets b and c in
Figure 3. They are obviously ﬁnite since they are the inter-
section of a set of α-consequences with a ﬁnite alignment.
They are not, however, a real count of the true positive by any
means.

The semantic precision and recall are based on these sets:
Deﬁnition 12 (Semantic precision and recall). Given a refer-
ence alignment R, the precision of some alignment A is given
by

Psem(A, R) =

|A ∩ Cn(R)|

|A|

and recall is given by

Rsem(A, R) =

|Cn(A) ∩ R|

|R|

Both values are deﬁned when the alignments are ﬁnite.
Moreover, the considered values can be computed if there
exists a complete and correct prover for the languages be-
cause there is always a ﬁnite set of assertions to check (i.e.,
Cn(A) ∩ R = {δ ∈ R; A |= δ}).
Property 2. Psem and Rsem satisfy:

– positiveness;
– maximality;
– boundedness;
– completeness-maximality;
– correctness-maximality;
– deﬁniteness;

if A ∩ R = ∅,

These measures satisfy positiveness and boundedness
(since it is clear that Cn(X) ⊇ X). They have the classi-
cally expected values: Psem(R, R) = 1 and Rsem(R, R) =
1. They do not satisfy anymore,
then
Psem(A, R) = 0 which is replaced by if Cn(A) ∩ Cn(R) =
∅, then Psem(A, R) = 0.
4.3 Compactness and independence
Now we can ﬁnd that a particular alignment is semanti-
cally equivalent to some reference alignment. However, what
makes that the reference alignment has been chosen other-
wise? Are there criteria that enable to measure the quality of
these alignments so that some of them are better than others?
Indeed, more compact alignments seem to be preferable.
Compactness can be measured as the number of correspon-
dences. So it is possible to measure either, this absolute num-
ber or the ratio of correspondences in the reference align-
ments and the found alignments:

Compactness(A, R) =

|R|
|A|

There is no reason that this measure cannot be higher than 1
(if the found alignment is more compact than the reference
alignment).

Compactness depends on the raw set of correspondences is
however primitive and non semantically grounded (it is espe-
cially useful for complete and correct alignments). A more
adapted measure is that of independence.

Ind(A) =

|{c ∈ A; A − {c} (cid:16)|= c}|

|A|

which checks that alignments are not redundant.

It measures the ratio of independent correspondences in an
alignment independently of a reference. If we want to mea-
sure independence with regard to the reference alignment, it
is possible to measure the independence of correspondences
that do not appear in the reference alignment:

Ind(A, R) =

|{c ∈ A − R; A − {c} (cid:16)|= c}|

|A − R|

In the examples considered here independence measures re-
turn 1. for all alignments.

5 Examples
In order to compare the behavior of the proposed measure, we
compare it with previously provided measures on the exam-
ples of Figure 1. Additionally to standard precision and recall
we compare them with two measures introduced in [Ehrig
and Euzenat, 2005]: symmetry considers as close a corre-
spondence in which a class is replaced by its direct sub- or
super-class; effort takes as proximity the measure of the ef-
fort to produce for correcting the alignment. A third measure,
oriented, is not deﬁned in this context (because of the pres-
ence of non-equivalent correspondences).

The results are provided in Table 1. As can be expected,
the results of the semantic measures match exactly the cor-
rectness and completeness of the alignment. These results

IJCAI-07

352

ω
A
R
A1
A2
A3
A4

standard
R
P
1.
1.
.5
.5
.5
.33
.5
.5
.5
.5

symm.
R
P
1.
1.
.75
.75
.75
.5
.5
.5
.5
.5

effort
R
P
1.
1.
.8
.8
.75
.5
.5
.5
.65
.65

semantic
R
P
1.
1.
.5
1.
1.
1.
.5
1.
.5
.5

Comp.

1.
1.
.66
1.
1.

Table 1: Precision and recall results on the alignments of Fig-
ure 1.

are far more discriminating than the other ones as far as A4
is concerned. The equivalent alignment A2 which did not
stand out with the other measures is now clearly identiﬁed
as equivalent. An interesting aspect for A1 which is correct
but incomplete, is that the other measures fail to recognize
this asymmetry. A1 and A3 are both correct and incomplete,
they thus have the same semantic values while A1 is arguably
more complete than A3 (in fact A1 |= A3): this is accounted
better by the syntactic measures.

No redundancy was present in the selected alignments, so
they all score 100% in independence. A2 is less compact than
R (and the others) as expected.

6 Related work
Relevant related work is that of [Langlais et al., 1998] in com-
putational linguistics, [Sun and Lin, 2001] in information re-
trieval and [Ehrig and Euzenat, 2005] in artiﬁcial intelligence.
All rely on a syntactic distance between entities of the ontolo-
gies (or words or documents). They have been compared in
[Ehrig and Euzenat, 2005]. However, these work tackle the
problem of measuring how far is a result from the solution.
Here, the semantic foundations only consider valid solutions:
the semantic deﬁnitions account for the semantically equiva-
lent but syntactically different results.

This explains why, with regard to [Ehrig and Euzenat,
2005], we used different but compatible properties not fully
relying on a proximity measure ω. Hence, it should be pos-
sible to combine the semantic precision and recall with the
proposed syntactic relaxed measures.

The results of Table 1 show how the semantic approach
compares with [Ehrig and Euzenat, 2005] on a small exam-
ple. One important difference is that the syntactic measures
can be easily computed because they only work on the syn-
tax of the alignments while the semantic measures require a
prover for the ontology languages (and even for the alignment
semantics).

7 Discussion
Evaluation of matching results is often made on the basis
of the well-known and well-understood precision and recall
measures. However, these measures are based on the syntax
of alignments and are not able to take into account the seman-
tics of the formalism.

In this paper we provided a semantics for alignments based
on the semantics of ontologies and we designed semantic pre-
cision and recall measures that take advantage of this seman-
tics. The deﬁnition of these measures is thus independent

from the semantics of ontologies. We showed that these mea-
sures are compliant with (an adapted version of) constraints
put on precision and recall generalization of [Ehrig and Eu-
zenat, 2005] and that they behave as expected in the motivat-
ing example.

In particular, the new measures have the expected behavior:
– they are still maximal for the reference alignment;
– they correspond to correctness and completeness;
– they help discriminating between irrelevant alignments

and not far from target ones.

The examples have been given based on the alignment of
simple taxonomies with very limited languages. However, all
the deﬁnitions are independent from this language. We plan
to implement these measures and apply them to larger sets of
data (results of the OAEI1 evaluation campaigns for instance).
This requires the use of a correct and complete prover for the
considered ontology languages.

Acknowledgements
This work has been partially supported by the Knowledge
Web European network of excellence (IST-2004-507482).
Thanks to Mark Ehrig for pushing me on this track, to Ste-
fano Zanobini for complaining about OAEI-2005 results and
to Antoine Zimmermann for his comments.

References
[Do et al., 2002] Hong-Hai Do, Sergei Melnik, and Erhard
Rahm. Comparison of schema matching evaluations. In
Proc. GI-Workshop "Web and Databases", Erfurt (DE),
2002.

[Ehrig and Euzenat, 2005] Marc Ehrig and Jérôme Euzenat.
Relaxed precision and recall for ontology matching.
In
Ben Ashpole, Jérôme Euzenat, Marc Ehrig, and Heiner
Stuckenschmidt, editors, Proc. K-Cap 2005 workshop on
Integrating ontology, Banff (CA), pages 25–32, 2005.

[Euzenat and Shvaiko, 2007] Jérôme Euzenat and Pavel
Shvaiko. Ontology matching. Springer, Heidelberg (DE),
2007. to appear.

[Ghidini and Seraﬁni, 1998] Chiara Ghidini and Luciano
Seraﬁni. Distributed ﬁrst order logics.
In Franz Baader
and Klaus Ulrich Schulz, editors, Frontiers of Combining
Systems 2, pages 121–139, Berlin, 1998. Research Studies
Press.

[Langlais et al., 1998] Philippe Langlais, Jean Véronis, and
Michel Simard. Methods and practical issues in evaluating
alignment techniques. In Proc. 17th international confer-
ence on Computational linguistics, Montréal (CA), pages
711–717, 1998.

[Sun and Lin, 2001] Aixin Sun and Ee-Peng Lin. Hierarchi-
cal text classiﬁcation and evaluation. In Proc. IEEE inter-
national conference on data mining, pages 521–528, 2001.
[van Rijsbergen, 1975] Cornelis Joost (Keith) van Rijsber-
gen. Information retrieval. Butterworths, London (UK),
1975. http://www.dcs.gla.ac.uk/Keith/Preface.html.

1http://oaei.ontologymatching.org

IJCAI-07

353

