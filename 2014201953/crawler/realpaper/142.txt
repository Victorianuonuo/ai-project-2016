Maintaining Coherent Perceptual Information Using Anchoring

Amy Lout(cid:2), Silvia Coradeschi and Alessandro Saf(cid:2)otti

Center for Applied Autonomous Sensor Systems

¤Orebro University

¤Orebro, Sweden 701-82

www.aass.oru.se

Abstract

The purpose of this paper is to address the prob-
lem of maintaining coherent perceptual information
in a mobile robotic system working over extended
periods of time, interacting with a user and using
multiple sensing modalities to gather information
about the environment and speci(cid:2)c objects. We
present a system which is able to use spatial and
olfactory sensors to patrol a corridor and execute
user requested tasks. To cope with perceptual main-
tenance we present an extension of the anchoring
framework capable of maintaining the correspon-
dence between sensor data and the symbolic de-
scriptions referring to objects. It is also capable of
tracking and acquiring information from observa-
tions derived from sensor-data as well as informa-
tion from a priori symbolic concepts. The general
system is described and an experimental validation
on a mobile robot is presented.

1 Introduction
Consider a scenario where a mobile robot is patrolling a cor-
ridor.
Its task is to discover new objects and gather infor-
mation about them using both traditional modalities such as
vision and sonar and also non-traditional modalities such as
an electronic nose. A user is able to monitor the robot, sug-
gest actions to improve perceptual performance and request
the robot to perform speci(cid:2)c tasks. Tasks are requested from
the user using a symbolic representation consisting of natural
language concepts. While no requests by the user are given,
the robot autonomously prioritises tasks alternating between
patrolling the corridor and inspecting objects or simply wait-
ing on stand-by.

An important facet to this scenario, and scenarios of a simi-
lar nature, is the ability to maintain coherent perceptual infor-
mation. This means that the system should be able to main-
tain the correspondence between the symbolic representation
of objects (requests from the user) and the perceptual data that
refers to them. The system should collect information from
different sensing modalities working concurrently and/or se-
quentially and correctly attribute that information to its inter-
nal representation of the object. The system should include

the preservation of object consistency, so that new informa-
tion about previously seen objects is also correctly attributed.
All the while, the insertion and/or removal of objects from
the environment needs to be considered and accounted for.
From a cognitive perspective, the maintenance of perceptual
information is an integral part of the binding problem [Black-
more, 2003]. That is, how the conjunction of properties are
represented, ranging from the binding of shape and colour
in detecting blue triangles or red squares to the binding that
must occur between and within the senses: (cid:147)the way the smell
and touch and sight of the sandwich in your hand all seem to
belong to the same object(cid:148) [Blackmore, 2003] (p.250).

For robotic systems, an important ingredient for maintain-
ing perceptual information is an internal structure to store a
representation of an object. Such an internal structure needs
to satisfy a series of requirements. On one hand, perception
management [Ronnie et al., 2003], an extension of sensor
management [Adrian, 1993], is required to integrate high-
level information about the state of the object in order to make
situation dependent decisions, direct control and select sens-
ing actions. On the other hand, tracking and data association
are also fundamental ingredients necessary to propagate in-
formation about coherent perceptions over time [D.Schulz et
al., 2003]. A third requirement, especially in the context of
a cognitive robot, involves processes, which can create and
maintain the link between high-level information (e.g. sym-
bols) and low-level percepts.

In this paper, we show how the concept of anchoring can
be used as a tool to confront some of the issues relating to
perception management. The anchoring framework [Corade-
schi and Saf(cid:2)otti, 2000] aims at de(cid:2)ning a theoretical basis
for grounding symbols to percepts originating from physical
objects. We present an extension of the framework that is
able to cope with perception management considering multi-
sensing resources and temporal factors. The pivot of this ex-
tension is the use of anchors as internal representations of
objects that integrate symbolic and perceptual information
across time and across sensing modalities. Our ultimate aim
is to shed light on this important aspect of cognitive robotics
as applications extend into realistic environments involving
human-robot interactions and lifelong acquisition of knowl-
edge.

We begin our discussions with a description and review of
the anchoring framework in Section 2. We then present a

modi(cid:2)cation of the anchoring framework in Section 3 which
is adapted for the task of perception maintanance. We pro-
ceed by detailing the robotic system architecture used in our
experiments. Section 5 gives the implementation details and
provides a performance example of the complete system. The
paper concludes with a summary of the presented work.
2 The Anchoring Framework
To date, the anchoring framework presented by [Coradeschi
and Saf(cid:2)otti, 2000] has mainly been considered in the context
of abstraction of perceptual information. This includes asso-
ciation of words to visually recognised objects [Knoblauch et
al., 2004], managing of dynamic object anchoring for high-
level reasoning [Chella et al., 2004] and preliminary works
considering people tracking applications [Kleinehagenbrock
et al., 2002]. A good overview of the range of applications
of the anchoring concept is found in 2004 Robotics and Au-
tonomous Systems special issue on anchoring symbols to sen-
sor data [Coradeschi and Saf(cid:2)otti, 2003].

Before we present our extension of the framework, we
summarise here the basic elements of the computational the-
ory of anchoring. See ?? for a full account. The theory con-
siders an autonomous system that includes a symbol system
and a perceptual system, and it focuses on the problem of
creating and maintaining a correspondence between symbols
and percepts that refer to the same physical object. The main
ingredients of anchoring are the following [Coradeschi and
Saf(cid:2)otti, 2000]:

(cid:15) A symbol system including: a set X = fx1; x2; : : :g
of individual symbols (variables and constants); a set
P = fp1; p2; : : :g of predicate symbols; and an infer-
ence mechanism whose details are not relevant here.

(cid:15) A perceptual system including: a set (cid:5) = f(cid:25)1; (cid:25)2; : : :g
of percepts; a set (cid:8) = f(cid:30)1; (cid:30)2; : : :g of attributes; and
perceptual routines whose details are not relevant here.
A percept is a structured collection of measurements as-
sumed to originate from the same physical object; an
attribute (cid:30)i is a measurable property of percepts, with
values in the domain Di.

The symbol system manipulates individual symbols, like
’cup-21’, which are meant to denote physical objects and as-
sociates each individual symbol with a set of symbolic pred-
icates, like ’red’, that assert properties of the corresponding
object. The perceptual system generates percepts and as-
sociates each percept with the observed values of a set of
measurable attributes. The task of anchoring is to create,
and maintain in time, the correspondence between individual
symbols and percepts that refer to the same physical objects.
The symbol-percept correspondence is rei(cid:2)ed in an inter-
nal data structure (cid:11), called an anchor. Since new percepts
are generated continuously within the perceptual system, this
correspondence is indexed by time. It is important that the
connections are dynamic, since the same symbol may be con-
nected to new percepts every time a new observation of the
corresponding object is acquired.

At every moment t, (cid:11)(t) contains: a symbol, meant to de-
note an object; a percept, generated by observing that object;

and a signature, a collection of property values meant to pro-
vide the (best) estimate of the values of the observable prop-
erties of the object.

3 Anchoring for Perception Management
In this section, we present our extension to the anchoring
framework. What makes this contribution unique is that we
extend the applications of anchoring beyond its traditional
use of data abstraction to also include percepts from differ-
ent modalities that may be accessible at different times.

To effectively present our extension, we refer to the three
abstract functionalities de(cid:2)ned by [Coradeschi and Saf(cid:2)otti,
2000]. used to manage anchors, namely, Find, Reacquire,
and Track. The functionalities have been developed for the
consideration of top-down approaches for information acqui-
sition (i.e. imposed a priori symbolic concepts). In this paper,
we revise these existing functionalities to include bottom-up
approaches so that anchors can be created by perceptual ob-
servations derived from interactions with the environment.
Bottom-up approaches have previously been considered on
anchoring frameworks [Knoblauch et al., 2004] but never
in conjunction with top-down approaches. We advocate the
presence of both approaches, in particular for robotic systems
interacting with a human user. To accomplish this, an addi-
tional Acquire functionality is introduced.
3.1 Creation of Anchors
The creation of anchors can occur in both a top-down and
bottom-up fashion. Bottom-up acquisition is driven by an
event originating from a sensing resource (e.g. the recogni-
tion of a segmented region in an image) when perceptual in-
formation which cannot be associated to any existing anchor
is perceived. Top-down acquisition occurs when a symbol
needs to be anchored to a percept, such a call may originate
from an external user or a top-level module (e.g. planner).
Acquire Initiates a new anchor whenever a percept is re-
ceived which currently does not match any existing an-
chor. It takes a percept (cid:25), and return an anchor (cid:11) de-
(cid:2)ned at t and unde(cid:2)ned elsewhere. To make this prob-
lem tractable, a priori information is given with regards
to which percepts to consider.
In bottom-up acquisi-
tion, a randomly generated symbol is attributed to the
anchor. Furthermore, information about the object and
its properties are included into the world model used by
the planner, in this way the object can be reasoned about
and acted upon.

Find Takes a symbol x and a symbolic description and re-
turns an anchor (cid:11) de(cid:2)ned at t (and possibly unde(cid:2)ned
elsewhere). It checks if existing anchors that have al-
ready been created by the Acquire satisfy the symbolic
description, and in that case, it selects one. Otherwise, it
performs a similar check with existing percepts (in case,
the description does not satisfy the constraint of percepts
considered by the Acquire).
If a matching percept is
found an anchor is created. Matching of anchor or per-
cept can be either partial or complete. It is partial if all
the observed properties in the percept or anchor match

TRACK

Symbolic System

door5

cup-22

table1

room23

FIND

Anchoring Module

Anch-1
Visual
Description

Anch-1
Visual &
odour

cup-22
Visual &
odour

ACQUIRE

Perceptual System

Figure 1: Graphical illustration of the extended anchoring
functionalities where bottom-up and top-down information is
possible and different sensing modalities are used.

the description, but there are some properties in the de-
scription that have not been observed.

3.2 Maintenance of Anchors
At each perceptual cycle, when new perceptual information
is received, it is important to determine if the new perceptual
information should be associated to existing anchors. The
following functionality addresses the problem of tracking ob-
jects over time.
In this extension, we include the previous
Reacquire functionality as an integral part of the Track and
make no special distinction for it.
Track The track functionality takes an anchor (cid:11) de(cid:2)ned for
t (cid:0) k and extends its de(cid:2)nition to t. The track assures
that the percept pointed to by the anchor is the most re-
cent and adequate perceptual representation of the ob-
ject. We consider that the signatures can be updated as
well as replaced but by preserving the anchor structure
we af(cid:2)rm the persistence of the object so that it can be
used even when the object is out of view. This facili-
tates the maintenance of information while the robot is
moving as well as maintaining a longer term and stable
representation of the world on a symbolic level without
catering to perceptual glitches.

3.3 Deletion of Anchors
By having an anchor structure maintained over time, it is pos-
sible to preserve the perceptual information even if the object
is not currently perceived (caused by the object being out of
view and/or by the inaccuracy in the measurement of percep-
tual data). The challenge is to determine if the association
of new percepts is justi(cid:2)ed or whether certain anchors should
be removed. Mechanisms for destroying anchors when the
corresponding object has been removed need to be in place.
This is a dif(cid:2)cult problem, because conceptually it is not clear

User goals &  tasks

Interface

Planner (top-level & recovery)

Plan

Problem (state & goal)

Plan executor & monitor

Request

Anchors,Status

Destination

Status

Anchoring

Navigation

Planner

Commands

Classes

Percepts

Behaviours

Status

Odour

Processing

Commands

Data

Vision

Processing

Images

E-Nose

CCD Camera

Fuzzy Control

Commands

Status

Robot,control,
odometry etc..

Figure 2: Overview of the robotic system which uses the an-
choring module. Arrows indicate the (cid:3)ow of information.

when it is appropriate to remove anchors from the system.
Anchors could be removed if they are not relevant for the
current task, because the object to which it refers has been
physically removed from the environment or the reliability of
the perceptual information has expired. Anchors may also
need to be removed if they have been associated to invalid
perceptual data such as sensory glitches. We currently adopt
simple solutions in which objects that are not perceived when
expected decrease in a (cid:147)life(cid:148) value of the respective anchor.
When the anchor has no remaining life, the anchor is re-
moved. The converse could be implemented where anchors
are created with initially lowlife values and persistent per-
cepts increase its life value. The decreasing life of anchors is
shown in Figure 4. A more adequate strategy to handle the
maintenance of anchors may also be to include a (cid:147)long term(cid:148)
memory where anchors may be stored for future use.
3.4
The event-based functionalities are now restricted to the Find
and Acquire while the Track functionality is regularly called.
Figure 1 shows an overview and an example of the framework
and its functionalities. In the example, anchors are created
bottom-up from the visual percepts of a cup. Later, additional
features of that object are required, for example, the olfactory
property. These features are stored in the anchor. When a
top-down request is sent to the anchor module to (cid:2)nd a cup
with matching properties denoted by the symbol (cid:147)cup-22(cid:148),
the Find functionality anchors the symbol to the perceptual
data.

Integration of the Functionalities

As seen in the (cid:2)gure, properties can be collected at differ-
ent time points using different modalities. Even when certain
perceptual properties are updated, such as the smell property,
which may change over time, other perceptual properties are
maintained. Conversely, if the visual percepts of an anchor is
replaced, the smell property previously obtained is not lost.
In this way, the anchor is used to compensate for any dynam-
ically changing features of an object. Furthermore, the per-
ceptual description of anchors can be accessed by the planner

Room T1209

Room T1203

WC

storage

1

 
r
o
d
i
r
r
o
C

Room T1210
Conference

x

Corridor 2

Corridor 3

Room T1201

Room T1204

Room T1206

Figure 3: (Left) The local space shows the detected objects, the robot is located in the center of the space. Grey areas in the
space are regions that are unexplored. Objects are represented by their visual percepts and are placed within the local space.
In this screen, the robot identi(cid:2)es 2 garbage cans, denoted by the percepts Gar-1 and Gar-2. (Middle) The a priori map of the
of(cid:2)ce environment to be patrolled. The robot starting position is shown at point X and a path of the robot is denoted by the
dotted line. (Right) The olfactory interface.

to reason about perceptual knowledge. In certain cases, this
may result in speci(cid:2)c calls to perceptual actions in order to
disambiguate between similar objects.
4 The System Architecture
In this section, we present our own instantiation of the ex-
tended anchoring framework discussed. We begin our de-
scription at the sensor level and proceed to the higher levels
which include a planner and user interfaces. An overview of
the robotic system is given in Figure 2.
4.1 Sensing modalities and control
Our physical robot is a Magellan Pro compact robot and in
the experiments we use its infrared sensors, sonars and tac-
tile sensors. In addition, a CCD camera is mounted on the
robot and the robot is able to recognise pre-de(cid:2)ned signa-
tures of objects using standard visual techniques. Perhaps
the most novel of sensors on the robot is an electronic nose.
The electronic nose consists of 32 conducting black polymer
sensors, pattern recognition and classi(cid:2)cation components,
and an electronic repository of odours stored in the on-board
computer in the robot. The classi(cid:2)cation algorithm uses the
odour repository as a training set for online recognition of
new odours. To navigate the robot, a collection of basic be-
haviours is used. These behaviours are based on fuzzy control
techniques and can be combined and reasoned about through
use of a behaviour planner (B-plan) explained in [Saf(cid:2)otti et
al., 1995].
4.2 Anchoring Module
The anchoring module, besides creating and maintaining the
anchor data structure, also serves a secondary purpose to
function as a (cid:3)ag between top-level tasks given by a plan-
ner and low-level sensor data. Although not immediately evi-
dent this function is important in order to co-ordinate percep-
tual processes such as a smelling action which may take up
to several minutes. In such a case, speci(cid:2)c calls to percep-
tual actions e.g. (cid:147)Smell gar-22(cid:148) are generated from the top-

level planner, which then translates into several behaviours
being activated e.g. (cid:147)Go near to Gar-22, Touch Gar-2(cid:148) and
calls to an odour server which activates the respective pumps
on valves on the nose. The odour classi(cid:2)cation provides the
smell description e.g. (cid:147)gar-22 smells ethanol(cid:148) and the per-
ceptual information is updated. Here the anchoring mod-
ule (cid:147)polices(cid:148) each event signalling to the respective modules
when certain process need to be activated and when they have
reached completion.

In our instance of the anchoring module, the track function-
ality is achieved by performing a fuzzy matching algorithm
between newly created percepts and previously stored an-
chors in order to partly deal with sensor noise. However, the
purpose of the anchoring framework allows different strate-
gies for the track functionality. A part of the future aims to
integrate more advanced solutions into the existing platform.
4.3 Planner
PTLplanner [Karlsson, 2001] is a planner for partially observ-
able domains with uncertainty (probabilities). It searches in
a space of epistemic states, or e-states for short, where an e-
state represents the agent’s incomplete and uncertain knowl-
edge about the world at some point in time. Although much of
the planning component is standard, it is still worth empha-
sising that the planner can reason about perceptive actions,
such as looking at or smelling an object. The consequence is
that calls to perceptual actions may be made in order to gather
more information about the environment.
4.4
In addition to the computations mentioned in the previous
section for control, perception and autonomy, the system also
has a number of processes for displaying the internal state of
the robot as well as its current model of the external world.
This model of the external world includes locally perceived
objects and a gridmap of the environment built from sensor
data. This is shown in Figure 3. In the left window, the local
view of the robot shows the incoming percepts of the vision

Interfaces

1

0
1

0
1

0

Gar-1

Gar-1

track

Gar-1

Gar-2

Gar-2

track

Gar-16

Gar-3

Gar-24

track

track

Gar-27

Gar-35

Figure 4: The top row shows the camera images at different time points, the middle row shows the activity at the anchoring
level. Grey bars indicate anchors with olfactory properties. The bottom row shows the corresponding local perceptual space
given the changing representation of visual percepts.

and spatial modules. In the center (cid:2)gure, a map of the envi-
ronment is shown. Additional interfaces include a live feed
of the images viewed from the CCD camera and an olfactory
interface which shows clusters and data points for a loaded
repository (Figure 3 (Right)). Certain points can be interac-
tively selected to generate new plans for perceptual actions.
It also shows the symbolic representation preserving the elec-
tronic perception of odours used to classify new odours. More
information about the olfactory interface and the categorisa-
tion of odours can be found in [Lout(cid:2) and Coradeschi, 2004;
2005].
5 Experiments
The general experiment is performed in a series of corridors.
In each corridor there may be several objects, in this case
garbage cans. The robot automatically toggles between the
task of patrolling the corridor, inspecting objects and waiting
for commands from the user. Patrolling the corridor involves
moving from corridor to corridor in a discovery for new ob-
jects and recognition of previous objects. When an inspect
is invoked, the robot visits each object collecting the odour
property. The inspect is usually autonomously invoked when
new objects are detected.

The purpose of the experiment is to evaluate the ability
of the extended anchoring framework to maitain an internal
representation of the objects in the corridors for an extended
period of time. Throughout the autonomous activity of pa-
trolling the corridor, a user may interrupt tasks by requesting
the acquisition of speci(cid:2)c objects. Object requests can be
given by using the image feed from the camera and directly
selecting a region in the screen. The sensory signature of the
object will be matched against current anchors and current
execution of the patrol will be interrupted to include a plan to
visit and inspect the selected object. Object can be requested

by giving to the robot a sample of the smelling object and re-
quest to (cid:2)nd similar objects. Finally top-down requests can
be given to (cid:2)nd objects by giving to the system a symbolic
description of the object. The anchor that most matches the
description will be returned.
5.1 Results
The a priori information given to the system consists of a
rough map of the environment, shown in Figure 3 (Middle),
and a repository of interesting objects, namely garbage cans
placed outside of(cid:2)ces. The robot patrolled the corridors for
a period of 4 days, with intermittent breaks during the day
and longer breaks during the evening for charging the bat-
teries. At any given time, garbage cans would be removed,
displaced, or added into the environment. The total distance
covered by the robot is approximately 1.2 km without the in-
clusion of the extra movement caused by smelling actions and
over 70 odour samples were collected.

The local space of the robot together with the visual image
from the camera as well as the creation, deletion and updat-
ing of anchors is depicted in Figure 4. The (cid:2)gure contains
four snapshots throughout an experimental run described as
follows:

(cid:15) Scene 1 - The robot begins patrolling the corridor, two
visual percepts are detected and two anchors denoted by
Gar-1 and Gar-2, are created. An inspect is performed
and both anchors obtain olfactory properties, shown in
the Figure by the grey colouring. Since the anchors are
created in a bottom-up fashion their labels are arbitrary.
(cid:15) Scene 2 - As the robot continues its patrol, another ob-
ject is inserted into the environment at a later time. Note
however, that the previous two anchors are still main-
tained by the track functionality. Although the local
space shows only the current percepts, the anchoring

module updates the link between the anchor Gar-1 and
the percept Gar-27. A new anchor is also created for the
third object denoted by Gar-3 with visual percept Gar-
24.

(cid:15) Scene 3 - The robot approaches the object in order to ac-
quire its odour property and the result is stored in the
corresponding anchor. Some time later, the object is
removed from the environment. The life of the anchor
slowly decreases when an expected percept is no longer
detected.

(cid:15) Scene 4 - The anchor is removed from the system and
unless it is perceived again, its properties cannot be ac-
cessed by the (cid:2)nd functionalities described above.

This scenario shows how the anchoring module is used
to create an internal structure which can then maintain the
perceptual coherence of objects, considering each object has
both spatial and olfactory properties. Even when visual prop-
erties of anchors are being updated, the stored smell property
remains until a new odour character is acquired by the next
inspect action. The previous odour character is then stored in
the odour repository.

6 Conclusion
(cid:147)Take a coin, toss it, and catch it again in your hand...you see
a single object (cid:3)y up in the air, twist over and over, and land in
one piece on your hand. Bits don’t (cid:3)y off. The silver doesn’t
depart from the shape, and the shape doesn’t lag behind the
motion.(cid:148) [Blackmore, 2003] (p.244).

Maintaining perceptual coherence of objects over extended
periods of time involves the management of perceptual infor-
mation from different sensing sources, tracking over time and
maintaining object persistency. In this paper we showed how
a modi(cid:2)ed anchoring framework could be used as a tool to
satisfy these requirements. Experiments on a mobile robot
were performed where a robot used both spatial and olfactory
sensors to monitor an of(cid:2)ce environment over an extended
period of time.

The problem of perception management is far from being
solved. In this paper, we have (cid:147)scratched its surface(cid:148) by rec-
ognizing the need to consider this problem, highlighting im-
portant issues that arise on an embedded system and present-
ing a (cid:2)rst implemented solution.

Acknowledgments This work has been supported by:
Vetenskapsr(cid:9)adet, and by ETRI (Electronics and Telecom-
munications Research Institute, Korea) through the project
(cid:148)Embedded Component Technology and Standardization for
URC(2004-2008)(cid:148). The authors would like to thank Math-
ias Broxvall and Lars Karlsson for their contribution to the
experimental work.

References
[Adrian, 1993] R. Adrian. Sensor management. In Proc of
AIAA/IEEE Conference on Digital Avionics System, pages
32(cid:150)37, 1993.

[Blackmore, 2003] S. Blackmore. Consciousness: An Intro-

duction. Hodder & Stoughton, Oxford, 2003.

[Chella et al., 2004] A. Chella, S. Coradeschi, M. Frixione,
and A. Saf(cid:2)otti.
Perceptual anchoring via conceptual
spaces. In Proc. of the AAAI-04 Workhsop on Anchoring
Symbols to Sensor Data, Menlo Park, CA, 2004. AAAI
Press. Online at http://www.aass.oru.se/(cid:152)asaf(cid:2)o/.

[Coradeschi and Saf(cid:2)otti, 2000] S. Coradeschi and A. Saf-
(cid:2)otti. Anchoring symbols to sensor data: preliminary re-
port. In Proc. of the 17th American Association for Arti(cid:2)-
cial Intelligence Conf. (AAAI), pages 129(cid:150)135, 2000.

[Coradeschi and Saf(cid:2)otti, 2003] S. Coradeschi and A. Saf-
(cid:2)otti, editors. Robotics and Autonomous Systems, special
issue on Perceptual Anchoring. Elsevier Science, 2003.

[D.Schulz et al., 2003] D.Schulz, W. Burgard, D. Fox, and
A. Cremers. People tracking with mobile robots using
sample-based joint probabilistic data association (cid:2)lters. I.
J. Robotic Res., 22(2):99(cid:150)116, 2003.

[Karlsson, 2001] L. Karlsson. Conditional progressive plan-
ning under uncertainty. In Proc. of the 17th Int. Joint Con-
ferences on Arti(cid:2)cial Intelligence (IJCAI), pages 431(cid:150)438,
2001.

[Kleinehagenbrock et al., 2002] M.

Kleinehagenbrock,
S. Lang, J. Fritsch, F. Lmker, G. A. Fink, and G. Sagerer.
Person tracking with a mobile robot based on multi-modal
In Proc. IEEE Int. Workshop on Robot and
anchoring.
Human Interactive Communication (ROMAN), pages
423(cid:150)429, 2002.

[Knoblauch et al., 2004] A. Knoblauch, R. Fay, U. Kauf-
mann, H. Markert, and G. Palm. Associating words to
visually recognized objects. In S. Coradeschi and A. Saf-
(cid:2)otti, editors, Anchoring symbols to sensor data. Papers
from the AAAI Workshop. Technical Report WS-04-03,
pages 10(cid:150)16. AAAI Press, Menlo Park, California, 2004.
[Lout(cid:2) and Coradeschi, 2004] A. Lout(cid:2) and S. Coradeschi.
In
Forming odour categories using an electronic nose.
Proc. of European Conference in Arti(cid:2)cial Intelligence
(ECAI 2004), pages 119(cid:150)124, 2004.

[Lout(cid:2) and Coradeschi, 2005] A. Lout(cid:2) and S. Coradeschi.
Improving odour analysis through human robot interac-
the IEEE International
tion.
Conference on Robotics and Automation (ICRA 2005),
Barcelona, Spain, 2005.

In To Appear Proc of

[Ronnie et al., 2003] L. Ronnie, M.

and
N. Xiong. Perception management - an emerging concept
for information fusion. Information Fusion, 4(3):231(cid:150)234,
2003.

Johansson,

[Saf(cid:2)otti et al., 1995] A. Saf(cid:2)otti, K. Konolige, and E. H.
Ruspini. A multivalued-logic approach to integrating plan-
ning and control. Arti(cid:2)cial Intelligence, 76(1-2):481(cid:150)526,
1995.

