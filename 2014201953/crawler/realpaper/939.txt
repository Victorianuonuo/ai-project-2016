Mechanism Design with Partial Revelation

Nathana¨el Hyaﬁl and Craig Boutilier

{nhyafil,cebly}@cs.toronto.edu

Department of Computer Science

University of Toronto

Toronto, ON, M5S 3H5, CANADA

Abstract

Classic direct mechanisms require full utility revelation
from agents, which can be very difﬁcult in practical
multi-attribute settings.
In this work, we study par-
tial revelation within the framework of one-shot mecha-
nisms. Each agent’s type space is partitioned into a ﬁnite
set of partial types and agents (should) report the partial
type within which their full type lies. A classic result
implies that implementation in dominant strategies is im-
possible in this model. We ﬁrst show that a relaxation
to Bayes-Nash implementation does not circumvent the
problem. We then propose a class of partial revelation
mechanisms that achieve approximate dominant strategy
implementation, and describe a computationally tractable
algorithm for myopically optimizing the partitioning of
each agent’s type space to reduce manipulability and so-
cial welfare loss. This allows for the automated design of
one-shot partial revelation mechanisms with worst-case
guarantees on both manipulability and efﬁciency.

1 Introduction

An important challenge facing AI is the design of protocols
through which self-interested agents might interact to achieve
some desirable outcome (such as negotiating an outcome that
maximizes social welfare). As a consequence, mechanism
design [17]—which studies precisely this problem from an
economic and game-theoretic point of view—has become an
important area of study within AI and computer science more
broadly. Roughly speaking, a mechanism is a game intended
to implement some social choice function (SCF), i.e., a func-
tion that selects some outcome as a function of the prefer-
ences of the participating agents.

A key result in mechanism design, the revelation princi-
ple, states that mechanisms can be restricted to incentive com-
patible, direct mechanisms, in which agents fully reveal their
true type (i.e., utility function over outcomes). For instance,
Vickrey-Clarke-Groves (VCG) is such a mechanism for so-
cial welfare maximization.

Unfortunately, direct type revelation is problematic in prac-
tice, since utility functions can be extremely difﬁcult for
agents to even compute effectively or communicate to the
mechanism, especially in settings with large, multiattribute
outcome spaces (a familiar example is combinatorial auctions
[7]). Thus the design of mechanisms where utility functions

are bot fully revealed (thus relieving agents of some of the
computational and communicational burden) has become an
important problem in computational mechanism design.

In this paper we consider the design of one-shot mech-
anisms that make decisions using partial type information.
In Section 2, we present a model of partial revelation and
survey those models and results that inﬂuence our approach,
with emphasis on the tension between partial revelation and
dominant strategy implementation.
In Section 3, we show
that relaxing implementation to Bayes-Nash or ex-post does
not allow for the design of “useful” partial revelation mech-
anisms. We therefore consider approximate dominant incen-
tive compatibility, in which the potential gain from misreport-
ing one’s partial type in bounded. We deﬁne a class of regret-
minimizing mechanisms (Section 4) that chooses an outcome
that minimizes the worst-case loss (w.r.t. social welfare) over
all possible types in the declared partial types. We then de-
ﬁne several payment schemes, describe the important proper-
ties of our mechanisms (speciﬁcally, approximate efﬁciency,
rationality and incentive compatibility) and argue for their
suitability. While these results hold for any partial types, the
quality of the approximation depends critically on the choice
of partial types. In Section 5 we deﬁne an algorithm to opti-
mize the choice of partial types that allows one to tradeoff the
amount of elicitation with the degree of efﬁciency and incen-
tive compatibility loss. Taken together, regret-based mech-
anisms and the optimization algorithm provide a framework
for the automated design of partial revelation mechanisms
in which one can explicitly address such tradeoffs. Prelim-
inary computational experiments conﬁrm the efﬁcacy of our
approach. We defer all proofs to a longer version of the paper.

2 Background and Deﬁnitions

We begin with some essential background. To motivate our
deﬁnitions, we will use a simple running example of a buyer
wishing to purchase a car from a seller. We wish to facilitate
the negotiation: they must agree on the car (from the seller’s
inventory) and the price to be paid; but buyer’s valuation for
different cars and the seller’s cost is not known to us. Ideally,
we would identify the car that maximizes surplus (the differ-
ence between the buyer’s valuation and the seller’s cost).

IJCAI-07

1333

(cid:2)

2.1 Mechanism Design
We adopt a standard quasi-linear environment with n agents
in which the aim is to choose an outcome or allocation x
from the set X of all possible allocations. Each agent i ≤ n
has type ti drawn from set Ti, and valuation function vi
:
X× Ti → R, with vi(x; ti) denoting the value of allocation x
if i has type ti. In many cases, we can view ti as encoding i’s
i Ti be the set of full type
utility function over X. Let T =
(cid:3)
vectors. The social welfare of x given t ∈ T is SW (x; t) =
i vi(x; ti). Let t−i denote a type vector over all agents but
j(cid:2)=i vj(x; tj ). In our example, the
i, and SW −i(x; t) =
buyer’s type tb would determine its valuation vb(x; tb) for any
transacted vehicle x (and similarly for the seller, its cost).
The space of possible types Tb could be deﬁned in a number
of ways. For instance, if |X| = n, Tb could be the set of
n-vectors 0 ≤ v ≤ c for some constant c (with vi denoting
the utility of the ith vehicle). However, valuations can often
be represented more compactly. For instance, if a buyer’s
utility is known to be linear with respect to a small set of car
features, then a Tb may be k-dimensional (for some k < n),
and any type captured by a set of k parameters.

(cid:3)

(cid:2)

A mechanism consists of a set of actions A =

i Ai, an
allocation function O : A → X and n payment functions
pi : A → R. Intuitively, the mechanism offers the action
set Ai to i, and chooses an allocation based on the actions
taken by each agent. We assume quasi-linear utility; that
is, an agent i’s utility for an allocation x and payment ρi
is ui(x, ρi, ti) = vi(x; ti) − ρi. Mechanism m induces a
(Bayesian) game assuming probabilistic beliefs over types:
each agent i adopts a strategy πi : Ti → Ai associating an
action with its type.1

The goal of mechanism design is to design m to imple-
ment some SCF f : T → X. For instance, f may be social
welfare maximization (i.e., f (t) = arg max SW (x; t)). In
this work, we focus on social welfare maximization or efﬁ-
cient allocation. Implementation then depends on the equi-
librium concept used; speciﬁcally, if m induces strategies πi
for each agent in equilibrium such that O(π(t)) = f (t) for
all t ∈ T , we say that m implements f . Standard equilibrium
concepts lead to dominant strategy, ex post, and Bayes-Nash
implementation.2 The revelation principle allows one to fo-
cus attention on direct, incentive compatible mechanisms in
which Ai = Ti and each agent will reveal his type truthfully
in equilibrium. In our example, this would allow restriction to
mechanisms in which we ask the car buyer and seller to report
their complete valuation and cost functions, respectively.

The Groves scheme is a famous class of mechanisms for
quasi-linear environments (of which VCG is an instance) in
which social welfare maximization is implemented in domi-

1Without priors, the game is in pre-Bayesian form [12] or has

strict type uncertainty [13].

2If each agent has a dominant strategy (i.e., a strategy that is
optimal no matter what others do) in the induced game, then we
have dominant strategy equilibrium and implementation. An ex post
equilibrium is a vector of strategies π such that πi is optimal for i
even when the types of others are known to i (assuming strategies in
π). A Bayes-Nash equilibrium is such that πi maximizes i’s utility
in expectation over others’ types.

nant strategies: it is characterized by any efﬁcient allocation
function, and the Groves payments [11]:

pi(t) = pi(t−i, x

∗) = hi(t−i) − SW −i(x

∗; t−i)

(1)

for any functions hi : T−i → R.
In non-trivial settings, the
Groves scheme is the only class of mechanisms that can im-
plement any SCF in dominant strategies. This follows from
two famous results: Roberts [22] showed that if X contains
at least 3 outcomes and all valuations are possible, then an
SCF is implementable in dominant strategies iff it is an afﬁne
welfare maximizer (i.e., afﬁne transformation of social wel-
fare); while Green and Laffont [10] proved that to implement
an afﬁne welfare maximizer one must use Groves payments.
Thus, to implement social welfare maximization in dominant
strategies, one must not only elicit enough information to de-
termine the efﬁcient allocation but generally also enough fur-
ther information to determine the Groves payments.3

2.2 Partial Revelation Mechanisms
We deﬁne a partial type θi ⊆ Ti for agent i to be any subset
of i’s types. A partial type vector θ includes a partial type for
each agent. A (direct) partial revelation mechanism (PRM)
is any mechanism in which the action set Ai is a set of partial
types Θi (i.e., the agent is asked to declare the partial type
in which its true type lies). Since agents only reveal partial
types, the notion of truth telling must be relaxed somewhat:
Deﬁnition 1. A PRM is incentive compatible (IC)—under
the relevant equilibrium concept—if it induces equilibrium
strategies πi for each agent i such that ti ∈ πi(ti).

In other words, an IC PRM will induce each agent to re-
port a partial type that contains its true type.
In our ex-
ample, we might deﬁne the partial type space of the buyer
by deﬁning a set of rough bounds on the valuation for each
car, with some cars having a more precise range than others.
For instance, one partial type might assert that vb(car 1) ∈
[17, 000, 20, 000], vb(car 2) ∈ [23, 000, 24, 000], and so on.
Limiting revelation to partial types of this form allows the
buyer to negotiate without having to precisely determine its
valuation for each car, but simply estimate it roughly.

Partial types may or may not be overlapping or exhaustive.
If they are not exhaustive, incentive compatibility is not gen-
erally possible. If they are overlapping, more than one truth-
ful report may be possible, and an agent can reason strategi-
cally to choose among them while maintaining truthfulness,
something that is not possible if types do not overlap. Our
key results, speciﬁcally incentive and efﬁciency guarantees,
do not require non-overlapping types. We will, however, as-
sume in what follows that partial types are exhaustive.

In general, given a partial type vector θ, a mechanism will
not be able to determine an efﬁcient allocation x—the allo-
cation x∗(t) that maximizes social welfare for type t may be
different for various t ∈ θ. A corollary of Roberts’ result
is that a one-shot PRM cannot be used for dominant strategy
implementation: unless the partitioning of each agent’s type
space is such that each joint partial type θ determines a unique
maximizing x∗
for all t ∈ θ, dominant strategy implementa-
tion will not be realized (in general).

3In auction-like settings, this result holds for any SCF satisfying

the independence of irrelevant alternatives [15].

IJCAI-07

1334

2.3 Related Work

Recent research has examined methods involving limited or
incremental elicitation of types to circumvent the difﬁculties
of full type revelation (especially in single-good and com-
binatorial auctions). Most work on incremental elicitation
involves techniques that elicit “just enough” information to
determine the VCG outcome fully, both allocation and pay-
ments fully, thus maintaining incentive properties (e.g., in
CAs [5; 20]). Such mechanisms, being incremental, do not
ﬁt precisely into our framework, and generally allow only ex
post implementation; issues pertaining to approximate efﬁ-
ciency are avoided altogether. Furthermore, the sequential
approach is critical to avoiding full revelation. Unfortunately,
the amount of information required to fully determine the
VCG outcome may be considerable [19] (and enforcing IC
over and above just implementing an SCF itself induces sig-
niﬁcant cost [8]).

Alternatively one can elicit enough information to deter-
mine an approximately optimal outcome, a common approach
in single-agent elicitation [4], sacriﬁcing decision quality to
reduce elicitation effort. We adopt this perspective here.
Recently, we used this approach in the design of sequen-
tial PRMs [14], leading to approximate ex-post implementa-
tion. The one-shot mechanisms presented in this paper have
stronger incentive properties (approximate dominant imple-
mentation), and allow for more interesting payment schemes.
Another class of approaches to PRMs is exempliﬁed by prior-
ity games [3; 2]. In these models, partial types are elicited and
exact (not approximate) dominant strategy implementation is
realized. However, these PRMs are designed only to deal
with agents having one-dimensional (or “single-parameter”)
types, for example, agents in a single-item auction where val-
uation for an outcome can be speciﬁed by one parameter. In-
deed, Roberts’ result is escaped only by restricting the space
of preferences in this severe fashion. Combinatorial auctions
with single-minded agents are similarly restricted [16]. Un-
like our model, these mechanisms do not generalize to more
realistic valuation structures [15].

Approximate IC has been considered before from several
perspectives. Nisan and Ronen [18] show that computational
approximation of VCG can destroy truth-telling, but manip-
ulation of approximate VCG can be made computationally
difﬁcult [23], thus inducing “practical” incentive compatibil-
ity.
IC in expectation or with high probability can also be
demanded [1]. Finally, one can attempt to bound the gain an
agent can achieve by lying (e.g., as proposed for exchanges
in [21]). It is this latter view of approximate IC that we adopt
here. Our class of partial revelation mechanisms, along with
our partitioning algorithm provide the ﬁrst approach to auto-
mated partial revelation mechanism design [6].

3 Bayes-Nash and Ex-Post Implementation

In the Bayes-Nash context, each agent has a probabilistic
prior over the types of the others, P r(t−i|ti). If truth-telling
is a Bayes-Nash equilibrium in a PRM, this deﬁnes a distri-
bution over the reports (partial types) of other agents; hence
for each of its reports θi, agent i has a distribution, xθi
i , over

allocations selected by the mechanism. For each x deﬁne:
xθi
i (x) = P r(x|θi) =

P r(θ−i|θi) · P r[O(θiθ−i) = x]

(cid:4)

θ−i

In this section, we restrict ourselves to partitions of the type
space that are “grid-based”: each parameter’s space of values
is split into a ﬁnite number of intervals of the form [lb, ub),
with lb < ub. We can derive the following results:
Theorem 1. If all valuation functions are possible, in a
Bayes-Nash IC grid-based PRM, we have:

∀i, ∀θi, θ

(cid:2)
i

θ(cid:2)
i

i =def xi

(2)

θi
i = x
: x
: xi = xj

∀i, j

(3)
Property 2 states that, regardless of its report, agent i has
the same posterior xi over outcomes. Property 3 states that
this distribution is also the same for all agents. If the alloca-
tion function is deterministic, then it selects the same alloca-
tion for each report vector. We call such a mechanism trivial.
Triviality may be avoided if allocations are probabilistic, but
even then, these properties are very restrictive:

Proposition 1. No Bayes-Nash IC grid-based PRM has
higher expected social welfare than the trivial mechanism
that always picks the allocation with highest ex ante social
welfare.

Proposition 2. If ex-interim (or, a fortiori ex-post) individual
rationality (IR) is required, the expected sum of payments of
any Bayes-Nash IC grid-based PRM is zero.

In a sense, though partial revelation Bayes-Nash imple-
mentation is not strictly trivial, it is useless since it achieves
the same result as a mechanism with no revelation. Given
that an ex-post equilibrium is a vector of strategies that are in
Bayes-Nash equilibrium for all possible probabilistic priors,
the above results imply that any ex-post IC PRM is trivial.

Note that the grid-based restriction is a sufﬁcient condition
for the above results to hold. We are currently looking into
identifying necessary conditions. For example, we strongly
suspect that any partitioning of type space into convex partial
types will lead to the same negative results. We do not have
such results at present however.

4 Regret-based PRMs
A partial revelation mechanism must choose an allocation
x(θ) for each reported partial type θ ∈ Θ, but cannot gen-
erally do so in a way that ensures efﬁciency. We propose the
use of minimax regret [4; 14] to choose the allocations asso-
ciated with each partial type vector.
Deﬁnition 2. The pairwise regret of decision x with respect
to decision ˆx over feasible type set θ is

R(x, ˆx, θ) = max

t∈θ

SW (ˆx; t) − SW (x; t),

(4)

This is the most the mechanism could regret choosing x in-
stead of ˆx (e.g., if an adversary could impose any type vector
in θ). The maximum regret of decision x and the minimax
regret of feasible type set θ are respectively:

MR(x, θ) = max

ˆx

R(x, ˆx, θ)

MMR(θ) = min

MR(x, θ)

x

(5)

(6)

IJCAI-07

1335

A minimax-optimal decision for θ, denoted x∗(θ), is any
allocation that minimizes Eq. 6. Without distributional infor-
mation over the set of possible utility functions, choosing (or
recommending) a minimax-optimal decision x∗
minimizes
the worst case loss in efﬁciency with respect to possible real-
izations of the types t ∈ θ. We refer to the regret maximizing
ˆx in Eq. (6) as the witness for x.

Recent approaches to minimax regret optimization have
shown it to be practical when utility models are factored into
a convenient functional form such as generalized additive in-
dependence (GAI) [9], and utility uncertainty is expressed in
the form of linear constraints on such factored models [4]. In
this setting, minimax regret optimization can be formulated
as a linear, mixed-integer program (MIP) with exponentially
many constraints, but can be solved using an iterative con-
straint generation procedure that, in practice, enumerates only
a small number of (active) constraints [4].

Deﬁnition 3. A regret-based partial revelation mechanism is
any mechanism in which the allocation function chooses an
outcome that minimizes max regret given the revealed partial
type vector; that is, O(θ) = x

∗(θ) for all θ ∈ Θ.

Assume we have a PRM m in which each agent declares
a partial type θi ∈ Θi, and that m is regret-based, i.e., O
∗(θ) with minimax regret w.r.t. social welfare for
chooses x
any declared type vector θ:
Observation 1. Let m be a regret-based partial revelation
mechanism with partial type space Θ. If MR(x∗(θ), θ) ≤ ε
for each θ ∈ Θ, then m is ε-efﬁcient for truth-telling agents.
This simply formalizes the obvious fact that since max re-
gret for any mechanism choice is bounded by ε, then if all
agents reveal their partial types truthfully we are assured to
be within ε of maximizing social welfare.

With PRMs we cannot generally guarantee efﬁciency: dif-
ferent type proﬁles within a partial type vector θ may require
a different allocation choice to maximize social welfare. As
a consequence, the result of Roberts means we will be unable
to implement our “approximate” choice function in dominant
strategies. Instead, we relax the implementation concept in
a natural fashion and derive a payment scheme that ensures
approximate IR and IC in dominant strategies.

Consider the following generalization of Groves payments.
Given joint report θ = (θi, θ−i) of all agents, and the corre-
sponding choice x∗
pi(θ) = pi(θ−i, x
where hi : Θ−i → R is an arbitrary function and fi : Θ−i →
Ti is any function that, given partial type vector θ−i, selects a
type vector t−i from that set (i.e., fi(θ−i) ∈ θ−i).

, agent i’s payment is:
∗) = hi(θ−i) − SW−i(x

∗; fi(θ−i))

Recall that under full revelation, fi(θ−i) is the complete
type vector t−i reported by the other agents and hi must take
that particular t−i as an argument. Our partial Groves pay-
ment scheme, however, can select an arbitrary type for each
agent consistent with their declared partial types and apply
standard Groves payments (Eq. 1) to these. The selected types
can differ for each payment function pi, and the arbitrary hi
functions also depend only on the partial types revealed. Par-
tial Groves payments can thus require signiﬁcantly less reve-
lation. Together with regret-based allocation, they give:

Theorem 2. Let m be a regret-based partial revelation mech-
anism with partial type space Θ and partial Groves payment
functions pi. If MR(x∗(θ), θ) ≤ ε for each θ ∈ Θ, then m is
ε-efﬁcient and ε-dominant IC.

In other words, truth telling is an ε-dominant strategy equi-
librium (i.e., truth telling for any agent has utility within ε of
optimal regardless of the reports of others).

We can specialize partial Groves payments to partial

Clarke payments:

∗

∗; fi(θ−i))

−i(θ−i); fi(θ−i)) − SW−i(x

pi(θ−i, x
∗) = SW (x
where x∗
−i : Θ−i → X is an arbitrary function that chooses
an allocation based only the reports of agents other than i.
This restriction allows the following IR guarantee:
Theorem 3. Let m be a regret-based partial revelation mech-
anism with partial type space Θ and partial Clarke payments
pi. If MR(x∗(θ), θ) ≤ ε for each θ ∈ Θ, then m is ε-efﬁcient,
ε-dominant IC and ex-post ε-IR.

In other words, no agent has incentive greater than ε not to

participate in the mechanism.

We have provided some intuitive justiﬁcation above for the
use of minimax regret to determine the allocation associated
with any revealed partial type proﬁle. We can also provide
formal justiﬁcation for the use of minimax regret with respect
to incentive properties of PRMs. Speciﬁcally, under the par-
tial Groves and Clarke payment schemes, worst-case manip-
ulability (over possible type proﬁles) is exactly equal to the
greatest minimax regret-level (again, over possible type pro-
ﬁles). Thus one can show:
Proposition 3. Let Θ be a ﬁxed partial type space, and M
a regret-based PRM (w.r.t. Θ) using the partial Clarke pay-
ment scheme. Any other PRM M (cid:4)
(w.r.t. Θ) using the par-
tial Clarke scheme, will have worst-case manipulability, efﬁ-
ciency loss and rationality violation at least as great as that of
M . There exist non-regret-based PRMs where this inequality
is strict.

In other words, no non-regret based scheme can perform
better than a regret-based scheme with respect to efﬁciency
loss (obviously), gain from misreporting one’s partial type,
and incentive for non-participation. The analog of this propo-
sition holds regarding manipulability and efﬁciency when us-
ing the partial Groves payment scheme.

Even with the “Clarke-style” restriction above, our pay-
ment scheme is quite general: x∗
−i and fi are arbitrary func-
tions. The choice of these will not affect the worst-case prop-
erties above, but it can be used to: (a) reduce the likelihood
(if any) of a rationality violation; and/or (b) maximize rev-
enue of the mechanism. If reducing or removing a rationality
violation implies revenue loss, then a trade-off can be made
between the two criteria. An attractive feature of our PRMs
is the considerable scope for optimization of the payment
scheme due to the nature of the partial type revelation.

When dealing with approximate incentive properties, one
must be aware that a small deviation from the truth by one
agent can cause major changes in the mechanism’s alloca-
tion (leading, say, to large losses in efﬁciency). But with par-
tial Groves payments, an agent can gain at most ε compared

IJCAI-07

1336

(θ1,...θi,...θn)

node 1

(θ'1,...θi,...θn)

node 2

(θ''1,...θi,...θn)

node 3

(θ'1,...θ'i,...θn)

(θ'1,...θ''i,...θn)

(θ''1,...θ'i,...θn)

(θ''1,...θ''i,...θn)

node 4

node 5

node 6

node 7

Figure 1: Example of a mechanism tree.

5.1 Partial Type Optimization Algorithm

We describe an ofﬂine, iterative, myopic approach to the op-
timization of agent type space partitions. It is myopic in the
following two senses: (a) at each step, it focuses on reducing
the minimax regret of the joint partial type with greatest regret
by reﬁning (or splitting) it, without considering the impact on
other partial types; and (b) it only considers the immediate
effects of this reﬁnement, with no look-ahead to future splits.
To simplify the presentation, we ﬁrst describe a naive, com-
putationally intensive method, formulated in terms of deci-
sion tree construction, and then show how it can be modiﬁed
to be made much more tractable. The algorithm uses a heuris-
tic function which, given a partial type vector, selects an agent
whose partial type will be split. It is important to realize that
these splits are not “queries” to the agent—the mechanism is
not sequential. Rather, splitting a partial type further will in-
crease the number of partial types from which an agent must
choose when the mechanism is actually executed. Once all
splits to all agents are determined, the mechanism will ask
agents to select from the partial types induced by this reﬁne-
ment process. In other words, ofﬂine we construct the par-
tial types used by the one-shot mechanism. We discuss the
heuristic function further below.

to revealing its partial type truthfully. In most settings, the
computational cost of ﬁnding a good lie, especially given the
considerable uncertainty in the value of any lie (due to un-
certainty about others’ types), will be substantial (see, e.g.,
[23]). Thus, if ε is small enough, it will not be worth the cost:
our formal, approximate incentive compatibility is sufﬁcient
to ensure practical, exact incentive compatibility.

To develop a sense of the difﬁculty associated with manip-
ulating such a mechanism, consider that an agent must be able
to compute an untruthful strategy (or lie) with greater utility
than truth-telling in order to exploit our approximate incen-
tive guarantee. To do this one must ﬁrst determine the true
value of a lie (incurring the valuation or cognitive costs sim-
ilar to revealing truthfully). However evaluating a lie also
requires considerable (and accurate) information about the
types and strategies of the others; even with decent priors,
the costliness of such computations (e.g., in time, cognitive,
or computational resources) implies that manipulation is not
worthwhile unless the bound ε is quite loose, and incentive
compatibility will thus, in practice, be exact.

A similar argument can be made regarding approximate
IR: determining whether you gain from not participating will
be very difﬁcult. Thus a potential small loss will be worth-
while for an agent given the savings our mechanism provides
in revelation and computational costs (relative to the full rev-
elation alternative). Finally, given the complexity of many
mechanism design settings, when cognitive, computational
and communication costs are accounted for, the potential loss
in efﬁciency will be an acceptable trade-off, given the high
level of revelation required by exactly efﬁcient mechanisms.

5 Construction of Partial Types

So far we have focused on the design of regret-based PRMs
with a ﬁxed collection of partial types. However, the se-
lection of partial types is critical to the performance guar-
antees above, since it is these types that determine the de-
gree of regret incurred by the mechanism. The key design
issue is the construction of a suitable set of partial types that
minimizes both revelation and the maximum minimax regret
(i.e., ε) over that set. We describe a heuristic, but reason-
ably tractable, approach to the automated optimization of the
type space partitioning. Although the class of mechanisms
is ﬁxed and it is the partition that is being optimized by our
algorithm, together these constitutes a tractable approach to
automated partial revelation mechanism design.

In what follows, we assume an agent type is simply a
bounded n-vector with valuations for each allocation x ∈ X.
When dealing with a multi-attribute outcome space, we al-
low for an agent’s type/utility function to be factored us-
ing a generalized additive independence representation [9],
in which utility parameterized with local sub-utility functions
over small sets of attributes. In a ﬂat (un-factored) model, the
parameters are simply the valuations for allocations x. We
assume in what follows that the type space Ti is given by up-
per and lower bounds over the parameters of agent i’s utility
model and focus on partial types speciﬁed similarly.

1

IJCAI-07

1337

1 and θ(cid:4)(cid:4)

Figure 5.1 illustrates the creation of partial types for a PRM
in terms of decision tree construction. At the outset, the only
information available to the mechanism is the set of possible
types for each agent given by our prior, deﬁning the initial
partial type vector (θ1, . . . , θn) with θi = Ti. This labels the
initial (root) node of our tree (node 1). We call the heuris-
tic function on this vector, which selects an agent, say agent
1, and a split of that agent’s partial type θ1 into two more
reﬁned partial types θ(cid:4)
1 . The reasons for choosing a
particular split are elaborated below, but intuitively, such a
split should have a positive impact with respect to max regret
reduction of the mechanism. This creates two child nodes
corresponding to partial type vectors (θ(cid:4)
1, . . . , θi, . . . , θn) and
(θ(cid:4)(cid:4)
, . . . , θi, . . . , θn) (see nodes 2 and 3 in Figure 5.1). These
two new leaves in the tree correspond to the partial type vec-
tors to be used by the mechanism should the splitting process
terminate at this point. Thus, we update the partial type space
Θi for agent 1 by removing θ1 and adding θ(cid:4)
1 . We then
compute the minimax regret level, optimal allocation and wit-
ness (in a single optimization) for these two new leaf nodes
given their partial type vectors.

1 and θ(cid:4)(cid:4)

With multiple leaves, the heuristic function must ﬁrst select
a leaf node for splitting before selecting a split. It does this by
selecting the partial type vector (leaf node) with greatest min-
imax regret. The algorithm iterates in this fashion, repeatedly

selecting the leaf node with greatest minimax regret and us-
ing the heuristic to decide which agent’s partial type (within
that node) to split (and how to split it), until some termination
criterion is met (e.g., the worst-case max regret is reduced to
some threshold, or some maximum number of partial types—
per agent or overall—is reached).

Unfortunately, unlike standard decision tree construction,
a split at one leaf has implications for all other leaves as
well. For example, after the initial split above, a split may
be recommended at node 2 in the tree, corresponding to
(θ(cid:4)
1, . . . , θi, . . . , θn). Suppose a split of agent i’s partial type
θi into θ(cid:4)
is suggested for some i (cid:6)= 1. Since θi is
included in the partial type vectors of both nodes 2 and 3,
this split affects both child nodes, since agent i will have to
distinguish (at the very least) θ(cid:4)
i . We there must re-
place nodes 2 and 3 with four new leaf nodes (nodes 4–7),
corresponding to the combinations of θ(cid:4)

i from θ(cid:4)(cid:4)

i and θ(cid:4)(cid:4)

1 and θ(cid:4)

1, θ(cid:4)(cid:4)

i, θ(cid:4)(cid:4)
i .

i

This naive approach has two obvious problems. First, there
is an exponential blow-up in the number of leaves of the
“mechanism tree” since any reasonable heuristic (including
the one described below) will often (roughly) alternate splits
between the agents whose type uncertainty is still relevant.
The algorithm is therefore computationally demanding. Sec-
ond, consider the example above. The split of θi at the second
iteration of the algorithm was recommended by the heuristic
based on the partial type vector at node 2 (which includes θ(cid:4)
1),
because of its ability to reduce the minimax regret level of that
speciﬁc partial type vector. However, this split may have lit-
tle or no effect on minimax regret when applied to node 3 (in
which agent 1’s partial type θ(cid:4)(cid:4)
1 is different). This split may
indeed be “useless” when considered at node 3. These prob-
lems can be avoided by modifying the algorithm as follows.
When a split is made at some node k, even though the par-
tition has been updated in a way that might affect a partial
type at another node k(cid:4)
, we can choose to ignore the effect
on k(cid:4)
corresponds to a partial type vector that
is no longer in our partition but includes a collection of par-
tial type vectors that are. We call k(cid:4)
a joint node, and for
each such node, we record the splits that have been ignored.
In our example, the split of node 2 on θi may be ignored at
node 3, leaving node 3 to be a joint node. In the tree, node 2
would generate two descendants (nodes 4 and 5), while node
3 would remain a leaf node (nodes 6 and 7 would not be gen-
erated). While the split of i’s type into θ(cid:4)
i will even-
tually need to be considered at node 3 (or its descendants),
we defer this decision (as discussed below), and can consider
making additional splits of node 3 ﬁrst should this split of θi
be of little value. This saves having to consider the splits of
multiple descendants of node 3 independently.

. Thus node k(cid:4)

i and θ(cid:4)(cid:4)

) and one where it is lower (θ<0.5
on p1 at .7; the third splits θ<0.5

Note that multiple ignored splits may be “nested”. For ex-
ample, perhaps the ﬁrst split cuts the partial type into one
where some utility parameter p1 is greater than .5 (call this
θ>0.5
); the second splits
i
θ>0.5
along parameter p2 at
i
.4, and so on. When such joint node is the leaf with greatest
regret level (i.e., the one to be considered for expansion), we
ﬁrst check if there is a useful ignored split before considering
the split recommended by the heuristic. If so, we “un-ignore”
it, thus creating another leaf but without increasing the com-

i

i

Find leaf node N with highest regret
Call heuristic on N ’s partial type vector. Output: hSplit
If there exists ignored split iSplit on same parameter as hSplit:

splitN ode(N, iSplit)

Else Search for “good” ignored split gSplit

If there exists one:

splitN ode(N, gSplit)

Else Test hSplit

If hSplit is “good’:

splitN ode(N, hSplit)

Else-if hSplit is “OK’:

Search for “OK” ignored split okSplit
If there exists one:

splitN ode(N, okSplit)

Else: splitN ode(N, hSplit)

Table 1: Split selection algorithm

splitN ode(N, split)

i and θ(cid:2)(cid:2)

i according to split

θ = partial type vector of N ; i = agent involved in split
split θi into θ(cid:2)
update i’s partition
compute new MMR for both (θ(cid:2)
create corresponding new nodes N (cid:2) and N (cid:2)(cid:2)
separate N ’s ignored split list into those for N (cid:2) and N (cid:2)(cid:2)
replace leaf N in tree with leaf nodes N (cid:2) and N (cid:2)(cid:2)
For all leaf nodes with θi in their partial type vector

i, θ−i) and (θ(cid:2)(cid:2)

i , θ−i)

add split to list of ignored splits

Table 2: splitNode function

plexity of the partition. The precise way in which we select
splits is described in Tables 1 and 2. A split is called “good”
if both resulting nodes have lower regret than the node that
was split, and “OK” if only one of them does. With this im-
proved algorithm, new mechanism nodes are only added if
they are helpful. Since the naive approach results in useless
splits, computational requirements can be greatly reduced by
adopting this more sophisticated approach.

5.2 Heuristic Function
The role of the heuristic function is to split a partial type vec-
tor in two, creating one additional node in the mechanism.
This must be done by splitting the partial type of one of the
agents. However, in the case of a joint node, the partial type
of an agent passed to the heuristic function may correspond
to several “actual” partial types in the partition. For exam-
ple, the input partial type may ignore the fact that it has been
split along parameter μ1 at the value .5. If the heuristic rec-
ommends splitting that partial type along parameter μ2, this
corresponds to splitting two actual partial types (with values
greater or less than .5 for μ1). But the partial type vector is
only split in two, each successor node inheriting the ignored
splits of its parent.

In a ﬂat utility model, each utility parameter is simply the
valuation for an allocation x. In this case, our heuristic can
be described as follows. At each node, given its partial type
vector, we have the corresponding minimax regret solution
x∗
and witness ˆx. Intuitively, regret can be reduced by rais-
ing the lower bound of x∗
or lowering the upper bound on ˆx.
However, since the optimization is ofﬂine, the split “Is utility
for x greater than .5?” must account for both possibilities,

IJCAI-07

1338

yes and no. When splitting, say, x∗
, the partial type corre-
sponding to the no answer (i.e., lowering the upper bound)
is unlikely to have lower regret unless x∗
also turns out to
be the witness of the second best regret minimizing alloca-
tion. In that case, lowering its upper bound will help reduce
the second lowest regret and raising the lower bound will help
with the lowest. We therefore also compute the second lowest
max regret solution x∗2 and its witness ˆx2. If both ˆx = x∗2
∗ = ˆx2 are true, or neither is true, we split the one with
and x
the largest gap (the difference between its upper and lower
bounds). If only one is true, we split that parameter, unless
its gap is below some threshold, and the other gap is not.

This seemingly trivial strategy has interesting properties
when utility models are factored using GAI. In this setting,
our heuristic is an adaptation of the current solution elicita-
tion strategy of [4] to an ofﬂine one-shot elicitation scenario.
We defer details to a longer version of this paper.

6 Empirical Results

We report on experiments in a multi-attribute negotiation do-
main. A buyer and a seller are bargaining over a multi-
attribute good to trade. The set of 16 possible goods is
speciﬁed by four boolean variables, X1, X2, X3, X4, denot-
ing the presence or absence of four speciﬁc item features.
The buyer’s valuation and the seller’s cost are represented
using GAI structure. Each agent’s utility function is de-
composed into two factors, each factor with two different
variables: vb(x) = v1
b (x3, x4) and vs(x) =
s (x2, x4). Each subutility function is speciﬁed
s (x1, x3) + v2
v1
using four parameters, indicating the local value of the four
possible combinations of features. Thus eight utility parame-
ters fully deﬁne each agent’s utility function.

b (x1, x2) + v2

Initial prior bounds on utility parameters (i.e., the ini-
tial type space) are drawn uniformly between 0 and 100
(seller cost) or 100 and 200 (buyer value), ensuring a posi-
tive transaction exists. Though 16 goods may seem small, it
is much larger than problems solved by existing automated
approaches to (one-shot) mechanism design (all of which are
restricted to a small, ﬁnite type space). The social welfare
maximizing allocation is that good that maximizes surplus
(difference between buyer value and seller cost).

We assess the performance of our mechanisms by showing
how the worst case minimax regret level (over all possible
agent types) reduces with the number of partial types cre-
ated by our approach (expressed in number of bits). Since
PRMs are designed to work for agents with any true types,
there is no single true type or optimal allocation to compare
to. We could simulate speciﬁc agents, but our worst-case re-
gret bounds any such “true loss” results, and these bounds are
tight in the sense that at least one set of agent type proﬁles
will incur this worst case regret. Of course, regret any speciﬁc
collection of agents (or type proﬁle) will generally be lower,
so we also show expected regret in our results, assuming a
uniform distribution over type parameters. We compare our
myopic approach to type construction (i.e., where regret re-
duction is used to determine splits of partial types) to a simple
approach for partial type construction that simply splits each

partial type evenly across all parameters.4

Figure 6 shows the worst case minimax regret level of our
regret-based PRMs (averaged over thirty runs using different
priors) when partial types are constructed using our myopic
algorithm and when uniform splitting is used. We also show
expected minimax regret level (assuming a uniform distribu-
tion over types). Results are reported as a function of the
number of bits of communication necessary for an agent to
report some partial type in the proposed partition. Bounds on
manipulability, efﬁciency loss, and rationality violation are
all dictated by this worst-case regret (depending on whether
partial Groves or Clarke payments are used).5

It is clear that using regret-reduction to decide how to “re-
ﬁne” partial type space offers a signiﬁcant improvement over
a uniform partitioning. Our regret-based approach provides
good anytime behavior while uniform partitioning reduces ε
as a step function (averaging smooths the results in the graph).
Naturally, average manipulability is lower than worst-case
manipulability, thus further justifying the use of approximate
incentives. We note that the initial regret level (assuming only
one partial type, i.e., Ti, for each agent i) corresponds to an
error between 50% and 146% of the optimal social welfare,
depending on the actual agent types, and is reduced using 11
bits of communication (to communicate one’s partial type) to
20–56% error by our regret-based approach versus only 30–
86% by the uniform approach. With only 11 bits, the regret-
based approach reduces efﬁciency loss and manipulability by
about 60% while a uniform partition reduces it by about 38%.
To reach an average manipulability level of around 70, a uni-
form approach requires 11 bits compared to 6.5 for regret-
based splitting, which constitutes a 40% savings in commu-
nication. To reach manipulability level of roughly 90, the
regret-based approach provides a 50% savings in communi-
cation (5.5 bits vs. 11 bits). Note that this savings will be
realized repeatedly if the mechanism is used to support, say,
multiple bargaining instances. Finally, it is worth remarking
that 11 bits corresponds to about 1.4 bits per parameter and
0.7 bits per allocation, which is quite small in an example of
this size.

Preliminary tests using a (computationally demanding)
myopically optimal heuristic (that considers each parameter
and chooses the highest regret drop) show only modest im-
provement over regret-based splitting, thus motivating the in-
vestigation of non-myopic splitting techniques.

7 Conclusion

We have proposed a general model for partial revelation
mechanisms in which social welfare maximization is the de-
sired objective and explored their incentive properties. As a
result of our negative results on Bayes-Nash and ex-post im-
plementation (along with classical results on dominant strate-
gies), we have relaxed the requirement of exact incentive

4This is simulated so that at each step only one partial type is
split in order to allow a more accurate comparison to our approach.
5For agents with a speciﬁc type, we can usually derive much
tighter bounds on gain from manipulation than the worst case ε;
hence expected manipulability is less.

IJCAI-07

1339

Uniform: Worse
Uniform: Average
Regret−based: Worse
Regret−based: Average

n
o

l
i

s
p
E

140

130

120

110

100

90

80

70

60

50

0

1

2

3

4

5

6

7

8

9

10

11

Number of bits per agent

Figure 2: Worst case and expected ε, as a function of the number
of bits used per agent. Averaged over 30 runs.

compatibility and focused on approximating both the efﬁ-
ciency and incentive properties of PRMs, allowing one to
exploit the trade-off between the computational, communi-
cation and cognitive costs of type revelation with the degree
of approximation. Regret-based PRMs, in particular, allow
one to bound efﬁciency loss, gain from manipulation and
non-participation, and admit promising optimization meth-
ods for the automated design of PRMs. Critically, when the
gain from non-truthful revelation is sufﬁciently small, our re-
sults on formal, approximate incentive compatibility ensures
“practical” true incentive compatibility.

Apart from more extensive empirical evaluation, there are
several directions in which this work should be extended. The
ﬁrst is the integration of techniques for approximating regret
computations into our algorithm to tackle realistic problems
[4]. The second is the investigation of more efﬁcient splitting
heuristics that improve both the communication requirements
of our mechanisms and the computational costs of designing
them. The design of non-myopic incremental partial mecha-
nisms is of special interest. Precisely determining the com-
plexity of manipulation by formally modeling the costs in-
volved is also an important task in further justifying our em-
phasis on approximate IC and IR. We are exploring further
beneﬁts offered by partial revelation and (bounded) approxi-
mate IC w.r.t. to circumventing some other classic drawbacks
and “impossibility” results for direct mechanisms. Finally,
we are very interested in the exploiting prior distributional in-
formation about types in the construction of partial type space
to reduce expected efﬁciency loss and manipulability, while
retaining our worst-case guarantees, similar to the approach
taken in (full revelation) automated mechanism design [6].

Acknowledgements: Thanks to Vincent Conitzer, Kevin-Leyton
Brown, David Parkes and the referees for helpful discussions and
comments. This work was funded by NSERC.

References
[1] A. Archer, C. Papadimitriou, K. Talwar, and E. Tardos. An ap-
proximate truthful mechanism for combinatorial auctions with
single parameter agents. SODA-03, pp.205–214, Baltimore,
2003.

[2] L. Blumrosen, M. Feldman. Implementation with a bounded

action space. ACM EC-06, pp.62–71, Ann Arbor, 2006.

[3] L. Blumrosen and N. Nisan. Auctions with severely bounded

communication. FOCS-02, pp.406–416, Vancouver, 2002.

[4] C. Boutilier, R. Patrascu, P. Poupart, and D. Schuurmans.
Constraint-based optimization and utility elicitation using the
minimax decision criterion. Art. Intell., 170:686–713, 2006.

[5] W. Conen and T. Sandholm. Partial-revelation VCG mecha-
nisms for combinatorial auctions. AAAI-02, pp.367–372, Ed-
monton, 2002.

[6] V. Conitzer and T. Sandholm. Complexity of mechanism de-

sign. UAI-02, pp.103–110, Edmonton, 2002.

[7] P. Cramton, Y. Shoham, and R. Steinberg, editors. Combina-

torial Auctions. MIT Press, Cambridge, 2005.

[8] R. Fadel, I. Segal. The communication cost of selﬁshness: ex
post implementation. TARK-05, pp.165–176, Singapore, 2005.
[9] P. C. Fishburn. Interdependence and additivity in multivariate,
unidimensional expected utility theory. Intl. Econ. Rev., 8:335–
342, 1967.

[10] J. Green and J.-J. Laffont. Characterization of satisfactory
mechanisms for the revelation of preferences for public goods.
Econometrica, 45:427–438, 1977.

[11] T. Groves. Incentives in teams. Econometrica, 41:617–631,

1973.

[12] R. Holzman, N. Kﬁr-Dahav, D. Monderer, and M. Tennen-
holtz. Bundling equilibrium in combinatorial auctions. Games
and Econ. Behavior, pp.104–123, 2004.

[13] N. Hyaﬁl and C. Boutilier. Regret minimizing equilibria and
mechanisms for games with strict type uncertainty. UAI-04,
pp.268–277, Banff, AB, 2004.

[14] N. Hyaﬁl and C. Boutilier. Regret-based incremental partial
revelation mechanisms. AAAI-06, pp.672–678, Boston, 2006.
[15] R. Lavi, A. Mu’alem, and N. Nisan. Towards a characteriza-
tion of truthful combinatorial auctions. FOCS-03, pp.574–583,
Cambridge, MA, 2003.

[16] D. Lehman, L. I. O’Callaghan, and Y. Shoham. Truth rev-
elation in approximately efﬁcient combinatorial auctions. J.
ACM, 49:577–602, 2002.

[17] A. Mas-Colell, M. ˜D. Whinston, and J. ˜R. Green. Microeco-

nomic Theory. Oxford University Press, New York, 1995.

[18] N. Nisan and A. Ronen. Computationally feasible VCG mech-

anisms. ACM EC-00, pp.242–252, Minneapolis, 2000.

[19] N. Nisan and I. Segal. The communication requirements of ef-
ﬁcient allocations and supporting prices. J. Economic Theory,
2006. to appear.

[20] D. ˜C. Parkes. Auction design with costly preference elicitation.

Annals of Math. and AI, 44:269–302, 2005.

[21] D. ˜C. Parkes and J. Kalagnanam. Iterative multiattribute Vick-

rey auctions. Management Science, 51:435–451, 2005.

[22] K. Roberts. The characterization of implementable choice
rules. In J.-J. Laffont, ed., Aggregation and Revelation of Pref-
erences, pp.321–349. North-Holland, Amsterdam, 1979.

[23] S. Sanghvi and D. ˜C. Parkes. Hard-to-manipulate combinato-

rial auctions. Tech. report, Harvard Univ. Boston, 2004.

IJCAI-07

1340

