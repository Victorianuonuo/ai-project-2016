Trust No One: Evaluating Trust-based Filtering for Recommenders

John O’Donovan, Barry Smyth

Adaptive Information Cluster

Department of Computer Science

University College Dublin
Belﬁeld, Dublin 4, Ireland

john.odonovan@ucd.ie, barry.smyth@ucd.ie

Abstract

To be successful recommender systems must gain
the trust of users. To do this they must demonstrate
their ability to make reliable predictions. We ar-
gue that collaborative ﬁltering recommendation al-
gorithms can beneﬁt from explicit models of trust
to inform their predictions. We present one such
model of trust along with a cost-beneﬁt analysis
that focuses on the classical trade-off that exists be-
tween recommendation coverage and prediction ac-
curacy.

Introduction

1
Recommender systems have been developed as a solu-
tion to the well documented information overload problem.
[Resnick et al., 1994], [Breese et al., 1998]. These systems
employ techniques from user proﬁling, machine learning and
information ﬁltering to produce individual recommendations
of items to suit users’ requirements. Collaborative ﬁltering
(CF) recommenders operate on the assumption that similar
users share similar tastes; recommendations are generated for
a target user by analysing the rating histories of a set of suit-
able recommendation partners.

The traditional CF approach relies heavily on the similar-
ity between the target user and its partner as a way to weight
each partner’s predictions [Resnick et al., 1994]. In this pa-
per we propose that, in addition, it is possible to model the
trustworthiness of these partners, and to use this as another
factor to inﬂuence their prediction contributions. Indeed the
idea of explicitly modeling and using trust in ﬁltering tasks is
becoming increasingly popular. For example, [Golbeck and
Hendler, 2004] presents a trust-based email ﬁlter, trust scores
in this system are calculated through inference and propaga-
tion, of the form (A ⇒ B ⇒ C) ⇒ (A ⇒ C), where A,
B and C are users with interpersonal trust scores. The Trust-
Mail application [Golbeck and Hendler, 2004] looks up an
email sender in the reputation/trust network, and provides an
inline rating for each mail. These trust values can tell a user
if a mail is important or unimportant. Trust values in this sys-
tem can be deﬁned with respect to a certain topic, or on a
general level, in a similar manner to work in [O’Donovan and
Smyth, 2005a] and [O’Donovan and Smyth, 2005b].

[Avesani et al., 2004] describe a trust-based recommender
system in the skiing domain. However these approaches rely
on models of trust that are built from the direct feedback of
users; in short, individual users are expected to indicate those
partners that they place the most trust in and a trust model is
generated from the resulting graph of relationships.

[Massa and Bhattacharjee, 2004] build a trust model di-
rectly from explicit user-provided trust ratings. This work
is carried out using the popular epinions.com service. Epin-
ions.com is a web site that allows users to review various
items (cars, books, music, etc.). In addition they can assign
a trust rating to reviewers based on the degree to which they
have found them to be helpful and reliable in the past. [Massa
and Bhattacharjee, 2004] argue that this trust data can be ex-
tracted and used as part of the recommendation process, espe-
cially as a means to relieve the sparsity problem (lack of over-
lapping user ratings) that has hampered traditional collabora-
tive ﬁltering techniques [O’Sullivan et al., 2002]. [Massa and
Bhattacharjee, 2004] argue that it is possible to compare users
according to their degree of connectedness in the trust-graph
encoded by Epinions.com, but do not show that this method
of comparison maintains recommendation accuracy.

Our benchmark algorithm uses Resnick’s standard predic-
tion formula which is reproduced below as Equation 1; see
also [Resnick et al., 1994]. In this formula c(i) is the rating
to be predicted for item i in consumer proﬁle c and p(i) is
the rating for item i by a producer proﬁle p who has rated
i. In addition, c and p refers to the mean ratings for c and p
respectively. The weighting factor sim(c, p) is a measure of
the similarity between proﬁles c and p, which is traditionally
calculated as Pearson’s correlation coefﬁcient.

X

X

(p(i) − p)sim(c, p)

c(i) = c +

pP (i)

|sim(c, p)|

(1)

pPi

As we have seen above Resnick’s prediction formula dis-
counts the contribution of a partner’s prediction according to
its degree of similarity with the target user so that more simi-
lar partners have a large impact on the ﬁnal ratings prediction.
We argue that there is another factor which might be used
in conjunction with similarity to inﬂuence recommendation
and prediction. We believe that the reliability of a partner

proﬁle to deliver accurate recommendations in the past is an-
other important factor, one that we refer to as the trust. In-
tuitively, if a proﬁle has made lots of accurate predictions in
the past, then they can be viewed as more trustworthy than
another proﬁle that has made many poor predictions. We de-
scribe a computational model of trust that can be generated
unobtrusively, during the normal operation of a CF recom-
mender system, by mining the recommendation histories of
different recommendation partners. We re-evaluate work in
[O’Donovan and Smyth, 2005b] which shows that trust-based
methods can improve prediction accuracy when compared to
existing CF approaches. However, we describe a more com-
prehensive cost-beneﬁt analysis by considering three accu-
racy beneﬁts against changes in recommendation coverage.

2 A Computational Model of Trust
Intuitively, if a recommendation partner (proﬁle) has made
many good predictions in the past, it can be viewed as more
trustworthy than one with many poor predictions. The trust
model [O’Donovan and Smyth, 2005b] is based on this idea.
We differentiate between proﬁles generating recommenda-
tions (producer proﬁles) and those receiving recommenda-
tions (consumer proﬁles) in a particular recommendation ses-
sion. To generate a predicted rating, p(i), for item i for some
consumer c, conventional CF systems draw on the services
of a number of producer proﬁles, combining their individual
recommendations according to some suitable function, such
as Resnick’s formula. (see Equation 1). Our trust model de-
pends on whether these predicted ratings are correct relative
to the true ratings of the consumer, c(i); see Equation 2.

Correct(i, p, c) ⇔ |p(i) − c(i)| < 

(2)

Item-Level Trust

2.1
We deﬁne the item-level trust for each producer p with respect
to a given proﬁle item i to be the percentage of times that p
has made a correct rating prediction for i across some set
of consumers; see Equation 3. To do this we consider the
rating that p alone predicts for i, for the consumer in question.
We deﬁne the RecSet(p) (Equation 4) to be the total set of
rating predictions that p has made; each (rk, ik) refers to a
rating prediction, rk that p has made for item ik. Similarly,
CorrSet(p) is the subset of these ratings that are considered
to be correct; Equation 5.

T rustI(p, i) =

|{(rk, ik) ∈ CorrSet(p) : ik = i}|
|{(rk, ik) ∈ RecSet(p) : ik = i}|

RecSet(p) = {(r1, i1), ..., (rn, in)}

(3)

(4)

CorrSet(p) = {(ck, ik) ∈ RecSet(p) : Correct(ik, p, ck)}
(5)
Thus, the trust of p in relation to item i is a measure of how
often p’s predicted ratings for i have been considered correct
in the past. This information can be accumulated during the
normal course of operation of a CF recommender system in
a variety of ways. For example, users could be asked their

Figure 1: Recommendation Error.

opinions of the predicted ratings, or this might be conﬁrmed
by evaluating the user’s actions on the basis of the rating pre-
dictions; if a user buys a highly rated item then we might
assume that the high rating was justiﬁed.

2.2 Trust-Based Recommendation
We incorporate our trust-model into CF by modifying the
standard Resnick prediction algorithm in 3 ways to produce
3 different trust-based variations. Resnick’s standard predic-
tion formula is given in Equation 1. Normally it uses the
similarity between the target user proﬁle and each recommen-
dation partner proﬁle to weight their prediction contributions,
shown as sim(c, p) in Equation 1; Equation 6 shows our mod-
iﬁcations to this standard equation by adding the w(c, p, i)
weighting term. Our ﬁrst variation (WItem) modiﬁes this so
that the weighting term is a combination of item trust and pro-
ﬁle similarity; we use the harmonic mean of trust and similar-
ity. The FItem approach differs in that it uses proﬁle similar-
ity as the weight factor, but ﬁlters out proﬁles that fall below a
given trust level for the target item prior to recommendation.
Finally, the CItem approach uses the obvious combination of
WItem and FItem.

r(i) = r +

pP (i)

|w(c, p, i)|

(6)

pP (i)

3 Evaluation
For the following evaluation we use the 943 proﬁles from
the MovieLens data-set, split into 80% as training proﬁles
and the remaining 20% as test proﬁles. During training we
use a leave-one-out approach to build our trust model over
the training proﬁles. Brieﬂy, each training proﬁle is used as
a consumer with the remaining acting as producers.
Item-
level trust values are computed on the basis of the correct-
ness or otherwise of the producer predictions. During testing,
we evaluate the predictions of the training proﬁles for each
of the items in the test proﬁles using our 4 basic algorithms
(Resnick, WItem, FItem, CItem).

In this evaluation we are especially interested in the trade-
off between the coverage of a recommender (the percentage
of items that a rating can be predicted for) (Figure 2) and

X

X

(p(i) − p)w(c, p, i)

recommender system. 1st Workshop on Friend of a Friend,
Social Networking and the Semantic Web. Galway, Ire-
land, 2004.

[Breese et al., 1998] John S. Breese, David Heckerman, and
Carl Kadie. Empirical analysis of predictive algorithms for
collaborative ﬁltering. In Gregory F. Cooper and Seraf´ın
Moral, editors, Proceedings of the 14th Conference on Un-
certainty in Artiﬁcial Intelligence (UAI-98), pages 43–52,
San Francisco, July 24–26 1998. Morgan Kaufmann.

[Golbeck and Hendler, 2004] Jennifer Golbeck and James
Hendler. Accuracy of metrics for inferring trust and repu-
tation in semantic web-based social networks. In Proceed-
ings of EKAW’04, pages LNAI 2416, p. 278 ff., 2004.

[Kushmerick, 2002] N. Kushmerick. Robustness analyses of
instance-based collaborative recommendation. In T. Elo-
maa, H. Mannila, and H. Toivonen, editors, Proceedings of
the European Conference on Machine Learning, Helsinki,
Finland., volume 2430, pages 232–244. Lecture Notes in
Computer Science Springer-Verlag Heidelberg, 2002.

[Levien, 2003] Raph Levien. Attack resistant trust metrics.

Ph.D Thesis, UC Berkeley, 2003.

[Massa and Bhattacharjee, 2004] Paolo Massa and Bobby
Bhattacharjee. Using trust in recommender systems: an
experimental analysis. Proceedings of 2nd International
Conference on Trust Managment, Oxford, England, 2004.
[O’Donovan and Smyth, 2005a] John O’Donovan and Barry
Smyth. Eliciting trust values from recommendation errors.
In Proceedings of the 18th International FLAIRS Confer-
ence. AAAI Press, 2005.

[O’Donovan and Smyth, 2005b] John O’Donovan and Barry
Smyth. Trust in recommender systems.
In Proceedings
of the 10th International Conference on Intelligent User
Interfaces, pages 167–174. ACM Press, 2005.

[O’Mahony et al., 2002] Michael P. O’Mahony, Neil Hurley,
and Guenole C. M. Silvestre. An attack on collabora-
tive ﬁltering.
In Proceedings of the 13th Int. Conf. on
Database and Expert Systems Applications, pages 494–
503. Springer-Verlag, 2002.

[O’Sullivan et al., 2002] Derry O’Sullivan, David C. Wilson,
and Barry Smyth.
Improving case-based recommenda-
tion: A collaborative ﬁltering approach.
In Proceedings
of the Sixth European Conference on Case Based Reason-
ing., pages LNAI 2416, p. 278 ff., 2002.

[Resnick et al., 1994] Paul Resnick, Neophytos Iacovou,
Mitesh Suchak, Peter Bergstrom, and John Riedl. Grou-
plens: An open architecture for collaborative ﬁltering of
netnews.
In Proceedings of ACM CSCW’94 Conference
on Computer-Supported Cooperative Work, Sharing Infor-
mation and Creating Meaning, pages 175–186, 1994.

Figure 2: Recommendation Coverage.

the error over these predictions (Figure 1). The error graph
shows a positive response to error for the trust-based meth-
ods, especially those that employ trust-based ﬁltering and in
particular for the higher trust-levels. For example, at a trust
level of 0.9 only those proﬁles that have previously been cor-
rect 90% or more of the time that they have been called upon
to rate an item, are included as recommendation partners for
the ﬁlter-based approaches (FItem and CItem). And for these
approaches we see signiﬁcant error reductions of up to 57%
compared to the baseline Resnick. However, the coverage re-
sults indicate that these error reductions come at a cost. In
particular, the minimal error rates at the highest trust thresh-
olds reduce coverage by over 90%, which is unlikely to be
acceptable in most recommendation scenarios. However, for
trust thresholds below 0.5 we get signiﬁcant error reductions
while preserving coverage to a reasonable degree. In partic-
ular, the error for CItem is seen to drop most rapidly up to a
trust threshold of 0.2, at which point it offers 85% coverage
and an error of 0.71; Resnick’s error is 22% higher than this.

4 Conclusions
We believe that computational models of trust can improve
the effectiveness of recommender systems. We have shown
that by integrating an item-level model of trust into standard
collaborative ﬁltering we can increase accuracy by up to 57%
by using only the top 1% most trustworthy proﬁles as recom-
mendation partners. While this beneﬁt comes at a signiﬁcant
coverage cost, more reasonable coverage can be achieved
with reduced error rates by less drastic ﬁltering thresholds.
In addition to improving prediction accuracy, we believe that
this trust-based approach may make recommenders more ro-
bust to attack by malicious users, as discussed in [O’Mahony
et al., 2002], [Levien, 2003] and [Kushmerick, 2002]. This is
a matter that we will investigate as part of future work.

5 Acknowledgments
This material is based on works supported by Science Foun-
dation Ireland under Grant No. 03/IN.3/I361

References
[Avesani et al., 2004] Paolo Avesani, Paolo Massa, and
Roberto Tiella. Moleskiing: a trust-aware decentralized

