Session  24  P e r c e p t i on 

f or  Robots 

ON  CALIBRATING  COMPUTER  CONTROLLED  CAMERAS  FOR  PERCEIVING  3-D  SCENES 

by 

I r w in  S o b e l* 

Department  of  Computer  Sciences 

Technion  - 

I s r a el 

I n s t i t u te  of  Technology 

H a i f a, 

I s r a el 

A b s t r a ct 

to  p e r­
from  s e v e r al 

A  problem 

t h at  a r i s es 

in  g e t t i ng  computers 

if 

is 

it  has 

r e l a t i ng 

to  be  a b le 

i ts  s e n s o r, 

i n f o r m a t i on 

the  computer 

In  p a r t i c u l a r, 

images  of  o b j e c ts 

to  p r e d i ct  changes 

it  has  seen  w i t h o ut  h a v i ng 

c e i ve  3-D  scenes 
d i f f e r e nt  v i e w p o i n t s. 
moves 
in 
c o m p l e t e ly  r e - r e c o g n i ze 
lem  has  been 
r a t ed  camera  model  w h i ch  expresses 
ween  o b j e ct  space  and 
the 
computer's  c o n t r ol  v a r i a b l e s.  The  m o d e l l i ng  problem  is 
r e l a t i v e ly  w e ll  u n d e r s t o o d.  C a l i b r a t i on 
however,  are  n o t.  This  a r t i c le  d e a ls  w i th 

implemented  at  S t a n f o rd  u s i ng  a  c a l i b­
the  r e l a t i on  b e t­

image  space  as  a 

them.  A  s o l u t i on 

t e c h n i q u e s, 

f u n c t i on  of 

t h is  p r o b­

t h e s e. 

to 

to 

D e s c r i p t i ve  Terms 

r o b o t s,  computer  v i s i o n,  a r t i f i c i al 
photogrammetry,  v i s u a l ly  guided  m a n i p u l a t o r s,  a u t o­
m a t ic  assembly 

i n t e l l i g e n c e, 

I n t r o d u c t i on 

Image  a n a l y s is 

f or  3-D  scene  p e r c e p t i on 

is  comput­

in 

a t i o n a l ly  e x p e n s i v e. 
computer  which  moves 
changes 
the 
w i t h o ut  h a v i ng 
w i ll  p r e s e nt  a  s o l u t i on 
implemented  at  S t a n f o rd 
u l a t or  system. 

is 

thus 

It 
i ts  sensor  be  able 

i m p o r t a nt 

t h at  a 

to  p r e d i ct 

images  of  o b j e c ts 
to  c o m p l e t e ly  r e - r e c o g n i ze 

it  has  a l r e a dy  seen 

them.  We 

t h is  problem 

to 
f or  a  v i s u a l ly  g u i d ed  manip­

t h at  has  been 

in 

In 

to 

to 

t u rn 

i n t e r f a c ed 

the  work  space 

to  see  any  p o i nt 

in  3  d i m e n s i o n s, 

f i g u re  1 ).  To  have 

the  c e n t r al  p a rt  of 

t u r n t a b le 
to  v i s u a l ly 

is  d e s i r e a b le 
from 

(see 
l o c a te  o b j e c ts 

they  s e r ve  as  hands  and  eyes 

The  S t a n f o rd  hand-eye  p r o j e ct 

two  s t a n d a rd  TV 
the  com­

r e s p e c t i v e l y. 
is  a 
the 

to  be  a b le 
two  d i s t i n ct  v i e w p o i n t s. 

the 
In  g e n e r al 
f i x ed  cameras,  and/or  a  h i g h ly 
the  a b i l i ty 

T 
is  o r g a n i z ed  around  a 
d u a l - p r o c e s s or  PDP-10/PDP-6  computer  system.  Two  e l e c­
t r i c a l l y - p o w e r ed  mechanical  arms  and 
cameras  w i th  p a n - t i lt  heads  are 
p u t e r; 
a d d i t i o n, 
" l a zy  s u s a n" 
c a p a b i l i ty 
it 
work  space 
t h is 
r e q u i r es  s e v e r al 
m o b i le  camera,  and/or 
environment  so  as 
b e t t e r.  The 
l a zy  susan, 
moving 
the  p o s i t i on  of  a ll  moveable 
is  schematized 
f i g u re  2.  One  camera 
the  o t h er  has  a 
are 
t i o n,  and  c o l o r - f i l t e r - s e l e c t i on  are  under  computer 
c o n t r o l.  Also  under  computer  c o n t r ol  are 
i r is 
(on 
i n f o r m a t i on 
is 
i ng  a  TV  image 
sample 
l i g ht 
may  be  read 

t r a n s m i t t ed 
I n to  an  a r r ay  of  250  *  333  samples.  Each 
is  a  4 - b it  number  r e p r e s e n t i ng  1  of  16  p o s s i b le 
r e c t a n g u l ar  s u b f i e ld 

t u r n t a b l e,  and  cameras,  and  s e n s i ng 
f l ow 
in 

the  zoom  camera),  and  v i d i c on  s e n s i t i v i t y.  V i s u al 
the  computer  by  q u a n t i z­

two  cameras  w i th  p a n - t i lt  heads,  and 
f a c i l i t a te 

f or  m a n i p u l a t i ng 
them 
the 

f i t t ed  w i th  c o l or  w h e e l s.  Zoom, 

I n f o r m a t i on 
the  system 

the  computer  memory 

the  " r i g ht  h a l f"  of 

t h i s.  The  computer 

f i t t ed  w i th  a  zoom 

t u r r e t - l e n s - s e l e c­

l e v e l s.  A  whole 

from  a  camera. 

t h i n gs  around 

t u r r et  w i th  4 

is  capable  of 

image  or  any 

l e n s e s.  Both 

l e n s,  w h i le 

the  'arms, 

r o t a t a b le 

j o i n t s. 

to  see 

f o c u s, 

i n to 

the 

f or 

to 

is 

T h is  d i s c u s s i on  d e a ls  w i th  o n ly  one  aspect  of 

the 

*The 
f o rd  A r t i f i c i al 
in  p a rt  by 
O f f i ce  of 

r e s e a r ch  r e p o r t ed  here  was  performed  at 

the  S t a n-
I n t e l l i g e n ce  P r o j e ct  and  was  s u p p o r t ed 
t he  Advanced  Research  P r o j e c ts  Agency  of 
t he 
t he  S e c r e t a ry  of  Defense  under  C o n t r a ct  SD183 

hand-eye  s y s t e m.  For  more 
h i s t o r i c al  n a t u r e, 
z " * 3 6. 
Four  PhD. 
a s p e c ts  of 
t h e s is 
t i on  of 
m a n i p u l a t o r s,  s e e 1 8 ' 2 9 ' 2 8. 

the  system. 
forthcoming14  and 

i n f o r m a t i on  of  a  g e n e r al  and 
t o 8 ' ' * 1 3 * 2 0' 

the  reader 
t h e s e s 7*  12,21,34  d e s c r i be  o t h er  major 

r e f e r r ed 

is 

In  a d d i t i on  another  p r o j e ct 

is 
I ts  p u b l i c a t i o n.  For  d e t a i l ed 

is 

r e f e r e n c ed 

in  a n t i c i p a­

i n f o r m a t i on  about 

The  Problem 

The  problem  can  be  s e p a r a t ed 

i n to 

two  main  s u b p r o b-

it  have  been 

in  many  p l a c e s 2 * 3 ' * * 1 6 ' 2 6 ' 3 0. 

lems  -  m o d e l l i ng  and  c a l i b r a t i o n.  The  m o d e l l i ng  problem 
is  s t r a i g h t f o r w a rd  geometry;  p a r ts  of 
worked  out 
it 
b r i e f l y,  we  want  an  a n a l y t ic  camera  model  r e l a t i ng  3-D 
c o o r d i n a t es  of  p o i n ts 
l o c a­
t i o ns  of 
images 
quate  model 
t r e a t­
i ng  a  p i c t u re  as  a  c e n t r al  p r o j e c t i on  of  o b j e ct  p o i n ts 
o n to  a 
ed  by 

(image)  p l a n e.  Such  a  p r o j e c t i on  can  be  d e s c r i b­
(see 

in  o b j e ct  space 
in  a  d i g i t i z ed  p i c t u r e.  An  a d e­

these  purposes  can  be  d e r i v ed  by 

f i g u re  3 a ): 

To  review 

the  2-D 

t h e ir 

f or 

to 

A  - 

R  " 

(A 
,A 
e c t i on 

VZ 

X

the 

,A  ) 
in  o b j e ct  space 

l o c a t i on  of 

the  c e n t er  of  p r o j-

(camera 

l o c a t i o n ). 

r

-J 

f or  s p e c i f y i ng 

the 

[ r i j]  a  3-D  r o t a t i on  m a t r ix 
camera's  o r i e n t a t i o n. 
frame  at  A  w . r . t. 
the 
in 
thus  has  o n ly  3  degrees  of 
case  were  chosen 
angles 

to  be 
f i g u re  3 b ): 

f i g u r e ).  Such  a  m a t r ix 

(see 

the 

It  o r i e n ts  an 
(XYZ)  o b j e ct 

(xyz)  camera 

frame 

( at  0 

is  o r t h o n o r m al  and 

freedom  which 

in  our 
the  elementary  r o t a t i on 

PAN  -  about 

the  u n r o t a t ed  y - a x is 

(assumed 

p a r a l l el 
-  about 

TILT 
SWING  -  about 

to 

the  o b j e ct  Z - a x i s) 
r o t a t ed  x - a x is 

the  once 

the 

t w i ce 

r o t a t ed  z - a x is 

f  - 

the  normal  d i s t a n ce 

from  A 

to 

the 

image  p l a ne 

The  6  degrees  of 
and  o r i e nt 
s c a le  of 
geometry  parameters  of 

freedom  c o n t a i n ed 

in  A  and  R  l o c a te 

the  camera,  w h i le 

the  b a s ic 
t he  p r o j e c t i o n.  A  and  It  are  c a l l ed  e x t e r n al 

f  determines 

the  camera. 

The  process'  of  d i g i t i z a t i on 

f u r t h er  s c a l es 
f a c t o rs  Mx,My  w h i ch  r e p r e s e nt 

image 

the 
the  d e n­

r e s p e c t i v e l y. 
from 
the 

by  q u a n t i z a t i on 
s i ty  of  samples  per  u n it 
t i o ns 
is 
t r a n s l a t ed 
l e ft  c o m er  of 
fMy,  and  p"o  are  c a l l ed 
the  camera.  The 
(hv)  are  c a l l ed 
t i v e ly 

f i g u re  3 c ). 

(see 

l e n g th 
In  a d d i t i on 

the  p r i n c i p al  p o i nt  pe 
image* 

in 
the  x  and  y  d i r e c­
the  c o o r d i n a te  o r i g in 
the  upper 
fMx  and 
i n t e r n al  geometry  parameters  of 
image  c o o r d i n a t es 

The  combined  s c a l es 

r e s u l t i ng  d i g i t i z ed 
(image)  h o r i z o n t al  and  v e r t i c al  r e s p e c­

to 

C o n t r o l l i ng 

the  camera  here  means  p r o v i d i ng 

the 

to  sense  and  change  some  or  a ll  of 

a b i l i ty 
i n t e r n al  geometry  p a r a m e t e r s. 
sors  do  n ot  measure 
f u n c t i o ns  of 
c o n t r ol  v a r i a b l e s.  For  a  g i v en  c o n f i g u r a t i on  we  can 

these  parameters  d i r e c t l y,  b ut 
f u n c t i o ns 

them.  We  c a ll  these  sensed 

In  g e n e r al 

feedback  s e n­

the  e x t e r n a l/ 

*The  p r i n c i p le  p o i nt 
the 
f r om  X  normal 
to 
s m a ll  c o r r e c t i on 
(<  1  p i x e l) 
t he  scanning  r a s t e r. 
ness  of 

the  p i e r c i ng  p o i nt  of 

is 
image  p l a n e.  For  TV  systems  a 

the 

ray 

is  a l so  made 

f or 

the  skew-

646 

f i nd  expressions  for  the  camera  geometry  parameters  in 
terms  of  the  control  variables.  These  expressions  a l­
ways  contain  f i x e d,  but  unknown,  parameters  which  must 
be  measured.  The  process  of  s a t i s f a c t o r i ly  measuring 
these  fixed  parameters  is  what  we  c a ll  c a l i b r a t i o n. 
Since  we  are  interested  in  developping  a  predictive 
to  find  a  set  of  such  param­
model, 
eters 
for  images  of  known  object 
configurations.  An  analytical  derivation  of  such  a 
"best"  set  t y p i c a l ly  leads 
to  complicated  simultaneous 
transcendental  equations  which  do  not  y i e ld  to  closed 
form  s o l u t i o n.  Moreover, 
the  form  of  these  equations 
depends  strongly  upon  camera  geometry  and  the  number 
and  type  of  control  variables. 

that  best  accounts 

it  is  desireable 

To  be  more  precise,  modelling  can  be  described  as 
follows:  Write  down  the  transformation  relating  the 
3-D  coordinates  of  objects  to  the  2-D  coordinates  of 
t h e ir  images.  This  depends  upon  the  position  and  orien­
t a t i on  of  the  camera  in  object  space  -  so-called  ex­
ternal  geometry  -  and  on  i ts  i n t e r n al  geometry.  A ll 
elements  of  external  and  internal  camera  geometry  under 
computer  c o n t r o l,  should  be  expressed  as  functions  of 
the  computer's  control  variables  ex  ■  ( a 1 , ..  . ,0n) .  These 
w i ll  t y p i c a l ly  be  outputs  of  feedback  sensors.  The 
transformation  is  schematized  in  figure  4.  Typical  geo­
metric  variables  for  a  camera  on  a  p a n - t i lt  head  are 
the  angles  of  PAN  and  TILT,  and  f  which  is  the  distance 
from  the  lens  rear  nodal  point  to  the  image, 
f  is 
affected  by  both  zooming  and  focusing  motions.  The 
corresponding  control  variables  are  potentiometer  or 
shaft-encoder  readings. 
They  are  usually  linearly  -
but  not  always  -  related  to  the  geometric  quantities. 
e.g-

operational  system30,31 
for  c a l i b r a t i on  of  a  camera 
with  a  zoom  lens  on  a  p a n - t i lt  head  (Bee  figure  5)* 
There  are  in  fact  m  -  18  S's: 

8  in  class  (a)  above  -  2  each  for  r e l a t i ng  sensor 
to  geometric  quantitias  associated  with 

outputs 
pan,  t i l t,  zoom,  focus. 

Of  the  remaining  10,  7  represent  the  external 

camera  geometry  and  f a ll  into  class  (b)  above, 
while  3  represent  the  internal  camera  geometry 
-  2  in  (b)  and  1  in  (c). 

There  are  n  =  4  control  variables  (a's) 
focus,  and  zoom.  The  system  calculates  a  "best" B 
vector  given  10  or  more  object-image  point-pairs  and 
their  associated  a's. 
data  collection  and  model  optimization  (see  figure  6). 

is  divided  into  two  parts: 

for  p a n , _ t i l t, 

It 

For  data  c o l l e c t i o n,  pictures  are  taken  of  reference 

objects,with  known  shape  (usually  cubic)  and  location 
that  are  provided  to  the  program  by  a  human  operator. 
At  the  time  an  image  is  transferred  to  the  computer, 
the  program  reads  the  camera-control  feedback  sensors 
to  ascertain  the  cur­
(pan, 
t i l t,  zoom,  and  focus  pots} 
rent  a.  An  edge-follower  program 
' 
then  processes 
the  image  to  extract  boundary  points  of  the  object.  A 
polygon  is  f it  to  the  points.  The  polygon  vertices  are 
ordered  to  match  up  with  the  object  space  coordinates. 
Thus  for  the  j—  picture  of  a  reference  cube, 
the  c o l­
lection  routines  w i ll  generate 

the  data 

649 

(5) 

in  that  h,v  are  measure(cid:173)

These  are  d i f f e r e nt  from  (3) 
ments  and  B  is  to  be  calculated.  Assuming  non-degener(cid:173)
ate  equations,  we  need  at  least  18/2-9  such  t r i p l e ts  to 
completely  constrain  B.  The  t r i p l e ts  should  also  be 
Independent  in  the  sense  that  each  t r i p l et  yields  new 
information  (e.g.  2  P's  in  the  same  image  along  the 
same  central  ray  y i e ld  the  same  p"  and  are  not  indepen(cid:173)
dent). 

We  can  get  an  idea  of  the  minimum  number  images  ( i. 
e.  d i s t i n ct  values  of  a)  needed,  by  using  the  fact  that 
there  are  10  basic  geometric  parameters  for  a  fixed 
camera  (a  -  const);  A",  PAN,  TILT,  SWING,  fMy,  MRAT, 
and  p"D -  We  can  w r i te  constraint  equations  similar  to 
(5)  with  the  B's  replaced  by  the  geometric  parameters, 
and  deduce  that  we  need  10/2-5  points  P  to  completely 
solve  for  these.  Of  these  basic  parameters,  MRAT,  po * 
and  SWING,  are  also  B's.  Another  image,  taken  with 
d i f f e r e nt  values 
for  a ll  the  a ' s,  w i ll  only  have  6 
Parameters  unknown  Of,  PAN,  TILT,  fMy),  and  only  6/2-3 
P's  w i ll  be  needed  to  solve  for  the  new  values.  They 
may_In  fact  be  part  of  the  o r i g i n al  5.  T h e a l u es 
of  A  are  s u f f i c i e nt  to  solve  for  6  more  (J's  
to 
bring  the  t o t al  to  10.  The  two  values  each  of  PAN  and 
TILT  are  also  s u f f i c i e nt  to  solve  for  their  A  associa(cid:173)
ted  B's, 
leaving  only  the  4  B's  r e l a t i ng  the  focus  and 
zoom  pots  to  fMy.  Unfortunately  each  new  image,  created 
by  changing  focus  and/or  zoom  gives  us  only  one  new 
equation  i n.  Thus WE need  at  least  2  more  images 
of  one  point 
to  get  a  t o t al 
of  4  values  for  fMy  and  associated  pot  readings  to  give 
a  soluble  system  of  4  equations 
in  the  remaining  4  B's 
In  summary  we  have  a  specific  method  of  solving  for  the 
18  bv's  using  4  images  using  5+3+1+1-10  data  t r i p l e s. 
The  t o t al  number  of  d i s t i n ct  points  can  be  the  o r i g i n al 
5.  Thus  though  considerations  of  numbers  of  variables 
and  constraint  equations  t e ll  us  that  9  data  t r i p l es 
are  necessary,  the  form  of  the  equations  seems  to  say 
that  we  need  at  least  10,  arranged  in  4  images  as 
explained. 

not  on  the  camera  axis, 

One  of  the  features  of  the  optimization  program  is 

that 

it 

is 

I n t e r a c t i v e: 

1  - 

2  - 

It  has  a  rather  elaborate  dynamic  display 
(figure  6b). 
It  allows 
specified  subspace  of  

to  r e s t r i ct 
space. 

the  user 

the  search  to  any 

3  -  It  allows  him  to  choose  between  two  search  algo-

i n i t i a l i ze  

to  any  values  he 

4  - 

r i t h m s " ' " ' 8 1. 
It  allows  him  to 
cares 

to. 
5  -  It  allocs 

the  search  to  be  interrupted  at  any 

time  and  the  residual  error/image  to  be  d i s(cid:173)
played  as  a  function  of  any  of  the  a ' s.  This  is 
to  see  if  there  systematic  deviations  w . r . t.  any 
given  control  variable.  Such  a  deviation  would 
indicate  a  defect  in  the  model  or  the  equipment 
associated  with 

that 

6  -  It  has  a  test  mode  for  exploring  the  convergence 

the  optimization  algorithms 

of 
in  the  neighbor(cid:173)
hood  of  any  desired  B  The  user  can  either  man(cid:173)
ually  Input  8  or  take  a  t y p i c al  value  arrived  at 
from  data.  Upon  entering  test  mode,  p 
replaces 
IP, 
to  zero.  The  user  is  then  allowed 
to  add  a  simulated  d i s t o r t i on  function  to  the 
new  P 
turb  (J  and  observe  the  resulting  convergence 
back  to  the  ideal  point. 

if  he  chooes.  He  is  f i n a l ly  asked  to  per(cid:173)

forcing  E 

The  search  is  complicated  by  the  fact  that  subsets 
to  f i r st  order 

of  parameters  are  interdependent  -  e.g. 

650 

accuracy,  changes  in  E  due  to  changes  in  po,  can  be 
offset  by  the  PAN  and  TILT  offset 
i r i c a l ly  determined  that  there  are  multiple  minima  of 
E2,  but  they  are  spaced  s u f f i c i e n t ly  far  apart  so  that 
pur  i n i t i al  guesses  are  good  enough  not  to  go  astray. 
Starting  points  are  usually  arrived  at  from  rough 
manual  measurements  and  calculations  of  the  system 
geometry.  A  t y p i c al  optimization  sequence  consists  of: 

It  has  been  emp(cid:173)

1  -  reading  in  about  10  data  sets 
2  -  If  a  previous 
with  the  data, 

i n i t i al 
it  must  now  be  typed  i n. 

has  not  been  stored 

3  -  choosing  an  appropriate  subspace  of 

to  search 

(maybe  a ll  of  i t) 

4  -  l e t t i ng 

the  f i r st  algorithm  (usually  more 

e f f i c i e n t)  converge 

5  -  applying  the  second  algorithm  to  t ry  to  improve 

the  result  if  not  good  enough 

6  -  possibly  returning  to  3  and  changing  the  sub-
(optimizing  over  the  whole  space  if  not 

space 
done) 

The  residual  rros  error  E  Is  a  measure  of  the  good(cid:173)

t y p i c a l ly  I  to  2  picture 
to  3.0 

ness  of  the  model,  and  Is 
elements  ( p i x e l s ),  which  corresponds  to  1.5 
milliradians  on  the  camera  axis  -  with  the  particular 
optics  used.  Convergence  t y p i c a l ly  takes  about  5  min. 
of  PDP-10  cpu  time  for  a ll  18  parameters.  The  r e s i d(cid:173)
ual  errors  are  due  mainly  to  mechanical  v i b r a t i on  of 
the  optical  system  and  e l e c t r i c al  j i t t er  of  the  scan 
electronics.  These  have  so  Ear  masked  lens  and  scan 
d i s t o r t i o n s. 

At  present  there  is  a  program  at  the  hand-eye  pro(cid:173)

j e ct  to  expand  the  scope  and  efficiency  of  the  c a l i(cid:173)
bration  system.  The  f i r st  step  is  to  elimenate  the 
operator  to  manually  measure  and  specify  reference-
object  coordinates  (see  figure  6a).  We  hope  to  do  this 
by  using  the  mechanical  arm  to  place  the  objects  ac(cid:173)
cording  to  a  prespecified  c a l i b r a t i on  sequence.  The 
resulting  scheme  w i ll  look  as  shown  in  figure  7.  The 
prediction  error  in  effect  then  becomes  a  "coordina(cid:173)
t i on  error"  between  the  hand  and  eye; 
l er  w i ll  be  reporting  the  object  vertex  positions 
to  the  precision  of  the  model  r e l a t i ng  i ts  control 
variables a a rm to  requested  hand  position  and  o r i e n(cid:173)
t a t i o n.  Meanwhile  the  camera  c a l i b r a t i on  w i ll  be  using 
the  reported  position 
to 
predict  image  coordinates.  Gill12  measured  this  coor(cid:173)
dination  error  in  his  system  for  precise  object  mani(cid:173)
p u l a t i o n.  He  adjusted  several  camera  B's  suspected  of 
d r i f t i ng  sO  as  to  minimize  i t. 

the  arm  c o n t r o l-

information  

In  this  system,  predicted  image  coordinates  

are 

1  -  The  behavior  of  the  overall  error  function  E! 

w . r . t.  a ll  these  has  not  been  investigated  -
in  p a r t i c u l a r, 
near  the  global  minimum. 

for  the  presence  of  local  minima 

2  -  Unless  the  i n i t i al  E2  is  already  quite  small, 
our  current  optimization  procedures  may  w e ll 
bog  down  on  so  many  parameters,  so  as  to  be 
useless. 

This  strongly  suggests  that  we  use  j o i nt  optimiza(cid:173)

tion  only  as  a  l a st  refinement,  and  even  then  possibly 
with  approximate 
transform  equations  for  faster  conver(cid:173)
gence  near  the  minimum.  Joint  c a l i b r a t i on  is  ultimately 
desireable,  since  the  principal  use  of  camera  calibra(cid:173)
t i on  is 
guiding  the  arm. 

to  get  world  coordinates  for  the  purpose  of 

5.  Duda,  R.,  Hart,  P.,  book  in  press:  Pattern  Classic 
f l c a t i on  and  Scene  Analysis,  D e c,  1970,  a v a i l. 
in  preprint  form  from  Stanford  Research  I n s t i(cid:173)
tute. 

6.  Earnest,  L.E.,  "On  Coosing  an  Eye  for  a  Computer", 

Stanford  AIH-51,  A p r il  1967 

Another  system  being  considered  u t i l i z es  two  came(cid:173)

their  r e l a t i ve  orientation  based 

ras,  and  optimizes 
upon  simultaneous  measurement  of  the  same  calibration 
object  from  two  different  viewpoints.  Thus,  if  a  f i r st 
camera  has  been  calibrated  r e l a t i ve  to  the  reference 
object-space,  a  second  can  be  calibrated  relative  to  it 
etc.  This 
metry2 
from  large  numbers  of  aerial 
photographs.  A  two-camera  system,  once  calibrated,  pro(cid:173)
vides  a  3-D  measuring  t o ol  which  can  in  turn  be  used 
for  basic  arm  c a l i b r a t i o n. 

technique  is  used  extensively  in  photogram-

for  compiling  maps 

What  is  really  needed  to  simplify  and  speed-up  opt(cid:173)
imization  is  a  separable  error  function.  For  example, 
something  of  the  form 

or  even 

which  is  more  l i k e l y,  would  allow  us  to  separately  op(cid:173)
timize  parts  of  the  system  while  s t i ll  guarantying 
minimum  overall  error. 

Yet  another  direction  for  improvement  is 

that  of 

that  i s,  re-calibrating  the  sys(cid:173)

calibration-updating; 
tem  rapidly  whenever  observations  in  the  course  of  nor(cid:173)
mal  operation  show  that  errors  have  grown  intolerably 
large.  The  emphasis  here  is  on  the  word  rapid  -  hope(cid:173)
f u l ly  near  real-time.  One  way 
to  accomplish  this  is  to 
collect  data  from  measurements  made  during  normal  op(cid:173)
eration  of  the  system. 

The  f u l ly  automatic  calibration  system  of  the  future 

w i ll  probably  go  through  a  bootstrapping  phase;  either 
an  arm  or  a  pair  of  eyes  -  whichever  is  more  accurate  -
w i ll  f i r st  be  calibrated.  This  w i ll  be  done  possibly 
with  the  aid  of  a  special  calibration  device  for  pro(cid:173)
viding  highly  accurate  reference  data.  The  calibrated 
half  of  the  system  w i ll  then  be  used  to  provide  data 
for  calibrating  the  other  half,  at  which  point  the  to(cid:173)
t al  system  w i ll  be  j o i n t ly  optimized  to  minimize 
coordination  errors. 

References  and  Bibliography 

1.  Agin,  G.,  "Representation  and  Description  of  Curved 
Objects",  PhD.  thesis  Elec.  Eng.  Dept.  Stanford 
Univ.  July  72.  Available  as  AIM-173  from  Stanford 
A . I.  Project 

2.  American  Society  of  Photograrametry,  Manual  of  Photo-

gramme t r y,  2  v o l s .,  Falls  Church,  Va.,  3rd  Ed., 
1966  (see  esp.  Vol.  1  Ch.  X  on  Analytical  Photo-
gramme try) . 

3.  Baumgart,  B.,  forthcoming  PhD. 

thesis  on  Computer 
Graphics  and  Visual  Perception,  Stanford  Univ. 
Computer  Science  Dept. 

4.  Brent,  R.P.,  "Algorithms 

for  Finding  Zeros  and  Ext-
rema  of  Functions  Without  Calculating  Derivativ(cid:173)
e s ",  PhD. 
thesis,  C.S.  Dept.,  Stanford  U.,  Mar. 
1971,  available  as  CS-198 

7.  Kalk,  G.,  "Machine  Analysis  of  Multi-Body  Scenes", 

thesis,  Stanford  U..C.S.  Dept.  1970, 

PhD. 
a v a i l,  as  CS-180  and  AIM-132 

8.  Feldman,  J.A.,  e t.  a l .,  "The  Stanford  Hand-Eye  Pro(cid:173)

j e c t ",  Proc.  First  I n t.  Conf.  on  A . I .,  Wash., 
D.C.,  1969 

9.  Feldman,  J.A.,  "Getting  a  Computer  to  See  Simple 

Scenes",  IEEE  Student  Jour.,  Sept.  1970 

10.  Gibson,  J . J .,  The  Senses  Considered  as  Perceptual 

Systems,  Houghton-Miflin,  Boston  1966 

11.  Gibson,  J . J .,  Percept! on  of  the  Visual  World, 

Houghton-Miflin,  Boston,  1950 

12.  G i l l,  A.,  "Visual  Feedback  and  Related  Problems  in 
Computer  Controlled  Hand-Eye  Coordination",  PhD 
thesis,  Elec.  Eng.  Dept.,  Stanford  U.,  a v a i l. 
AIM-178  from  Stanford  A . I.  Project 

13.  Grape,  G.,  "Computer  Vision  Through  Sequential 

Abstractions", 
Memo  (SAIL0N)  June,  1969 

Internal  Stanford  A . I.  Project 

14.  Grape,  G.,  "Computer  Vision  Through  Sequential 
thesis,  C.S. 

Abstractions",  forthcoming  PhD. 
Dept. ,  Stanford  U. 

15.  Horn,  B.K.P,  "Focusing",  MTT  Project  MAC  A . l.  Memo 

No.  160,  May  1968 

16.  Horn,  B.K.P.,  "Shape  from  Shading",  MIT  PhD. 

thesis,  a v a i l, 
MAC  TR-79,  Nov.  1970 

from  MIT  A . I.  Project  as 

for  geometry  see  "V1SMEM:  A  bag  of  "robotics" 

formulae,  MIT  A.I.Lab.  Memo  (Dec.  1972) 

17.  Hueckel,  M.H.,  "An  Operator  Which  Locates  Edges 

in  Digitized  Pictures",  JACM,  V.  18,  NO.  1, 
Jan.  1971,  pp.  113-125.  Also  Stanford  AIM-105 

18.  Kahn,  M.,  "Optimal  Control  of  a  Hydraulic  Arm", 
PhD.  thesis,  Stanford  M.E.  Dept.  1969,  a v a i l, 
as  Stanford  AIM-106 

19.  Nilsson,  N.J.,  "A  Mobile  Automaton:  An  Application 

of  A r t i f i c i al 
IJCAI,  pp.509-515,  May  1969 

Intelligence  Techniques",  Proc. 

20.  Paul,  R.,  Falk,  G.,  Feldman,  J .,  "The  Computer 
Representation  of  Simply  Described  Scenes", 
Proc. 
Urbana,  111.  A p r il  1969 

I l l i n o is  Graphics  Conf.,  U.  of  1 1 1 ., 

21.  Paul,  R.,  "Studies  With  a  Computer  Controlled  Arm", 

PhD.  thesis,  C.S.Dept.,  Stanford  U.  Aug.  1972 
A v a i l,  as  Stanford  A1M-

22.  Perkins,  D.,  MIT  PhD.  thesis  Math.  Dept.  on  Stereo 

Perception  of  Line  Drawing  Pairs,  Oct.  1970 

23.  Pieper,  D.L.,  "The  Kinematics  of  Manipulators 
Under  Computer  Control",  M.E.  PhD. 
thesis, 
Stanford  U.,  Oct.  1968,  a v a i l,  as  Stanford 
AIM-72 

651 

24.  Pingle,  K.,  Singer,  J .,  Wichman,  W.,  "Computer  Con­
Input", 

t r ol  of  a  Mechanical  Arm  Through  Visual 
Froc. 

IFIP  Congress  1968  Vol.2 

25.  Pingle,  K.,  "Visual  Perception  by  a  Computer", 

in 
Automatic  Interpretation  and  Classification  of 
Images,  Ed.  G r a s s e l l i,  Academic  Press,  N.Y., 
London  1969,  pp.  277-284.  see  also  "System 
Manual  for  Hand-Eye  Hackers",  Stanford  A . I. 
Project  Internal  Memo  (SAILQN)  June  1971 

26.  Roberts,L.G.,  "Machine  Perception  of  Three-Dimen-

sional  Solids",  MIT  Lincoln  Lab.,  Lexington, 
Mass.  Tech.  Rpt.  No.  31S,  May  1963 

27.  Roberts,  L.G.  "Homogeneous  Matrix  Representation 
and  Manipulation  of  N-Dimensional  Constructs", 
MIT  Lincoln  Lab.,  Lexington,  Mass.,  Memo  MS14Q5 
May,  1965 

28.  Scheinman,  V.D.,  "Design  of  a  Computer-Controlled 
thesis  M.E.  Dept.  Stanford 

Manipulator",  Engr. 
V.,  a v a i l,  as  Stanford  AIM-92,  June  1969 

29-  Schmidt,  R.,  "A  Study  of  the  Real-Time  Control  of 

a  Computer  Driven  Vehicle",  PhD- 
U.  Elec.  Eng.  Dept,,  Aug.  1971,  avail  as 
Stanford  AIM-149/CS-231 

thesis  Stanford 

30.  Sobel, 

I . E .,  "Camera  Models  and  Machine  Perception" 

thesis,  Stanford  U.,  Elec-  Eng.  Dept. 

PhD. 
May,  1970,  a v a i l,  as  AIM-121 

31.  Sobel, 

I . E .,  "Operating  Manual  for  Camera  Calib­
r a t i o n ",  Stanford  A . I.  Project  Internal  Memo 
Oct.  1972 

32.  Springer,  C.E.,  Geometry  and  Analysis  of  Projective 

Spaces,  W.H.  Freeman  and  Co.,  San  Francisco, 
1964  (see  sections  5.2  and  7.1) 

33.  Temes,  G.C.,  Calahan,  D.A.,  "Computer  Aided  Network 
IEEE 

Optimization  -  The  State  of  the  A r t ",  Proc, 
Vol.  55,  No.11,  Nov.  1967,  pp.1832-63 

34.  Tenenbaum,  J.M.,  "Accomodation  in  Machine  Percep­

t i o n ",  PhD. 
Aug.  1970,  a v a i l,  as  Stanford  AIM-134/CS-182 

thesis,  Stanford  U.  E l ec  Eng.  Dept. 

35.  Von  Senden,  M.,  Space  and  Sight,  The  Free  Press, 

Glencoe,  111.,  1960  e d i t i on 

36.  Wichman,  W.,  "Use  of  Optical  Feedback  in  the 
Computer  Control  of  an  Arm",  Engr.  thesis, 
Stanford  U.  Elec.  Eng.  Dept.  Aug.  1967,  avail 
as  Stanford  AIM-56 

653 

654 

655 

656 

