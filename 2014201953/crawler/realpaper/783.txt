A Logic Program Characterization of Causal Theories

∗

Paolo Ferraris

Department of Computer Sciences

University of Texas at Austin
1 University Station C0500

Austin, TX 78705
otto@cs.utexas.edu

Abstract

Nonmonotonic causal logic, invented by McCain
and Turner, is a formalism well suited for repre-
senting knowledge about actions, and the deﬁnite
fragment of that formalism has been implemented
in the reasoning and planning system called CCalc.
A 1997 theorem due to McCain shows how to trans-
late deﬁnite causal theories into logic programming
under the answer set semantics, and thus opens the
possibility of using answer set programming for the
implementation of such theories. In this paper we
propose a generalization of McCain’s theorem that
extends it in two directions. First, it is applicable to
arbitrary causal theories, not only deﬁnite. Second,
it covers causal theories of a more general kind,
which can describe non-Boolean ﬂuents.

1 Introduction
Causal logic [McCain and Turner, 1997] is a formalism for
knowledge representation, especially suited for representing
effects of actions. Causal theories are syntactically simple but
also very general: they consist of causal rules of the form

F ⇐ G

(1)

where F and G are propositional formulas.
Intuitively,
rule (1) says that there is a cause for F to be true if G is
true. For instance, the causal rule

pt+1 ⇐ at

(2)

can be used to describe the effect of an action a on a Boolean
ﬂuent p: if a is executed at time t then there is a cause for p to
hold at time t + 1. Other important concepts in commonsense
reasoning can be easily expressed by rules of this kind too.
For instance, a rule of the form

F ⇐ F

(“if F is true then there is a cause for this”) expresses, in-
tuitively, that F is true by default. In particular, the causal
rule

pt ⇐ pt

(3)

∗This research was partially supported by the National Science

Foundation under Grant IIS-0412907.

says that Boolean ﬂuent p is normally true. The frame prob-
lem [McCarthy and Hayes, 1969] is solved in causal logic
using the rules

pt+1 ⇐ pt ∧ pt+1

¬pt+1 ⇐ ¬pt ∧ ¬pt+1.

(4)

These rules express inertia: if a ﬂuent p is true (false) at time
t then normally it remains true (false) at time t + 1.

The equivalence of two ﬂuents or actions can be expressed
by equivalences in the head. For instance, to express that two
actions constants a and a(cid:2)
are synonymous, we can use causal
rule

at ≡ a(cid:2)

t ⇐ (cid:6).

(5)

Rules of those kind are used to semantically characterize
the relationship between modules in the Modular Action De-
scription language MAD [Lifschitz and Ren, 2006]. For in-
stance, [Erdo˘gan and Lifschitz, 2006; Erdo˘gan et al., 2007]
use an equivalence of this kind to state that pushing the box
in the Monkey and Bananas domain is a specialization of a
more general action “move”.
The language of causal

theories has been extended
in [Giunchiglia et al., 2004] to handle multi-valued constants,
in which a constant may assume values different from true
and false. For instance, we can express the fact that object
x is in location l with loc(x) = l. One advantage of us-
ing loc(x) = l instead of the Boolean ﬂuent loc(x, l) is that
loc(x) = l implicitly expresses the commonsense fact that
every object is exactly in one position.

In many useful causal rules, such as (2)–(4), the formula
before the “⇐” is a Boolean literal, a non-Boolean atom
(such as loc(x) = l) or ⊥. Rules of this kinds are called
deﬁnite. Such rules are important because a causal theory
consisting of deﬁnite rules can be converted into an equiva-
lent set of propositional formulas [McCain and Turner, 1997;
Giunchiglia et al., 2004], so that its models can be computed
using a satisﬁability solver. That translation is used in an im-
plementation of the deﬁnite fragment of causal logic, called
the Causal Calculator, or CCALC.1 The Causal Calculator
has been applied to several problems in the theory of com-
monsense reasoning [Lifschitz et al., 2000; Lifschitz, 2000;
Akman et al., 2004; Campbell and Lifschitz, 2003; Lee and
Lifschitz, 2006].

1http://www.cs.utexas.edu/˜tag/ccalc/ .

IJCAI-07

366

On the other hand, a rule of the form (5) is not deﬁnite, so
that the method of computing models described above is not
applicable in the presence of such rules.

Another method of computing the models of a causal the-
ory uses converting it into a logic program under the an-
swer set semantics [Gelfond and Lifschitz, 1988; 1991]. This
translation, discovered by McCain [1997], is modular (i.e.,
can be applied to a causal theory rule-by-rule). It converts,
for instance, causal rule (3) into

pt ← not ¬pt,

which is the usual way of expressing that pt is true by default
in logic programs [Gelfond and Lifschitz, 1991, Section 3].
Answer set solvers — systems that ﬁnd the answer sets for
logic programs — can then be used to ﬁnd the models of def-
inite causal theories [Do˘ganda˘g et al., 2001]. On the other
hand, this translation is only applicable to Boolean causal the-
ories consisting of deﬁnite rules.

In this paper we propose a translation that is more general
than McCain’s: it is applicable to arbitrary causal theories,
including multi-valued theories containing nondeﬁnite rules.
The price that we pay for this generality is that the logic pro-
grams produced by our translation are programs with nested
expressions. Such programs, deﬁned in [Lifschitz et al.,
1999], can be converted into disjunctive programs in polyno-
mial time at the price of introducing additional atoms [Pearce
et al., 2002]; this process has been implemented.2 Conse-
quently, our translation may allow us to compute the mod-
els of arbitrary causal theories using answer set solvers ap-
plicable to disjunctive programs, such as DLV 3, GNT 4 and
CMODELS, 5.

Our translation, like the one due to McCain, is modular. It
is deﬁned in two steps. First, every rule of the given causal
theory is converted into a set of rules in clausal form

l1 ∨ · · · ∨ ln ⇐ G

(6)

where each li is a literal, using [Giunchiglia et al., 2004,
Proposition 4]. Then each rule (6) is replaced by a logic pro-
gram with nested expressions; we will see that this program
is ”small” – usually linear in the size of the input.

In addition, we show how both steps can be done more ef-
ﬁciently. First of all, the “clausiﬁcation” of a causal theory
can be done without much increase in size if we agree to in-
troduce auxiliary atoms. About converting a clausiﬁed causal
theory into a logic program, we will show that many rules
and atoms can be dropped in special cases. For instance, in
case of causal theories with Boolean signature, we get a much
simpler deﬁnition of the translation. Our optimizations also
allow us to translate causal theories whose heads are literals
or ⊥ into nondisjunctive logic programs. It follows that, for
this class of causal theories, the problem of the existence of a
model is in class NP.

We review the syntax and semantics of causal theories and
logic programs in Sections 2 and 3, respectively. The trans-

2http://www.cs.uni-potsdam.de/˜torsten/nlp/
3http://www.dbai.tuwien.ac.at/proj/dlv/ .
4http://www.tcs.hut.fi/Software/gnt/ .
5http://www.cs.utexas.edu/˜tag/cmodels/ .

formation from causal theories in clausal form into logic pro-
gram is shown in Section 4, and Section 5 describes how to
make it more compact. Clausifying causal theories is dis-
cussed in Section 6.

2 Causal Theories

We review the more general syntax and semantics of
causal theories — which allow multi-valued constants —
from [Giunchiglia et al., 2004].

A (multi-valued) signature is a set σ of symbols c, called
constants, with a set of symbols Dom(c) (the domain of c)
associated to each of them. A (multi-valued) atom is a string
of the form c = v, where c ∈ σ and v ∈ Dom(c). A (multi-
valued) formula is built from atoms using the connectives ∧,
∨, ¬, (cid:6) and ⊥. Formulas of the forms F ⊃ G and F ≡ G
can be seen as abbreviations in the usual way.

A (multi-valued) causal rule is an expression of the form
F ⇐ G, where F and G are formulas. These formulas
are called the head and the body of the rule respectively. A
(multi-valued)causal theory is a set of causal rules.

A (multi-valued) interpretation over σ is a (total) function
that maps each constant c of σ to an element of Dom(c). An
interpretation I satisﬁes (or is a model of) an atom c = v if
I(c) = v. The deﬁnition of satisfaction and model of formu-
las of more general form follows the usual rules of proposi-
tional logic.

The semantics of causal theories of [Giunchiglia et al.,
2004] deﬁnes when an interpretation I of σ is a model of
a causal theory T , as follows. The reduct T I
of T relative to
I is the set of the heads of the rules of T whose bodies are
satisﬁed by I. We say that I is a model of T if I is the only
model of T I
. It is clear that replacing the head or the body
of a causal rule by an equivalent formula doesn’t change the
models of a causal theory.

Take,

Dom(c) = {1, 2, 3}:

for instance,

the following causal

theory with

¬(c = 1) ∨ c = 2 ⇐ (cid:6)
¬(c = 2) ∨ c = 1 ⇐ (cid:6),

(7)

The reduct relative to any I is always

{¬(c = 1) ∨ c = 2, ¬(c = 2) ∨ c = 1},

which is equivalent to c = 1 ≡ c = 2. The only model of the
reduct is the interpretation J such that J(c) = 3. It is then
clear that J is a model of (7), while no other interpretation I
is a model of this causal theory because I is not a model of
the reduct.

A literal is either an atom a or its negation ¬a. A rule of
the form (6), where n ≥ 0 and l1, . . . , ln are literals, is said
to be in clausal form. It is also semi-deﬁnite if n ≤ 1, and
deﬁnite if either the head is ⊥ (n = 0) or an atom. A causal
theory is in clausal form (semi-deﬁnite, deﬁnite) if all its rules
are in clausal form (respectively semi-deﬁnite, deﬁnite).

A constant c is binary if |Dom(c)| = 2. It is also Boolean
if Dom(c) = {t, f }. Signatures, formulas, causal rules and
causal theories are binary (Boolean), if they contain binary
(respectively, Boolean) constants only. In case of a binary
signature, the difference between deﬁnite and semi-deﬁnite

IJCAI-07

367

causal rules is not essential, because every negative literal can
be rewritten as an atom. For instance, if the underlying signa-
ture is Boolean then ¬(c = t) is equivalent to c = f . In case
of Boolean constants c, we will often write c = t simply as
c. If a causal theory of a Boolean signature doesn’t contain
atoms of the form c = f then the heads and bodies of its rules
are essentially classical, as in the original deﬁnition of causal
theories [McCain and Turner, 1997]. We call such theories
MCT theories.

Take, for instance, the following MCT theory T of signa-

ture {p, q}:

p ∨ ¬q ⇐ (cid:6)
q ⇐ p.

(8)

The interpretation I deﬁned by I(p) = I(q) = t is a model of
T . Indeed, in this case T I = {p ∨ ¬q, q}, and its only model
is I. No other interpretation is a model of T : if I(p) = t and
I(q) = f then I is not a model of the reduct T I = {p∨¬q, q},
while if I(p) = f then the reduct T I = {p ∨ ¬q} has more
than one model.

3 Logic programs
The answer set semantics was originally deﬁned in [Gelfond
and Lifschitz, 1988] for logic programs of a very simple
form and has been generalized several times. Here we re-
view the syntax and semantics of programs with nested ex-
pressions [Lifschitz et al., 1999]. In this section, the words
”atom” and ”literal” are understood as in classical proposi-
tional logic. A nested expression is built from literals using
the 0-place connectives (cid:6) and ⊥, the unary connective “not”
(negation as failure) and the binary connectives “,” (conjunc-
tion) and “;” (disjunction).

A logic program rule (with nested expressions) has the

form

F ← G

where F and G are nested expressions. As in causal rules, F
is called the head of the rule and G its body. Finally, a logic
program (with nested expressions) is a set of logic program
rules.

The answer set semantics deﬁnes when a consistent set of
literals (a set that doesn’t contain both a and ¬a for the same
atom a) is an answer set for a logic program. In the rest of this
section X stands for a consistent set of literals, l for a literal,
F and G for nested expressions and Π for a logic program.

We deﬁne when X satisﬁes F (symbolically, X |= F ) re-

cursively as follows:
• X |= l if l ∈ X,
• X |= (cid:6) and X (cid:14)|= ⊥,
• X |= not F if X (cid:14)|= F ,
• X |= F, G if X |= F and X |= G, and
• X |= F ; G if X |= F or X |= G.

Finally, X satisﬁes Π (X |= Π) if, for all rules F ← G in Π,
X |= F whenever X |= G.

The reduct ΠX

of Π relative to X is the result of replacing
every maximal subexpression of Π that has the form not F

with ⊥ if X |= F , and with (cid:6) otherwise. A set X is an
answer set for Π if X is a minimal set (in the sense of set
inclusion) satisfying ΠX

An expression of the form F ↔ G will stand for two rules

.

F ← G and G ← F .

4 Main translation
Consider a multi-valued signature σ. For any formula F of
that signature, we deﬁne F ne as the nested expression ob-
tained from F by replacing each ∧ with a comma, ∨ with
a semicolon and ¬ with not.

We are now ready to deﬁne our translation. Given any
causal theory T in clausal form, we deﬁne ΠT as the program
with nested expressions obtained from T
• by replacing each causal rule (6) by

l1; . . . ; ln ← not not Gne, (l1; not l1), . . . , (ln; not ln)
(9)
where each li stands for the literal complementary to li,
and

• by adding, for every constant c ∈ σ and every distinct

v, v(cid:2) ∈ Dom(c), rules

c = v ↔

,

w∈Dom(c)\{v}

¬(c = w)

(10)

¬(c = v); ¬(c = v(cid:2)) ← not (c = v), not (c = v(cid:2)) (11)
where the “big comma” is used in the same way as big
conjunctions.

According to this deﬁnition, each rule (9) of ΠT can be
obtained from the corresponding rule of T in three steps: by
• replacing each propositional connective with the corre-
sponding “logic program connective”, with the excep-
tion of negation in the head,

• prepending not not to the body of the rule, and
• adding some “excluded middle hypotheses” to the body

of the rule.

This last step “compensates” the replacement of ∨ with the
corresponding “stronger” logic program connective.
It is
clear that this translation is linear if there is an upper bound
on the size of the domain for each constant in T (for instance,
when T is binary).

Rules (10) and (11) relate literals containing the same con-
stant. They are needed to establish a 1–1 relationship between
the models of T I

and the subsets of I that satisfy ΠI
T .

For instance, if T is (7) then ΠT is
¬(c = 1); c = 2 ← not not (cid:6), (c = 1; not (c = 1)),
(¬(c = 2); not ¬(c = 2))
¬(c = 2); c = 1 ← not not (cid:6), (c = 2; not (c = 2)),
(¬(c = 1); not ¬(c = 1))

c = 1 ↔ ¬(c = 2), ¬(c = 3)
c = 2 ↔ ¬(c = 1), ¬(c = 3)
c = 3 ↔ ¬(c = 1), ¬(c = 2)

(12)

¬(c = 1); ¬(c = 2) ← not (c = 1), not (c = 2)
¬(c = 1); ¬(c = 3) ← not (c = 1), not (c = 3)
¬(c = 2); ¬(c = 3) ← not (c = 2), not (c = 3).

IJCAI-07

368

If T is (8) then ΠT is

p; ¬q ← not not (cid:6), (¬p; not ¬p), (q; not q)

q ← not not p, (¬q; not ¬q)

p ↔ ¬(p = f )

p = f ↔ ¬p

q ↔ ¬(q = f )

q = f ↔ ¬q

¬p; ¬(p = f ) ← not p, not (p = f )
¬q; ¬(q = f ) ← not q, not (q = f ).

(13)

The theorem below expresses the soundness of this transla-
tion. We identify each interpretation with the (complete) set
of literals over σ that are satisﬁed by the interpretation.

Theorem 1 For any causal theory T in clausal form, the
models of T are identical to the answer sets for ΠT .

For instance,

the only answer set for (12) is {¬(c =
1), ¬(c = 2), c = 3}, and indeed it is the only model of (7).
The only answer set for (13) is {p, ¬(p = f ), q, ¬(q = f )},
which is the only model of (8).

For each causal rule (6) that has the form l1 ⇐ G (i.e.,
n = 1), we can drop the “excluded middle hypothesis” from
the corresponding rule (9) of ΠT . Two logic programs Π1
and Π2 are strongly equivalent if, for any program Π, Π1 ∪ Π
has the same answer sets of Π2 ∪ Π [Lifschitz et al., 2001].

Proposition 1 For any literal l and any nested expression F ,
the one-rule logic program

(cid:2)

(cid:3)

l ← F,

l; not l

is strongly equivalent to

l ← F.

For instance, the second rule of (13) can be rewritten as

q ← not not p

and the answer sets don’t change.

However, dropping terms of the form li; not li from (9) is
usually not sound when n > 1. Take, for instance, the one-
rule MCT causal theory:

p ∨ ¬p ⇐ (cid:6),

which has no models. As we expect, the corresponding logic
program ΠT :

p; ¬p ←not not (cid:6), (¬p; not ¬p), (p; not p)

p ↔ ¬(p = f )

p = f ↔ ¬p

¬p; ¬(p = f ) ← not p, not (p = f )

(14)

has no answer sets. If we drop the two disjunctions in the
body of the ﬁrst rule of (14) we get a logic program with two
answer sets {p, ¬(p = f )} and {¬p, p = f } instead.

5 Reducing the translation
Our simpliﬁcation of ΠT depends on two parameters:

• a set S of atoms of σ such that every atom occurring in

T belongs to S, and

• a set C of constants of σ such that every rule of T con-

taining a constant from C in the head is semideﬁnite.

For each constant c, let Nc denote the number of atoms
containing c that do not occur in S. We deﬁne the logic pro-
gram ΔT (S, C) as obtained from ΠT by:

• dropping all rules (11) such that c ∈ C or {c = v, c =

v(cid:2)} (cid:14)⊆ S,

• replacing, for each constant c such that Nc > 0,

rules (10) with the set of rules

,

w : c=w∈S,w(cid:4)=v

¬(c = w) ← c = v

(15)

for all v ∈ Dom(c) such that c = v ∈ S, and

• adding

⊥ ←

,

w : c=w∈S

not (c = w)

(16)

for each constant c such that Nc > 1.

We will denote ΔT (S, ∅) by simply ΔT (S). We can easily
notice that ΔT (S, ∅) contains atoms from S only. Clearly,
when S contains all atoms, ΔT (S) = ΠT . Taking S smaller
and C larger makes ΔT (S, C) contain less and generally sim-
pler rules.

Rules (15) impose a condition similar to the left-to-right
half of (10), but they are limited to atoms of S. Rule (16)
expresses, in the translation, the following fact about causal
theories: if neither of two distinct atoms c = v1 and c = v2
occurs in a causal theory T then no model of T maps c to
either v1 or v2. For instance, if Dom(c) = {1, 2, 3} and
only c = 1 occurs in T then every model of T maps c to 1.
However, if c = 2 occurs in T as well then c can be mapped
to 3, as shown by example (7).

For instance, if T is (7) then ΔT ({c = 1, c = 2}) is
¬(c = 1); c = 2 ← not not (cid:6), (c = 1; not (c = 1)),
(¬(c = 2); not ¬(c = 2))
¬(c = 2); c = 1 ← not not (cid:6), (c = 2; not (c = 2)),
(¬(c = 1); not ¬(c = 1))

(17)

¬(c = 2) ← c = 1
¬(c = 1) ← c = 2

¬(c = 1); ¬(c = 2) ← not (c = 1), not (c = 2)
If S is a set of atoms, a subset of {a, ¬a : a ∈ S} is
complete over S if it contains exactly one of the two literals
a or ¬a for each a ∈ S.
Theorem 2 Let T be a causal theory over σ. Let S be a set
of atoms of σ such that every atom occurring in T belongs to
S, and let C be a set of constants of σ such that every rule of
T containing a constant from C in the head is semideﬁnite.
Then I (cid:19)→ I ∩ {a, ¬a : a ∈ S} is a 1–1 correspondence
between the models of T and the answer sets of ΔT (S, C)
that are complete over S.

IJCAI-07

369

We get the models of the original causal theory by look-
ing at the unique interpretation that satisﬁes each complete
answer set for ΔT (S, C). (The uniqueness of the interpre-
tation is guaranteed by the theorem.) For instance, {¬(c =
1), ¬(c = 2)} is the only complete answer set for (17); it
corresponds to the interpretation that maps c to 3, and this is
indeed the only model of (7).

Program ΔT (S, C) may have incomplete answer sets, and
those don’t correspond to any interpretation. They can be
eliminated from ΔT (S, C) by adding the constraint

⊥ ← not a, not ¬a

(18)

for every a ∈ S.

We can notice that no constant c ∈ C occurs in the head
of “intrinsically disjunctive” rules of ΔT (S, C). Indeed, if
c ∈ C then each rule (9) with c in the head is nondisjunc-
tive because it comes from a semi-deﬁnite causal rule, and
ΔT (S, C) doesn’t contain rules (11) whose head contains c.
Moreover, rules (10) and (16) can be strongly equivalently
rewritten as nondisjunctive rules.
In particular, it is possi-
ble to translate semi-deﬁnite causal theories into nondisjunc-
tive programs of about the same size. As a consequence, the
problem of the existence of a model of a semi-deﬁnite causal
theory is in class NP.

When, for a binary constant c, only one of the two atoms
belongs to S, all rules (10) and (11) in ΠT for such constant
c are replaced in ΔT (S, C) by a single rule (15) whose head
is (cid:6), which can be dropped. In particular, an MCT theory T
over σ can be translated into logic program ΔT (σ), basically
consisting just of rules (9) for all rules (6) in T .

For instance, if T is (8) then ΔT ({p, q}) is

p; ¬q ← not not (cid:6), (¬p; not ¬p), (q; not q)

q ← not not p, (¬q; not ¬q)

• replacing the head of each rule F ⇐ G in T by dF , and
• adding, for each subformula F that occurs in the head of

rules of T , (⊗ denotes a binary connective)

– dF ≡ F ⇐ (cid:6), if F is an atom, (cid:6) and ⊥,
– dF ≡ ¬dG ⇐ (cid:6), if F has the form ¬G, and
– dF ≡ dG ⊗ dH ⇐ (cid:6), if F has the form G ⊗ H.

Intuitively, the equivalences in the heads of the rules above
to be equiv-

recursively deﬁne each atom dF occurring in T (cid:2)
alent to F . This translation is clearly modular.

If T is an MCT theory then T (cid:2)

is an MCT theory also. For

instance, MCT rule

p ∨ (q ∧ ¬r) ⇐ r

is transformed into the following 7 MCT rules:

dp∨(q∧¬r) ⇐ r
dp∨(q∧¬r) ≡ dp ∨ dq∧¬r ⇐ (cid:6)
dq∧¬r ≡ dq ∧ d¬r ⇐ (cid:6)
d¬r ≡ ¬dr ⇐ (cid:6)
da ≡ a ⇐ (cid:6)

(a ∈ {p, q, r})

Theorem 3 For any causal theory T over a signature σ,
I (cid:19)→ I|σ is a 1–1 correspondence between the models of T (cid:2)
and the models of T .

We can see that every rule in causal theories of the form
T (cid:2)
is either already in clausal form, or has the body (cid:6) and
at most three atoms in the head.
It is not hard to see that
the clausiﬁcation process described at the beginning of the
section is linear when applied to T (cid:2)

.

whose only complete answer set is {p, q} as expected.

7 Related work and conclusions

6 Clausifying a causal theory
As we mentioned in the introduction, the translations from
the previous sections can also be applied to arbitrary causal
theories, by ﬁrst converting them into clausal form. One way
to do that is by rewriting the head of each rule in conjunctive
normal form, and then by breaking each rule

C1 ∧ · · · ∧ Cn ⇐ G,

(19)

where C1, . . . , Cn (n ≥ 0) are clauses, into n rules

Ci ⇐ G

(20)
(i = 1, . . . , n) [Giunchiglia et al., 2004, Proposition 4].
However, this reduction may lead to an exponential increase
in size unless we assume an upper bound on the number of
atoms that occur in the head of each single rule.

We propose a reduction from an arbitrary causal theory
to a causal theory where the head of each rule has at most
three atoms. This translation can be computed in polyno-
mial time and requires the introduction of auxiliary Boolean
atoms. The translation is similar to the one for logic programs
from [Pearce et al., 2002] mentioned in the introduction.

We denote each auxiliary atom by dF , where F is a for-
is ob-

mula. For any causal theory T , the causal theory T (cid:2)
tained by T by

McCain’s translation [McCain and Turner, 1997] is a linear
and modular translation applicable to (semi-)deﬁnite MCT
theories T (over σ) whose bodies are conjunction of literals.
Our translation ΔT (σ) is similar to McCain’s translation for
causal theories of those kinds. Also, the two outputs are —
in presence of rules of the form (18) — strongly equivalent to
each others. In this sense, our translation is a generalization
of McCain’s translation.

Another translation [Do˘ganda˘g et al., 2004] turns MCT
theories called “almost deﬁnite” into logic programs. For a
causal theory T that is both almost deﬁnite and in normal
form, ΔT (σ) is essentially strongly equivalent to the out-
put of their translation. Causal theories in normal form seem
more general than almost deﬁnite causal theories, as we don’t
know if there is any simple, modular and almost linear trasfor-
mation from arbitrary causal theories (or even from MCT the-
ories) to almost deﬁnite causal theories.

Future work will include studying how we can turn a the-
ory in the Modular Action Description language MAD into
a logic program. This will require extending the translation
to causal theories with variables [Lifschitz, 1997] and ﬁnding
other simpliﬁcations of the translation.

We will also like to investigate the relationship between
causal theories and logic programs with aggregates. It turns

IJCAI-07

370

out that, for instance, all rules (10) and (11) for the same con-
stant c can be strongly equivalently replaced by a single ag-
gregate — as deﬁned in [Ferraris, 2005] — in the head of a
rule.

[Giunchiglia et al., 2004] Enrico Giunchiglia,

Joohyung
Lee, Vladimir Lifschitz, Norman McCain, and Hud-
son Turner. Nonmonotonic causal theories. Artiﬁcial
Intelligence, 153(1–2):49–104, 2004.

Acknowledgments
We thank Selim Erdo˘gan and Hudson Turner for comments
on this topic. We are grateful to Vladimir Lifschitz for many
discussions and suggestions.

References
[Akman et al., 2004] Varol Akman,

Selim Erdo˘gan,
Joohyung Lee, Vladimir Lifschitz, and Hudson Turner.
Representing the Zoo World and the Trafﬁc World in the
language of the Causal Calculator. Artiﬁcial Intelligence,
153(1–2):105–140, 2004.

[Campbell and Lifschitz, 2003] Jonathan Campbell

and
Vladimir Lifschitz. Reinforcing a claim in common-
sense reasoning.
In Working Notes of the AAAI Spring
Symposium on Logical Formalizations of Commonsense
Reasoning, 2003.

[Do˘ganda˘g et al., 2001] Semra Do˘ganda˘g, Ferda N. Al-
paslan, and Varol Akman. Using stable model seman-
tics (SMODELS) in the Causal Calculator (CCALC). In
Proc. 10th Turkish Symposium on Artiﬁcial Intelligence
and Neural Networks, pages 312–321, 2001.

[Do˘ganda˘g et al., 2004] Semra Do˘ganda˘g, Paolo Ferraris,
and Vladimir Lifschitz. Almost deﬁnite causal theories.
In Proc. 7th Int’l Conference on Logic Programming and
Nonmonotonic Reasoning, pages 74–86, 2004.

[Erdo˘gan and Lifschitz, 2006] Selim T.

and
Vladimir Lifschitz. Actions as special cases.
In Pro-
ceedings of International Conference on Principles of
Knowledge Representation and Reasoning (KR), pages
377–387, 2006.

Erdo˘gan

[Erdo˘gan et al., 2007] Selim T. Erdo˘gan, Paolo Ferraris,
Vladimir Lifschitz, and Wanwan Ren. Why the monkey
needs the box: A serious look at a toy domain. Submitted
for review. 6, 2007.

[Ferraris, 2005] Paolo Ferraris. Answer sets for proposi-
In Proceedings of International Confer-
tional theories.
ence on Logic Programming and Nonmonotonic Reason-
ing (LPNMR), pages 119–131, 2005.
[Gelfond and Lifschitz, 1988] Michael

and
The stable model semantics for
Vladimir Lifschitz.
logic programming.
In Robert Kowalski and Kenneth
Bowen, editors, Proceedings of International Logic Pro-
gramming Conference and Symposium, pages 1070–1080,
1988.

Gelfond

[Lee and Lifschitz, 2006] Joohyung Lee and Vladimir Lif-
schitz. A knowledge module: buying and selling. In Work-
ing Notes of the AAAI Symposium on Formalizing Back-
ground Knowledge, 2006.

[Lifschitz and Ren, 2006] Vladimir Lifschitz and Wanwan
Ren. A modular action description language.
In Pro-
ceedings of National Conference on Artiﬁcial Intelligence
(AAAI), pages 853–859, 2006.

[Lifschitz et al., 1999] Vladimir Lifschitz, Lappoon R. Tang,
and Hudson Turner. Nested expressions in logic programs.
Annals of Mathematics and Artiﬁcial Intelligence, 25:369–
389, 1999.

[Lifschitz et al., 2000] Vladimir Lifschitz, Norman McCain,
Emilio Remolina, and Armando Tacchella. Getting to
the airport: The oldest planning problem in AI. In Jack
Minker, editor, Logic-Based Artiﬁcial Intelligence, pages
147–165. Kluwer, 2000.

[Lifschitz et al., 2001] Vladimir Lifschitz, David Pearce,
and Agustin Valverde. Strongly equivalent logic programs.
ACM Transactions on Computational Logic, 2:526–541,
2001.

[Lifschitz, 1997] Vladimir Lifschitz. On the logic of causal

explanation. Artiﬁcial Intelligence, 96:451–465, 1997.

[Lifschitz, 2000] Vladimir Lifschitz. Missionaries and can-
nibals in the Causal Calculator. In Proceedings of Interna-
tional Conference on Principles of Knowledge Represen-
tation and Reasoning (KR), pages 85–96, 2000.

[McCain and Turner, 1997] Norman McCain and Hudson
Turner. Causal theories of action and change.
In Pro-
ceedings of National Conference on Artiﬁcial Intelligence
(AAAI), pages 460–465, 1997.

[McCain, 1997] Norman McCain. Causality in Common-
sense Reasoning about Actions.7 PhD thesis, University
of Texas at Austin, 1997.

[McCarthy and Hayes, 1969] John McCarthy and Patrick
Hayes. Some philosophical problems from the standpoint
of artiﬁcial intelligence. In B. Meltzer and D. Michie, edi-
tors, Machine Intelligence, volume 4, pages 463–502. Ed-
inburgh University Press, Edinburgh, 1969.

[Pearce et al., 2002] David

Pearce,

Schaub,
Vladimir Sarsakov, Hans Tompits, and Stefan Woltran.
logic programs with
A polynomial
nested expressions into disjunctive logic programs.
In
Proc. NMR-02, 2002.

translation of

Torsten

[Gelfond and Lifschitz, 1991] Michael

Vladimir Lifschitz.
grams and disjunctive databases.
Computing, 9:365–385, 1991.

and
Classical negation in logic pro-
New Generation

Gelfond

6http://www.cs.utexas.edu/˜otto/

papers/serious.pdf .

7ftp://ftp.cs.utexas.edu/pub/

techreports/tr97-25.ps.gz .

IJCAI-07

371

