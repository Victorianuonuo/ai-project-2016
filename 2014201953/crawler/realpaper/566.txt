On the application of least-commitment and heuristic search in temporal planning 

Antonio Garrido  and  EvaOnaindia 

Dpto. Sistemas Informaticos y Computation 

{agarridot,onaindia}@dsic.upv.es 

Universidad Politecnica de Valencia 

Camino de Vera s/n, 46071 Valencia, Spain 

Abstract 

Graphplan planning graphs are structures widely 
used in modern planners. The exclusion relations 
calculated in the planning graph extension pro(cid:173)
vide very useful information, especially in tempo(cid:173)
ral planning where actions have different duration. 
However, Graphplan backward search has some 
inefficiencies that impose limitations when dealing 
with large temporal problems. This paper presents 
a new search process for temporal planning to avoid 
these inefficiencies. This search uses the informa(cid:173)
tion of a planning graph and shows beneficial in 
the scalability of the planner.  Moreover, our ex(cid:173)
periments show that a planner with this new search 
is competitive with other state-of-the-art planners 
w.r.t. the plan quality. 

Introduction 

1 
Many of the current challenges in AI planning focus on in(cid:173)
creasing the functionalities of planners to deal with more real 
features, such as temporal capabilities, explicit management 
of resources, more expressive domain definition languages, 
heuristic techniques and optimisation criteria, etc.  [Fox and 
Long, 2001; Gerevini and Serina, 2002; Smith and Weld, 
1999].  This paper deals with three of the previous func(cid:173)
tionalities:  i) planning with temporal features (actions with 
duration), ii) more expressive domain definition languages 
(PDDL2.1 [Fox and Long, 2001]), and iii) plan optimisa(cid:173)
tion (makespan). Traditional temporal planners have adopted 
a conservative model of actions, where two actions cannot 
overlap in any way if they have conflicting preconditions or 
effects.  This model is adequate in some planning domains, 
but there exist others that require a richer model of actions. 
Level 3 of PDDL2.1 used in IPC-2002 provides a model of 
durative actions which allows a more accurate exploitation of 
action concurrency to obtain shorter makespan plans. 

This paper describes our experiences with a Temporal 
Planning SYStem (from now on TPSYS), based on Graph-
plan [Blum and Furst,  1997] and TGP [Smith and Weld, 
1999], to manage the model of durative actions proposed in 
level 3 of PDDL2.1. TPSYS performs a Graphplan back(cid:173)
ward search, which guarantees the properties of completeness 

and optimality. However, backward search has some ineffi(cid:173)
ciencies that impose important limitations in large temporal 
problems.  In these problems, the search space is vastly in(cid:173)
creased and the performance of the algorithm degrades. We 
suggest a new two-stage search process to overcome these 
inefficiencies.  First, a backward search generates an initial 
relaxed plan.  Next, this relaxed plan is used as an outline 
for generating a solution plan by means of a non-complete 
heuristic process, where actions are only definitively allo(cid:173)
cated in the plan when they are applicable and no mutex 
(least-commitment).  This allows to increase the scalability 
of search, producing non-optimal, but good quality, plans. 
2 A Review of TPSYS 
TPSYS is based on a three-stage process [Garrido et al, 
2002], which combines the ideas of Graphplan and TGP. 
This means that TPSYS incrementally extends a temporal 
planning graph, performs a backward search through that 
graph and extracts a plan. 

Unlike conservative actions, durative actions present more 

conditions to be guaranteed for the success of the action. 
These conditions are SConda, EConda and Inva with the 
conditions of a to be guaranteed at the start, end and over all 
the execution of a, respectively.  Durative actions have two 
types of effects:  SEffa and EEffa with the effects to be 
asserted at the start and end of a, respectively. 
The first stage of TPSYS calculates the action-action and 
proposition-action static mutex relationships.  These mutex 
relationships are static because they only depend on the def(cid:173)
inition of the actions and they always hold.  The second 
stage extends a temporal planning graph which alternates 
temporal levels of propositions (ify) and actions (A^). Un(cid:173)
like Graphplan, levels in TPSYS represent instants of time 
t  6  R+  in which propositions are present and actions can 
start/end. Action-action, proposition-action and proposition-
proposition mutex relationships are calculated during the ex(cid:173)
tension of the temporal planning graph. The third stage per(cid:173)
forms the search in a Graphplan backward way, extracting 
an optimal plan through the planning graph. Since the third 
stage starts as soon as all the propositions in the final situa(cid:173)
tion are present, non pairwise mutex, and the plan extraction 
is complete, TPSYS obtains the plan of optimal makespan. 
Backward search in TPSYS preserves the same proper(cid:173)
ties of completeness and optimality of Graphplan, but it en-

942 

PLANNING 

The worst performance happens when the gcd of the dura(cid:173)
tions is  1, forcing the algorithm to generate the maximum 
number of levels. In consequence, the previous inefficiencies 
and wasted search are repeated more frequently. 
3  Combining Least-Commitment and 

Heuristics to Improve the Search Process 

In this section we substitute the backward search by a two-
stage search to avoid the previous inefficiencies in a temporal 
planning approach.  First, a backward chaining stage gener(cid:173)
ates an initial relaxed plan from the information of the tem(cid:173)
poral planning graph. Second, a forward chaining stage allo(cid:173)
cates the execution time of the actions in the relaxed plan. 
3.1  Generation of an Initial Relaxed Plan 
This stage generates an initial relaxed plan from the informa(cid:173)
tion of the temporal planning graph (from now on TG) to be 
used as a skeleton of the final plan. We define a relaxed plan II 
as a partially ordered set of actions in which both the problem 
goals and action conditions hold. It is called relaxed because 
neither mutex relationships between actions nor commitment 
on their start time are considered. 

A relaxed plan always contains two fictitious actions with 
no duration called IS and FS. IS achieves the propositions of 
the initial situation, whereas FS requires the problem goals. 
II is generated similarly to the relaxed solution plan in the FF 
planner [Hoffmann, 2000] with the exception that we handle 
durative actions (see Algorithm 1). 

{obligatory actions 

from goals 

if  i is not supported in II then 

1: goals  problem goals {must hold in any plan for the problem 
2: FT 
3: while  goals  do 
4:  extract 
5: 
6: 
7: 
8: 
9: 
10: 

if a is the only action which supports 
of an obligatory action then 
mark a as obligatory in II 
II 
goals  goals  SConda 

arg min(number of mutex which a* imposes in II) 
Vaf  which supports 
is a condition 

commitment on start time oj a yet 

Algorithm 1: Generation of an initial relaxed plan II. 

In prob(cid:173)

Step 6 studies the actions which support Qi and selects the 

action which minimises the number of mutex in 
lems with multiple resources, this selection tends to use as 
many resources as available. For instance, in a f e r ry prob(cid:173)
lem with two or more ferries 
.., step 6 distributes 
the use of the ferries in a homogeneous way.  If action de-
bark(cljl,l2)  is  used  for  debarking  the  car  cl,  action  de-
bark(c2,f2,l2) is first selected when debarking the car c2 be(cid:173)
cause debark(c2,flJ2) is mutex with debark(c 1 ,fl,12) and im(cid:173)
poses more mutex in II.  This selection provides the relaxed 
plan  more  information about the structure of the problem, 
thus increasing the quality (number of actions in parallel) of 
the final plan. Note that in step 6 we do not need to perform 
real search (or backtracking) because none of the mutexes are 
considered and, therefore, this strategy always leads to a so(cid:173)
lution. Moreover, we introduce the term of obligatory action 

Figure  1:  Outline  of the  temporal  planning graph  for the 
f e r ry  problem.  Shaded propositions  represent the  non-
pairwise mutex problem goals at time  16.  Mutex relations 
between propositions are represented by thick lines. 

tails the most time consuming stage. Furthermore, this search 
presents  some  inefficiencies  (inherited  from  Graphplan) 
which  impose  important  limitations  in temporal  problems. 
Let us consider a simple problem from the f e r ry domain. 
The domain consists of transporting a number of cars from 
one location to another using a ferry which can carry only one 
car at a time. To keep the problem simple enough we assume 
three cars cl, c2 and c3 to be transported from location 11 
to 12 by ferry / l. The actions are board 
sail 
and debark 
with durations  1, 5 and 2,  respectively.  The optimal plan 
contains 11 actions (3xboard, 5xsail and 3\debark) and the 
makespan is 34.  The mutex relations are binary, so the sec(cid:173)
ond stage ends at time  16 and the search starts from there 
(see Figure 1). Since every pair of actions is mutex, only one 
action is planned in each level.  If we assume that applica(cid:173)
ble actions are selected in each level from top to bottom in 
the planning graph of Figure 1, action A2 is firstly planned 
at time  14.  Next, actions A7  and Al  are planned at times 
9 and 8, and so on.  Because no feasible plan is found, the 
search backs to time 14 where all permutations of actions A2, 
A4, A6 are planned under the same schema with no success. 
This is the  first  indication of inefficiency:  a lot of effort is 
wasted trying, unsuccessfully, to plan nearly identical actions 
in problems with symmetry.  As no plan is found from time 
16, the planning graph is extended to time 17 and the search is 
re-started from scratch. This entails the second indication of 
inefficiency: no actions planned in previous stages of search 
are reused as a part of the current plan, committing similar 
failures in the new one-deeper-level search space. Although 
memoization helps reduce the amount of failures committed 
during search, the way in which it prunes one branch of search 
does not allow to solve the real conflict until exhausting the 
whole level. This is the third indication of inefficiency: if one 
proposition becomes unsupported, no new actions supporting 
it are studied but that branch is discarded and the algorithm 
performs a backtracking stage. 

These inefficiencies have a negative influence in Graph-
plan-based temporal approaches.  While a classical Graph-
plan's planning graph for this problem has 11 levels, in tem(cid:173)
poral planning no plan is found until level 34 is extended and 
explored. Particularly, in TPSYS the number of levels gener(cid:173)
ated depends on the dispersion of the durations of the actions. 

PLANNING 

943 

a as the only action which supports a goal which must hold 
in any plan for the problem. This is helpful because it means 
that a must be always present in II (steps 7-8).  Obviously, 
both IS and FS are obligatory. 

One  important property of II  is that if there  is no mutex 
between overlapping actions, all actions in II form a feasible, 
optimal plan.  The proof of this is straightforward and relies 
on the complete extension of the temporal graph. The level in 
which the temporal graph extension ends indicates the mini(cid:173)
mal time in which the goals can be achieved by non-pairwise 
mutex actions. Thus, this level provides a minimal bound of 
the makespan for a feasible plan and, if no mutex between 
actions holds, the plan is not only feasible but also optimal. 
Unfortunately, this is not a very common situation and mutex 
relations break the plan relaxation.  This entails to postpone 
the allocation of actions, and/or to plan new actions to solve 
the unsupported (sub)goals. 

are divided into two disjunctive sets: 

3.2  Planning and Allocating of Actions 
This stage performs the allocation in time of actions in the re(cid:173)
laxed plan. We use a structure called set_of .plans, with 
the search space formed by all the generated plans 
. Ac(cid:173)
tions in each 
and 
contains the actions which have been al(cid:173)
located in time and will never be removed from 11;.  Relaxj 
contains the actions which have not been allocated yet, and 
so they can be removed from 
is empty 
and 
(the initial IIj is the 
relaxed plan computed in the previous section).  This stage 
finishes once 
gets empty, obtaining  i n t he  ac(cid:173)
tions of the plan which support all the problem goals. 

contains all the actions in 

Initially, 

supported the  algorithm exits with  success (step 5).  Oth(cid:173)
erwise,  actions from Relaxi  which can start at the current 
time.of-execution*  are tried to be allocated (step 7). 
If one  action  a  is  mutex  with  actions  in  Alloci  and  non-
obligatory, a is removed from H\ (step 10), delaying the ful(cid:173)
fillment of its goals to a future time of execution. The reason 
to remove a non-obligatory action is that it could be a bad 
choice for the plan.  If a is obligatory it is not removed but 
its start time is postponed (step 12). If a is not mutex and ap(cid:173)
plicable, a is allocated in time (step 15). This step entails the 
first indication of loss of completeness.  Although there exist 
alternative actions to a, if a can be allocated those actions arc 
not considered in IIj.  Step 17 is a branching point in which 
new actions are inserted (generating new plans) to achieve 
unsupported conditions of a.  For each action a,  supporting 
each condition a new plan IIj is generated and inserted into 
set.of .plans with a,j marked as obligatory in IIj. It is im(cid:173)
portant to note that a, is not allocated in time, but it is inserted 
with its earliest start time of execution extracted from the TG. 
This is part of the least-commitment technique performed in 
the allocation of actions when they are inserted into plans. 
Step 18 moves to the next relevant time-of-execution* 
in which actions can start, extending the TG if necessary. 

The algorithm has two important points of selection: steps 
3 and 7. Step 3 selects the plan Ili with the lowest cost from 
set.of .plans, where the cost is estimated as follows: 

, generated in Algorithm 1 

1: set.of .plans 
2: while  set.of .plans 
3:  extract the lowest cost Ili from set.of .plans 
4: 
5: 
6:  else 
7: 

if Alloa supports all the problem goals then 

exit with success 

(allocation 

max 

arg 

priority) 

I 
' 

if a is mutex in Alloci then 
if a is not obligatory then 
from Relaxi 

remove 

postpone start time of a in 

8: 
9: 
10: 
11: 
12: 
13: 
14: 
15: 
16: 
17: 

else 

else 
if 

else 

is applicable then 
allocate a in 

at time.of .execution! 

insert new plans into set.of .plans to make a ap(cid:173)
plicable 

18:  update  t ime.of.execut  io 

Algorithm 2: Planning and allocating of actions. 

The idea is to move forward in time, simulating the real ex(cid:173)
ecution of IIj, progressively taking care of the actions which 
can start their execution (see Algorithm 2). The current time 
of execution in Ili, time-of-execution*, is initialised to 
0.  The algorithm always selects the plan Ftj of lowest cost 
from set.of-plans (step 3).  If all the problem goals are 

from the  current  time.of-execution 

The cost of a plan IIj consists of the sum of the cost due 
to  Allod  and 
is an estimation of 
the  number of actions  necessary  to  solve  the  unsupported 
conditions  of 
It is estimated through the  TG,  ignoring the delete effects 
of actions  (as  in  the  heuristic  used  in FF), 
is 
the number of conditions of FS which 
supports, whereas 
del\  FS) is the number of conditions of FS which  deletes. 
PAjmutex\ 
FS)  is the number of mutex between condi(cid:173)
tions of FS and action  This mutex information is extracted 
from the TG and indicates the impossibility to have simulta(cid:173)
neously the conditions of FS and 
duration  represents the 
duration of the plan/action to take into account the makespan 
of 
0 because they have a pos(cid:173)
itive  impact in the cost of the plan.  In opposition, 
because it has a negative impact in the cost. 

Note that a, 

In step 7, the action a with the maximal allocation priority 
is selected to be studied at time.of -execution*. This 
priority is estimated as follows: 

The allocation priority of action a depends on several local 
is the number of direct successor 

factors,  succ 

944 

PLANNING 

(dependent) actions of a in 
rneetsuccis 
the number of direct successor actions  of  which can start 
as  soon  as  ends, i.e.  which meet 
These two values in(cid:173)
dicate the importance of an action for the successor actions 
Intuitively, the more successor actions are directly 
in 
supported  by  the more important 
is in the plan. Similarly, 
the meeting successor actions indicate the number of succes(cid:173)
sor actions which can be immediately executed without mu-
tex. unsup and duration are defined as above. Coefficients 
because they imply to select an appropriate action 
because they indicate that 

to be allocated. However, 
action 

is not promising enough to be allocated yet. 

The  previous evaluation  functions can have many more 
heuristic factors, but according to our experimental analysis 
they are general enough for most temporal planning prob(cid:173)
lems. We can also implement different heuristic methods by 
setting the values of the coefficients, which in our case are 
the same for all the domains. Although the values of the co(cid:173)
efficients can influence the search, their precise value is not 
as relevant as in other heuristic approaches based on local 
search as LPG [Gerevini and Serina, 2002].  For instance, 
the static cost of inserting an action in LPG is based on the 
number of unsupported conditions, what cannot represent the 
real complexity of solving each condition.  On the contrary, 
the coefficient 
deals with that complexity because it 
estimates the real cost to support it in the TG. 

It is important to note that plans are incrementally gener(cid:173)
ated without discarding allocated actions and with no redun(cid:173)
dancy due to symmetry.  Although Algorithm 2 explores the 
complete space of actions to make actions applicable, the al(cid:173)
location priority imposes an order of execution and discards 
the  rest  of feasible  orderings  (second  indication  of loss  of 
completeness).  For instance, in the f e r ry problem of sec(cid:173)
tion 2, when studying the actions to debark 
the algorithm allocates one action and postpones the others. 
This avoids the complete exploration of all the permutations 
of A2, A4 and A6, preventing the planner from the generation 
of symmetric plans. 
4  Experimental Results 
We have implemented the previous search on top of TPSYS, 
conducting several experiments1.  The two first experiments 
compare the new search vs. the Graphplan backward search. 
In the  first  experiment,  we studied the impact of the new 
search in problems with a high degree of symmetry, such as 
the  f e r ry and g r i p p e r,  focussing on the planner scala(cid:173)
bility.  Figures 2-a,b show the results for some problems of 
these domains.  Although it is not surprising that the least-
commitment search (tpsys-LC) is faster than Graphplan 
backward search (tpsys-GP), it is worthy to mention that 
tpsys-LC scales up much better than  tpsys-GP, espe(cid:173)
cially in the g r i p p er domain. Moreover, tpsys-LC found 
optimal plans without backtracking for all the problems. 

The second experiment deals with some problems of the 
simple-time track of the last IPC-20022.  Although both ap-

1 The experiments were run on a Pentium IV 2 GHz with 512 Mb. 
2More  information  on  the  domains,  problems  and  re(cid:173)
sults  of the  international  planning  competition  (IPC-2002)  in: 

proaches have difficulties to solve all the problems (see Fig(cid:173)
ures 2-c,d,e,f), the least-commitment search can solve more 
problems. On one hand, backward search difficulties rise as 
a result of the redundancy in the complete, blind search pro(cid:173)
cess. On the other hand, least-commitment search difficulties 
rise as a result of: i) the heuristic, greedy approach, which can 
lead to the wrong path in the search, and ii) the non-complete 
preserving search. The zenotravel and s a t e l l i te do(cid:173)
mains show the highest speedups. It is important to note that 
the best improvement is produced in  the  s a t e l l i te  do(cid:173)
main, which is the only domain in the competition that ex(cid:173)
ploits the end conditions of durative actions. 

The third and fourth experiments are aimed at evaluating 
the quality of the plans generated by the new approach.  We 
are mainly interested in the makespan of the plans, but we 
also consider the number of actions as an additional indica(cid:173)
tion of the plan quality. The third experiment uses the plans 
generated in the experiment 1 (Figures 2-a,b) and compares 
them with the plans generated by LPG3 [Gerevini and Serina, 
2002] and Mips4 [Edelkamp, 2002].  We have chosen these 
two planners as they handle temporal features and showed 
distinguished performance in the last IPC. To date our inter(cid:173)
est has not focussed on code optimisation, so in this experi(cid:173)
ment we will not compare the execution time of the planners5 
but only their plan quality. Table 1 shows the comparison be(cid:173)
tween the three planners taking into account the makespan 
and the number of actions of each plan.  We have not  in(cid:173)
cluded the results for the  f e r ry domain because the three 
planners generate the same fully sequential plans.  However, 
plans for the g r i p p er domain can have actions in paral(cid:173)
lel (the gripper is a resource with capacity for two balls) so 
that the planner can exploit a better concurrency. In order to 
simplify the resulting plans the actions have been assigned 
1 and the 
duration 1.  Hence, the optimal makespan is 
number of actions in an optimal plan is 
is the 
number of balls in the problem.  Surprisingly, both LPG or 
Mips generate sequential plans as can be easily noticed from 
the fact that the makespan comes directly from the number 
of actions in the plan.  tpsys-LC is the only of the three 
planners which generates optimal plans for all the problems, 
highly exploiting the action parallelism. 

1, where 

In the fourth experiment, we have used the plans gen(cid:173)
erated  in  the  last  IPC  to  perform  a  comparison  between 
tpsys-LC and some of the state-of-the-art planners which 
participated  in  the  simple-time  track.  We  have  analysed 

http://www.dur.ac.uk/d.p.long/IPC 

3 LPG is based on a non-deterministic local search and, con(cid:173)
sequently,  it  would  not  be  fair  to  work  with  the  plan  from 
only  one  execution. 
In  our  experiments  with  LPG,  we  have 
run  each  problem  ten  times  and  extracted  the  average  val(cid:173)
ues.  Wc  have  used  the  LPG  1.0  version  as  provided  in: 
http://prometeo.ing.unibs.it/lpg 

4We  have  used 

the  Mips  version  as  provided 

http://www.informatik.uni-freiburg.de/~mmips 

5LPG and Mips arc clearly faster than tpsys-LC. For instance, 
they get to solve some simple problems before tpsys - LC finishes 
its 1st and 2nd stages. Currently, these stages represent an impor(cid:173)
tant bottleneck in our implementation and we think they could be 
drastically reduced. 

in: 

PLANNING 

945 

Figure 2: Comparison of the least-commitment search vs. the Graphplan backward search. Tests were censored after 300 s. 

Problem 
gripper-4 
grippcr-8 
|  gripper-12 
gripper-16 
grippcr-20 
gripper-24 
gripper-28 
gripper-32 
grippcr-36 
gripper-40 

tpsys-LC 

7(11) 
15(23) 
23 (35) 
31(47) 
39 (59) 
47(71) 
55 (83) 
63 (95) 
71(107) 
79(119) 

LPG 
13(13) 
25 (25) 
45 (45) 
53 (53) 
63 (63) 
77 (77) 
89 (89) 
105(105) 
117(117) 
127(127) 

Mips 
15(15) 
31(31) 
47 (47) 
63 (63) 
79 (79) 
95 (95) 
111 (111) 
127(127) 
143(143) 
159(159) 

Table 1: Comparison of the makespan (number of actions are 
in brackets) of the plans for the g r i p p er domain obtained 
by tpsys-LC, LPG and Mips planners. 

the plans generated by the domain-independent (di) planners 
LPG,  Mips and VHPOP, and the domain-dependent (dd) 
planners SHOP2, TALPIanner and TLPIan.  For LPG and 
Mips we have run the problems again and for the rest of the 
planners we have used the results of the competition.  Al(cid:173)
though Sapa, TP4 and IxTeT also participated in the com(cid:173)
petition we have not found enough results for the simple-time 
track to be considered in our comparison. Figure 3 shows the 
results of this comparison (for lack of space we only include 
the domains with more problems solved).  In the d r i v e r-
l og domain, the plans of tpsys-LC are generally longer 
than  the  rest  of planners  with  the  exception  of LPG  and 
SHOP2.  In the s a t e l l i te domain, tpsys-LC behaves 
in average better than the rest of the planners, with the only 
exception of TLPIan.  In the rovers domain, tpsys-LC 
generates again plans of very good quality, which are only 

improved by  SHOP2 and TLPIan.  Further,  we have no(cid:173)
ticed that tpsys-LC generates plans with nearly the same 
(or even fewer) actions than the rest of the planners.  These 
experimental results show that the new approach significantly 
improves the scalability of the Graphplan backward search. 
5  Conclusions through Related Work 
Least-commitment techniques have been widely used in plan(cid:173)
ning,  relying  on  the  consistency  of  temporal  constraints 
(IxTeT and HSTS), postponing the assignment of values to 
variables or the  order of execution of actions,  etc.  [Weld, 
1994].  We use a least-commitment approach to overcome 
the limitations of the Graphplan backward search detected 
in previous works  [Fox and Long,  1999; Zimmerman and 
Kambhampati, 1999]. Our approach basically postpones the 
allocation in time of actions until they become not mutex and 
applicable. Thus, the algorithm generates a relaxed plan sim(cid:173)
ilarly to FF, to be used as a skeleton of the plan.  Next, it 
allocates actions in time according to their mutex relations 
and to several local heuristic criteria in the line of LPG. Our 
critical difference with LPG relies on several points.  First, 
the planning graph is temporal and moves chronologically in 
time instead of planning steps.  Second, the TG is not only 
used to extract heuristic information but also to generate a 
relaxed plan. Third, this plan is repaired in a forward chain(cid:173)
ing direction, and unlike LPG the allocated actions are never 
removed. Fourth, the heuristics exploit better the structure of 
the plan and the real importance of each action in the plan. Fi(cid:173)
nally, tpsys-LC uses a more precise model of action mutex 
which implies fewer constraints on the execution of actions 
and a larger search space. 

This  paper  contributes  in  the  way  in  which  least-

946 

PLANNING 

(a) - d r i v e r l og domain (di planners) 

(c)- s a t e l l i te domain (di planners) 

(e) - rovers domain (di planners) 

Figure 3: Comparison of the quality of the plans obtained by tpsys -LC and some state-of-the-art planners 

commitment can be applied in a Graphplan-bascd temporal 
(or classical) approach, substituting the backward search by 
the new two-stage search.  The new search combines the in(cid:173)
formation calculated in the planning graph with a heuristic, 
greedy search process, and increases the planner scalability. 
The advantage is that the planner can exploit a high level of 
action concurrency, what leads to plans highly competitive 
with other state-of-the-art planners under a deterministic ap(cid:173)
proach.  Although in temporal planning the most important 
criterion of quality is the makespan, the experimental results 
show that the new search generates plans in which the number 
of actions is quite good (even in problems of IPC-1998 and 
IPO2000). The main disadvantage of this approach is that it 
is not complete preserving. However, although completeness 
and optimality are desired properties, guaranteeing them en(cid:173)
tails a huge complexity, preventing planners from producing 
plans with more than a few actions.  The algorithm has still 
some limitations and our future work is to refine the heuristic 
functions to improve the quality of the plans, the performance 
and to avoid some of the inconveniences of the greedy search. 
Acknowledgments 
This work has been partially supported by the Spanish MCyT 
under projects DPI2001-2094-C03-03 and TIC2001-4936-E, 
and by the Universidad Politecnica de Valencia under projects 
20010017 and 20010980. 
References 
[Blum and Furst, 1997]  A.L.  Blum  and M.L.  Furst.  Fast 
planning through planning graph analysis.  Artificial In(cid:173)
telligence, 90:281-300,1997. 

[Edelkamp, 2002]  S.  Edelkamp.  Mixed propositional and 
numeric planning in the model checking integrated plan(cid:173)
ning system. In Proc. Workshop on Planning for Temporal 
Domains (AIPS-2002), pages 47-55, 2002. 

[Fox and Long, 1999]  M. Fox and D. Long.  The detection 
In 

and  exploitation of symmetry  in  planning domains. 
Proc. UCA1-99, pages 956-961, 1999. 

LFox and Long, 2001]  M. Fox and D. Long.  PDDL2.1:  an 
extension to PDDL for expressing temporal planning do(cid:173)
mains. Technical report, University of Durham, UK, 2001. 
[Garridoef  tf/.,2002]  A.  Garrido,  M.  Fox,  and  D.  Long. 
A  temporal  planning  system  for  durative  actions  of 
PDDL2.1. In Proc. ECAI-2002, pages 586-590,2002. 

[Gerevini and Serina, 2002] A. Gerevini and I. Serina. LPG: 
a planner based on local search for planning graphs with 
action costs. In Proc. AIPS-2002, pages 281-290. 2002. 
[Hoffmann, 2000] J. Hoffmann. A heuristic for domain inde(cid:173)
pendent planning and its use in an enforced hill-climbing 
algorithm. In Proc. 12th Int. Symp. on Methodologies for 
Intelligent Systems, Charlotte, North Carolina, USA, 2000. 

[Smith and Weld, 1999]  D.E Smith and D.S. Weld.  Tempo(cid:173)
ral planning with mutual exclusion reasoning.  In Proc. 
IJCAI-99, pages 326-337, Stockholm, Sweden, 1999. 

[Weld, 1994]  D. Weld. An introduction to least commitment 

planning. AI Magazine, 15(4):93-123,1994. 

[Zimmerman and Kambhampati, 1999]  T.  Zimmerman and 
S. Kambhampati.  Exploiting symmetry in the planning-
graph via explanation-guided search. In Proc. AAA 1-99, 
1999. 

PLANNING 

947 

