Combining Learning Constraints and Numerical Regression

Dorian ˇSuc1,2, Ivan Bratko2

1National ICT Australia, Sydney Laboratory at UNSW, NSW 2052, Australia

2Faculty of Computer and Information Science, University of Ljubljana

Trˇzaˇska 25, 1000 Ljubljana, Slovenia
{dorian.suc, ivan.bratko}@fri.uni-lj.si

Abstract

Usual numerical learning methods are primarily
concerned with ﬁnding a good numerical ﬁt to data
and often make predictions that do not correspond
to qualitative laws in the domain of modelling or
expert intuition. In contrast, the idea of Q 2 learn-
ing is to induce qualitative constraints from training
data, and use the constraints to guide numerical re-
gression. The resulting numerical predictions are
consistent with a learned qualitative model which
is beneﬁcial in terms of explanation of phenomena
in the modelled domain, and can also improve nu-
merical accuracy. This paper proposes a method for
combining the learning of qualitative constraints
with an arbitrary numerical learner and explores
the accuracy and explanation beneﬁts of learning
monotonic qualitative constraints in a number of
domains. We show that Q2 learning can correct
for errors caused by the bias of the learning algo-
rithm and discuss the potentials of similar hierar-
chical learning schemes.

1 Introduction
Learning understandable models is one of the main goals of
machine learning, but has been recently overshadowed by
methods that mainly concentrate on classiﬁcation or regres-
sion accuracy. Less effort has been devoted to improving
the explanation strength of machine learning methods.
In-
duced models are often too complex and overly detailed to
provide an understandable explanation of phenomena in a
modelled domain. This is particularly notable with methods
that achieve excellent accuracy by constructing ensembles of
classiﬁers (overview in [Dietterich, 1998]). Another problem,
illustrated and discussed in [ ˇSuc et al., 2004], is that state-of-
the-art numerical machine learning methods often make pre-
dictions that a knowledgeable user ﬁnds obviously incorrect
– not so much in numerical, but in qualitative terms. Such
qualitative errors of numerical predictors are undesirable par-
ticularly because they make numerical results difﬁcult to in-
terpret. The underlying mechanism in the domain is usually
best explained in qualitative terms. However, this is obscured
by qualitative errors in numerical predictions.

Qualitatively faithful quantitative learning, called Q 2
learning for short, was proposed [ ˇSuc et al., 2004] to rectify
the qualitative problems of numerical learning. Q 2 learning
combines qualitative and numerical learning to give numer-
ical predictions that both ﬁt the data well and are consistent
with an induced qualitative model. The qualitative consis-
tency is beneﬁcial in terms of explanation of phenomena in a
modelled domain. Quite surprisingly, a case study with Q 2
learning shows that induced qualitative constraints can also
improve numerical accuracy. This paper extends the previous
work in several directions.

One contribution of this paper is a Q 2 learning scheme that
combines learning of monotonic qualitative constraints with
an arbitrary numerical learner and enables us to study accu-
racy beneﬁts of the induced constraints. Qualitative learning
has been previously used in a number of applications that are
mainly tied to dynamic systems and control. In these applica-
tions, advantages in terms of explanation and in terms of the
control performance of the induced qualitative models were
observed. Since these models deﬁne only constraints on a
class variable, a direct assessment of their accuracy beneﬁts
was previously not possible. The second contribution is an
empirical evaluation in a number of domains and a demon-
stration that such regression, guided by induced qualitative
constraints, often increases numerical accuracy.

We analyze the reasons for these accuracy improvements
and show that Q2 learning corrects for errors caused by the
In this respect Q2 learning is similar to
bias of a learner.
ensembles of classiﬁers, in particular approaches that com-
bine classiﬁers constructed by different learning algorithms,
e.g. combining instance and model-based learning [Quin-
lan, 1993] or stacking and its variations [Wolpert, 1992;
Gama and Brazdil, 2000; Todorovski and Dˇzeroski, 2003 ].
An important distinction of Q2 learning is the (qualitative)
consistency of models at different levels of abstraction. We
discuss advantages of similar hierarchical learning schemes
and we demonstrate that explanation improvements do not
necessarily come at the price of lower accuracy.

In Section 2 we describe the Q2 learning scheme proposed
in this paper. The elements and the details of Q 2 learning
are described in Section 3. Then we give experimental results
in various domains and study accuracy improvements using
bias-variance decomposition. Section 5 discusses results and
beneﬁts of Q2 learning, and gives directions for future work.

2 Q2 Learning with QUIN and Qﬁlter
The idea of Q2 learning is to combine qualitative and numer-
ical learning to ﬁnd a regression function that ﬁts the data
well and is consistent with an induced qualitative model. In
this paper, Q2 learning consists of two stages:

1. Program QUIN 1 (described in Section 3.1) induces a
qualitative tree from numerical training examples. Qual-
itative trees are similar to decision trees, but have mono-
tonic qualitative constraints in their leaves.

2. Algorithm Qﬁlter (described in Section 3.2) uses the in-
duced qualitative tree, plus training examples, plus class
predictions of an arbitrary numerical learner, to alter the
predictions to respect the induced qualitative tree. Qﬁl-
ter is an optimization procedure that ﬁnds the minimal
quadratic changes in class values that achieve consis-
tency with the qualitative tree. In our experiments, the
numerical learners, also called base-learners, are regres-
sion trees, model trees and locally weighted regression.
In this paper, a Q2 learner consists of a qualitative con-
straints learner and a numerical base-learner, and can be de-
noted by Q2(qual-learner, base-learner). We abbreviate the
common case Q2(QUIN, base-learner) simply as Q2base-
learner. This learning scheme is particulary interesting be-
cause base-learner’s predictions are changed optimally in the
sense of squared error. Therefore, the differences between
base-learner’s predictions and Q 2 predictions come just from
induced qualitative constraints.

3 Elements of Q2 Learning
3.1 Monotonic Qualitative Constraints,

Qualitative Trees and QUIN

Monotonic qualitative constraints (MQCs) are a kind of
monotonicity constraints that are widely used in the ﬁeld
of qualitative reasoning and are a generalization of mono-
tonic function constraint used in QSIM [Kuipers, 1994]. A
simple example of an MQC is: Y = M +(X). This says
that Y is monotonically increasing in its dependance on X,
i.e. whenever X increases, Y also increases.
In general,
MQCs can have more than one argument. For example,
Z = M +,−(X, Y ) says that Z is monotonically increasing
in X and monotonically decreasing in Y . If both X and Y
increase, then according to this constraint, Z may increase,
decrease or stay unchanged. In such a case, an MQC cannot
make an unambiguous prediction of the qualitative change in
Z.

Qualitative trees are similar to decision trees, but have
monotonic qualitative constraints in the leaves. Figure 1 gives
an example of a simple qualitative tree. This qualitative tree
is a qualitative model of the function Y = L sin(Φ), where
0 ≤ Φ ≤ π and L > 0. It describes how Y qualitatively de-
pends on attributes Φ and L. The tree partitions the attribute
space into two regions that correspond to the two leaves of

1QUIN with a graphical user

interface, Qﬁlter and lo-
cally weighted regression as a base-learner are available at
http://ai.fri.uni-lj.si/dorian/q2/quin.htm.

(cid:73) (cid:100) 1.57 

>

(cid:100)

Y = M+,+((cid:73), L)

Y = M-,+((cid:73), L)

Figure 1: A qualitative tree induced from examples for the
function Y = L sin(Φ), where 0 ≤ Φ ≤ π and L > 0. The
right leaf, which applies when Φ > π/2, says that Y is mono-
tonically decreasing in Φ and monotonically increasing in L.

)

 

A
(
+
M
=
C
 
s
s
a
c

 

l

Data points
Points satisfying C = M+(A)

0

1

2

3

4

5

6

7

attribute A

5

4

3

2

1

Figure 2: Achieving consistency with MQC C = M +(A):
class values ci (denoted by circles) are changed into c i + di
(denoted by crosses) by minimizing the sum of squared
changes di. The arrows denote the class changes di.

the tree. Note that a simple qualitative tree can describe a rel-
atively complicated nonlinear function. Such qualitative trees
are induced from numerical data by learning program QUIN
[ ˇSuc, 2003].

QUIN constructs a qualitative tree in a top-down greedy
fashion, similar to decision or regression tree learning algo-
rithms. The split selection criterion is based on the minimum
description length principle and takes into account the encod-
ing complexity of the subtrees, the consistency of the MQCs
in the subtrees with the corresponding data, and the “ambi-
guity” of the MQCs with respect to the data (the more unam-
biguous qualitative predictions the MQC can make, the bet-
ter).

3.2 Qﬁlter Algorithm
Qﬁlter handles each leaf of a qualitative tree separately. It
ﬁrst splits the examples according to the qualitative tree and
then changes class values to achieve consistency with MQCs
in corresponding leaves.

Let us ﬁrst observe a simple example in Figure 2. We have
eight examples (ai, ci), i=0, 1, ..., 7. Class C has values ci
and attribute A has values ai=i. The examples are not con-
sistent with the given MQC C = M +(A), because the MQC
requires that ci+1 > ci which is violated at i = 1 and i = 4.
To achieve consistency with C = M +(A), class values
should be changed into ci + di, where the unknown param-
eter di denotes the change in the i-th class value. Class
changes di are constrained by MQC-imposed inequalities:
ci+1 + di+1 > ci + di where i = 0, 1, ..., 6. These inequal-
ities can be formulated in matrix notation as A d > b, where
d is a vector of unknown parameters d i, vector b has ele-

ments bi = ci − ci+i, and matrix A has elements ai,i = −1,
ai,i+1 = 1 and zeros elsewhere. In general, b and A depend
on the MQC-imposed inequalities, which in turn depend on
the MQC and on the ordering of attributes’ values.

Therefore, ﬁnding minimal quadratic changes in class val-
ues that achieve consistency with a given MQC can be posed
as the quadratic programming optimization problem: ﬁnd
vector d that minimizes the criterion function d T H d such that
A d > b. In the above formulation matrix H is the identity
matrix. In general H can be changed to differently penalize
the changes in class values as described in Section 3.3.

Since the criterion function with diagonal matrix H is a
convex function, and because the linear constraints A d > b
deﬁne a convex hull, a local minimum of the criterion func-
tion is a globally optimal solution. A more elaborate descrip-
tion of Qﬁlter, deﬁning also the appropriate ordering of class
values when more than one attributes are used in an MQC,
is given in [ ˇSuc and Bratko, 2003]. In previous work Qﬁlter
was used with qualitative trees derived manually from domain
knowledge. Here we use it in a different and a more challeng-
ing context, where qualitative trees are induced from data.
3.3 Qﬁlter for Q2 Learning
Qﬁlter is supplied with a qualitative tree, training exam-
ples with their class values and test examples with the base-
learner’s class predictions. Qﬁlter then adjusts the class val-
ues of the training and the test examples to achieve consis-
tency with the qualitative tree.

One improvement of Qﬁlter is to use the base-learner’s
conﬁdence estimates in its predictions. In this case, Qﬁlter
makes smaller adjustments to the class values with higher
conﬁdences at the expense of larger changes of class val-
ues that have lower conﬁdences. This is achieved by chang-
ing the quadratic programming criterion function. Namely,
matrix H is changed from the identity to a diagonal matrix
with elements hi,i = wi. Weight wi is computed from the
base-learner’s conﬁdence estimate in the i-th class value. Of
course, the computation of weight w i depends on a type and
a scale of conﬁdence estimates, but would generally be larger
if a numerical predictor is more conﬁdent in the i-th class
prediction.
Based on this idea, we used a heuristic weighting function:
wi = 1+sign(µ−ci)(1−exp (−(ci−µ)2
)), where ci denotes
base-learner’s conﬁdence in the class prediction of the i-th
test example, and µ and σ denote the mean and the standard
deviation of base-learner’s conﬁdences over all test examples.
Therefore, the weight of a test example is between zero and
two. The weight of all training examples is set to two. In
experiments with locally weighted regression, conﬁdence es-
timates ci were set to the sizes of conﬁdence intervals. Model
and regression trees do not provide similar conﬁdence esti-
mates. For this reason, conﬁdence estimates of all test exam-
ples were set to one.

2σ

4 Empirical Evaluation
4.1 Experimental Details
Here we evaluate accuracy beneﬁts of Q 2 learning with var-
ious numerical base-learners. Given a set of training exam-

Figure 3: A planar two-link, two-joint robot arm. The ﬁrst
link is extendible with length L1 ranging from 2 to 10.

ples, a base-learner is used to predict class values of test ex-
amples. The same training examples are used for QUIN to
induce a qualitative tree. The qualitative tree, the training
and the test examples with base-learner’s class predictions
are then used by Qﬁlter to give predictions that are consis-
tent with the qualitative tree. This procedure is then repeated
(for example, ten times with ten-fold cross-validation) with
different training and test examples.

In the experiments we compare root relative squared er-
rors (RREs for short) of the base-learner and the Q 2 learner.
Here, the RRE is the root mean squared error normalized by
the root mean squared error of average class value. The base-
learners in our study are regression and model trees [Breiman
et al., 1984; Quinlan, 1993], and locally weighted regres-
sion [Atkeson et al., 1997]. The ﬁrst two base-learners were
chosen because they are well-established numerical learners
that provide a symbolical model. Locally weighted regres-
sion (LWR for short) does not provide a model explaining
a studied domain, but often gives more accurate predictions
than model or regression trees. With such base-learners, the
explanation beneﬁts of Q2 learning are even more obvious.
In experiments we used our implementations of these base-
learners. Our regression and model trees use cost-complexity
pruning [Breiman et al., 1984] and smoothing. LWR uses
Gaussian weighting function with local optimization to set
the kernel size at each prediction point. We also give RREs of
M5 model trees [Quinlan, 1993] and its Weka implementation
called M5Prime [Witten and Wang, 1997] to show that we are
not comparing Q2 to base-learners that perform poorly. With
all learners, default values of their parameters were used.

We analyze the reasons for the Q2 accuracy improvements
using bias-variance decomposition [Geman et al., 1992] and
draw some interesting conclusions.

4.2 Robot Arm Domain
Here we describe experiments in the domain of a planar two-
link, two-joint robot arm depicted in Figure 3. The angle in
the shoulder joint is denoted by Φ 1 and the angle in the elbow
joint is denoted by Φ2. Angle Φ1 is between zero and π,
while Φ2 is between −π/2 and π/2. The ﬁrst link, i.e. the
link from the shoulder to the elbow joint, is extendible with
length L1 ranging from 2 to 10. The second link has ﬁxed
length 5. Y-coordinates of the ﬁrst and the second link ends
are denoted by Y1 and Y2 respectively. We experimented with
four learning problems that differ in class variable (Y 1 or Y2)
and the attributes used for learning. These learning problems
were deﬁned to pose increasingly more difﬁcult problems to
Q2 learning.

Figure 4: Comparing RREs of base-learners and Q 2 learners in learning problems A, B, C and D with 0%, 5% and 10% noise.

Table 1: RREs of LWR, model (Mt) and regression trees (Rt)
and the corresponding Q 2 learners with no noise. The last
column gives RREs of M5Prime.

Rt

0.327
0.318
0.434
0.542

Q2Rt M5Pr
0.512
0.293
0.462
0.263
0.489
0.378
0.448
0.553

LWR Q2LWR Mt

A 0.187
0.196
B
C
0.327
D 0.403

0.145
0.139
0.300
0.362

0.264
0.159
0.336
0.366

Q2Mt
0.238
0.146
0.324
0.363

The easiest learning problem, called problem A, is to pre-
dict the y-coordinate of the ﬁrst link end given its length and
angle, i.e. learning Y1 = f(L1, Φ1). Other learning problems
require predicting the y-coordinate of the second link end us-
ing different attributes.
In learning problems B and C we
helped the learners with a derived attribute Φ sum = Φ1+Φ2,
i.e.
the deﬂection of the second link from the horizontal.
Problem C is to learn Y2 = f(L1, Φ1, Φ2, Φsum), while in
problem B we also used Y1 as an attribute. Problem D re-
quires learning Y2 = f(L1, Φ1, Φ2). These problems pose
increasingly more difﬁcult problems to Q 2 learning. The eas-
iest is problem A, because a correct qualitative model is a
simple qualitative tree, given also in Figure 1. Learning prob-
lem D is the most difﬁcult for Q2, since a correct qualitative
model cannot be expressed by a qualitative tree.

To compare accuracy of different base-learners and Q 2
learning we generated examples where angles Φ 1 and Φ2
and link length L1 were randomly generated from a uniform
distribution. We experimented with different percentages of
Gaussian noise in the class variable. Noise percentage p%
means that the standard deviation of noise is p × d c/100,
where dc denotes the difference between maximal and min-
imal class value. We used 100 training examples and mea-
sured accuracy on separate test sets of 200 examples with-
out noise. All results are averages on 20 randomly generated
training and test sets.

Table 1 gives RREs of LWR, model and regression trees
and Q2 learning that uses these base-learners. For compar-
ison RREs of M5Prime model trees are also given. Results
with zero, 5%, and 10% noise are given in Figure 4. In all of
the learning problems and with all noise levels, Q 2 improves
the average RREs of all base-learners. These improvements
in accuracy depend on the base-learner and the learning prob-
lem. Generally, the improvements are the greatest with re-
gression trees and the smallest with model trees. It is notable

that in general our base-learners are much more accurate than
M5Prime on these learning problems. Although we are here
not interested in comparison of different base-learners, it is
good to know that with Q2 we are not improving the base-
learners that perform poorly.

The signiﬁcance of the Q2 accuracy improvements for each
learning problem was tested using the resampled paired t test.
Four learning problems × three base-learners × three noise
levels gives 36 comparisons of RRE of a base-learner and a
corresponding Q2 learner. At 5% signiﬁcance level, the Q2
learners are signiﬁcantly better in 33 comparisons and about
the same in only three comparisons. The comparisons where
differences in RRE are not signiﬁcant correspond to model
trees on learning problem D with all three noise levels.

Bias-Variance Decomposition
To understand the reasons for the Q 2 accuracy improvements
we used bias-variance decomposition [Geman et al., 1992;
Domingos, 2000], which has proved to be a very useful
tool for understanding machine learning algorithms. Bias-
variance decomposition in regression states that the expected
squared error of a learner on test example x is the sum of the
irreducible noise N(x), the bias B(x) and the variance V (x).
The bias B(x) of the learner on an example x is the squared
difference between the true value and the mean prediction on
x over all possible training sets. Here deﬁned bias B(x) is in
the literature called also squared bias, but we use the notation
from [Domingos, 2000] and call it bias. The variance V (x) is
the expected value of the squared difference between the true
value and the mean prediction on x. The bias measures the
systematic error incurred by a learner, and the variance mea-
sures the error incurred by its ﬂuctuations around the central
tendency in response to different training sets.
Irreducible
noise is the error of the optimal (Bayes) model and is in gen-
eral very difﬁcult to estimate. However, we are here using an
artiﬁcial learning problem and can therefore measure the bias
and variance by directly simulating the deﬁnitions.

We used 100 training sets of size 100, generated as in the
previous experiment and measured the average bias and aver-
age variance on a test set of 810 equidistant data points. We
refer to these averages over different training sets and differ-
ent test examples simply as bias and variance. Comparing the
base-learners we noticed that regression trees have the highest
variance. This is in accordance with their complexity – they
usually had more than 20 leaves. Model trees are smaller and
have the smallest variance when no noise, but with increas-

Table 2: Description of data sets and average 10-fold cross-validation root relative squared errors (RREs) of base-learners and
the corresponding Q2 learners. The last column gives RREs of M5 where this is available, and M5Prime otherwise.
M5
0.383
0.402
0.431
0.414
0.536
0.247
0.215
0.412

LWR Q2LWR Mod.tr. Q2Mod.tr.
0.361
0.380
0.373
0.353
0.478
0.142
0.249
0.414

Reg.tr. Q2Reg.tr.
0.459
0.435
0.532
0.460
0.508
0.091
0.191
0.193

Cases Attributes
398
159
506
209
167
354
618
200

5/8
16/16
12/13
6/6
2/4
3/3
3/3
4/4

0.405
0.381
0.454
0.377
0.504
0.049
0.165
0.165

0.374
0.523
0.422
0.370
0.588
0.194
0.190
0.319

Data set
AutoMpg
AutoPrice
Housing

MachineCpu

Servo

CraneSkill1
CraneSkill2
AntiSway

0.380
0.346
0.363
0.317
0.457
0.065
0.169
0.157

0.386
0.364
0.358
0.334
0.584
0.086
0.159
0.250

ing noise the variance increases most notably. Comparing Q 2
learners to the corresponding base-learners we noticed that
Q2 always notably reduces the bias of the base-learners. This
happens in all four learning problems, with all three base-
learners and different noise levels. For example, in problem
D with no noise, Q2 reduces bias and variance of LWR from
3.85 and 2.57 to 2.13 and 1.99, respectively. Q 2 always no-
tably decreases the variance of regression trees, but some-
times increases the variance of LWR and model trees. The
base-learners, used here, have a bias towards linear models. It
seems that Q2, with less restrictive monotonicity constraints,
reduces their bias, but does not considerably increase the vari-
ance.

Q2 learning combines hypotheses of two different learning
algorithms, i.e. a qualitative learner and a numerical learner.
In this respect it is similar to ensembles of classiﬁers and in
particular approaches that combine classiﬁers constructed by
different learning algorithms, as for example stacking and its
variations. Such methods improve accuracy mainly by reduc-
ing the error due to the bias of a learner. This is the conse-
quence of combining hypotheses that make uncorrelated er-
rors [Dietterich, 1998]. We believe that such uncorrelated
errors lead to bias reductions also in the case of Q 2 learning.
It should be noted that, although Q 2 predictions are consis-
tent with an induced qualitative model, they combine both
the base-learner’s predictions, and the qualitative model.

4.3 UCI and Dynamic Domains
To explore the potentials of learning similar constraints with
a wider range of learning problems we describe experiments
with eight data sets. The ﬁrst ﬁve are the smallest regres-
sion data sets from the UCI repository [Blake and Merz,
1998] with the majority of continuous attributes. A reason
for choosing these data sets is also that Quinlan [1993] gives
results of M5 and several other regression methods on these
data sets, which enables a better comparison of Q 2 to other
methods. These data sets are AutoMpg, AutoPrice, Housing,
MachineCpu and Servo.

The other three data sets are from dynamic domains where
QUIN has typically been applied so far [ˇSuc, 2003; ˇSuc and
Bratko, 2002]. It should be noted that in these domains the
primary objective was to explain the underlying control skill
and to use the induced qualitative models to control a dy-
namic system. Until now, it was not possible to measure their
numerical accuracy or compare it to other learning methods.

 vgain (cid:100) 3 

>

(cid:100)

Servo qualitative tree 

M-(pgain)

M+,-(pgain,vgain)

peakRpm (cid:100) 5000 
>
(cid:100)

AutoPrice qualitative tree 

height (cid:100) 53 

losses (cid:100) 110 

M1

M2

losses (cid:100) 110 

engSize (cid:100) 140 

wheelBase (cid:100) 99.8 

M3

M4

M5

M6

M7

M1: M-,+,-(ctyMpg,stroke,peakRpm)    M2: M+,+(curbWght,width) 
    M4: M+,-(curbWght,ctyMpg)
M3: M+(losses) 
 
M5: M+(wheelBase)   
    M7: M-(compRatio)
M6: M-,+,+(ctyMpg,bore,curbWght)

 
 

Figure 5: Qualitative trees induced from data sets Servo and
AutoPrice. MQCs in leaves of each qualitative tree give
monotonic constraints on the class variable.

Data sets CraneSkill1 and CraneSkill2 are the logged data of
two experienced human operators controlling a crane simula-
tor. Such control traces are typically used to reconstruct the
underlying operator’s control skill. The learning task is to
predict the velocity of a crane trolley given the position of the
trolley, rope angle and its velocity. Data set AntiSway was
used in reverse-engineering an industrial gantry crane con-
troller. This so-called anti-sway crane is used in metallurgi-
cal companies to reduce the swing of the load and increase
the productivity of transportation of slabs. The learning task
is to learn the control force applied to the trolley, given the
desired and the current trolley velocity and the position and
velocity of the load relative to the trolley.

In all experiments, qualitative trees were considerably sim-
pler than other induced models. Figure 5 gives examples of
qualitative trees induced in data sets Servo and AutoPrice.
These qualitative trees are considerably simpler than model
trees. In Servo, M5Prime induces a model tree with eleven
leaves, with all four attributes appearing in all eleven linear
models. In AutoPrice, M5Prime induces a model tree with
ten leaves, with at least ten attributes in each linear model.

Ten-fold cross-validation results are given Table 2. For

Figure 6: Comparison of RREs of base-learners and corresponding Q 2 learners. Disjoint columns give RREs of M5 model trees
where available, and M5Prime otherwise.

each data set we give, respectively, the numbers of cases,
numbers of continuous and all attributes, RREs of base-
learners and RREs of corresponding Q 2 learners. The last
column gives published RREs of M5 model trees [Quinlan,
1993] on UCI data sets, and RREs of M5Prime for others.
These results are presented also in Figure 6.

A general observation is that Q2 improves RREs of all three
base-learners in seven out of eight data sets. Q 2 is worse just
in AutoMpg with LWR and model trees. Smaller root rel-
ative squared errors in the last three data sets do not imply
that these learning problems are easier, but are just the con-
sequence of the normalization of RREs with large class vari-
ances.

The signiﬁcance of the Q2 accuracy improvements was
tested using the 10-fold cross-validated paired t test. Eight
data sets × three base-learners gives 24 comparisons of RRE
of a base-learner and the corresponding Q 2 learner. At 5%
signiﬁcance level, the Q2 learners are signiﬁcantly better in
18 comparisons and about the same in six comparisons. The
differences are not signiﬁcant in AutoMPG with all three
base-learners and with one base-learner in AutoPrice, Hous-
ing and CraneSkill2. Q2 is never signiﬁcantly worse.

5 Discussion and Conclusions
The goal of this paper is to explore the accuracy and expla-
nation beneﬁts of Q2 learning that were observed also in pre-
vious work [ ˇSuc et al., 2004]. We extend the empirical eval-
uation to a number of domains and analyze the results. The
proposed Q2 learning scheme, makes it possible to combine
learning of qualitative constraints with an arbitrary numerical
learner. It uses algorithm Qﬁlter, which is particulary interest-
ing since the base-learner predictions are optimally changed
(in the sense of squared error) to be consistent with an in-
duced qualitative tree. Therefore, the accuracy improvements
of Q2 with respect to a base-learner are only due to the in-
duced qualitative trees.
Q2 learning as a hierarchical learning scheme
Q2 learning, as presented in this paper, can be seen as a hi-
erarchical learning scheme, where a learner at a higher level
induces a hypothesis hn that guides the learner at a lower
level. At higher levels of the scheme more abstract concepts
(or more general constraints) are learned. In this way, h n pro-

vides inductive bias for learning of hypothesis h n−1. In the
case of Q2 learning, h1 is a qualitative tree induced by QUIN
and h0 are numerical predictions found by Qﬁlter. Similar
hierarchical learning schemes were proposed either to im-
prove the generalization of a single learning task, for example
Stacked Generalization [Wolpert, 1992] and Cascade Gener-
alization [Gama and Brazdil, 2000], or to facilitate the learn-
ing of several tasks in a hierarchy [Stone and Veloso, 2000].
Q2 learning has two distinctive properties. First, the hypothe-
ses in the hierarchy are consistent and described at different
levels of abstraction. This is important for the explanation
of the phenomena in the modelled domain. Second, the hy-
potheses are learned in the general-to-speciﬁc order, which
can reduce the search space, and can consequently improve
also the generalization properties.
Explanation and Accuracy Beneﬁts of Q2 Learning
Q2 predictions are consistent with a qualitative model that
provides an explanation at a higher level of abstraction. In
this respect Q2 learning is different than other methods for
combining classiﬁers. Qualitative consistency enables Q 2
to improve numerical accuracy by combining hypotheses in-
duced by different learners, but retain a simple explanation.

Beneﬁts of qualitative learning in terms of providing sim-
ple and understandable explanations in various domains, in-
cluding CraneSkill1, CraneSkill2 and AntiSway are discussed
in [ ˇSuc, 2003; ˇSuc and Bratko, 2002]. For example, qualita-
tive trees induced in CraneSkill1 and CraneSkill2 have only
a few leaves and were, because of their simplicity, preferred
over the previous approaches for skill reconstruction, which
typically learned regression or model trees with more than
twenty leaves. Although the induced qualitative trees are
simple, they reveal some surprising and nontrivial aspect of
the human skill. Simple and understandable models were in-
duced also in other domains studied in this paper. For exam-
ple, in robot arm domain (problems A, B and C) QUIN usu-
ally induced qualitative trees that are very close to the correct
qualitative models even with high percentage of noise. Sim-
ple qualitative trees were induced also from UCI data sets (see
Figure 5).

In the presented experiments, Q 2 typically improved ac-
curacy of the three base-learners. We compared root rela-
tive squared errors, but similar improvements were observed
also with mean absolute errors. We experimented also with

k-nearest-neighbor algorithm as a base-learner. It generally
performed worse than the other three base-learners and the
accuracy improvements of Q 2 learning were even more obvi-
ous.

Bias-variance decomposition in the robot arm domain
shows that the accuracy improvements stem mainly from cor-
recting for errors caused by the bias of a base-learner. Experi-
ments in the previous section suggest that combining “mono-
tonic regularities” inductive bias with inductive bias of other
learners is beneﬁcial in a wide range of domains, also in do-
mains when this might be less expected. As noted in Sec-
tion 4.2, Q2 learning is similar to ensembles of classiﬁers,
in particular approaches that combine classiﬁers constructed
by different learning algorithms. Although, the accuracy im-
provements of Q2 are not comparable to those achieved by
ensembles of classiﬁers, Q2 has advantages in terms of ex-
planation.

Limitations and Future Work
Limitations of Q2 learning presented in this paper are mainly
tied to the current implementation of QUIN. Because of its
complexity it is difﬁcult to apply it to very large data sets.
Incorporating sampling techniques with qualitative learning
might be beneﬁcial. Another idea for future work is to assess
and use the quality of the induced MQCs in leaves, for exam-
ple on a separate set of examples. The error of a Q 2 learner
could be used to prune a qualitative tree. This might be use-
ful also in data sets such as AutoMpg, where Q 2 otherwise
has problems. By considering only leaves where MQCs sig-
niﬁcantly improves a base-learner, a qualitative tree could be
transformed into a set of qualitative association rules.

An interesting direction for future work is to explore the
possibilities of the proposed hierarchical learning scheme
with several layers of constrains, describing hypotheses at
different levels of abstraction. Experimental results with Q 2
learning suggest that such scheme can be used to combine
classiﬁers and improve accuracy, and, at the same time pro-
vide an understandable explanation of the phenomena in a
modelled domain.

Acknowledgements
The work reported in this paper was supported by National
ICT Australia and the Slovenian Ministry of Education, Sci-
ence and Sport. National ICT Australia is founded by the
Australian Government’s Backing Australia’s Ability initia-
tive, in part through the Australian Research Council.

References
[Atkeson et al., 1997] C.G Atkeson, A.W Moore, and S.A.
Schaal. Locally weighted learning. Artiﬁcial Intelligence
Review, 11:11–73, 1997.

[Blake and Merz, 1998] C.L. Blake and C.J. Merz. UCI

repository of machine learning databases, 1998.

[Breiman et al., 1984] L. Breiman, J.H. Friedman, R.A. Ol-
shen, and C.J. Stone. Classiﬁcation and Regression Trees.
Wadsworth, Belmont, California, 1984.

[Dietterich, 1998] T.G. Dietterich. Machine-learning re-
The AI Magazine,

search: Four current directions.
18(4):97–136, 1998.

[Domingos, 2000] Pedro Domingos. A uniﬁed bias-variance
decomposition and its applications. In Proc. 17th Interna-
tional Conf. on Machine Learning, pages 231–238. Mor-
gan Kaufmann, San Francisco, CA, 2000.

[Gama and Brazdil, 2000] J. Gama and P. Brazdil. Cascade
generalization. Machine Learning, 41(3):315–343, 2000.
and
Neural networks and the bias/variance

[Geman et al., 1992] S. Geman, E. Bienenstock,

R. Doursat.
dilemma. Neural Computation, 4(1):1–58, 1992.

[Kuipers, 1994] B. Kuipers. Qualitative Reasoning: Mod-
eling and Simulation with Incomplete Knowledge. MIT
Press, Cambridge, Massachusetts, 1994.

[Quinlan, 1993] J.R. Quinlan. Combining instance-based
and model-based learning. In Proceedings of the 12th In-
ternational Conf. on Machine Learning, pages 236–243,
San Mateo, CA, 1993. Morgan Kaufmann.

[Stone and Veloso, 2000] P. Stone and M. Veloso. Layered
learning. In Machine Learning: ECML 2000 (Proceedings
of the 11th European Conference on Machine Learning),
pages 369–381. Springer Verlag, 2000.

[Todorovski and Dˇzeroski, 2003] L.

Todorovski

S. Dˇzeroski.
sion trees. Machine Learning, 50(3):223–249, 2003.

and
Combining classiﬁers with meta deci-

[ ˇSuc and Bratko, 2002] D. ˇSuc and I. Bratko. Qualitative re-
verse engineering.
In Proceedings of the 19th Interna-
tional Conf. on Machine Learning, pages 610–617. Mor-
gan Kaufmann, 2002.

[ ˇSuc and Bratko, 2003] D. ˇSuc and I. Bratko. Improving nu-
merical accuracy with qualitative constraints. In Proceed-
ings of the 14th European Conference on Machine Learn-
ing, pages 385–396. Springer, 2003.

[ ˇSuc et al., 2004] D. ˇSuc, D. Vladuˇsiˇc, and I. Bratko. Qual-
itatively faithful quantitative prediction. Artiﬁcial Intelli-
gence, 158(2):190–219, 2004.

[ ˇSuc, 2003] D. ˇSuc. Machine Reconstruction of Human Con-
trol Strategies, volume 99 of Frontiers in Artiﬁcial Intel-
ligence and Applications.
IOS Press, Amsterdam, The
Netherlands, 2003.

[Witten and Wang, 1997] I.H. Witten and Y. Wang.

Induc-
tion of model trees for predicting continuous classes.
In Proc. Poster Papers Europ. Conf. Machine Learning,
1997.

[Wolpert, 1992] D.H. Wolpert. Stacked generalization. Neu-

ral Networks, 5(2):241–259, 1992.

