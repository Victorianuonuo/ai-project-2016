Optimal Soft Arc Consistency

M.C. Cooper

S. de Givry and T. Schiex

IRIT, Univ. Toulouse III, France

cooper@irit.fr

INRA, Applied Math. & CS Dept., France

{degivry,tschiex}@toulouse.inra.fr

Abstract

The Valued (VCSP) framework is a generic opti-
mization framework with a wide range of applica-
tions. Soft arc consistency operations transform
a VCSP into an equivalent problem by shifting
weights between cost functions. The principal aim
is to produce a good lower bound on the cost of
solutions, an essential ingredient of a branch and
bound search.
But soft AC is much more complex than tradi-
tional AC: there may be several closures (ﬁxpoints)
and ﬁnding the closure with a maximum lower
bound has been shown to be NP-hard for integer
costs [Cooper and Schiex, 2004].
We introduce a relaxed variant of soft arc consis-
tency using rational costs. In this case, an optimal
closure can be found in polynomial time. Further-
more, for ﬁnite rational costs, the associated lower
bound is shown to provide an optimal arc consistent
reformulation of the initial problem.
Preliminary experiments on random and structured
problems are reported, showing the strength of the
lower bound produced.

1 Introduction
The Valued Constraint Satisfaction Problem [Schiex et al.,
1995] is a generic cost function optimization framework with
many applications. A VCSP is deﬁned by a set of variables
with ﬁnite domains and a set of local cost functions (soft con-
straints) which associate costs to tuples. The goal is then to
ﬁnd an assignment to all variables with a minimum com-
bined cost. Costs from different constraints are combined
with a domain dependent operator ⊕. In this paper, we focus
on Weighted CSP (WCSP) where costs are natural numbers,
combined by addition. This VCSP sub-case has been shown
to capture the essential complexity of non-idempotent VCSP
in [Cooper, 2005] and has a lot of direct applications in do-
mains such as resource allocation, combinatorial auctions,
bioinformatics, probabilistic reasoning, graph theory...

Following the initial deﬁnition of arc consistency for non
idempotent operators in [Schiex, 2000], local consistency
is now considered as a crucial mechanism for solving WC-
SPs. Based on iterated integer cost movements between cost

functions of different arities which preserve problem equiva-
lence, local consistency offers all the services of local con-
sistency in classical CSP. It is speciﬁcally capable of pro-
ducing strong incrementally maintained lower bounds which
are crucial for efﬁcient branch and bound search. It is how-
ever plagued by the absence of uniqueness of the ﬁxpoint
(so-called arc consistent closure) and by the fact that ﬁnding
a closure which maximizes the lower bound is an NP-hard
problem [Cooper and Schiex, 2004]. This has led to the def-
inition of a large number of variants of arc consistency (di-
rectional [Cooper, 2003], existential [Larrosa et al., 2005],
cyclic [Cooper, 2004]...), each using different strategies to try
to get closer to an optimal closure.

In this paper, we show that by relaxing the condition that
costs be integers and by allowing simultaneous cost move-
ments between cost functions, it is possible to deﬁne a new
class of local consistency such that ﬁnding an optimal closure
is a polynomial time problem. On a large class of problems,
we show that the lower bound produced is always better than
the previous integer arc consistency variants and provides an
optimal reformulation of the initial problem.

Beyond a better understanding of local consistency in WC-
SPs, preliminary experiments of Optimal Soft Arc Consis-
tency on random and structured WCSPs show that it may also
be used in practice as a preprocessing algorithm.

2 Preliminaries

Valued CSP extends the CSP framework by associating costs
to tuples [Schiex et al., 1995]. In general, costs are speciﬁed
by means of a so-called valuation structure deﬁned as a triple
S = (E, ⊕, (cid:3)), where E is the set of costs totally ordered
by (cid:3). The maximum and a minimum costs are noted (cid:4) and
⊥, respectively. ⊕ is a commutative, associative and mono-
tonic operation on E used to combine costs. ⊥ is the identity
element and (cid:4) is absorbing.

Weighted CSPs (WCSP) form a speciﬁc subclass of valued

CSP that relies on a speciﬁc valuation structure S(k).
Deﬁnition 2.1 S(k) is a triple ({0, 1, . . . , k}, ⊕, ≥) where,

• k ∈ {1, . . . , ∞}.
• ⊕ is deﬁned as a ⊕ b = min{k, a + b}
• ≥ is the standard order among numbers.

IJCAI-07

68

Observe that in S(k), we have 0 = ⊥ and k = (cid:4). k may be
either ﬁnite or inﬁnite.

A WCSP P is deﬁned by P = (X, D, C, k). The valu-
ation structure is S(k). X and D are sets of variables and
domains, as in a standard CSP. For a set of variables S ⊂ X,
we note (cid:2)(S) the set of tuples over S. C is a set of cost func-
tions. Each cost function (or soft constraint) cS in C is de-
ﬁned on a set of variables S called its scope. A cost func-
tion cS assigns costs to assignments of the variables in S i.e.:
cS : (cid:2)(S) → {0, . . . , k}. For simplicity, we assume that ev-
ery constraint has a different scope. For binary and unary
constraints, we use simpliﬁed notations: a binary soft con-
straint between variables i and j is denoted cij. A unary con-
straint on variable i is denoted ci. We assume the existence
of a unary constraint ci for every variable, and a zero-arity
constraint, noted c∅ (if no such constraint is deﬁned, we can
always deﬁne dummy ones ci(a) = 0, ∀a ∈ Di and c∅ = 0).
When a constraint cS assigns cost (cid:4) = k to a tuple t, it
means that cS forbids t, otherwise t is permitted by cS with
the corresponding cost. The cost of a complete tuple t in a
WCSP P , noted VP (t), is the sum of all costs:

(cid:2)

VP (t) =

cS(t[S])

cS ∈C

where t[S] denotes the usual projection of a tuple on the
set of variables S. A complete assignment is feasible if it has
a cost less than k and optimal if there are no complete assign-
ment with a lower cost. The problem is to ﬁnd a complete
optimal assignment (NP-hard).

We say that two WCSPs P and P (cid:3)

deﬁned over the same
variables are equivalent if they deﬁne the same global cost
function, i.e. VP and VP (cid:2) are identical.

3 Node and arc consistencies

Local consistency algorithms are characterized by the fact
that they reason at a subproblem level and that they preserve
equivalence. This is captured by the following notion:
Deﬁnition 3.1 For a valued CSP with a set of variables X,
an equivalence preserving transformation (EPT) on W ⊆ X
is an operation which transforms cost functions whose scope
is included in W to produce an equivalent valued CSP.

In WCSP, basic EPT move costs between cost functions in
order to preserve the equivalence of the problem. To move
costs, it is necessary to be able to subtract costs from its ori-
gin. This is done using the (cid:13) operation deﬁned as:

(cid:3)

a (cid:13) b =

a − b

: a (cid:14)= k
k : a = k

Although we restrict our presentation to WCSPs for the
sake of simplicity, we remind the reader that such a pseudo-
difference operator exists in a large class of VCSPs (fair
VCSP [Cooper and Schiex, 2004]).

Algorithm 1 gives two elementary EPT. Project works in
the scope of a single constraint cS. It moves an amount of
cost α from cS to a unary cost function ci, i ∈ S, for a
value a ∈ di.
If the cost α is negative, cost moves from

Figure 1: A simple WCSP and two arc consistent closures.

the unary cost function ci to the cost function cS. To guaran-
tee that the problem obtained after each application is valid,
one must guarantee that its cost functions remain in the val-
uation structure. To avoid negative costs, one must have
−ci(a) ≤ α ≤ mint∈(cid:2)(S),t[{i}]=a{cS(t)}. Similarly, Projec-
tUnary works on a subproblem deﬁned just by one variable
i ∈ X. It moves a cost α from the unary cost function ci to the
nullary cost function c∅ (with −c∅ ≤ α ≤ mina∈di
{ci(a)}
in order to get a valid WCSP).

Algorithm 1: Project and UnaryProject for soft arc and
node consistency enforcing
Procedure Project(cS, i, a, α)

ci(a) ← ci(a) ⊕ α;
foreach (t ∈ (cid:2)(S) such that t[{i}] = a) do

cS(t) ← cS(t) (cid:13) α;

Procedure UnaryProject(i, α)

c∅ ← c∅ ⊕ α;
foreach (a ∈ di) do

ci(a) ← ci(a) (cid:13) α;

A variable i is said to be node consistent [Larrosa, 2002]
if 1) for all values a ∈ di, ci(a) ⊕ c∅ (cid:14)= k, 2) there exists a
value b ∈ di such that ci(b) = 0. A WCSP is node consistent
(NC) if every variable is node consistent.

Stronger arc level consistencies rely on the notion of sup-
port. For simplicity, we introduce these notions for binary
WCSP but most have been generalized to arbitrary arities
(see [Cooper and Schiex, 2004]). A value b ∈ dj is a sup-
port for a value a ∈ di along cij if cij(a, b) = 0.

Variable i is arc consistent if every value a ∈ di has a sup-
port in every constraint cij ∈ C. A WCSP is arc consistent
(AC) if every variable is arc and node consistent.

When a value (i, a) has no support on a constraint, one
can create one using the Project operation. This is exempli-
ﬁed in Figure 1a. This WCSP has two variables with 2 val-
ues a and b. Vertices, representing values, can be weighted
by unary costs. An edge connecting two values represents a
cost of 1. If two values are not connected, it means that the
corresponding cost is 0. Notice that value (1, b) has no sup-
port on variable 2. We can apply Project(c12, 1, b, 1). This
creates a unary cost of 1 for (1, b) which is now AC. Apply-
ing UnaryProject(1, 1) on the resulting WCSP (Figure 1b)
makes the problem AC and increases c∅ by 1.

But a different sequencing may lead to a different result. If
we ﬁrst note that value (2, a) has no support on c12 and apply
Project(c12, 2, a, 1), we get the problem in Figure 1c. It is
now AC, but the lower bound c∅ is 0.

IJCAI-07

69

Given an initial WCSP P , any WCSP obtained from P
by iterated applications of Project and UnaryProject with
a positive integer α until a ﬁxpoint is reached is called an
arc consistent closure of P . An AC closure of a WCSP P is
optimal if it has the maximum lower bound c∅ among all AC
closures of P . [Cooper and Schiex, 2004] showed that ﬁnding
an optimal AC closure for a WCSP is an NP-hard problem.

Alternative deﬁnitions of AC have therefore been pro-
posed. They exploit the notion of full support. b is a full
support for a on cij if cij(a, b) ⊕ cj(b) = 0. Replacing the
notion of support by the stronger notion of full supports in
AC is attractive but the corresponding property cannot be en-
forced [Schiex, 2000]. Restricted versions must be used.

Given a variable ordering <, variable i is directional arc
consistent (DAC) if every value a ∈ di has a full support
in every constraint cij ∈ C such that j > i. A WCSP
is DAC if every variable is DAC and node consistent. It is
full directional arc consistent (FDAC) if it is AC and DAC.
Several heuristics for ordering variables in FDAC have been
tried [Heras and Larrosa, 2006a].

Variable i is existential arc consistent [Larrosa et al., 2005]
if there exists a ∈ di such that ci(a) = 0 and a has a full
support on every constraint cij. A WCSP is existential arc
consistent (EAC) if every variable is EAC and node consis-
tent. It is existential directional arc consistent (EDAC) if it
is EAC, and FDAC. All these deﬁnitions can be seen as well
deﬁned polynomial time heuristics trying to get closer to the
optimal closure, but without any guarantee.

4 Optimal arc consistency
From now on, we relax the deﬁnition of WCSP by allowing
rational costs. This mean we use the new valuation structure
SQ(k) = ([0, k], ⊕, ≥) where [0, k] denotes the set of rational
numbers (elements of Q) between (and including) 0 and k.
Deﬁnition 4.1 Given a WCSP P , a Soft Arc Consistent (SAC)
Transformation is a set of soft arc consistency operations
Project and UnaryProject which, when applied simultane-
ously, transform P into a valid WCSP.

Note that in this deﬁnition there is no precondition on the
costs moved individually by each EPT application. We just
want the ﬁnal equivalent WCSP to be valid (with positive ra-
tional costs): this also guarantees that c∅ is a lower bound of
the optimal cost. Previously, [Affane and Bennaceur, 1998]
proposed to split integer costs by propagating a fraction wij
of the binary constraint cij towards variable i and the remain-
ing fraction 1 − wij towards j (where 0 ≤ wij ≤ 1), sug-
gested determining optimal wij but just used wij = 1
2 . [Ben-
naceur and Osamni, 2003] further suggested to use different
weights wiajb for every pair of values (a, b) ∈ di × dj . It
turns out that using one weight for each triple (i, j, a) where
a ∈ di, allows us to ﬁnd optimal weights in polynomial time.
Theorem 4.2 If the valuation structure SQ(∞) is used, then
it is possible to ﬁnd in polynomial time a SAC transformation
of P which maximizes the lower bound c∅ provided the arity
of the constraints in P is bounded.
Proof: Assume ﬁrst as in [Cooper, 2003] that all inﬁ-
nite costs have been propagated using standard generalized

AC [Mohr and Masini, 1988]. Then only ﬁnite costs can be
further propagated by Project and UnaryProject. We then
want to determine a set of SAC operations which, when ap-
plied simultaneously, maximize the increase in c∅. For each
cS ∈ C with |S| > 1, and for every variable i ∈ S, let pS
i,a
be the amount of cost projected from cS to ci(a) (remember
that costs moved from ci(a) to cS are counted as negative in
Project). Let ui ≥ 0 be the amount of cost projected by
(cid:4)
UnaryProject from ci to c∅. Thus the problem is to maxi-
i ui while keeping the WCSP valid (no negative cost
mize
appears) i.e.:

∀i ∈ X, ∀a ∈ di,

ci(a) − ui +

pS
i,a ≥ 0

(cid:2)
(cid:2)

(cS ∈C),(i∈S)

∀cS ∈ C, |S| > 1, ∀t ∈ (cid:2)(S)

cS(t) −

pS
i,t[{i}] ≥ 0

i∈S

All inequalities for which ci(a) = (cid:4) = ∞ or cS(t) = (cid:4) can
be ignored since they are necessarily satisﬁed. The remain-
ing inequalities deﬁne a linear programming problem over Q
with O(ed + n) variables which can be solved in polynomial
time [Karmarkar, 1984].

A local version of the above theorem, limited to subprob-
lems of 3 variables, is actually the basis of the algorithm en-
forcing 3-cyclic consistency [Cooper, 2004]. In our case, a
problem will be called Optimal Soft Arc Consistent (OSAC)
when c∅ cannot be improved as above. Obviously, in SQ(∞),
OSAC is stronger than AC, DAC, FDAC or EDAC.

Note that if k < ∞, things get more involved since an in-
crease in c∅ can, through node consistency, lead to the dele-
tion of values, thus requiring a new optimization. Because
value deletion cannot occur more than nd times, this is still
polynomial time but the proof of optimality of the ﬁnal clo-
sure is an open question.

To better understand how
OSAC works, consider the 4-
variable WCSP on the left.
All unary costs are equal to
0. All edges represent a unit
cost, omitted for clarity. c∅
is assumed to be 0. None of
the basic EPTs can transform
the problem into a valid one.
However, we may simultane-
ously perform the following
operations:

1. Project(c23, 2, c, −1): we move (a virtual) cost of 1

from value (2, c) to 3 pairs inside c23.

2. Project(c23, 3, a, 1), Project(c23, 3, b, 1):

two unary costs of 1 to (3, a) and (3, b).

this moves

3. Project(c34, 3, a, −1), Project(c31, 3, b, −1): these two

unary costs are moved inside c34 and c31 respectively.

4. Project(c34, 4, c, 1):

(4, c).

this moves a unary cost of 1 to

5. Project(c31, 1, a, 1), Project(c31, 1, c, 1):

two unary costs of 1 to (1, c) and (1, a).

this moves

IJCAI-07

70

6. Project(c12, 1, a, −1), Project(c12, 2, c, 1): we reim-

burse our initial loan on value (c, 2).

7. Project(c14, 1, c, −1), Project(c14, 4, a, 1): we send a

unary cost to value (4, a).

Finally, the application of UnaryProject(4, 1) yields the
problem above with a lower bound c∅ = 1. This set of EPT
corresponds to a solution of the previous linear programming
problem where p23
1c = −1 and
3a = p23
1a = p31
p23
4a = u4 = 1 (all
other variables being equal to 0).

3b = p12

3a = p31

1a = p14

2c = p34

3b = p34

2c = p14

4c = p31

1c = p12

5 Properties
Theorem 4.2 shows that on SQ(∞), OSAC always provides
an optimal lower bound using only a set of arc level preserv-
ing operations. Actually, one can prove that for a large class
of WCSP the ﬁnal problem obtained is an optimal reformula-
tion of the problem using the initial set of scopes.
Deﬁnition 5.1 A WCSP P is in-scope c∅-irreducible if there
is no equivalent WCSP Q with the same set of constraint
scopes as P and such that cQ
∅ are the
nullary constraints in P , Q).
Theorem 5.2 Let P be a WCSP over SQ(∞) using only ﬁ-
nite costs. If no SAC transformation applied to P produces a
WCSP Q with cQ

∅, then P is in-scope c∅-irreducible.

∅ (where cP

∅ > cP

∅ > cP

∅, cQ

Proof:
in [Cooper, 2004].

This is a direct consequence of Lemma 5.2

Thus, for ﬁnite rational costs, OSAC can be used to estab-
lish in-scope c∅-irreducibility. This naturally does not work
when inﬁnite costs (hard constraints) exist. The 3-clique 2-
coloring problem is inconsistent and is therefore equivalent
to the same problem with just c∅ set to (cid:4) but no SAC trans-
formation can be applied to this WCSP.

Naturally, higher-order consistencies which may change
scopes could provide possibly stronger lower bounds: soft
3-consistency [Cooper, 2005] or soft path inverse consis-
tency [Heras and Larrosa, 2006b] applied to the previous 2-
coloring problem would detect infeasibility.

6 Experiments

bound produced is then compared to the lower bound pro-
duced by EDAC.

The ﬁrst set of instances processed are random Max-CSP
created by the random vcsp generator1 using the usual four
parameters model. The aim here is to ﬁnd an assignment that
minimizes the number of violated constraints. Four differ-
ent categories of problems with domain size 10 were gener-
ated following the same protocol as in [Larrosa et al., 2005]:
sparse loose (SL, 40 var.), sparse tight (ST, 25 var.), dense
loose (DL, 30 var.) and dense tight (DT, 25 var.) (see the
Benchmarks section of [de Givry et al., 2006b]).

SL
Optimum 2.84
EDAC lb.
OSAC lb.

0
0

ST

19.68
4.26
12.30

DL
2.22

0
0

DT

29.62
9.96
19.80

Samples have 50 instances. The table above shows re-
spectively the average optimum value, the average values of
the EDAC lower bound and the average value of the OSAC
lower bound. On loose problems, OSAC and EDAC leave the
lower bound unchanged. This shows that higher level local
consistencies are required here. However for tight problems,
OSAC is extremely powerful, providing lower bounds which
are sometime three times better than EDAC.

of

the Radio Link

The second set of benchmarks is deﬁned by open
Frequency Assign-
instances
the CELAR [Cabon et al., 1999].2
ment Problem of
These problems have been extensively studied (see
http://www.zib.de/fap/problems/CALMA)
gap
between the best upper bound (computed by local search
lower bound (computed by ex-
methods) and the best
ponential time algorithms) is not closed.
The problem
the scen0{7,8}reduc.wcsp and
considered
graph1{1,3}reducmore.wcsp which have already
been through different strong preprocessing (see the Bench-
marks section in [de Givry et al., 2006b]).

but

are

the

Total # of values
Best known ub
Best known lb
EDAC lb
OSAC lb
Cpu-time

scen07
4824

343592
300000
10000
31453.1
3530”

scen08
14194

262
216

6
48

6718”

graph11

5747
3080
3016
2710
2957
492”

graph13
13153
10110
9925
8722
9797.5
6254”

U B

As the table above shows, OSAC offers substantial im-
provements over EDAC, especially on the graph11 and
graph13 instances. For these instances, the optimality gap
U B−OSAC
is reduced to 4% and 3% respectively. The poly-
nomial time lower bounds obtained by OSAC are actually
close to the best known (exponential time) lower bounds. The
cpu-time show the cpu-time for computing the OSAC lower
bound.

To actually assess the practical interest of OSAC for pre-
processing, we tried to solve problems where OSAC was ef-
fective: tight problems. The difﬁculty here lies in the fact

We applied OSAC during preprocessing. The linear pro-
gramming problem deﬁned by OSAC was solved using ILOG
CPLEX version 9.1.3 (using the barrier algorithm). The lower

1www.inra.fr/mia/T/VCSP
2We would like to thank the french Centre Electronique de

l’Armement for making these instances available.

IJCAI-07

71

that CPLEX is a ﬂoating point solver while the open source
WCSP solver used (toolbar, section Algorithms in [de Givry
et al., 2006b]) deals with integer costs. To address this is-
sue, we use “ﬁxed point” costs: for all WCSP considered, we
ﬁrst multiply all costs by a large integer constant λ = 1, 000,
and then solve the linear programming problem deﬁned by
OSAC using integer variables (instead of ﬂoating point). The
ﬁrst integer solution found is used. The resulting problem
has integer costs and can be tackled by toolbar3. This means
that we shift from a polynomial problem to an NP-hard one.
In practice, we found that the problems obtained have a very
good linear continuous relaxation and are not too expensive
to solve as integer problems. Using a polytime rational LP
solver would allow time complexity to remain polynomial.

strength of OSAC used as a preprocessing technique (remem-
ber that EDAC is maintained during search).

The strength of OSAC compared to local consistencies us-
ing full supports such as DAC is that is does not require an
initial variable ordering. Indeed, DAC directly solves tree-
structured problems but only if the variable ordering used for
DAC enforcing is a topological ordering of the tree. To eval-
uate to what extent OSAC can overcome these limitations,
we used random problems structured as binary clique trees as
in [de Givry et al., 2006a]. Each clique contains 6 variables
with domain size 5, each sharing 2 variables with its parent
clique. The overall tree height is 4 leading to a total number
of 62 variables, with a graph density of 11%.

The ﬁgure above uses a logarithmic scale for cpu-time for
different constraint tightnesses (below 40%, problems are sat-
isﬁable). On these tree-like problems, two DAC ordering
were used. One is compatible with a topological ordering
of the binary tree (and should give good lower bounds), the
inverse order can be considered as pathological. The cpu-
times for MEDAC alone (default toolbar parameters and up-
per bound) and OSAC+MEDAC (as previously) are shown in
each case. Clearly, OSAC leads to drastic (up to 20 fold) im-
provements when a bad DAC ordering is used. Being used
just during preprocessing, it does not totally compensate for
the bad ordering. But, even when a good DAC ordering is
used, OSAC still allows impressive (up to 4 fold) speedups,
especially on tight problems.

Finally, we also tried to solve the challenging open CELAR
instances after OSAC preprocessing. Despite the strength of
OSAC, all problems remained unsolvable. Simultaneously
taking into account the strong structure of the problems as
in [de Givry et al., 2006a] is an attractive direction here.

7 Related work

As a reviewer pointed out, the LP program optimized for
OSAC is the dual of the relaxation of the 01-linear formu-
lation proposed in [Koster, 1999]. The LP formulation of
OSAC was also found in the image processing community
[Schlesinger, 1976; Werner, 2005].

If all constraints are binary over boolean domains, WCSP
reduces to weighted MAX-2SAT. A direct encoding of
MAX-2SAT to quadratic pseudo-boolean function optimiza-
tion [Boros and Hammer, 2002] exists: using 0 and 1 to repre-
sent respectively true and false, × for disjunction, (1 − x) for

The Figure above reports cpu-time (up) and size of the tree
search (down) for dense tight problems of increasing size.
The time limit was set to 1800”. Four cpu-times are reported:
(1) OSAC LP: time taken by CPLEX to solve the ﬁrst lin-
ear relaxation (2) OSAC MIP: time taken to get the ﬁrst in-
teger solution, (3) MEDAC: time taken to solve the original
problem by maintaining EDAC [Larrosa et al., 2005] in tool-
bar with default parameters and a good initial upper bound,
(4) OSAC+MEDAC is the sum of OSAC MIP with the time
needed by toolbar to solve the OSAC problem (with the same
default parameters and upper bound).

Clearly, for small problems (with less than 29 variables),
OSAC is more expensive than the resolution itself. But as the
problem size increases, OSAC becomes effective and for 33
variables, it divides the overall cpu-time by roughly 2. The
number of nodes explored by toolbar in both cases shows the

3The code of toolbar has been modiﬁed accordingly: if a solution
of cost 2λ is known for example and if the current lb. is 1.1λ then
backtrack occurs since all global costs in the original problem are
integer and the ﬁrst integer above 1.1 is 2, the upper bound.

IJCAI-07

72

negation and + for combination of costs, a set of weighted
2-clauses can be transformed into a quadratic function. For
example, the clauses {a∨ b, a∨¯b} with weights 3 and 5 trans-
lates to the function f (a, b) = 3ab + 5a(1 − b).

The problem of producing a so-called “equivalent
quadratic posiform representation” with a high constant term
(the equivalent of c∅) has been shown to reduce to the com-
putation of a maximum ﬂow [Goldberg and Tarjan, 1988] in
an appropriately deﬁned network [Boros and Hammer, 2002].
Given the close connection between maximum ﬂow and lin-
ear programming, a ﬁne comparison of the lower bound pro-
duced by OSAC on MAX-2SAT problems and by the max-
ﬂow formulation of [Boros and Hammer, 2002] would be in-
teresting.

8 Conclusion

OSAC provides a polynomial time optimal arc consistent clo-
sure in a large class of WCSPs. Despite very preliminary test-
ing and comparatively high computational cost to enforce it,
OSAC already shows its usefulness as a preprocessing algo-
rithm for sufﬁciently large and tight problems.

Beyond this practical usefulness, we think that OSAC
brings to light the fact that, in order to increase their strength,
new soft local consistency algorithms should probably not be
restricted to the mechanical application of elementary oper-
ations but should instead try to identify worthy set of equiv-
alence preserving operations that should be simultaneously
applied. If maintaining OSAC during search is an obvious
but challenging next step, the construction of simpler limited
versions of OSAC should also be considered.

This approach is radically different from the ongoing trend
of using higher level consistencies (such as path [Cooper,
2005] or path inverse consistency [Heras and Larrosa,
2006b]). The extension of OSAC to such higher level con-
sistencies is also an open question.

References
[Affane and Bennaceur, 1998] M. S. Affane and H. Ben-
naceur. A weighted arc consistency technique for Max-
ECAI, pages 209–213, Brighton,
CSP. In Proc. of the 13
United Kingdom, 1998.

th

[Bennaceur and Osamni, 2003] H. Bennaceur and A. Os-
amni. Computing lower bounds for Max-CSP problems.
In Proc. 16

International IEA/AIE conference, 2003.

th

[Boros and Hammer, 2002] E. Boros

and P. Hammer.
Pseudo-Boolean Optimization. Discrete Appl. Math.,
123:155–225, 2002.

[Cabon et al., 1999] B. Cabon, S. de Givry, L. Lobjois,
T. Schiex, and J.P. Warners. Radio link frequency assign-
ment. Constraints, 4:79–89, 1999.

[Cooper and Schiex, 2004] M. Cooper and T. Schiex. Arc
consistency for soft constraints. Artiﬁcial Intelligence,
154(1-2):199–227, 2004.

[Cooper, 2003] Martin C. Cooper. Reduction operations in
fuzzy or valued constraint satisfaction. Fuzzy Sets and Sys-
tems, 134(3), 2003.

[Cooper, 2004] M. Cooper. Cyclic consistency: a local re-
duction operation for binary valued constraints. Artiﬁcial
Intelligence, 155(1-2):69–92, 2004.

[Cooper, 2005] M. Cooper. High-order consistency in Val-
ued Constraint Satisfaction. Constraints, 10:283–305,
2005.

[de Givry et al., 2006b] S. de Givry, F. Heras,

J. Lar-
rosa, E. Rollon,
The SoftCSP
and Max-SAT benchmarks and algorithms web site.
http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/softcsp.

and T. Schiex.

[de Givry et al., 2006a] S. de Givry, T. Schiex, and G. Ver-
faillie. Exploiting Tree Decomposition and Soft Local
Consistency in Weighted CSP. In Proc. of AAAI, 2006.

[Goldberg and Tarjan, 1988] A. Goldberg and R.E. Tarjan. A
new approach to the maximum ﬂow problem. Journal of
the ACM, 35:921–940, 1988.

[Heras and Larrosa, 2006a] F. Heras and J. Larrosa.

Intel-
ligent variable orderings and re-orderings in DAC-based
solvers for WCSP. Journal of Heuristics, 12(4-5):287 –
306, September 2006.

[Heras and Larrosa, 2006b] F. Heras and J. Larrosa. New In-
ference Rules for Efﬁcient Max-SAT Solving. In Proc. of
AAAI, 2006.

[Karmarkar, 1984] N. Karmarkar. A new polynomial time
algorithm for linear programming. Combinatorica, 4:373–
395, 1984.

[Koster, 1999] A.M.C.A. Koster. Frequency Assignment—
Models and Algorithms. PhD. Thesis. UM (Maastricht,
The Netherlands), 1999.

[Larrosa et al., 2005] J. Larrosa, S. de Givry, F. Heras, and
M. Zytnicki. Existential arc consistency: getting closer to
th
full arc consistency in weighted CSPs. In Proc. of the 19
IJCAI, Edinburgh, Scotland, August 2005.

[Larrosa, 2002] J. Larrosa. On arc and node consistency in
weighted CSP. In Proc. of AAAI, pages 48–53, Edmonton,
(CA), 2002.

[Mohr and Masini, 1988] R. Mohr and G. Masini. Good old
ECAI, pages 651–

discrete relaxation. In Proc. of the 8
656, Munchen FRG, 1988.

th

[Schiex et al., 1995] T. Schiex, H. Fargier, and G. Verfail-
lie. Valued constraint satisfaction problems: hard and easy
IJCAI, pages 631–637,
problems.
Montr´eal, Canada, August 1995.

In Proc. of the 14

th

[Schiex, 2000] T. Schiex. Arc consistency for soft con-
In Proc. of CP’2000, volume 1894 of LNCS,

straints.
pages 411–424, Singapore, September 2000.

[Schlesinger, 1976] M.I. Schlesinger. Syntactic analysis of
two-dimensional visual signals in noisy conditions. Kiber-
netika, 4:113–130, 1976. In Russian.

[Werner, 2005] T. Werner. A Linear Programming Ap-
proach to Max-sum Problem: A Review. Technical report
CTU-CMP-2005-25. Czech Technical University, 2005.
http://cmp.felk.cvut.cz/cmp/software/maxsum/

IJCAI-07

73

