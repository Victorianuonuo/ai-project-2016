Selective Supervision: Guiding Supervised Learning with Decision-Theoretic

Active Learning

Ashish Kapoor, Eric Horvitz and Sumit Basu

Microsoft Research

1 Microsoft Way, Redmond, WA 98052, USA

{akapoor, horvitz, sumitb}@microsoft.com

Abstract

An inescapable bottleneck with learning from large
data sets is the high cost of labeling training data.
Unsupervised learning methods have promised to
lower the cost of tagging by leveraging notions of
similarity among data points to assign tags. How-
ever, unsupervised and semi-supervised learning
techniques often provide poor results due to errors
in estimation. We look at methods that guide the
allocation of human effort for labeling data so as to
get the greatest boosts in discriminatory power with
increasing amounts of work. We focus on the ap-
plication of value of information to Gaussian Pro-
cess classiﬁers and explore the effectiveness of the
method on the task of classifying voice messages.

1 Introduction
Increased sensing and decreased storage costs are leading to
the growing availability of large data sets. However, data re-
sources are often unavailable for machine learning and rea-
soning because of the high cost of labeling cases. As an ex-
ample, we may have access to several thousand voice mes-
sages stored on a server and wish to build a classiﬁcation
system that could automatically classify voicemail messages
into different categories. Unfortunately, performing super-
vised learning with the data set would require the manual ef-
fort of listening to voice messages and applying labels.

Unsupervised learning shows promise for reducing the ef-
fort required for tagging, such as its use in preparing data
sets for supervised learning. However, pure unsupervised
learning, based on notions of clusters and similarity, is often
fraught with labeling errors.

We believe that there is a rich space of opportunities within
the realm of complementary computing [Horvitz and Paek,
2007] for machine learning. We focus on the ideal coupling
of human supervision with unsupervised methods and we dis-
cuss selective supervision, the use of value-of-information to
triage human tagging efforts. The active-learning method
considers both the cost required to tag data as well as the
costs associated with the use of a classiﬁer in a real-world set-
ting. We show how we can minimize the total cost associated
with the construction and use of classiﬁcation systems, where
costs are measured in currencies such as monetary quantities
or other valuable resources.

Given the cost of labeling previously unlabeled cases and
the cost of misclassiﬁcation—which may be different for dif-
ferent classes—we seek to quantify the expected gain in ex-
pected value associated with seeking information on an unla-
beled data point. This expected gain, which corresponds to
the value of information provided by labeling, is the guid-
ing principle for the active learning framework. We shall
show how we can employ this value of information in learn-
ing within the Gaussian Process classiﬁcation framework, and
describe the applicability of the approach to both supervised
and semi-supervised scenarios.

After a review of some key work in active learning, we de-
scribe the active learning framework that uses expected value-
of-information (VOI) criterion to triage labeling. Then, we
present concepts and computational issues with the use of
Gaussian Process classiﬁcation, and we show how the meth-
ods can be extended to handle semi-supervised learning. We
highlight the effectiveness of the framework on the task of
classifying voice messages and we conclude with experimen-
tal results and discussion.

2 Background
Interest has been growing in recent years in active learn-
ing. Numerous heuristics and schemes have been proposed
for choosing unlabeled points for tagging. For example, Fre-
und et al. 1997 propose disagreement among the commit-
tee of classiﬁers as a criterion for active learning. Tong and
Koller, 2000 explore the selection of unlabeled cases to query
based on minimizing the version space within the support
vector machines (SVM) formulation. Within the Gaussian
Process framework, the method of choice has been to look
at the expected informativeness of an unlabeled data point
[MacKay, 1992; Lawrence et al., 2002]. Speciﬁcally, the idea
is to choose to query cases that are expected to maximally
inﬂuence the posterior distribution over the set of possible
classiﬁers. Additional studies have sought to combine ac-
tive learning with semi-supervised learning [McCallum and
Nigam, 1998; Muslea et al., 2002; Zhu et al., 2003].

All of these methods inherently focus on minimizing the
misclassiﬁcation rate. We focus on the value of moving to
a decision-theoretic framework in active learning, where we
consider the costs and risks in real-world currencies and em-
ploy computations of expected value of information to bal-
ance the cost of misdiagnosis with the costs of providing la-
bels.

IJCAI-07

877

3 Decision-Theoretic Active Learning

A linear classiﬁer parameterized by w classiﬁes a test point
x according to: sign(f (x)), where f (x) = wT x. Given a set
of training data points XL = {x1, .., xn}, with class labels
TL = {t1, .., tn}, where ti ∈ {1, −1}, the goal of a learning
algorithm is to learn the parameters w. Most classiﬁcation
techniques focus on minimizing classiﬁcation error. How-
ever, preferences about the relative numbers of false positives
and negatives produced by a classiﬁcation system can vary by
person and task. These preferences can be expressed in terms
of real-world measures of cost such as a monetary value and
we can seek to minimize the expected cost for the use of a
classiﬁer over time. Additionally, we have the cost of tag-
ging cases for training, which can vary for cases in different
classes or with other problem-speciﬁc variables.

We aim to quantify the values of acquiring labels of differ-
ent data points and to use computations of these values as a
guiding principle in active learning. Intuitively, knowing the
label of one or more currently unlabeled points may reduce
the total risk in the classiﬁcation task. On the other hand, la-
bels are acquired at a price. The difference in the reduction in
the total expected cost of the use of the classiﬁer, which we
shall refer to as the risk, and the cost of acquiring a new label
is the expected value of information for learning that label.
The real-world cost associated with the usage of a classiﬁer
is a function of the number of times that a classiﬁer will be
used in the real world, so a probability distribution over usage
is considered in the computation of expected cost.

For simplicity, we shall focus in the discussion on two-
class discrimination problems. The methods discussed in the
paper can be generalized in a straightforward manner to han-
dle multiple classes. We note that the work presented here
makes a myopic assumption, where we only seek to label one
data point at a time. This can be generalized by applying
lookahead procedures that consider the acquisition of labels
for different sets of points.

Let us deﬁne the risk matrix R = [Rij] ∈ IR2×2, where
Rij denote the cost or risk associated with classifying a data
point belonging to class i as j. We use the index 2 to de-
note the class -1. We assume that the diagonal elements of R
are zero, specifying that correct classiﬁcation incurs no cost.
Thus, given the labeled set XL with labels TL we can train a
classiﬁer f (x) and compute the total risk on the labeled data
points as:

(cid:2)

(cid:2)

JL =

R12(1 − pi) +

R21pi

(1)

i∈L+

i∈L

−

Here, pi denotes the probability that the point xi is classiﬁed
as class +1, i.e. pi = p(sign(f (xi)) = 1|xi). Further, L+
and L− are the indices of positively and negatively labeled
points respectively. Note, that pi is the predictive distribu-
tion and depending upon the classiﬁcation technique may or
may not be available. Predictive distributions are available for
Gaussian Process classiﬁcation (Section 4) and other proba-
bilistic classiﬁers, including probabilistic mappings of out-
puts of SVMs [Platt, 2000].

Beyond labeled cases, we also have a set of unlabeled data
points XU = {xn+1, .., xn+m}, that we wish to classify. We
seek to include the total risk associated with the unlabeled

data points:

JU =

(cid:2)

i∈U

R12(1 − pi) · p∗

i + R21pi · (1 − p∗
i )

(2)

i = p(ti = 1|xi) is the true conditional density of
Here, p∗
the class label given the data point. As we do not have the
true conditional, we cannot compute this expression exactly.
i with pi; thus, we approxi-
However, we can approximate p∗
mate the total risk on the unlabeled data points as:

JU ≈

(R12 + R21)(1 − pi) · pi

(3)

(cid:2)

i∈U

Now, let Ci denote the cost of knowing the class label of xi.
We assume that the costs Ci and the risks R12 and R21 are
measured with the same currency. This assumption does not
impose signiﬁcant constraints as different currencies can be
transformed into a single utility by using appropriate real-
world conversions.

Given the risks (JL and JU ), we approximate1 the expected
misclassiﬁcation cost per point as ¯J = JL+JU
n+m . Assuming a
closed world, where the system only encounters the n + m
points in XL ∪ XU , the expected cost is the sum of the total
risk (Jall = (n + m) ¯J ) and the cost of obtaining the labels:

(cid:2)

(cid:2)

U = Jall +

Ci = JL + JU +

Ci

(4)

i∈L

i∈L

all) − Cj

Upon querying the new point, we may see a reduction in the
total risk. However, a cost is incurred when we query a label
and computing the difference in these quantities triages the
selection of cases to label. Formally, we deﬁne the VOI of
an unlabeled point xj as the difference in the reduction in the
total risk and the cost of obtaining the label:
V OI(xj ) = U − U j = (Jall − J j
and J j

Here, U j
all denote the total expected cost and the to-
tal misclassiﬁcation risk respectively if we consider xj as la-
beled. The VOI quantiﬁes the gain in utilities in terms of the
real-world currency that can be obtained by querying a point;
hence, our strategy would be to choose next for labeling the
point that has the highest value of information. This results in
minimization of the total cost U that consists of the total risk
in misclassiﬁcation as well as the labeling cost. We note that
this approach differs from the earlier methods in active learn-
ing where the focus has been to minimize the classiﬁcation
error.

(5)

Now, let us consider xj for querying. Note that we need to
compute the expression for VOI before we know the label for
xj and the total risk J j
all cannot be computed before we know
the actual label tj. Similarly, Cj cannot be computed if the
costs of labels are different for different classes. We approxi-
mate the terms J j
data point with an expectation
of the empirical risk as: J j
all ≈ pjJ j,+ + J j,−(1 − pj). Here
J j,+ and J j,− denote the total risks when xj is labeled as
class 1 and class -1 respectively. These risks can be written
as sum of risks on labeled and unlabeled data as following:

all for the jth

J j,+ = J j,+

L + J j,+

U

and

J j,− = J j,−

L + J j,−

U

(6)

1This approximation can be used for any case, whether previ-

ously seen or unseen, provided the density p(x) does not change.

IJCAI-07

878

Equal Risk (R

 = 1, R

 = 1) & Equal Label Cost (C1 = 1, C2 = 1)

12

21

1.5

1

0.5

0

−0.5

−1

 = 1, R

12

21

 = 10) & Equal Label Cost (C1 = 1, C2 = 1)

Asymmetric Risk (R

1.5

1

0.5

0

−0.5

−1

Equal Risk (R

 = 1, R

12

21

 = 1) & Asymmetric Label Cost (C1 = 1, C2 = 1.25)

1.5

1

0.5

0

−0.5

−1

−1

−0.5

0

0.5

(a)

1

1.5

2

−1

−0.5

0

0.5

(b)

1

1.5

2

−1

−0.5

0

1

1.5

2

0.5

(c)

Figure 1: Selection of points to query for label based on the value of information. The circles represent the unlabeled cases and the radii
correspond to the VOI of labeling each case. The squares (class 1) and the triangles (class -1) represent previously labeled cases. The
different ﬁgures correspond to the following situations: (a) symmetry in the costs of both the risks and the labeling, (b) asymmetric risk, and
(c) asymmetric label costs. The cross corresponds to the selection of the next query. The curve denotes the decision boundary based on the
currently available labels.

To calculate these risks we ﬁrst compute pj,+, the resulting
posterior probability upon adding xj as a positively labeled
example in the active set. Now, using similar expressions to
equations 1 and 3 we can compute J j,+
U , the risks
on the labeled and the unlabeled data points when xj is as-
sumed to be positively labeled. The corresponding computa-
tions follow for J j,−
U as well. Similarly, we can use
expectation of Cj if costs of labeling vary by class.

L and J j,−

and J j,+

L

Thus, our strategy is to select cases for labeling that have

the highest VOI:

jsel = arg max
j∈U

V OI(xj )

(7)

We note that whenever V OI(xjsel ) is less than zero, we have
a condition where knowing a single label does not reduce the
total cost; thus, this situation can be employed as a stopping
criterion. Stopping criteria for open-world situations would
include the computation of gains in accuracy of the classiﬁer
over multiple uses, based on a probability distribution over
expected cases and the lifespan of the system. We note that
a greedy policy might indicate stopping when there is still
potential for further reduction of the overall cost via querying
a set of points.

We now demonstrate the approach, starting with illustra-
tions with a toy data set. We shall employ Gaussian Process
classiﬁcation (see section 4) within the active learning frame-
work. Figure 1 shows the selection of unlabeled points to
query based on the VOI criterion. The sample data consists
of two half moons in a multidimensional space, where the top
half belongs to class +1 and the bottom to the class -1. In the
simulation, we start with a few cases that are already labeled
and are represented as squares for class 1 and triangles for the
class -1. The different graphs in the ﬁgure correspond to dif-
ferent settings of risks (R12 and R21) and labeling costs. We
assume that C 1 and C 2 are the costs for querying points that
belong to class +1 and −1 respectively. The unlabeled points
are displayed as circles and the radii correspond to the VOI
of labeling these cases. The next case selected to be queried

is marked with a cross. Figure 1(a) shows the VOI for all the
unlabeled data points and the case selected for the next query
when the risks and the cost of labelings are equal for both
classes. For this situation, cases that are nearest to the deci-
sion boundary are associated with the highest VOI. Choosing
cases that minimize the objective for overall cost corresponds
to the selection of queries that would minimize the classiﬁ-
cation error; hence, the points at the decision boundary are
the ones that are the most informative. Figure 1(b) illustrates
the situation where it is far more expensive to misclassify a
point belonging to class -1. Due to this asymmetry in risks,
the points that are likely to belong to class -1, but that also lay
close to the decision boundary, have the highest VOI. Figure
1(c) depicts the situation where obtaining a label for a point
in class -1 is 1.25 times as expensive to obtain the label for
a point belonging to class 1. The VOI is highest for those
points that are more likely to belong to class 1 and that are
close to the decision boundary. The sample data set illustrates
how VOI can be used effectively to guide tagging supervision
such that it minimizes both the operational and training costs
of a classiﬁer.

We point out that we have assumed a closed system where
both the set of the labeled and the unlabeled data are avail-
able beforehand. Prior work on active learning includes stud-
ies that assume an open system, where the data points arrive
one at a time. The methods discussed in this paper can be
extended to handle the open system case by using the aver-
age empirical risk ( JL
n ) as a guiding principle as earlier used
by Zhu et al., 2003. Note that this is not a transductive learn-
ing framework; the ﬁnal classiﬁcation boundary depends only
on the labeled data. Both the labeled and the unlabeled data
points are used only to determine which cases to query. Once
trained, the classiﬁer can be applied to novel test points, be-
yond the original set of labeled and the unlabeled points. We
shall describe in Section 4.2 extensions to handle the trans-
ductive case by using a semi-supervised learning algorithm
to train the classiﬁer. Before that, we will pause to review
Gaussian Process classiﬁcation.

IJCAI-07

879

Table 1: Features extracted from voice messages

Prosodic features

Metadata information

(∗ includes max, min, mean and variance)

Duration of silence∗

Duration of voiced segment∗

Absolute pitch∗

Length of productive segment∗

Length of pause∗

Change in pitch during productive segments∗

Rate features (syllable, silence, productive segments, pauses)

Is Weekend?

Is AM on a work day?
Is PM on a work day?

Is after hours on a work day?

Size in bytes

Size in seconds

Is external caller?

4 Gaussian Process Classiﬁcation
In this work, we explore active learning with the use of Gaus-
sian Process (GP) classiﬁers. One of the advantages of using
GP classiﬁcation is that we directly model the predictive con-
ditional distribution p(t|x), consequently making it easy to
compute the actual conditional probabilities without any cal-
ibrations or post-processing. GP methods provide a Bayesian
interpretation of classiﬁcation. With the approach, the goal is
to infer the posterior distribution over the set of all possible
classiﬁers given a training set:

(cid:3)

p(w|XL, TL) = p(w)

p(ti|w, xi)

(8)

i∈L

Here, p(w) corresponds to the prior distribution over the clas-
siﬁers and is selected typically so as to prefer parameters w
that have a small norm. Speciﬁcally, we assume a spherical
Gaussian prior on the weights: w ∼ N (0, I). The prior im-
poses a smoothness constraint and acts as a regularizer such
that it gives higher probability to the labelings that respect
the similarity between the data points. The likelihood terms
p(ti|w, xi) incorporate the information from the labeled data
and different forms of distributions can be selected. A popu-
lar choice is the probit likelihood: p(t|w, x) = Ψ(t · wT x).
Here, Ψ(·) denotes the cumulative density function of the
standard normal distribution. The posterior prefers those pa-
rameters that have small norm and that are consistent with the
training data.

Computing the posterior, p(w|X , T ), is non-trivial and
approximate inference techniques such as Assumed Density
Filtering (ADF) or Expectation Propagation (EP) are typ-
ically required. The idea behind ADF is to approximate
the posterior p(w|XL, TL) as a Gaussian distribution, i.e.
p(w|XL, TL) ≈ N ( ¯w, Σw). Similarly, EP is another approx-
imate inference technique. EP is a generalization of ADF,
where the approximation obtained from ADF is reﬁned us-
ing an iterative message passing scheme. We refer readers to
Minka, 2001 for the details.

approximate

p(w|X , T )

∼
N ( ¯w, Σw), a frequent practice is to choose the mean
¯w of the distribution as the point classiﬁer. The mean, which
is also called the Bayes point, classiﬁes a test point according
to: sign( ¯wT x). It is relatively straightforward to generalize
to the non-linear case by using the kernel trick, where the
idea is to ﬁrst project the data into a higher dimensional
space to make it separable [Evgeniou et al., 2000].

Given

the

posterior

One of

the byproducts of using the GP classiﬁca-
tion framework is that we obtain a predictive distribution

p(sign(f (x))|x):

p(sign(f (x)) = 1|x) = Ψ(

(cid:4)

¯wT x

xT Σwx + 1

)

(9)

Unlike other classiﬁers, the GP classiﬁcation models the pre-
dictive conditional distribution p(t|x), making it easy to com-
pute the actual conditional probabilities without any calibra-
tions or post-processing. Probabilistic interpretations have
been made of other kernel classiﬁers such as SVM [Sollich,
1999] and other attempts that map the output of the classi-
ﬁers directly to the probability [Platt, 2000]. Our approach is
to use this predictive distribution in the selective-supervision
framework to compute expected risks and to quantify the
value of information.

4.1 Computational Issues

As mentioned earlier, ADF or EP can be used for approximate
inference in GP classiﬁcation. However, the proposed scheme
for selecting unlabeled points is computationally expensive.
Note, that computational complexity for EP is O(n3), where
n is the size of labeled training set. In the proposed method,
we have to compute VOI for every unlabeled data point, re-
quiring us to perform EP twice for every point under consid-
eration.

A faster alternative is to use ADF for approximating
rather than com-
the new posterior over the classiﬁer
puting EP. Speciﬁcally,
to compute the new posterior
pj,+(w|XL∪j, {TL ∪+1}) we can compute the Gaussian pro-
jection of the old posterior multiplied by the likelihood term
data point. That is: pj,+(w|XL∪j, {TL ∪ +1}) ≈
for the jth
N ( ¯wj,+, Σj,+
w ), where ¯wj,+ and Σj,+
w are respectively the
mean and the covariance of p(w|XL, TL) · Ψ(1 · wT xj).
This is equivalent to performing ADF starting with the old
posterior p(w|XL, TL) and incorporating the likelihood term
Ψ(1 · wT xj ) and does not require O(n3) operations to com-
pute VOI for every unlabeled data point. We can use similar
computations to approximate pj,−(w|XL∪j, {TL ∪ −1}).

4.2 From Supervised to Semi-Supervised Learning

The underlying classiﬁer in the proposed framework is based
on Gaussian Processes and it can be easily extended for the
semi-supervised case [Kapoor, 2006; Sindhwani et al., 2005].
Speciﬁcally, at the core in the GP classiﬁcation is the kernel
matrix K, where entry Kij encodes the similarity between
the ijth
data points. Rather than using K as the

and the jth

IJCAI-07

880

50

s
t

i

l

 

n
o
P
d
e
e
b
a
n
U
n
o

 

l

 
r
o
r
r

E

45

40

35

30

5

5

1050

1000

950

900

850

800

750

700

650

600

550

d
e
r
r
u
c
n

I
 
t
s
o
C

 
l

a

t

o
T

Caller Close / Not Close

Mobile / Non−Mobile

VOI

Random

Uncertainity

Entropy

s
t

i

l

 

n
o
P
d
e
e
b
a
n
U
n
o

 

l

 
r
o
r
r

E

VOI

Random

Uncertainity

Entropy

52

50

48

46

44

42

40

38

36

34

32

10

15

Number of Labeled Points

20

5

10

15

Number of Labeled Points

20

(a)

Caller Close / Not Close

(b)

Mobile / Non−Mobile

VOI

Random

Uncertainity

Entropy

VOI

Random

Uncertainity

Entropy

d
e
r
r
u
c
n

I
 
t
s
o
C

 
l

a

t

o
T

1050

1000

950

900

850

800

750

700

650

10

15

20

5

Number of Labeled Points

10

15

Number of Labeled Points

20

(c)

(d)

Figure 2: Comparison of different active learning schemes. Graphs (a) and (b) show the error on unlabeled points versus the number of
labels for classifying voicemails. Graphs (c) and (d) show the total cost incurred versus the number of labels. VOI criteria can provide good
classiﬁcation performance with signiﬁcantly lower costs. The results are averaged over 20 runs and the error bars represent the standard error.

similarity matrix for GP classiﬁcation, we can use the inverse
of the transformed Laplacian:

routing of email messages with statistical classiﬁers [Horvitz
et al., 1999].

r(Δ) = Δ + σI where Δ = D − K

(cid:5)

Here, D is the diagonal matrix where the diagonal elements
j Kij and σ > 0 is added to remove the zero
are: Dii =
eigenvalue from the spectrum of r(Δ).
Intuitively, rather
than computing similarity directly via the kernel Kij, the
inverse of the transformed Laplacian computes the similar-
ity over a manifold. Thus, the unlabeled data points help
in classiﬁcation by populating the manifold and using the
similarity over the manifold to guide the decision bound-
ary. The extension of GP classiﬁcation to handle semi-
supervised learning has been recently studied [Kapoor, 2006;
Sindhwani et al., 2005] and is related to the graph-based
methods for semi-supervised learning. The rest of the active
learning framework can be used as it is on top of this semi-
supervised GP classiﬁcation framework.

5 Sample Challenge: Classifying Voicemail
We shall now move to a challenging classiﬁcation task that
highlights the value of employing the selective supervision
methods. Speciﬁcally, our goal is to build a system that can
classify voice messages in several ways, including whether
the messages are urgent vs. non-urgent, the caller is person-
ally close vs. not close to the person being called, and to
detect if the caller is calling from a mobile phone. The classi-
ﬁcation task is related to prior work on the prioritization and

Given a set of voice messages, we ﬁrst extract features that
promise to be of value in discriminating among the target
classes. Speciﬁcally, we look at the prosody and metadata
that accompanies the messages.
Prosodic features: We consider multiple prosodic features
including syllable rate, pause structure, and pitch dynamics.
We employ a pitch tracker and then extract the prosodic fea-
tures summarized in table 1.
Message metadata: We also extract metadata from the voice
messages. Speciﬁcally, we extract features that indicate the
day and the time of the call. Additionally, we consider the
size of the voicemail in bytes as well as the length of the
message in seconds. We also extract features that indicate
whether the caller is calling from outside the recipient’s orga-
nization. Several metadata features are shown in table 1.

We now explore the selective supervision concepts applied
to the voicemail classiﬁcation challenge. The data set con-
sists of 207 labeled voice messages received by a single user
over a period of 8 months. We explore the use of the methods
to guide the labeling efforts for supervised classiﬁcation. An-
notating a voicemail is tedious and shorter voicemails can be
labeled more quickly than the longer ones. Thus, we use the
asymmetric cost criterion where the cost of a label scales with
the length of the voicemail. Speciﬁcally, we assume that the
cost of labeling voicemail is 0.01 US dollars per second of
message length. Further, for all of the experiments we assume

IJCAI-07

881

Table 2: Average accuracy (standard error) on the unlabeled points
and on the total cost when starting with one labeled point per class
and choosing 20 other points. The bold ﬁgures indicate signiﬁcant
performance difference with 95% conﬁdence.

Task

Accuracy

Close?
Mobile?
Urgent?

VOI

Random

72.9±0.8 67.8±1.1
66.9±1.0 63.0±1.4
53.2±0.5 53.2±0.6

Cost

VOI

Random

518.5±14.9 635.0±20.8
632.2±19.5 727.6±26.8
899.5±10.1 913.0±12.7

that misclassiﬁcation costs R12 = R21 = 10 US dollars. For
Gaussian Process classiﬁcation, the polynomial kernel of de-
gree 2 is used.

We compare the selective-supervision strategy in super-
vised learning with three other schemes: 1) selecting points
randomly, 2) choosing the point where the classiﬁcation is
most uncertain (i.e., jsel = arg minj∈U |pj − 0.5|) and 3)
choosing the point that is likely to change the posterior over
w the most [MacKay, 1992; Lawrence et al., 2002], i.e.,
jsel = arg maxj∈U pjΔj,+ + (1 − pj)Δj,−. Here, Δj,+
and Δj,− are the differential entropy scores [Lawrence et al.,
2002] when jth
point is added as a positively and a nega-
tively labeled point in the training set respectively. The term
being maximized quantiﬁes the expected change in the poste-
rior over w when point xj is added to the training set.

Graphs (a) and (c) in Figure 2 compare the different ac-
tive learning schemes on the task of detecting if the caller is
personally close to the person being called. Similarly, graphs
(b) and (d) in Figure 2 show the plots for the task of classi-
fying whether the voice messages originated from a mobile
phone. For the studies, results are averaged over 20 runs,
where, for each run, we select one case per class as labeled
and the rest of the points are selected according to the dif-
ferent active learning policies. Note, that, in the beginning,
when there are a very few labeled data points, it is difﬁcult
to estimate the misclassiﬁcation risk (RL + RU ). However,
with increasing numbers of labeled cases, the Gaussian Pro-
cess classiﬁcation will typically provide a better estimate of
the posterior p(sign(f (x) = 1|w, x).

We found that the VOI policy results in signiﬁcant gains
over the other methods, both in terms of the accuracy as well
as the cost. Table 2 shows the average classiﬁcation accuracy
and the standard error on the unlabeled data points together
with the total cost (the sum of the misclassiﬁcation and train-
ing costs) incurred after querying 20 points guided by the VOI
criterion and random selection policy. As indicated by the
results, the VOI criterion provides signiﬁcant gains over ran-
dom sampling in terms of cost and accuracy for classifying
messages as personally close versus not close and mobile ver-
sus non-mobile. The VOI criterion for selective supervision
provides valuable guidance on labeling efforts under budget
constraints. We found that the gain with the use of VOI was
not signiﬁcant for detecting urgency. We hypothesize that this
is due to the poor separability of the data.

6 Conclusion

We have investigated a decision-theoretic approach to classi-
ﬁcation, focusing on the use of value of information as the ba-

sis for guiding supervision. We showed how the risks of mis-
classiﬁcation and cost of obtaining labels can be used to quan-
tify the value of querying for labels of unknown cases. We
applied and tested the ideas within the Gaussian Process clas-
siﬁcation framework. Finally, we reviewed results obtained
from applying the methods to the task of building predictive
models for classifying voice messages, where the cost of la-
beling a voicemail scales with the length of messages. We are
continuing to explore challenges with the efﬁcient computa-
tion of VOI and with studying the value of using the methods
in triaging labeling effort in selective supervision.

References
[Evgeniou et al., 2000] T. Evgeniou, M. Pontil, and T. Poggio. Reg-
ularization networks and support vector machines. Advances in
Computational Mathematics, 13(1):1–50, 2000.

[Freund et al., 1997] Y. Freund, H. S. Seung, E. Shamir, and
N. Tishby. Selective sampling using the query by committee al-
gorithm. Machine Learning, 28(2-3), 1997.

[Horvitz and Paek, 2007] E. Horvitz and T. Paek. Complemen-
tary computing, User Modeling and User-Adapted Interaction 17.
Special Issue on Statistical and Probabilistic Methods for User
Modeling, 2007.

[Horvitz et al., 1999] E. Horvitz, A.

and D. Hovel.
Attention-sensitive alerting. In Uncertainty in Artiﬁcial Intelli-
gence, 1999.

Jacobs,

[Kapoor, 2006] A. Kapoor. Learning Discriminative Models with
Incomplete Data. PhD thesis, Massachusetts Institute of Tech-
nology, 2006.

[Lawrence et al., 2002] N. Lawrence, M. Seeger, and R. Herbrich.
Fast sparse Gaussian process method: Informative vector ma-
chines. Neural Information Processing Systems, 15, 2002.

[MacKay, 1992] D. MacKay.

Information-based objective func-
tions for active data selection. Neural Computation, 4(4), 1992.

[McCallum and Nigam, 1998] A. K. McCallum and K. Nigam.
Employing EM in pool-based active learning for text classiﬁca-
tion. In International Conference on Machine Learning, 1998.

[Minka, 2001] T. P. Minka. A Family of Algorithms for Approxi-
mate Bayesian Inference. PhD thesis, Massachusetts Institue of
Technology, 2001.

[Muslea et al., 2002] I. Muslea, S. Minton, and C. A. Knoblock.
Active + semi-supervised learning = robust multi-view learning.
In International Conference on Machine Learning, 2002.

[Platt, 2000] J. C. Platt. Probabilities for support vector machines.

Advances in Large Margin Classiﬁers, 2000.

[Sindhwani et al., 2005] V. Sindhwani, W. Chu, and S. S. Keerthi.
Semi-supervised Gaussian processes. Technical Report YRL-
2005-60, Yahoo! Research Labs, 2005.

[Sollich, 1999] P. Sollich. Probabilistic methods for support vector

machines. Neural Information Processing Systems, 12, 1999.

[Tong and Koller, 2000] S. Tong and D. Koller. Support vector ma-
chine active learning with applications to text classiﬁcation. In
International Conference on Machine Learning, 2000.

[Zhu et al., 2003] X. Zhu, J. Lafferty, and Z. Ghahramani. Combin-
ing active learning and semi-supervised learning using gaussian
ﬁelds and harmonic functions. In Workshop on The Continuum
from Labeled to Unlabeled Data in Machine Learning and Data
Mining at ICML, 2003.

IJCAI-07

882

