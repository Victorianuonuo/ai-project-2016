On Mining Closed Sets in Multi-Relational Data

Gemma C. Garriga

∗

†
Roni Khardon

‡
Luc De Raedt

Dept. of Computer Science

Dept. of Computer Science

Machine Learning Lab

Uni. Polit`ecnica de Catalunya, Spain

Tufts University, USA

University of Freiburg, Germany

garriga@lsi.upc.edu

roni@cs.tufts.edu

luc.deraedt@cs.kuleuven.be

Abstract

We investigate the problem of mining closed sets
in multi-relational databases. Previous work in-
troduced different semantics and associated algo-
rithms for mining closed sets in multi-relational
databases. However, insight into the implications
of semantic choices and the relationships among
them was still lacking. Our investigation shows that
the semantic choices are important because they
imply different properties, which in turn affect the
range of algorithms that can mine for such sets. Of
particular interest is the question whether the sem-
inal LCM algorithm by Uno et al. can be upgraded
towards multi-relational problems. LCM is attrac-
tive since its run time is linear in the number of
closed sets and it does not need to store outputs
in order to avoid duplicates. We provide a posi-
tive answer to this question for some of the seman-
tic choices, and report on experiments that evaluate
the scalability and applicability of the upgraded al-
gorithm on benchmark problems.

1 Introduction

The problem of mining frequent itemsets has been a topic of
intensive research (see e.g. [Agrawal et al., 1996; Goethals
and Zaki, 2004; Han et al., 2000]). Since the number of
such sets is huge, it is common and more efﬁcient to re-
strict the search to closed item-sets [Bastide et al., 2000;
Zaki, 2004], where a set is closed if all its supersets have
strictly lower frequency in the database. The collection of fre-
quent closed sets contains the same information as the overall
collection of frequent item-sets, but is much smaller. There
is also a growing interest in mining structured data, such as
graphs, and more generally multi-relational databases, and
the notion of closed sets has also been imported to this
richer setup [De Raedt and Ramon, 2004; Yan and Han,
2003]. However, there is no general agreement on an ap-
propriate semantics for closed multi-relational patterns as

∗

Partly supported by MECD, Spanish goverment, through grant

AP2000-4016, and by an EU IHP Marie Curie Fellowship.

Partly supported by NSF Grant IIS-0099446, and by a Research

Semester Fellowship Award from Tufts University.

†

‡

Partly supported by the EU IST FET project IQ. Now at the

Katholieke Universiteit Leuven.

there exist various possible settings. Some approaches em-
ploy θ-subsumption (subgraph homomorphism in the graph
[Dehaspe
setting) to deﬁne the frequency of patterns, e.g.
and Toivonen, 2000] but others employ object identity sub-
sumption (subgraph isomorphism) [Malerba and Lisi, 2001;
Nijssen and Kok, 2003]. Another variation exist between
mining in a single interpretation (graph), or across multiple
interpretations. Finally, some authors (e.g. [De Raedt and
Ramon, 2004; De Raedt and Dehaspe, 1997]) restrict the im-
plication relation used in deﬁning closures to range-restricted
clauses only. In addition to these differences, the notion of a
closed set can be coupled with a closure operator that takes a
set and calculates its closure and there is more than one way
to deﬁne such closures. The literature gives the impression
that these different choices are unimportant and that algorith-
mic issues can be studied independently of the semantics. Our
investigation shows that this impression is false and that se-
mantics do matter.

Our investigation follows a seminal paper by Uno et al.
[2004] who utilized semantic properties in the itemset case
to provide a very effective enumeration algorithm for closed
sets, named LCM (Linear time Closed pattern Miner). In this
paper, we systematically explore the different semantics for
mining closed sets in multi-relational databases, and study
their effect on the applicability of LCM. Our results identify
three types of behaviors that can arise as follows.

First, some deﬁnitions specify when a set is closed but
make it hard to specify a closure operator. This is the case
for the deﬁnitions used in CloseGraph [Yan and Han, 2003]
and Farmer [Nijssen and Kok, 2003]. As a result this setting
is limited to methods that search by applying reﬁnements (in
BFS or DFS mode) until a closed set is found.

Secondly, stronger deﬁnitions can specify a closure op-
erator yielding unique closures.
In this case one can enu-
merate closed sets by iteratively extending other closed sets
(their “parent”), so that the search is more focused. This
can be done in the setting of Warmr [De Raedt and Ramon,
2004; Dehaspe and Toivonen, 2000] and Jimi [Maloberti and
Suzuki, 2003], which follow normal ﬁrst order logic seman-
tics. For this setting, we contribute such an enumeration algo-
rithm generalizing LCM. However, just like the simple algo-
rithms, this algorithm must store previously discovered sets
to avoid duplicates in the output inducing a serious memory
requirement.

Finally, some deﬁnitions provide unique closures such that
each closed pattern has a unique “parent” closed pattern. This

IJCAI-07

804

is the case for the Claudien [De Raedt and Dehaspe, 1997]
setting, whose semantics is speciﬁed using substitutions to
variables in a clause. For this case, we provide a full general-
ization of the LCM algorithm of Uno et al. [2004] that does
not need to store previous sets.

Due to space constraints most proofs and some details are

omitted from the paper.

2 Problem Deﬁnition and Basic Insights

The problems we consider assume that we have a given
database DB, a language of patterns L and a notion of
“frequency” measuring how often a pattern occurs in the
database. Our databases and pattern are expressed in logi-
cal notation. We assume some familiarity with basic notions
of logic [Lloyd, 1987] but the following introduces some no-
tation and terminology.

An atom is an expression of the form p(t1, . . . , tn) where
p is a relation of arity n and each ti is a term, i.e. a constant
or a variable. This paper employs conjunctions a1 ∧ · · · ∧ an
as data (where terms in the atoms are concrete objects) which
we will refer to as interpretations. Conjunctions also serve as
patterns (where terms can be variables) which are sometimes
referred to as queries. Notice that when all relations are of
arity 0, conjunctions correspond to item-sets. Notice also that
if we only have one binary predicate, we can consider it as
capturing the edge relation of a graph, so graphs and graph
patterns form another special case of relational patterns.

We shall represent conjunctions in list notation, i.e. as
[a1, . . . , an]. For a conjunction C and atom p, by [C, p] we
refer to the conjunction that results from adding p after the
last element of C. For a conjunction C and index i, C[i]
[a1, . . . , ai]. A substitution θ =
is the preﬁx of C, i.e.
{V1/t1, . . . , Vn/tn} maps variables to terms. The result of
applying a substitution θ to an expression C is the expression
Cθ where all variables Vi have been simultaneously replaced
by their corresponding term ti in θ.

2.1 Semantics and Frequent Sets

To relate the data to a query, we employ subsumption. Within
inductive logic programming, two notions are popular:

θ-subsumption ([Plotkin, 1970]): C1 θ-subsumes C2 if and

only if there exists a substitution such that C1θ ⊆ C2.

OI-subsumption ([Malerba and Lisi, 2001]): C1 OI-
subsumes C2 if and only if there exists a substitution
θ = {V1/c1, . . . , Vn/cn} such that C1θ ⊆ C2 and the ci
are different terms not occurring in C1.

We will refer to both cases as subsumption, denoted as
C1 (cid:4) C2. When we want to identify the substitution witness-
ing the subsumption we say that C1 (cid:4) C2 via substitution θ.
Applied to graphs, the former notion corresponds to subgraph
homomorphism; the latter one to subgraph isomorphism.

Two forms of databases will be considered. In the learning
from (multiple) interpretations (LI) setting, the database con-
tains a set of interpretations. In this case the natural notion of
coverage is

coversLI (C, DB) = {D ∈ DB|C (cid:4) D}

where each interpretation contributes one element to the
cover set.

In the single interpretation (SI) setting, the database is a

single conjunction and the natural notion of coverage is

coversSI (C, DB) = {θ|C (cid:4) DB via substitution θ}

Notice that here the cover set includes substitutions and
not interpretations. In both deﬁnitions (cid:4) can be either of the
notions of subsumption given above.

We now have four different semantics. The LI-θ setting
learns from interpretations using θ-subsumption. This closely
corresponds to the setting employed by Warmr [Dehaspe and
Toivonen, 2000] and Jimi [Maloberti and Suzuki, 2003]. The
LI-OI employs OI-subsumption instead and is employed by
CloseGraph [Yan and Han, 2003] and Farmer [Nijssen and
Kok, 2003]. Finally, the SI-θ and SI-OI settings learn from a
single interpretation only. As we shall see, SI-θ closely corre-
sponds to Claudien’s setting [De Raedt and Dehaspe, 1997].
The problem of ﬁnding frequent queries is that of ﬁnding
all queries C ∈ L whose frequency f req(C, DB) ≥ t for
some ﬁxed threshold t. The natural notion for frequency is
f req(C, DB) = |covers(C, DB)|. It is easy to see that fre-
quency is anti-monotonic for the LI setting, i.e. adding an
atom to a conjunction can only decrease the frequency. This
important property is used by all frequent set miners.
Remark 1 f req(C, DB) is not anti-monotonic for
SI setting.
which subsumes
[q(a), p(a, b), p(a, c)],
[q(X), p(X, Z)] has two substitutions.

the
the query [q(X)]
For
interpretation
[q(X)] has one substitution but

To see this, consider

[q(X), p(X, Z)].

Therefore, for the SI setting, we use the notion of relative fre-
quency deﬁned as relf req(C, DB) = f req(C, DB)/|D|v
,
where D is the domain (i.e. the set of constants) and v the
number of variables appearing in C. Relative frequency is in-
tuitively appealing and it is anti-monotonic for the SI setting.

Remark 2 Note that
if we have data from the LI set-
ting we can modify it slightly and interpret it in the SI
setting.
This is a standard transformation in Inductive
Logic Programming. For example consider a dataset with
two interpretations I1 = [p(a), q(a, b), q(a, c)] and I2 =
[p(d), q(e, f )]. We add an identiﬁer argument to each pred-
icate and collapse the data into one interpretation: DB =
[p(i1, a), q(i1, a, b), q(i1, a, c), p(i2, d), q(i2, e, f )]. It is easy
to see that f reqLI (C, DB) = |coversLI (C, DB)| is anti-
monotonic in this case. Therefore in this case we have a
choice of frequency criterion to use.

2.2 Closures

Finding frequent item-sets is a special case of frequent pat-
tern mining in the LI case. When mining frequent item-
sets many patterns are redundant, and therefore one is typi-
cally interested in closed patterns. Indeed, consider the item-
sets [a, d, e], [a, c, d], [b, c] and [b, d]. Then f req([a], DB) =
f req([a, d], DB) = 2. The item a is said to imply d (w.r.t.
the database). Therefore, we deﬁne:

IJCAI-07

805

Deﬁnition 3 A conjunction C implies an atom p in the
database DB, denoted DB |= C → [C, p], if and only if
covers(C, DB) = covers([C, p], DB).
The rules of the form C → [C, p] denote relational associa-
tion rules that hold with 100 per cent conﬁdence. They are to
be understood as implications that are satisﬁed by all conjunc-
tions in the database. These expressions correspond to the re-
lational association rules, also called query extensions, intro-
duced in Warmr [Dehaspe and Toivonen, 2000]. In case the
database consists of a single interpretation only, it does not
make sense to allow for atoms p that contain variables that do
not appear in C. The reason is that the resulting substitutions
are not comparable, cf. also Remark 1. Therefore, in this case
one imposes the range-restriction requirement [De Raedt and
Ramon, 2004], which states that p only contains variables and
constants appearing in C. The resulting expression can then
be simpliﬁed to a (range-restricted) clause C → p and cor-
responds to the pattern type induced by Claudien [De Raedt
and Dehaspe, 1997].

In the itemset case the closure of a set of items I is deﬁned
as the set of items whose existence in a tuple is implied by
the existence of I. Continuing our illustration, one can ver-
ify that the closure of [a] w.r.t. the speciﬁed tuples is [a, d].
An alternative characterization of closed item-sets states that
the closure of an item-set I corresponds to the intersection of
all tuples in the database subsumed by the item-set I [Zaki,
2004]. Note that intersecting item-sets corresponds to com-
puting the minimally general generalizations of two patterns.
This will also play an important role in our work.

The item-set case motivates the iterative closure proce-
dure (ICP) deﬁned below. Note that this procedure em-
ploys a reﬁnement operator ρ which computes atoms p to
be added to the conjunction. Notice also that the condition
DB |= C (cid:2) → p can be interpreted according to the four dif-
ferent semantics.

closure(input: pattern C = q1, . . . , qn;ρ: ref. operator)
1 C (cid:2) ← C
2
repeat
3
4
5
6

Find an atom p ∈ ρ(C (cid:2)) s.t. DB |= C (cid:2) → p
C (cid:2) ← [C (cid:2), p]

until no such atom is found

output C (cid:2)

We ﬁrst consider a general reﬁnement operator ρG that im-
poses no restrictions on p other than that p (cid:9)∈ C (cid:2). Some of our
theorems below using the normal form require the following
syntactic version for the input and output of the reﬁnement
operator. We will assume that C (cid:2) uses variables x1, . . . , xm
for some m and that new variables introduced form a contigu-
ous sequences starting with xm+1. This does not change the
semantics and does not restrict the form of reﬁnements so we
still refer to this case as ρG. Until Section 4 we assume that
ICP uses ρG. The following notion is natural:

Deﬁnition 4 (Closed conjunctions of atoms) A conjunc-
tion C is closed if closure(C) = C.

The ICP algorithm deﬁnes closure in a non-deterministic way
that may depend on the order of atom additions. Depending

on the semantics, the properties of ICP may vary. In partic-
ular, the result may or may not be unique, or the algorithm
may not always terminate, in which case the result would not
be well deﬁned.

Example 5 Consider using θ-subsumption and the dataset
[R1(1, 2), R1(2, 1)]. Then the pattern R1(x1, x2) implies
[R1(x1, x2), R1(x2, x3)] as well as [R1(x1, x2), R1(x2, x3),
R1(x3, x4)] and so on. So we can add a chain of any size,
the closure is not ﬁnite in size, and the procedure may not
terminate.

Therefore, under θ-subsumption, it is necessary to restrict the
atoms that can be added to the initial conjunction. Section 3
gives a solution that gets around this problem by abstracting
the properties of the item-set case from a different perspec-
tive. Section 4 gives a different solution for the SI setting.

Before presenting these, we brieﬂy consider the LI-OI set-
ting used in CloseGraph [Yan and Han, 2003] and Farmer
[Nijssen and Kok, 2003]. Here the closure procedure is guar-
anteed to terminate but the results need not be unique:

Example 6 Consider the two conjunctions:

[e(1, 2, a), e(2, 3, b), e(3, 4, d), e(4, 5, a), e(5, 6, c)]
[e(11, 12, a), e(12, 13, b), e(12, 14, c)]

This database represents two edge-labeled graphs, and we
consider calculating the closure of C = e(N1, N2, a). Then
ICP may add e(N2, N3, b) to get the closed set [e(N1, N2, a),
e(N2, N3, b)]. On the other hand it can add e(N2, N3, c) to
get the closed set [e(N1, N2, a), e(N2, N3, c)].

2.3 Normal Form

Most relational frequent pattern mining algorithms employ a
normal-form based on an ordering of patterns to avoid investi-
gating the same pattern more than once. We use the following
order similar to Nijssen and Kok [2003]. We assume that the
predicates and constants are ordered (e.g. alphabetically). In
addition, we employ a special set of variables z1, z2, z3, . . .,
ordered according to their index, and impose that all constants
are smaller than these variables. An order over atoms is then
induced by the order over lists composed by the predicate
name as ﬁrst element and its list of arguments following that.
An order over conjunctions is induced by the order over lists
where the atoms in the conjunction are listed in order.
Deﬁnition 7 (Normal form) The normal form nf(C) of a
conjunction C over variables x1, . . . , xu is Cθ where θ is (1)
a one to one substitution from x1, . . . , xu to new variables
z1, . . . , zu and (2) Cθ is minimal in the order of conjunctions
for substitutions of type (1).

Clearly the normal form of every conjunction is unique. The
normal form also satisﬁes the following useful properties.
Lemma 8 Let C = [q1, q2, . . . , qn] be a conjunction in nor-
mal form. (i) For any i ≤ n, [q1, . . . , qi] is in normal form.
(ii) For any i < n and any subset of indices i < j1 < j2 <
. . . < jk ≤ n, [q1, . . . , qi] is a preﬁx of the normal form of
[q1, . . . , qi, qj1 , . . . , qjk

].

IJCAI-07

806

3 LI-θ: the lgg Closure

One way to deﬁne closures in the item-set case is by inter-
secting the covered tuples. The equivalent in the LI-θ set-
ting is to apply the well-known lgg operator introduced by
Plotkin [1970]. The lgg of s1, s2 is a conjunction of atoms
s that θ-subsumes both s1 and s2 i.e. s (cid:4) s1, and s (cid:4) s2,
and in addition for any other conjunction s(cid:2) that θ-subsumes
both s1, s2 it holds that s(cid:2) (cid:4) s. Plotkin [1970] proved that
the lgg is well deﬁned and provided an efﬁcient algorithm
for calculating the lgg of two conjunctions. Note that we do
not reduce the lgg. For sets of more than two conjunctions we
simply calculate the lgg by iteratively adding one conjunction
at a time. The result of this process is unique up to variable
renaming regardless of the order of adding the conjunctions.
The downside here is that, since the size of the lgg may grow
as the product of the sizes of the input conjunctions, the total
size may grow exponentially in the number of conjunctions.

Deﬁnition 9 (lgg closure) Let C be a conjunction and DB a
database, then closureLGG(C) = lgg(coversLI (C, DB)).

We note that a generalization of LCM using the idea of lgg is
reported in [Arimura and Uno, 2005]. Their setting however
is specialized to ordered tree patterns with a matching rela-
tion that corresponds to OI subsumption. Interestingly in this
setting the size of the lgg is always small.

We now employ Formal Concept Analysis (FCA) [Ganter
and Wille, 1998] to show that the lgg closure produces a Ga-
lois connection. We consider the formal context (2DB, L)
where L is the set of possible conjunctions, with the par-
, and (cid:4) on L. We deﬁne ψ(C) =
tial orders ⊆ on 2DB
coversLI (C, DB) and φ(S) = lgg(S) where C ∈ L and
S ⊆ DB.

Theorem 10 The mappings (φ, ⊆) and (ψ, (cid:4)) form a Galois
connection. More speciﬁcally, (1) S ⊆ S (cid:2) ⇒ φ(S (cid:2)) (cid:4) φ(S);
(2) S ⊆ ψ(φ(S)); (3) C (cid:4) C (cid:2) ⇒ ψ(C (cid:2)) ⊆ ψ(C); and (4)
C (cid:4) φ(ψ(C)).

Theorem 11 The compositions (cid:2)Δ = ψ · φ and Δ = φ · ψ
are closure operators. That is, they satisfy monotonicity
(C (cid:4) C (cid:2) ⇒ Δ(C) (cid:4) Δ(C (cid:2)), extensivity (C (cid:4) Δ(C)), and
idempotency (Δ(Δ(C)) = Δ(C)).

Using this result, closed conjunctions can be formalized as
those coinciding with their closure, that is, Δ(C) = C. The
result also establishes that for any set of interpretations S of
the database, there is a unique conjunction (up to subsump-
tion equivalence) that is the most speciﬁc conjunction satis-
ﬁed in S. Moreover, the number of closed queries is ﬁnite, as
is the number of interpretations in our database DB.

We now develop an algorithm RelLCM1 that upgrades the
ﬁrst algorithm in Uno et al. [2004] to the LI-θ case. We need a
notion of closure extension that allows us to go directly from
one closed conjunction to another.

Deﬁnition 12 (Closure extension) A conjunction C (cid:2) is an
extension of a conjunction C if C (cid:2) = closureLGG([C, p]) for
p ∈ ρG(C).

RELLCM1(input: closed pattern C)
1 if C is not frequent then return
2 if C is already in closed pattern table then return
3 store C in closed pattern table
4 output C
5 for all reﬁnements p ∈ ρG(C)
6
7
8
9
10
11 return

if coversLI ([C, p]) = ∅
or coversLI ([C, p]) = coversLI (C)
then skip reﬁnement
else Calculate C (cid:2) = nf(closureLGG([C, p]))

RELLCM1(C (cid:2))

RelLCM1 stores all previously discovered closed sets in a
table and in this way avoids calling the procedure twice on
the same set. It uses depth ﬁrst search. Each closed conjunc-
tion is reﬁned in all possible ways and closed. The algorithm
checks whether the resulting closed set was already discov-
ered, and if not it is output and further reﬁned to identify
more closed conjunctions. The algorithm is started by call-
ing RELLCM1(closure(∅)). Clearly every conjunction out-
put by the algorithm is closed. The following theorem guar-
antees completeness, that is, that every closed conjunction is
output by the algorithm.
Theorem 13 If C (cid:9)= ∅ is a closed conjunction in normal
form, then there is a closed conjunction C (cid:2) and a literal
p ∈ ρG(C (cid:2)) such that C = nf(closureLGG([C (cid:2), p])).

Clearly, in any run of the algorithm the number of calls to
RelLCM1 is exactly the number of closed sets. While the
number of calls is linear we do discover some patterns more
than once. The maximum number of patterns discovered is
bounded by the branching factor of the reﬁnement operator
times the number of closed sets.

4 SI: Range Restricted Closures
We now consider the SI setting (both under θ- and OI sub-
sumption). As argued in Section 2.2 we need to impose
range-restriction when deﬁning the closures. Thus the ICP
algorithm employs the operator ρRR(C) that can only gener-
ate atoms containing terms already occurring in C.
Deﬁnition 14 (Range restricted closure) closureRR(C) =
closure(C, ρRR).
The next lemma shows that closureRR(C) is well behaved:
Lemma 15 For any conjunction C and atoms p, q, if DB |=
C → p then DB |= [C, q] → p.
To get a complete generalization of LCM we need to ensure
that each conjunction has a unique parent. Then the algo-
rithm does not need to store the enumerated conjunctions in
order to avoid duplicates as in RelLCM1. Therefore, we need
a more reﬁned notion of closure extension. The following
generalizes the corresponding ideas from [Uno et al., 2004].

Deﬁnition 16 (Core preﬁx) Let C be a conjunction in nor-
mal form. The core preﬁx core(C) of C is the least preﬁx pr
of nf(C) such that covers(pr, DB) = covers(nf(C), DB).
Notice that since we are working in the SI setting, if the cov-
ers are the same then pr and C must have the same variables.

IJCAI-07

807

Deﬁnition 17 (Preﬁx preserving closure extension) Let
C = [q1, . . . , qn] be a closed conjunction in normal form. A
conjunction C (cid:2) is a ppc-extension of C if:
P1: C (cid:2) = nf(closureRR([C, p])) with p ∈ ρG(C), i.e. C (cid:2)
is obtained by adding the atom p to C, taking the closure of
[C, p] and normalizing.
P2: The atom p satisﬁes p > q, for all q ∈ core(C). Note
that because C is in normal form this only requires to check
that p is larger than the last atom q in core(C).
P3: The normal form operation deﬁning C (cid:2) does not change
any of the variables in C and p. That is, the normal form may
reorder atoms but may not rename atoms in [C, p].
P4: Let C[j] = q1, . . . , qj be the preﬁx of C up to qj, where
qj is the largest atom in C s.t. qj < p. Then, [C[j], p] is a
preﬁx of C (cid:2). This means that the core preﬁx is preserved and
that no new atom can appear between p and qj.

The following statements show that closures and cores are
well-behaved, and that ppc-extensions deﬁne unique parents.
Lemma 18 Consider any conjunction C in normal form,
any subset C (cid:2) ⊆ C \ core(C), and any atom p
/∈
(1) closureRR(C) ⊆ closureRR([C, p]).
closureRR(C).
(2) closureRR([C, p]) = closureRR([core(C), p]) =
closureRR([core(C), C (cid:2), p]).

It is worth noting that part (2) of the lemma above is vio-
lated by the lgg closure: in some cases coversLI ([C, p]) (cid:9)=
coversLI ([core(C), p]) and the closures are different.
Theorem 19 (1) Let C be a closed conjunction and C (cid:2) a ppc-
extension of C obtained as in condition (P1) in Deﬁnition 17.
Then core(C (cid:2)) = [C[j], p] where C[j] is given by condition
(P4) in Deﬁnition 17 . (2) Let C (cid:2) be a closed conjunction in
normal form. Let T = core(C (cid:2)) = [L, p] (that is, L is a con-
junction and p is the last atom in T ). Let C1 = closureRR(L)
and let C = nf(C1). Then C (cid:2) is a ppc-extension of C and C
is the only conjunction for which this holds.

There is one further caveat to consider: the set of closed
patterns can be inﬁnite since adding a variable changes the
semantics of the conjunction. Therefore one should employ
a “depth bound” on the patterns searched for. The algorithm
below is started by calling RELLCM2(closure(∅)).
RELLCM2(input: closed pattern C = q1, . . . , qn)
1 if C violates depth bound then return
2 if C is not frequent then return
3 output C
4 for all reﬁnements [C, p] with p ∈ ρG(C)
5
6
7
8
9
10
11
12
13 return

and s.t. p is greater than all atoms in core(C)
if coversSI ([C, p]) = ∅
then skip reﬁnement
else Calculate C (cid:2) = nf(closureRR([C, p]))

Let C[j] = [q1, . . . , qj], where

[qj is largest atom in C with qj < p]

if [C[j], p] is a preﬁx of C (cid:2)

then RELLCM2(C (cid:2))

As in the previous section the number of calls to RelLCM2
is exactly the number of closed sets. Notice that the ppc-
extension restriction reduces the branching factor as well. Fi-

min
freq.
0.9
0.7
0.5
0.3
0.1
0.0

# closed

142 (490 s)
248 (493 s)
561 (658 s)
1206 (992 s)
2243 (1008 s)
3443 (1025 s)

RelLCM2

# freq

743 (391 s)
1297 (499 s)
3247 (723 s)
9743 (1023 s)

-
-

CF%
80.8
80.8
82.7
87.6

-
-

# closed
96 (5 s)
159 (8 s)
358 (18 s)
756 (29 s)
1601 (57 s)
2808 (97 s)

RelLCM2-OI

# freq

483 (302 s)
747 (392 s)
1761 (605 s)
3647 (726 s)
7456 (827 s)
19224 (922 s)

CF%
80.1
78.7
79.6
79.2
78.5
85.3

Table 1: Effect of decreasing the minimum frequency thresh-
old for NCTRER (with up to 4 variables in patterns and a
maximum depth bound of 7).

nally we note that the results of this section hold for both the
SI-OI and SI-θ settings.

5 Experimental Evaluation

We now present an empirical evaluation of the RelLCM2 al-
gorithm on two datasets.1 All experiments were run in a PC
Pentium IV EM64T 3.2MHz under Linux 10.0.

The ﬁrst dataset is the NCTR Estrogen Receptor Binding
Database (NCTRER), containing 232 molecules, including
bond structures.2 Since each molecule is a separate structure
this is natural for the LI setting so the data can be viewed as
DB = {d1, ..., dn}. However as discussed in Remark 2 we
can embed it as data for the SI setting suitable for RelLCM2.
When doing this we can use |coversLI (C, DB)| as our no-
tion of frequency but still use the proper coversSI (C, ∪idi)
for implication and closure calculation.

We ﬁrst investigate the effect of increasing the frequency
threshold for the NCTRER dataset where patterns may con-
tain at most 4 variables and depth bound of 7. Table 1 sum-
marizes the results for RelLCM2 and RelCLM2 under ob-
ject identity (RelLCM2-OI). The table reports the number of
patterns in each case and the associated run time in paren-
theses. The table also gives results for enumerating all fre-
quent queries (this was done using a level-wise style algo-
rithm). The ﬁrst observation is that the OI restriction alone
substantially decreases the number of frequent and closed
sets. This partly explains the speed of systems using this re-
striction reported in the literature. To see the effect of us-
ing closures we calculate the compression factor as CF % =
(1− #closed
)×100. One can see that in both semantic settings
#f req
closures further decrease the number of patterns and runtime.
We next investigate the effect of increasing the number
of variables for the NCTRER dataset for a ﬁxed threshold
of 0.3 and a maximum depth bound of 7. Results are
summarized in Table 2. One can see that RelLCM2-OI
scales much better than RelLCM2 when increasing the
number of variables and that the use of closures signiﬁ-
cantly reduces the number of patterns and runtime. We
also observe that
the CF% increases when more vari-
ables are considered. As an example, one of the closed
structures enumerated which captures active molecules is:
[dsstox ids(x), active(x), atom(x, y, ‘C‘), atom(x, z, ‘O‘),
bond(x, z, y, single), bond(x, w, y, double)]

1A direct comparison with a previous system c-armr [De Raedt
and Ramon, 2004] was not possible since it forces the use of syntac-
tic constraints which RelLCM2 forbids so the outputs are different.

2http://www.epa.gov/ncct/dsstox/sdf nctrer.html

IJCAI-07

808

Vars

1
2
3
4
5
6

# closed

3 (0.004 s)
51 (0.2 s)
303 (3 s)

RelLCM2

# freq

5 (0.004 s)
109 (0.3 s)
1197 (8 s)

1206 (992 s)

9743 (1023 s)

-
-

-
-

CF%
40.0
53.2
74.6
87.6

-
-

# closed

3 (0.004 s)
51 (0.2 s)
216 (3 s)
756 (29 s)

RelLCM2-OI
# freq

5 (0.004 s)
109 (0.4 s)
711 (10 s)

3647 (726 s)

2100 ( 724 s)

3707 ( 11703 s)

-
-

CF%
40.0
53.2
69.6
79.2

-
-

Table 2: Effect of increasing the number of variables for the
NCTRER dataset (with frequency threshold 0.3 and maxi-
mum depth bound of 7).

Vars

# closed

# freq

RelLCM2

1
2
3

7 (0.024 s )
28 (8.6 s )

7 (0.024 s )
35 (15.16 s)

117 (4610.3 s)

158 (7597.4 s)

CF%

0.0
20.0
25.9

Table 3: Effect of increasing the number of variables on Cora
with a relative frequency threshold of 0.1.

The second data set is drawn from Cora, a database of com-
puter science research papers [McCallum et al., 1999]. The
resulting collection contains 2706 objects and 12439 links.
Here we investigate the number of generated closures when
increasing the number of variables. Since this is the true SI
setting we use relative frequency. The results for RelLCM2
with threshold 0.01 are reported in Table 3 (the numbers for
the OI setting are the same for this small number of vari-
ables). We see that in this domain closures are effective both
in terms of compression and runtime but the effect is less
pronounced than in NCTRER. Among the patterns discov-
ered by RelLCM2, there are closed relational sets such as:
[neural netw(x), prob methods(y), link to(p, x, y)], say-
ing that a good proportion of researchers publish papers in
both areas.

6 Conclusions

The paper investigated different semantic settings for closed
clauses in multi-relational datasets. We have demonstrated
that variant deﬁnitions from the literature have signiﬁcant im-
plications for properties of closed sets, and algorithms for dis-
covering them. The paper developed relational variants of
the LCM algorithm that are a promising alternative for min-
ing closed conjunctions in datasets. The experiments demon-
strated that closed sets signiﬁcantly compress the number of
frequent sets and that the new algorithms scale well and can
be used to mine large patterns.

References
[Agrawal et al., 1996] R. Agrawal, H. Mannila, R. Srikant,
H. Toivonen, and A.I. Verkamo. Fast discovery of associ-
ation rules. Advances in Knowledge Discovery and Data
Mining, pages 307–328, 1996.

[Arimura and Uno, 2005] H. Arimura and T. Uno.

An
output-polynomial time algorithm for mining frequent
closed attribute trees.
In Proc. 15th Conference on In-
ductive Logic Programming, volume 3625 of LNCS, pages
1–19, 2005.

[Bastide et al., 2000] Y. Bastide, N. Pasquier, R. Taouil,
G. Stumme, and L. Lakhal. Mining minimal non-
redundant association rules using frequent closed itemsets.

In Proc. of 1st Conference on Computational Logic, vol-
ume 1861 of LNCS, pages 972–986, 2000.

[De Raedt and Dehaspe, 1997] L. De Raedt and L. Dehaspe.

Clausal discovery. Mach. Learn., 26(2-3), 1997.

[De Raedt and Ramon, 2004] L. De Raedt and J. Ramon.
Condensed representations for Inductive Logic Program-
ming.
In Proc. of the 9th Intl. Conf. on Principles of
Knowledge Representation and Reasoning, pages 438–
446, 2004.

[Dehaspe and Toivonen, 2000] L. Dehaspe and H. Toivonen.
Discovery of relational association rules. Relational Data
Mining, pages 189–208, 2000.

[Ganter and Wille, 1998] B. Ganter and R. Wille. Formal
Concept Analysis. Mathematical Foundations. Springer,
1998.

[Goethals and Zaki, 2004] B. Goethals and M. Zaki. Ad-
vances in frequent itemset mining implementations: re-
port on FIMI’03. SIGKDD Explor. Newsl., 6(1):109–117,
2004.

[Han et al., 2000] J. Han, J. Pei, and Y. Yin. Mining frequent
patterns without candidate generation. In Proc. of the ACM
SIGMOD Intl. Conf. on Management of Data, pages 1–12.
ACM Press, 2000.

[Lloyd, 1987] J.W. Lloyd. Foundations of Logic Program-

ming. Springer Verlag, 1987.

[Malerba and Lisi, 2001] D. Malerba and F.A. Lisi. Discov-
ering associations between spatial objects: An ILP appli-
cation. In Proc. 15th Conference on Inductive Logic Pro-
gramming, volume 2157 of LNCS, pages 156–163, 2001.

[Maloberti and Suzuki, 2003] J. Maloberti and E. Suzuki.
Improving efﬁciency of frequent query discovery by elimi-
nating non-relevant candidates. In Discovery Science, vol-
ume 2843 of LNCS, pages 220–232, 2003.

[McCallum et al., 1999] A. McCallum, K. Nigam, J. Rennie,
and K. Seymore. A machine learning approach to build-
ing domain-speciﬁc search engines. In The 16th Int. Joint
Conf. on Artiﬁcial Intelligence, 1999.

[Nijssen and Kok, 2003] S. Nijssen and J.N. Kok. Efﬁcient
frequent query discovery in FARMER. In Proc. of the 7th
PKDD, volume 2838 of LNCS, pages 350–362, 2003.

[Plotkin, 1970] G. D. Plotkin. A note on inductive general-
In B. Meltzer and D. Michie, editors, Machine

ization.
Intelligence, pages 153–163. American Elsevier, 1970.

[Uno et al., 2004] T. Uno, T. Asai, Y. Uchida,

and
H. Arimura. An efﬁcient algorithm for enumerating closed
patterns in transaction databases.
In Discovery Science,
pages 16–31, 2004.

[Yan and Han, 2003] X. Yan and J. Han. CloseGraph: min-
ing closed frequent graph patterns. In Proc. of the 9th ACM
SIGKDD, pages 286–295. ACM Press, 2003.

[Zaki, 2004] M. Zaki. Mining non-redundant association
rules. Data Mining and Knowledge Discovery, 4(3):223–
248, 2004.

IJCAI-07

809

