RoxyBot-06: An (SAA)

2

TAC Travel Agent

Seong Jae Lee, Amy Greenwald, and Victor Naroditskiy

Department of Computer Science, Brown University, Providence, RI 02912

{sjlee,amy,vnarodit}@cs.brown.edu

Abstract

In this paper, we describe our entrant in the travel divi-
sion of the 2006 Trading Agent Competition (TAC). At
a high level, the design of many successful autonomous
trading agents can be summarized as follows: (i) price
prediction: build a model of market prices; and (ii) opti-
mization: solve for an approximately optimal set of bids,
given this model. To predict, we simulate simultaneous
ascending auctions. To optimize, we apply the sample
average approximation method. Both of these proce-
dures might naturally be abbreviated SAA; hence the title
of this paper. Our agent dominated the preliminary and
seeding rounds of TAC Travel in 2006, and emerged as
champion in the ﬁnals in a photo ﬁnish.

1 Introduction
A TAC Travel agent is a simulated travel agent whose task is
to organize itineraries for a group of clients to travel to and
from TACTown. The agent’s objective is to procure travel
goods that satisfy its clients’ preferences as inexpensively as
possible. Travel goods are sold in simultaneous auctions:

• ﬂights are sold by the “TAC seller” in dynamic posted-

pricing environments; no resale is permitted

• hotel reservations are sold by the “TAC seller” in multi-
unit ascending call markets; speciﬁcally, 16 hotel reser-
vations are sold in each hotel auction to the 16 highest
bidders at the 16th highest price; no resale is permitted
• agents trade tickets to entertainment events among them-
selves in continuous double auctions; resale is permitted

Flights and hotel reservations are complementary goods:
ﬂights are not useful to a client without the complementary
hotel reservations, nor vice versa. Tickets to entertainment
events, e.g., the Boston Red Sox and the Boston Symphony
Orchestra, are substitutable.

The TAC Travel environment models the problem faced by
an agent bidding in simultaneous auctions for complementary
and substitutable goods, e.g., an agent bidding on eBay. At a
high-level, the design of many successful TAC Travel agents
(e.g., Walverine [Cheng et al., 2004] and ATTac [Stone et al.,
2003]) can be summarized as: (i) price prediction: build a
model of the auctions’ clearing prices, and (ii) optimization:
solve for a near-optimal set of bids, given this model.

In this paper, we describe RoxyBot–06, the top-scoring
TAC Travel agent in 2006. Here, we reveal RoxyBot’s secrets.
One feature that distinguishes RoxyBot–06 from most other
TAC agents is that it builds noisy (i.e., stochastic) models of
the auctions’ clearing prices, rather than predicting clearing
prices via point estimates. Given stochastic price predictions,
stochastic optimization is at the heart of RoxyBot–06. Our
approach is decision-theoretic rather than game-theoretic.

REPEAT

{start bid interval}

0. Download current prices and winnings from server

1. predict: build stochastic models

a. ﬂights: Bayesian updating/learning
b. hotels: simultaneous ascending auctions
c. entertainment: sample historical data

2. optimize: sample average approximation

3. Upload current bids to server

(three separate threads)
{end bid interval}

UNTIL game over

Table 1: A high-level view of RoxyBot-06’s architecture.

2 RoxyBot-06’s Architecture
Table 1 depicts the high-level architecture of RoxyBot–06.
After current prices and winnings are downloaded from the
server, the key prediction and optimization routines are run.
Output from the optimization routine is a bidding policy, that
is, a mapping from auctions to bids. Finally, current bids
are uploaded to the server by three separate threads, one for
ﬂights, one for hotels, and one for entertainment.

TAC Travel games last 9 minutes. Flight price updates are
broadcast every ten seconds. The eight hotel auctions clear on
the minute at each of minutes 1 through 8, with exactly one
auction closing. (The precise auction to close is decided at
random, with all open auctions equally likely to be selected.)
For the others, the server reports the “hypothetical quantity
won” by each agent as well as the current ask price. Although

IJCAI-07

1378

the entertainment auctions clear continuously, price updates
are broadcast only every 30 seconds.

RoxyBot–06 discretizes time into bid intervals.

Since
server updates are received only every ten seconds, it sufﬁces
for TAC Travel agents to reason about intervals of this length.
For simplicity, assume the prediction and optimization
steps are instantaneous. Under this assumption, based on the
current bidding policy, (i) the ﬂight thread bids on a ﬂight
only if its price is near its predicted minimum; (ii) the hotel
thread bids on a hotel only if it is moments before the end of
a minute; and (iii) the entertainment thread places bids im-
mediately. In practice, the prediction and optimization steps
are time-consuming, so the timing of bid placement in TAC
Travel games is often complex.

3 Price Prediction
In this section, we describe how RoxyBot-06 builds its
stochastic models of ﬂight, hotel, and event prices. Each
model is a discrete probability distribution, represented by
a weighted set of “scenarios.” Each scenario is comprised
of a vector of “current” prices—prices at which goods can
be bought and sold during the current stage—and a vector
of “future” prices—prices at which goods can be bought and
sold after the current stage. For ﬂights, the current (or future)
buy price is RoxyBot-06’s prediction of the expected mini-
mum price during (or after) the current stage. For hotels, the
current buy prices are predicted by simulating simultaneous
ascending auctions to approximate competitive equilibrium
prices. There are no future buy prices for hotels. For enter-
tainment, RoxyBot-06 predicts current and future buy and sell
prices based on historical data.

3.1 Flights

Flight prices follow a biased random walk. They are initial-
ized uniformly in the range [250, 400], and constrained to re-
main in the range [150, 800]. At the start of each TAC game
instance, a bound z on the ﬁnal perturbation value is selected
for each ﬂight. These bounds are not revealed to the agents.
What is revealed to the agents is a sequence of random ﬂight
prices. Every ten seconds, TACAir perturbs the price of each
ﬂight by a random value that depends on the hidden parame-
ter z and the current time t as follows: given constants c ∈ R
and T > 0, each (intermediate) bound on the perturbation
value is a linear function of t:

x(t, z) = c +

t
T

(z − c)

(1)

The perturbation value at time t is drawn uniformly from one
of the following ranges:

• U [−c, x(t, z)], if x(t, z) > 0
• U [−c, +c], if x(t, z) = 0
• U [x(t, z), +c], if x(t, z) < 0
For TAC’s parameter settings, namely c = 10 and T =
540, with z uniformly distributed in the range R = [−10, 30],
given no further information about z, ﬂight prices are ex-
pected to increase (i.e., the expected perturbation is positive).

Conditioned on z, however, ﬂight prices may increase or de-
crease (i.e., the expected perturbation can be positive or neg-
ative). To facilitate their ﬂight deliberations, one of the tasks
faced by TAC agents is to model the probability distribution
Pt[z] associated with z at time t for use in predicting current
and future ﬂight prices. Models of probability distributions
can be built using Bayesian updating.

Given a probability distribution Pt[z], to predict a ﬂight
price, RoxyBot could simulate a random walk from time
t + 1, . . . , t(cid:2) and select the minimum price. In practice, how-
ever, only RoxyBot-06’s hotel and event price predictions are
stochastic; its ﬂight price predictions are point estimates (i.e.,
constant across scenarios). For each ﬂight and for each possi-
ble value of the hidden parameter z, RoxyBot-06 simulates an
“expected” random walk (see Algorithm 1), selects the min-
imum price, and then outputs as its prediction the expecta-
tion of these minima, averaging according to Pt[z]. Alter-
native scenario generation procedures are also possible: e.g.,
an agent could sample instead of calculating expected per-
turbations. Our choice of ﬂight price prediction method was
guided by time constraints.

Algorithm 1 Expected Minimum Price(t, t(cid:2), pt, Pt)

for all z ∈ R do
min[z] = +∞
for τ = t + 1, . . . , t(cid:2) do

2

{expected perturbation}

[a, b] = getRange(τ, z)
Δ = b−a
pτ = pτ −1 + Δ {perturb price}
pτ = max(150, min(800, pτ ))
if pτ < min[z] then

min[z] = pτ

end if
end for
(cid:2)

end for
return

z Pt[z] min[z]

3.2 Hotels
RoxyBot-06’s approach to hotel price prediction is inspired by
Walverine’s [Cheng et al., 2004], in which the tˆatonnement
method is used to approximate competitive equilibrium
prices. In a competitive market where each individual’s ef-
fect on prices is negligible, equilibrium prices are prices at
which supply equals demand, assuming all producers are
proﬁt-maximizing and all consumers are utility-maximizing.
Formally, let (cid:3)p denote a vector of prices. If (cid:3)y((cid:3)p) denotes the
cumulative supply of all producers, and if (cid:3)x((cid:3)p) denotes the
cumulative demand of all consumers, then (cid:3)z((cid:3)p) = (cid:3)x((cid:3)p)−(cid:3)y((cid:3)p)
denotes the excess demand in the market. The tˆatonnement
process adjusts the price vector at iteration n + 1, given the
price vector at iteration n and a sequence {αn} of adjustment
rates: (cid:3)pn+1 = (cid:3)pn + αn(cid:3)z((cid:3)pn).
In the TAC game context,

tˆatonnement is not guaran-
teed to converge. Walverine forces convergence by letting
αn → 0. We force convergence by modifying the adjust-
ment process to simulate simultaneous ascending auctions
(SimAA) [Cramton, 2005].
In SimAAs prices increase as

IJCAI-07

1379

long as there is excess demand but they can never decrease:
(cid:3)pn+1 = (cid:3)pn + αn max{(cid:3)z((cid:3)pn), 0}.

Following [Wellman et al., 2004], we evaluate these ho-
tel price predictions using two metrics: Euclidean distance
and “expected value of perfect prediction” (EVPP). Euclidean
distance is a standard way of measuring the difference be-
tween two vectors, in this case the actual and the predicted
prices. The value of perfect prediction (VPP) for a client
is the difference between the value of the best package for
the client based on the actual prices and the value of the best
package for the client based on the predicted prices. EVPP is
the expected VPP averaged over the client distribution.

In Figure 1 (left), we reproduce a scatter plot generated
by the Walverine team that evaluates the hotel price predic-
tion methods of TAC 2002 agents at the beginning of the
game. We add two versions of SimAA and tˆatonnement to the
plot. Following Wellman et al. [Cheng et al., 2003], one uses
56 “expected” clients; the other samples 56 random clients.
Eight agents play the TAC game, each with eight clients.
Each agent knows the preferences of its own clients, but must
simulate the demand of the 56 others. An expected client cor-
responds to one of ten different arrival/departure pairs, with
average hotel and entertainment values.

We interpret each prediction with 56 random clients as a
sample scenario, so that a set of such scenarios represents
draws from a probability distribution over competitive equi-
librium prices. The vector of predicted prices that is evaluated
and plotted is the average of multiple (40) such predictions.
The predictions generated using sets of random clients are
not as good as the predictions with expected clients, although
with more than 40 sets of random clients, the results might
improve. Still, using random clients helps us make better in-
terim predictions later in the game as we explain next.

As hotel auctions close, RoxyBot-06 updates the predicted
clearing prices of the open hotel auctions. We experimented
with two ways of constructing interim price predictions. The
ﬁrst is to ﬁx the prices of the closed auctions at their clearing
prices and then to run SimAA or tˆatonnement with expected
or random clients. The second is to distribute goods from
the closed auctions to the clients who want them the most,
and then to exclude any closed auctions in further runs of
SimAA or tˆatonnement. (NB: We determine which clients
want which goods most by running SimAA or tˆatonnement
as usual.) Note that we can only distribute goods to random
clients. It is not clear how to distribute goods to “expected
clients,” which are aggregate clients rather than real clients.
Figure 1 (center and right) shows that the predictions based
on the distribution method are better than the others. Hotels
that close early tend to sell for less than hotels that close late;
hence, any method that makes relatively constant predictions
all throughout the game is bound to suffer.

3.3 Entertainment
During each bid interval, RoxyBot-06 predicts current and fu-
ture buy and sell prices for tickets to all entertainment events.
These price predictions are optimistic: the agent assumes it
can buy (or sell) goods at the least (or most) expensive prices
that it expects to see before the end of the game. More specif-
ically, each current (or future) price prediction is the best pre-

dicted price during (or after) the current bid interval.

RoxyBot-06’s estimates of entertainment ticket prices are
based on historical data from the past 40 games. To gener-
ate a scenario, a sample game is drawn at random from this
collection, and the sequences of entertainment bid, ask, and
transaction prices are extracted. Given such a history, for each
auction a, let trade ai denote the price at which the last trade
before time i transacted; this value is initialized to 200 for
buying and 0 for selling. In addition, let bid ai denote the bid
price at time i, and let ask ai denote the ask price at time i.

To predict current buy price in auction a at time t, RoxyBot-
06 ﬁrst computes the minimum among the historical trade and
ask prices at time t and the current ask price in the present
game. The current buy price is then constrained to be above
the current bid price in the present game. Without this latter
constraint, the agent might be inclined to buy a good at a price
that is lower than the outstanding bid, which is impossible.
Formally,
curr buy at = max{currBid , min{trade at, ask at, currAsk}}

(2)

The current sell price is predicted analogously:
curr sell at = min{currAsk, max{trade at, bid at, currBid }}

(3)
RoxyBot-06 predicts the future buy price in auction a after

time t as follows:

future buy at = min

i=t+1,...,T

min{trade ai, ask ai}

(4)

In words, the future buy price at each time i = t + 1, . . . , T is
the minimum of the ask price after time i and the most recent
trade price. The future buy price at time t is the minimum
across the future buy prices at all later times. As above, the
future sell price after time t is predicted analogously:
max{trade ai, bid ai}

future sell at = max

(5)

i=t+1,...,T

4 Optimization
We characterize RoxyBot-06’s optimization routine as
(i) stochastic, (ii) global, and (iii) dynamic. It takes as in-
put stochastic price predictions; it simultaneously considers
ﬂight, hotel, and entertainment bids in unison; and it simul-
taneously reasons about bids to be placed in both current and
future stages of the game.

We assume that our agent’s decisions do not affect
prices and express the game-theoretic bidding problem as a
decision-theoretic optimization problem. The inﬂuence of
other agents on prices is represented by a set of scenarios or,
more generally, a distribution over prices.

Hence, RoxyBot-06 is confronted with a dynamic stochas-
tic optimization problem. It solves this problem by collapsing
the future into only two relevant stages—“current” and “fu-
ture”. This approach is reasonable in TAC, and other similar
combinations of sealed-bid and continuously-clearing simul-
taneous auction environments, as we now explain.

The key bidding decisions are: what goods to bid on, at
what price, and when? Since hotel auctions close in an un-
known random order, RoxyBot-06, like most TAC agents, op-
erates under the assumption that all hotel auctions close at the

IJCAI-07

1380

n
o

i

i
t
c
d
e
r
P

 
t
c
e

f
r
e
P

 
f

 

l

o
e
u
a
V
d
e

 

t
c
e
p
x
E

 70

 65

 60

 55

 50

 45

 40

 35

 30

 livingagents

PackaTAC
Southampton
UMBCTAC

SICS_baseline

 RoxyBot

whitebear

ATTac

harami

cuhk

 tatonnement, random

kavayaH

Walverine

 SimAA, random
 tatonnement, expected

 SimAA, expected

ATTac01

 190

 200

 210

 220

 230
Euclidean Distance

 240

 250

 260

l

e

t

o
H

 
r
e
p
n
o

 

i

i
t
c
d
e
r
P

 
t
c
e

f
r
e
P

 
f

o

 

l

e
u
a
V
d
e

 

t
c
e
p
x
E

 22

 20

 18

 16

 14

 12

 10

 8

 6

 4

 2

 0

 0

tatonnement, expected clients
SimAA, expected clients
tatonnement, random clients
SimAA, random clients

tatonnement, random clients, with distribution
SimAA, random clients, with distribution

l

e

t

o
H

 

 
r
e
p
e
c
n
a

i

 

t
s
D
n
a
e
d

i
l

c
u
E

 1

 2

 3

 4

 5

 6

 7

Minute

 140

 120

 100

 80

 60

 40

 20

 0

 0

tatonnement, expected clients
SimAA, expected clients
tatonnement, random clients
SimAA, random clients

tatonnement, random clients, with distribution
SimAA, random clients, with distribution

 1

 2

 3

 4

 5

 6

 7

Minute

Figure 1: Left: EVPP and Euc. Dist. for TAC 2002 agents as well as our prediction methods: Tˆat. and SimAA; expected and
random. Center and Right: EVPP and Euc. Dist. in TAC 2006 of our hotel price prediction methods with distribution as the
game progresses.

end of the current stage. Hence, the only pressing decisions
regarding hotels are: what goods to bid on and at what price?
There is no need to consider the timing of bids. Accordingly,
the only model of hotel prices is the current one.

In contrast, since ﬂight and entertainment auctions are con-
tinuous, a trading agent should reason about the timing of
its bids for these goods. Still, it sufﬁces to consider only
two pricing models. The current model predicts the best
good prices during the current bid interval, whereas the fu-
ture model predicts the best good prices after the current bid
interval, conditioned on current prices.

We express the bidding problem as a stochastic program
where current and future prices are given by corresponding
stochastic models. The sample average approximation (SAA)
method is a numerical means of approximating solutions to
stochastic programs via Monte Carlo simulation [Ahmed and
Shapiro, 2002]. The main idea is simple: (i) sample a set
of scenarios from the input distribution, and (ii) approximate
the solution to the stochastic program by solving an approx-
imation of the stochastic optimization problem which incor-
porates only the sample scenarios. RoxyBot–06 samples sce-
narios by simulating SimAA as described in Section 3.2.

The ILP formulation of SAA applied to the TAC bidding
problem is included in Appendix A. The power of this for-
mulation is in its ability to make globally optimal decisions.
Flight, hotel, and entertainment bids are optimized together
to produce a consistent bidding policy. The ﬁrst stage deci-
sions are the bids that are submitted now. The second stage
decisions are the bids that can be submitted later. All hotel
bids are submitted now; ﬂight and entertainment bids can be
submitted now or later.

The formulation of the problem facilitates reasoning not
only about what bids to place but also about when to place
them. The fundamental issue regarding TAC ﬂight decisions
is a common one: balancing concern about future price in-
creases with the beneﬁt of delaying commitment to travel on
particular days. We model this tradeoff explicitly by giving
the agent the option of buying ﬂight and entertainment tickets
now at the current prices or later at the scenario’s (i.e., future)
prices. If the agent decides to buy a ﬂight or entertainment
ticket later, it can submit different bids in different scenarios.
One of the weaknesses of the ILP formulation is that its

hotel bids can only be as high (or as low) as the maximum
(minimum) price in the scenarios although an agent may be
willing to pay more (less). We overcome this problem by
adding to the set of scenarios generated by our stochatic
model additional scenarios in which one of the hotels is
priced higher/lower than in any other scenario. This way the
agent may bid higher or lower than predictions in case the ac-
tual clearing prices are unexpectedly high or low. RoxyBot-06
optimized with respect to 30 scenarios generated as described
in Section 3 and up to 30 extra scenarios with high and low
prices. These choices were guided by time constraints.

5 Competition Results

We present the results of the last day of the TAC-06 Finals (80
games). We omit the ﬁrst two days because agents can vary
across days, but cannot vary within. Presumaly, the entries on
the last day are the teams’ preferred versions of the agents.
Mean scores are plotted in Figure 2 and detailed statistics are
tabulated in Table 2.

There is no single metric such as low hotel or ﬂight costs
that is responsible for RoxyBot’s success. Rather its success
derives from the right balance of contradictory goals. In par-
ticular, RoxyBot incurs high hotel and mid-range ﬂight costs
while achieving mid-range trip penalty and high event proﬁt.
We compare RoxyBot with two closest rivals: Walverine
and WhiteDolphin. Comparing to Walverine ﬁrst, Walver-
ine bids lower prices (by 55) on fewer hotels (49 less), yet
wins more (0.8) and wastes less (0.42).
It would appear
that Walverine’s hotel bidding strategy outperforms Roxy-
Bot’s, except that RoxyBot earns a higher hotel bonus (15
more). RoxyBot also gains an advantage by spending 40 less
on ﬂights and earning 24 more in total entertainment proﬁt.

A very different competition takes place between RoxyBot
and WhiteDolphin. WhiteDolphin bids lower prices (120 less)
on more hotels (by 52) than RoxyBot. RoxyBot spends much
more (220) on hotels than WhiteDolphin but makes up for it by
earning a higher hotel bonus (by 96) and a lower trip penalty
(by 153). It seems that WhiteDolphin’s strategy is to minimize
costs even if that means sacriﬁcing utility.

IJCAI-07

1381

# of Hotel Bids
Average of Hotel Bids
# of Hotels Won
Hotel Costs
# of Unused Hotels
Hotel Bonus
Trip Penalty
Flight Costs
Event Proﬁts
Event Bonus
Total Event Proﬁts
Average Utility
Average Cost
Average Score

Rox
130
170
15.99
1102
2.24
613
296
4615
110
1470
1580
9787
5608
4179

Wal
81
115
16.79
1065
1.82
598
281
4655

26

1530
1556
9847
5693
4154

Whi
182
50

23.21
882
9.48
517
449
4592

6

1529
1535
9597
5468
4130

SIC
33
513
13.68
1031
0.49
617
340
4729

-6

1498
1492
9775
5765
4010

Mer
94
147
18.44
902
4.86
590
380
4834
123
1369
1492
9579
5628
3951

L-A
58
88

14.89
987
1.89
592
388
4525
-93
1399
1306
9604
5605
3999

kin
15
356
15.05
1185
0.00
601
145
4867
-162
1619
1457
10075
6213
3862

UTT

24
498
9.39
786
0.48
424
213
3199

-4
996
992
6607
3989
2618

Table 2: Last day of Final 2006. 80 games.

)
s
d
n
a
s
u
o
h

t
(
 

e
r
o
c
S

4.5

4

3.5

3

2.5

2

2006 Finals, Last Day

Rox Wal Whi SIC Mer L-A kin UTT

Agent

Figure 2: 2006 Finals’ Scores and 95% Conﬁdence Intervals.

6 Conclusion

The success of an autonomous trading agent, particularly
TAC agents, often hinges upon two key modules: (i) price
prediction, in which the agent builds a model of market
prices; and (ii) optimization, in which the agent solves for an
approximately optimal set of bids, given this model. For ex-
ample, at the core of RoxyBot’s 2000 architecture [Greenwald
and Boyan, 2005] was a deterministic optimization problem,
namely how to bid given price predictions in the form of
point estimates. In spite of its effectiveness in the TAC-00
tournament, a weakness of the 2000 design was that RoxyBot
could not explicitly reason about variance within prices. In
the years since 2000, we recast the key challenges faced by
TAC agents as several different stochastic bidding problems
(see [Greenwald and Boyan, 2004]), whose solutions exploit
price predictions in the form of distributions. In spite of our
perseverance, RoxyBot fared unimpressively in tournament
conditions year after year. . . until 2006. Half a decade in the
laboratory spent searching for bidding heuristics that can ex-
ploit stochastic information at reasonable computational ex-
pense ﬁnally bore fruit, as RoxyBot emerged victorious in
In a nutshell, the secret of RoxyBot-06’s success
TAC-06.
is: hotel price prediction by simulating simultaneous ascend-
ing auctions, and optimization based on the sample average
approximation method.

References
[Ahmed and Shapiro, 2002] Shabbir Ahmed and Alexander Shapiro. The sample av-
erage approximation method for stochastic programs with integer recourse. Opti-
mization Online, http://www.optimization-online.org, 2002.

[Cheng et al., 2003] S.F. Cheng, E. Leung, K.M. Lochner, K.O’Malley, D.M. Reeves,
L.J. Schvartzman, and M.P. Wellman. Walverine: A Walrasian trading agent. In
Proceedings of the Second International Joint Conference on Autonomous Agents
and Multi-Agent Systems, pages 465–472, July 2003.

[Cheng et al., 2004] S.F. Cheng, E. Leung, K.M. Lochner, K.O’Malley, D.M. Reeves,
L.J. Schvartzman, and M.P. Wellman. Walverine: A Walrasian trading agent. Deci-
sion Support Systems, page To Appear, 2004.

[Cramton, 2005] Peter Cramton. Simultaneous ascending auctions. In Peter Cramton,
Yoav Shoham, and Richard Steinberg, editors, Combinatorial Auctions. MIT Press,
2005.

[Greenwald and Boyan, 2004] A. Greenwald and J. Boyan. Bidding under uncertainty:
Theory and experiments. In Proceedings of the 20th Conference on Uncertainty in
Artiﬁcial Intelligence, pages 209–216, July 2004.

[Greenwald and Boyan, 2005] Amy Greenwald and Justin Boyan. Bidding algorithms
for simultaneous auctions: A case study. Journal of Autonomous Agents and Multi-
agent Systems, 10(1):67–89, 2005.

[Stone et al., 2003] P. Stone, R.E. Schapire, M.L. Littman,

J.A. Csirik, and
D. McAllester. Decision-theoretic bidding based on learned density models in simul-
taneous, interacting auctions. Journal of Artiﬁcial Intelligence Research, 19:209–
242, 2003.

[Wellman et al., 2004] M.P. Wellman, D.M. Reeves, K.M. Lochner, and Y. Vorobey-
chik. Price prediction in a Trading Agent Competition. Artiﬁcial Intelligence Re-
search, 21:19–36, 2004.

A TAC Bidding Problem: SAA
The problem of bidding in the simultaneous auctions that charac-
terize TAC can be formulated as a two-stage stochastic program, in
which bids are placed in the ﬁrst stage and winnings are allocated in
the second stage. In this appendix, we present the implementation
details of the integer linear program (ILP) encoded in RoxyBot-06
that approximates an optimal solution to this stochastic program.

This ILP formulation of the TAC bidding problem assumes linear
prices, that is, constant economies of scale. Table 3 lists the the
price constants that comprise scenarios. Each scenario includes a
“current” price, which is the best price expected within the stage,
and a “future” price, which is the best price expected from the start
of the next stage until the end of the game, for each good (except
hotels, which do not have future buy prices because they are treated
as one-shot auctions).

Table 3 also lists the decision variables that pertain to each auc-
tion type. For hotels, the only decisions pertain to buy offers, right
now; for ﬂights, the agent chooses buy offers for now and for later;
for entertainment events, both buy and sell offers are made now and

IJCAI-07

1382

later. “Now” decisions are taken under uncertainty. They are the
bids to be placed on each good, necessarily constant across sce-
narios. “Later” decisions are scenario dependent. Uncertainty is
resolved (i.e., prices are known) in scenarios; there, it sufﬁces to
simply choose the quantity of each good to trade.

Scenario

Flights
buy now current price Mas
future price Yas
buy later

Decision Type

bid μapq

quantity υas

Hotels
buy now current price Mas

Scenario

Decision Type

bid μapq

A.4 Objective Function

X

S

» trip value
{X
z
}|
}|

C,T

ﬂight cost

}|

X

current

Masμapq +

max

Γ,M,N,Y,Z

z
X

z

0
B@
0
z
BBBBBB@
z
X

Ae

Af

Q,p≥Mas

}|

}|

X

current

Uctγcts −event −

{

{

{
1
z }| {
CA −

future
Yasυas

z

X

}|

hotel cost

–
{

Masμapq

(6)

Ah,Q,p≥Mas

}|

{

}|

X

current

z
z

{
z }| {

future
Yasυas −

1
{
z }| {

future
Zasζas

CCCCCCA

event cost

event revenue

Masμapq+

Nasνapq+

Q,p≥Mas

Q,p≤Nas

Scenario

Events
buy now current price Mas
future price Yas
buy later
current price Nas
sell now
future price Zas
sell later

Decision Type

bid μapq

quantity υas

bid νapq

quantity ζas

event =

Table 3: Auction types and associated scenario prices and
decision types.

A.5 Constraints

γcstGat ≤

Oa +

υas +

μapq −

γcst ≤ 1 ∀c ∈ C, s ∈ S

(7)

(8)

∀a ∈ Af , s ∈ S

(9)

∀a ∈ Ah, s ∈ S (10)

z

}|
X

sell

{

ζas +

νapq

Q,p≤Nas

∀a ∈ Ae, s ∈ S (11)

μapq ≥ Ha ∀a ∈ Ah

(12)

Oa +

C,T

allocation

}|

γcstGat ≤

z
{X
}|

ownz}|{
z
{X
}|

z
{X

ownz}|{

allocation

allocation

C,T

γcstGat ≤

z

υas +

ownz}|{

Oa +

z

C,T

X

P

T

buy

{

μapq

X
}|
X
z
{X
}|
}|
{
X

μapq

buy

buy

Q,p≥Mas

Q,p≥Mas

Q,p≥Mas

X

P,Q

X

μapq ≤ 1 ∀a ∈ Af ∪ Ah ∪ Ae, q ∈ Q (13)

νapq ≤ 1 ∀a ∈ Ae, q ∈ Q (14)

P

Equation (8) limits each client to one trip in each scenario. Equa-
tion (9) prevents the agent from allocating ﬂights that it does not own
or buy. Equation (10) prevents the agent from allocating hotels that
it does not own or buy. Equation (11) prevents the agent from allo-
cating event tickets that it does not own or buy and not sell. Equation
(12) ensures the agent bids on at least HQW units in each hotel auc-
tion. Equation (13) prevents the agent from placing more than one
buy offer per unit in each ﬂight, hotel, or event auction. Equation
(14) prevents the agent from placing more than one sell offer per
unit in each event auction. An agent might also be constrained not
to place sell offers on more units of each good than it owns, and/or
not to place buy (sell) offers for more units of each good than the
market supplies (demands).

A.1 Index Sets

a ∈ A indexes the set of goods, or auctions.

af ∈ Af indexes the set of ﬂight auctions.
ah ∈ Ah indexes the set of hotel auctions.
ae ∈ Ae indexes the set of event auctions.

c ∈ C indexes the set of clients.
p ∈ P indexes the set of prices.
q ∈ Q indexes the set of quantities
(i.e., the units of each good in each auction).
s ∈ S indexes the set of scenarios.
t ∈ T indexes the set of trips.

A.2 Constants

Gat indicates the quantity of good a needed to complete trip t.
Mas indicates the current buy price of af , ah, ae in s.
Nas indicates the current sell price of ae in scenario s.
Yas indicates the future buy price of af , ae in scenario s.
Zas indicates the future sell price of ae in scenario s.
Ha indicates the hypothetical quantity won of hotel ah.
Oa indicates the quantity of good a the agent owns.
Uct indicates client c’s value for trip t.

A.3 Decision Variables

Γ = {γcst} is a set of boolean variables indicating whether or
not client c is allocated trip t in scenario s.
M = {μapq} is a set of boolean variables indicating whether
to bid price p to buy the qth unit of af , ah, ae now.
N = {νapq} is a set of boolean variables indicating whether
to bid price p to sell the qth unit of ae now.
Y = {υas} is a set of integer variables indicating how many
units of af , ae to buy later in scenario s.
Z = {ζas} is a set of integer variables indicating how many
units of ae to sell later in scenario s.

IJCAI-07

1383

