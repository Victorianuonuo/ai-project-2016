THE  MODELING  OF  SIMPLE  ANALOGIC  AND  INDUCTIVE  PROCESSES  IN  A  SEMANTIC  MEMORY  SYSTEM 

Joseph  D.  Becker 

Computer  Science  Department 

Stanford  University 
Stanford,  C a l i f o r n ia  * 

" It 

is  part  of  our  thesis  that  concepts 

in  the 
s t r i ct  sense  of  the  term,  as  we  know  them  -  which, 
since  Euler, 
the  great  mathematician  (1707-1.783), 
ore  represented  by  c i r c l e s,  a  fact  which  means  f ar 
more  than  meets  the  eye  -  are  foreign  to  the 
Chinese  mind."  -  Gustav  Herdan,  Linguistics  No.  28 

Summary 

In  t h is  paper  w.  present  a  general  data 

structure  f or  a  semantic  memory,  and  we  give  a 
d e f i n i t i on  of  "analogy"  between  items  of  semantic 
information.  We  then  construct  an  inductive  process 
in  which  general  laws  are  formulated  and  v e r i f i ed 
on  the  basis  of  observations  of  i n d i v i d u al  cases. 

I. 

Introduction 

The  model  described  in  t h is  paper  represents 

they  are  by  no  means  simple 
in  t h e ir  f u ll  g e n e r a l i t y.  Within 

on  attempt  to  formalize  a  number  of  general  cog(cid:173)
n i t i ve  processes.  Although  these  processes  may  be 
said  to  be  "simple" 
in  the  sense  of  being  p r i m i t i v es 
of  cognitive  behavior, 
to  make  e x p l i c it 
the  confines  of  t h is  paper  we  could  not  begin  to 
i n t r i c a c i es  of  modeling  these 
discuss  a ll  of  the 
processes,  and  if  we  could, 
the  reader  could  not 
begin  to  sort  out  the  main  ideas  underlying  the 
model.  Therefore  we  have  chosen  to  present  the 
elements  of  the  model  in  an  o v e r s i m p l i f i ed  form 
designed  to  b r i ng  out  the  major  ideas  they  embody; 
then  in  separate  sections  (Sections  I I . C, 
and  V.B)  we  i n d i c a te  what  elaborations  must  be  made 
in  order  f or  the  model  to  be  t r u ly  general. 
Section  V.B  we  also  discuss  the  formidable  problems 
t h at  a r i se  in  v a l i d a t i ng  a  model  such  as  t h is  one. 

I I I . B, 

In 

Relation  to  Other  Research 

We  w i ll  b r i e f ly  i n d i c a te  where  the  present 

model  stands  w i th  respect  to  other  semantic  systems 
which  are  c u r r e n t ly  under  development.  Obviously 

The  research  reported  here  was  supported  in  part 
by  the  Advanced  Research  Projects  Agency  of  the 
Office  of  the  Secretary  of  Defense  (SD-183). 

is  unjust  to  characterize  such  complex  models 
is  impossible  to  compare 

it 
a  phrase  or  two,  but 
them  in  d e t a il  here. 

it 

in 

Most  of  the  semantic  memory  systems  that  have 

is 

i ts 

[ 3 ], 

[1,2]  and 

[4],  Woods 

language-free  repre(cid:173)

the  input  is  t r a n s l a t ed 

In  the  systems  of  Q u i l l i an 

been  proposed  are  designed  around  the  problem  of 
dealing  w i th  n a t u r al  language.  A  primary  component 
of  the  "understanding"  of  an  input  t e xt 
t r a n s l a t i on  i n to  some  formal, 
sentation. 
Simmons  et  al 
d i r e c t ly  i n to  a  format  consistent  w i th  the  rest  of 
the  general  semantic  memory.  A  d i s t i n c t ly  d i f f e r e nt 
approach  is  being  pursued  by  Kellogg 
[ 5 ], 
and  Kochen  [ 6 ],  who  divide  t h e ir  semantic  systems 
i n to  two  components:  a  data  base  ( in  a  non-general 
format)  and  a  procedural  programming  language  which 
operates  on  t h is  data  base. 
input  t e xt 
gram  in  the  procedural  language,  and  then  t h is 
program  is  applied  (rather  than  added) 
base.  The  semantic  system  which  we  w i ll  present 
here  contains  elements  of  both  approaches.  The 
semantic  memory  is  a  single  structure  in  a  format 
which  is  claimed  to  be  general,  but  t h is  format  is 
i t s e lf  procedural. 

In  these  systems  the 
is  t r a n s l a t ed  i n to  an  appropriate  p r o(cid:173)

to  the  data 

The  formalism  is  also  closely  a l l i ed  to  the 

predicate  calculus  representation  adopted  by  many 
workers  who  are  concerned  w i th  preserving  deductive 
capacity  w i t h in  the  system,  e.g.  Green  and  Raphael  [ 7 ], 
McCarthy  [ 8 ],  and  Black  [ 9 ].  At  the  same  time,  we 
have  s t r i v en  to  maintain  consistency  w i th  what 
l i t t le  is  known  of  the  psychology  of  human  memory, 
as  discussed  by  B a r t l e tt 
[10]  and  O l d f i e ld  [ 1 1 ], 
and  w i th  the  belief-system  simulations  of  Colby 
and  Abelson  and  C a r r o ll  [33]• 

[ 1 2 ], 

The  notion  of  "analogy"  appears  to  have 

received  extremely  l i t t le  a t t e n t i on  in  the  t e c h(cid:173)
n i c al  l i t e r a t u r e.  Evans 
taker  of  course  deals  w i th  the  concept,  but  only  in 
a  very  constrained  context.  Much  deeper  studies 

in  h is  analogy-test 

[14] 

-655-

i n to  analogic  reasoning  have  been  made  by  K l i ng 
in  h is  analysis  of  analogies  between  mathematical 
p r o o f s.  Although  K l i n g'  s  i n v e s t i g a t i o ns  also  are 
l i m i t ed  to  a  h i g h ly  r e s t r i c t ed  problem  domain, 
they 
are  in  many  respects  r i c h er  than  those  reported  in 
the  present  paper  (see  Section  I I I . B ). 

[15] 

A.  Consequence  and  C r i t e r i a l i ty 

Before  introducing  the  syntax  of  the  memory 
s t r u c t u r e,  we  w i ll  discuss  the  two  notions  which 
it 
most  sharply  d i f f e r e n t i a te 
from  other  models 
which  have  been  proposed: 
t h at  of  "consequence" 
and  t h at  of  " c r i t e r i a l i t y " .1 

There  have  been  any  number  of  schemes  proposed 

Consequence. 

The  p r i n c i p al  u n it  of  i n f o r(cid:173)

it 

[ 1 7 ] ).  Unfortunately, 

under  the  name  " i n d u c t i o n ",  w i th  the  paradigm  of 
sequence  e x t r a p o l a t i on  gaining  perhaps  the  greatest 
amount  of  a t t e n t i on  ( i n c l u d i ng  an  empirically-based 
model  by  Simon  and  Kotovsky  [16]  and  an  exhaustive 
is 
analysis  by  Persson 
d i f f i c u lt  to  f i nd  any  u s e f ul  r e l a t i o n s h ip  between 
these  " i n d u c t i o n"  models  and  the  " g e n e r a l i z a t i o n-
over-cases"  process  described  in  the  present  paper. 
One  s t r i k i ng  difference  is  t h at 
in  our  model  the 
general  law  is  manufactured  d i r e c t ly  out  of  the 
instances  from  which  it 
r a t h er  than 
being  selected  from  some  n a r r o w l y - s p e c i f i ed  set  or 
grammar  of  possible  laws.  The  two  procedures  which 
seem  closest  to  our  generalization-over-cases  are 
the  g e n e r a l i z a t i on  techniques  discussed  by  Evans 
and  Doran  [ 1 8 ].  These  are  c e r t a i n ly  noteworthy 
studies,  but  again  in  these  models  there  is  a  f i x ed 
set  of  dimensions  along  which  g e n e r a l i z a t i on  can 
occur. 

i n f e r r e d, 

is 

[14] 

F i n a l l y, 

there  is  a  considerable  l i t e r a t u re  on 

including 

f o r m a t i o n ", 

the  process  of  "concept 
d e t a i l ed  simulations  by  Hunt  et  al 
g e n e r a l i z a t i on  process 
being  concept  formation  (see  Section  I V . A ),  we  w i ll 
not  attempt  any  comparison  w i th  concept-formation 
models  here. 

f a l ls  s l i g i t ly  short  of 

[ 1 9 ].  Since  our 

I I.  The  Semantic  Memory  Structure 

is  defined  here 

In  t h is  section  we  w i ll  describe  the  semantic 
s t r u c t u re  which  is  the  basis  of  the  present  model. 
What 
is  a c t u a l ly  a  reduced  version 
of  the  syntax  of  the  s t r u c t u r e; 
Throughout 
elaborations  are  given  in  Section  I I . C. 
the  paper  we  make  t he  convention  of  c a p i t a l i z i ng  a 
word  if 
r a t h er  than  in  i ts  usual  English  meaning 
( e . g.  " S i t u a t i o n " ). 

is  used  as  a  f o r m a l l y - d e f i n ed  term 

the  necessary 

it 

( l) 

temporal  sequence, 

(3)  l o g i c al  i m p l i c a t i o n,  and 

mation  in  t h is  model,  c a l l ed  the  Rule,  contains  an 
arrow  ' W,  whose  f u n c t i on  is  to  introduce  s e r i al 
order  as  a  p r i m i t i ve  of  the  data  s t r u c t u r e.  The 
number  of  reasons 
f or  d e s i r i ng  such  a  p r i m i t i ve  is 
so  large  t h at  we  can  give  only  a  sampling  of  them 
here.  The  idea  of  "consequence" 
in  an  expression 
such  as  " l i g h t n i ng  =»  thunder"  has  at  least  four 
possible  i n t e r p r e t a t i o n s: 
(2)  causal  law, 
(4)  behavioral  response  ( e . g.  "given  l i g h t n i n g, 
p r e d i ct  t h u n d e r " ).  What  is  important 
is  t h at  we 
can  store  t h is  item  of  data  in  a  noncommittal 
fashion  by  means  of  the  "=»"  p r i m i t i v e,  and  leave 
the  precise 
which  operate  on  the  item.  Thus,  a  given  Rule  may 
at  one  time  behave  as  a  predicate  calculus  formula, 
and  at  another  time  as  a  " p a t t e r n - o p e r a t i o n"  r u le 
or  "production-language"  procedure 
f or  behavior. 
This  use  of  s e r i al  order  as  a  basic  feature  of 
memory  is  of  course  consistent  w i th  almost  every 
psychological  observation  or  theory, 
Associationism  to  Stimulus-Response.  A  p a r t i c u l a r ly 
i n s i g h t f ul  discussion  of  i ts 
by  Lashley 

i n t e r p r e t a t i on  up  to  the  processes 

importance 

is  given 

[ 2 1 ]. 

from 

C r i t e r i a l i t y.  Given  formal  structures  A  and  B 

i d e n t i ty 

f or  the  d i s t i n c t i ve 

such  t h at  B  is  a  sub-structure  of  A,  we  w i ll  want 
a  measure  of  the  degree  to  which  the  presence  of 
B  in  A  is  responsible 
of  A.  This  we  w i ll  c a ll  the  " c r i t e r i a l i t y"  of  B 
if  it 
w i th  respect  to  A. 
For  example, 
whether  or  not  B  is  present  in  A, 
then  B  may  be 
said  to  have  zero  c r i t e r i a l i ty  w i th  respect  to  A. 
The  formal  u t i l i ty  of  such  a  n o t i on  w i ll  become 
clear  in  Section  I V;  at  t h is  p o i nt  we  may  give  an 
informal  motivation  in  terms  of  the  phenomenon  of 
" a t t e n t i o n ".  When  we  perceive  the  w o r l d,  various 

is 

i r r e l e v a nt 

The  idea  of  c r i t e r i a l i ty  was 
Q u i l l i an 
minor  r o le  in  h is  l a t e st  model,  Q u i l l i an 

introduced  by 
[ 2 0 ],  but  has  been  relegated  to  a 

[ 2 ]. 

656-

aspects  of  the  situation  at  hand  receive  varying 
degrees  of  attention.  These  variations  must  be 
recorded  in  the  semantic  memory,  for  they  clearly 
affect  the  recall  and  further  processing  of  our 
perceptions.  C r i t e r i a l i t y,  at  least  in  i ts 
i n i t i al  assignment,  is  merely  the  frozen  record  of 
attention. 

B.  Description  of  the  Memory  Structure 

The  "objects"  in  this  memory  system  are 

actually  graph  structures  ( i . e.  pointer  nests),  but 
it  is  generally  more  convenient  to  work  with  them 
in  a  notation  which  disguises  their  net-like  nature. 
The  reader  must  bear  in  mind  (as  when  programming 
in  LISP)  that  the  notation  does  not  t e ll  the  f u ll 
story,  and  that  an  "occurrence  of  an  object"  is 
identically  the  same  as  a  pointer  to  some  graph 
structure. 

Two  types  of  objects,  Facts  and  Rules,  are 

used  to  encode  the  content  of  any  assertion, 
situation,  or  event.  We  w i ll  begin  by  describing 
the  pieces  from  which  Facts  and  Rules  are  built  up. 

The  Node.  A  Node  is  a  nest  of  two-way 

I n t u i(cid:173)

pointers.  Two  Nodes  are  equal  if  and  only  if  they 
are  identically  the  same  Node.  Thus,  the  Node  is 
the  "atom"  of  the  system,  like  the  Atom  in  IISP 
except  that  here  the  pointers  are  two-way. 
tively,  Nodes  represent  "concepts".  Some  of  these 
are  bound  to  individual,  distinct  entities 
(e.g.  Eugene-McCarthy,  Paul-Bunyan),  while  others 
may  be  considered  as  classes  of  other  Nodes 
(e.g.  Minnesotan,  hero).  We  w i ll  usually  denote 
Nodes  by  English  words,  but  this  notation  is  for 
convenience  only,  and  bears  no  relation  to  the 
representation  of  English  words  within  the  model. 
When  we  need  to  discuss  Nodes  for  individual  objects 
which,  unlike  Eugene  McCarthy,  do  not  have  names 
assigned  to  them  already,  we  w i ll  invent  names  of 
the  form AA,  BB,  etc.  We  w i ll  also  use  a  special 
symbol  "@",  which  designates  "the  Situation  in 
which  this  symbol  occurs"  (a  "Situation"  is  defined 
below). 

The  Kernel.  A  Kernel  is  an  ordered  n-tuple 

of  Nodes,  where  to  each  Node  is  assigned  an  integer 
between  0  and  6,  called  i ts  (Node-)Criteriality. 
The  Kernel  is  interpreted  as  an  (n-l)-ary  predicate 

and  arguments  ( i . e.  i ts  presence  indicates  the 
assertion  of  that  relation),  where  the  f i r st  Node 
is  the  predicate  name.  The  integers  exhibit 
c r i t e r i a l i t i es  on  a  7-point  scale.  A  Node  of  zero 
C r i t e r i a l i ty  is  called  a  Dummy.  For  convenience 
in  the  examples  presented  in  this  paper,  we  w i ll 
conventionally  attach  a  C r i t e r i a l i ty  of  3  "to  a  Node 
unless  we  have  a  particular  reason  to  do  otherwise. 
In  the  notation,  Kernels  w i ll  be  enclosed  in  pointy 
brackets,  and  Node-Criterialities  w i ll  be  written 
as  superscripts,  e.g. 

The  Situation.  A  Situation  is  an  unordered 
set  of  Kernels,  where  to  each  Kernel  is  assigned 
an  integer  between  -6  and  6,  called  i ts  (Kernel-) 
C r i t e r i a l i t y.  The  Situation  is  interpreted  as  the 
conjunction  of  the  statements  made  by  i ts  Kernels. 
The  negative  Criterialities  indicate  the  importance 
of  the  absence  of  a  given  condition;  they  serve  to 
In  the 
introduce  a  scaled  logical  negation. 
notation,  Situations  w i ll  be  enclosed  in  wavy 
brackets,  and  Kernel-Criterialities  w i ll  be  written 
after  the  Kernels,  preceded  by  a  colon,  e.g.: 

(i) 
On  occasion  (e.g.  Figure  6)  we  w i ll  write  a  Kernel 
outside  of  the  Situation  to  which  it  belongs,  with 
a  two-way  arrow  joining  it  to  i ts  proper  location 
within  the  brackets. 

Weights. 

In  order  for  a  semantic  memory  to 

be  complete,  it  must  store  with  each  item  of  infor(cid:173)
mation  a  considerable  number  of  data  about  that 
item,  for  example:  the  subjective  probability  that 
it  is  true,  i ts  degree  of  surprisingness  or  incon(cid:173)
sistency  given  the  rest  of  the  information  in 
memory,  i ts  trace-strength  or  possibly  the  time 
elapsed  since  it  was  last  referred  t o,  i ts  degree 
of  pleasantness,  etc. 
processes,  this  "meta-information"  about  an  item 
must  play  a  role  second  only  to  i ts  content  in 
determining  what  is  done  with  the  item  in  a  given 
process.  Unfortunately,  this  role  is  d i f f i c u lt  to 
describe,  and  the  notation  for  many  weights  is 
messy.  Therefore  in  this  paper  we  w i ll  consider 
only  the  behavior  of  the  weight  for  Subjective 
Probability  in  any  detail.  We  w i ll  note  points  in 

In  the  modeling  of  cognitive 

-657 

Section  IV  at  which  the  absolute  likelihood  of  an 
item  is  c r i t i c al  in  determining  the  course  of  i ts 
processing. 

We  now  introduce  the  two  types  of  unit  in 

which  information  is  stored,  the  Fact  and  the  Rule. 
The  Fact.  A  Fact  i s,  syntactically,  simply  a 

Situation.  The  term  "Fact"  merely  distinguishes 
those  Situations  which  stand  free,  from  those 
which  occur  in  Rules. 

The  Rule.  A  Rule  is  an  ordered  pair  of 

It  is  interpreted  as  asserting  that 

Situations. 
the  second  Situation  (called  the  Right  Half)  is  a 
"consequence"  of  the  f i r st  (called  the  Left  Half), 
in  the  unspecified  sense  discussed  in  Section  II.A  . 
In  the  notation,  the  two  Situations  are  written 
between  square  brackets,  with  an  arrow  between 
them,  as  in  Figure  2  (above).  Any  Dummy which 
occurs  in  the  Left  Half  of  a  Rule  is  implicitly 
universally  quantified;  any  Dummy which  appears 
only  in  the  Right  Half  of  a  Rule  is  implicitly 
exist  entially  quantified.  Thus  we  have  translations 
such  as  the  following: 

(See  Step  4.3,  Section  IV.B,  for  justification  of 
these  conventions.)  Finally,  attached  to  each  Rule 
is  a  number  between  0  and  1,  interpreted  as  the 
Subjective  Probability  that  the  Right  Half  actually 
is  a  consequence  of  the  Left  Half. 
In  the  notation, 
we  may  display  this  "S.P."  to  the  right  of  the  Rule, 
but  in  most  cases  we  w i ll  suppress  i t. 

C.  Elaborations  of  the  Syntax 

For  the  purpose  of  simplicity  in  this  presen(cid:173)

tation,  we  have  shorn  the  data  format  of  the 
several  forms  of  recursive  nesting  it  must  have  if 
it  is  in  fact  to  be  able  to  represent  arbitrary 
information.  A  Node  must  be  able  to  denote  any 
Fact  or  Rule  (in  the  way  that  "@"  denotes  a 
Situation).  A  Situation  must  be  able  to  contain 
Facts  and  Rules  as  well  as  Kernels,  and  this  leads 
to  the  need  for  a  canonical  form  for  Situations. 
And  Rules  may  be  composed  out  of  other  Rules,  as 
well  as  Situations. 

The  latter  form  of  nesting  allows  us  to  define 

a  notion  of  equivalence  of  representations,  whose 
role  in  the  completed  model  is  extremely  significant. 
For  the  present  we  w i ll  content  ourselves  with 
giving  an  example  of  what  can  be  done.  We  can 
essentially  define  the  Node  "gives"  by  creating  two 
Rules  which  expand  a  Situation  involving  "gives" 
into  a  Rule  composed  of  more  primitive  predicates. 
This  "definition"  might  look  something  like 
Figure  4  (below). 

2 

F Recall  that  each  occurrence  of  the  special  symbol 

"@"  denotes  the  Situation  in  which  it  appears. 
The  Rule  in  Figure  2  records  the  event  expressed 
by  "Percy  gives  Fido  to  Agnes".  This  could  also 
be  represented  statically  as  a  Fact,  namely 
{<gives  Percy  Agnes  Fido>}  (cf.  Section  I I . C ). 

-/  Such  expansions  of  single  predicates  i n to  more 
issue  of  the 

basic  terms  r a i se  the  i n t e r e s t i ng 
existence  of  "semantic  p r i m i t i v e s ". 
is  s t i ll  very  much  open;  see  Bendix 
the  most  thorough  discussion  to  date. 
In  Figure  4  we  use  a  double  arrow  'V  merely  as 
a  n o t a t i o n al  device  to  express  two  d i s t i n ct 
Rules  (one  each  way) 

in  the  same  diagram. 

The  matter 
[22] 

f or 

As  an  additional  extension  of  the  syntax,  the 

Rule  must  be  redefined  to  be  a  sequence 
(of  Situations  and  Rules)  of  any_  length. 

I I I.  Analogy  between  Situations 

We  w i ll  give  a  semi-formal  definition  of  the 

notion  of  an  analogy  between  two  Situations, 
discuss  the  features  and  inadequacies  of  this 
definition,  and  then  consider  the  role  of  analogy 
formation  in  cognitive  processing. 

A,  Basic  Definition  of  Analogy 

The  intuitive  idea  we  are  striving  to  capture 

In  essence,  then,  an  Analogy 

is  that  an  analogy  between  two  situations  is  a 
motivated  correspondence  between  the  elements  of 
the  situations. 
between  two  Situations  S  and  S2  is  defined  to  be 
a  one-to-one  mapping  of  the  Kernels  of  S1  onto  the 
Kernels  of  S2  .  Each  Kernel-to-Kernel  pairing 
induces  a  mapping  of  the  Nodes  in  one  Kernel  onto 
the  Nodes  in  the  other;  we  w i ll  denote  such  mappings 
in  set-theoretic  notation  of  the  form 
We  require  that  a ll  of  the  Node-to-Node  mappings  be 
consistent  ( i . e.  that  their  union  be  one-to-one). 
To  formalize  the  idea  that  these  mappings  be 
"motivated",  we  further  require  that  for  each  non-
identical  pair  of  Nodes  
each  other,  we  be  able  to  exhibit  some  further 
information  which  w i ll  "justify"  the  identification 
of 
existence  of  a  Situation 
Situation 
identification 
Analogous.  There  are  two  possible  sources  of  each 
item  of  Justifying  Information  
namely  as  a  sub-
Situation  of  the  given  Situation  
independent  Fact  retrieved  from  memory. 

and a 
containing  ru,   such  that,  given  the 
are  themselves 

More  precisely:  we  require  the 

and 

mapped  into 

containing  

and 

or  as  an 

An  example  may  serve  to  clarify  this 

discussion.  Suppose  that  memory  contains  the  Fact 

and we  are 

presented  with: 

A  reasonable  Analogy  between S1. and  S2  w i ll  match 

(5) 

the  Kernel 
the  Kernel 
match  induces  the  identification  (Twirpy,Twinky). 
According  to  the  definition,  we  must  now  seek 
further  information  about  Twirpy  and  Twinky  which 
w i ll  justify  our  mapping  these  Nodes  into  each 
other.  The  Fact  F  presents  i t s e lf  as  information 
about  Twirpy;  the  sub-Situation  of  S2  consisting 
of  the  Kernel 
constitutes  a  Fact  about  Twinky.  The  definition 
requires  that  these  two  Facts  be  Analogous,  given 
the  identification  (Twirpy,Twinky),  which  is  the 
case  since  they  in  fact  become  identical  under 
that  substitution.  We  may  diagram  the  Analogy 
between  S1  and  S2  as: 

Here  the  Justifying  Information  is  on  the  right, 
and  the  vertical  arrows  denote  correspondences 
between  Nodes.  Expressed  in  English:  Willy's 
teasing  Twirpy  is  analogous  to  Willy's  teasing 
Twinky  in  that  both  Twirpy  and  Twinky  are  parakeets. 

It  is  important  to  note  that  our  definition 

of  Analogy  is  recursive  (at  the  point  where  

and 
are  required  to  be  Analogous,  given  the  proposed 

identification).  The  insistence  that  the  Node-to-
Node  mapping  be  one-to-one  makes  " is  Analogous  to" 
a  symmetric  relation  by  giving  each  Analogy  a  well-
defined  inverse.  The  definition  can  easily  be 
extended  into  a  definition  of  analogy  between  Rules. 

B.  Elaborations  of  the  Definition 

As  complex  as  the  definition  above  may  seem, 

it  is  s t i ll  far  too  simple  to  be  adequate  for  the 
analogy-formation  situations  that  arise  in  the 
actual  modeling  of  cognitive  processes.  Below  we 
w i ll  mention  several  extensions  which  must  be  made 
to  this  definition.  None  of  these  elaborations 
w i ll  be  pursued  in  the  present  paper. 

It  may  occur  that  two  Situations  w i ll  match 
closely  except  for  a  corresponding  pair  of  Nodes 
such  that  no  additional  information  is  available 
for  one  or  both  of  these  Nodes. 

In  such  a  case  one 

-659-

i d e n t i f y i ng  the  two 

would  probably  want  to  r i sk 
Nodes,  e s p e c i a l ly  if  they  were  of  low  C r i t e r i a l i t y. 
It  w i ll  also  occur  in  general  t h at  only  a  subset 
of  one  S i t u a t i on  can  be  mapped  i n to  a  subset  of  the 
other.  Whether  or  not  the  presence  of  unmatched 
Kernels  voids  the  analogy  must  depend  on  t h e ir 
number  and  t h e ir  C r i t e r i a l i t i e s.  We  see,  then, 
t h at  a  working  d e f i n i t i on  of  analogy  must  a c t u a l ly 
be  based  on  a  complex  scoring  f u n c t i on  i n v o l v i ng 
the  number  of  matched  and  unmatched  objects, 
C r i t e r i a l i t i e s, 
must  be  pushed,  and  so  on. 

the  depth  to  which  the  recursion 

t h e ir 

The 

i n t r i c a c i es  of  t h is  d e f i n i t i on  m u l t i p ly 

when  we  consider  the  need  f or  recognizing  s i m i l a r-
i t i es  which  transcend  simple  K e r n e l - t o - K e m el 
matching.  For  example, 
the  conjunction  of  the 
Kernels 

and 
should  c e r t a i n ly  match 

form 

a  s i n g le  Kernel  of  the 
In  f a c t,  a  s i n g le  Kernel  may  even  paraphrase  a 
whole  Rule.  C l e a r ly  the  n o t i on  of  equivalence 
i l l u s t r a t ed  in  Section  H.C  must  be  used  to 
supplement  the  simple  one-to-one  mapping  of  Kernels 
on  which  our  o r i g i n al  d e f i n i t i on  was  based. 

There  are  other  ways  in  which  s i t u a t i o ns  may 

be  said  to  be  analogous,  besides  corresponding 
d i r e c t l y.  They  may, 
f or  example,  have  s i m i l ar 
consequences:  eating  cyanide  and  jumping  o ff  a 
bridge  are  very  d i f f e r e nt  a c t i v i t i e s,  but  they  are 
analogous  inasmuch  as  they  have  s i m i l ar  r e s u l t s. 
Or  two  s i t u a t i o ns  may  have  s i m i l ar  antecedents:  a 
rainbow  and  a  puddle  are  q u i te  d i s s i m i l a r,  yet 
both  betoken  the  occurrence  of  r a i n.  Since  these 
other  types  of  analogy  involve  the  notion  of 
consequence, 

they  t oo  may  be  defined  in  our  system. 

An  inherent 

l i m i t a t i on  of  a ll  the  various 

i . e. 

they  cannot  ensure  t h at  the  analogies 

d e f i n i t i o ns  we  have  discussed  is  t h at  they  are  only 
s y n t a c t i c; 
produced  w i ll  be  semantically  meaningful  - 
the  J u s t i f y i ng  Information  w i ll  in  f a ct  be 
" r e l e v a n t ".  These  d e f i n i t i o ns  must  be  regarded 
merely  as  the  s y n t a c t ic  "necessary  conditions" 
analogy,  where  the  mustering  of  t r u ly  relevant 
information  is  the  r e s p o n s i b i l i ty  of  the  l a r g er 
process  which  makes  use  of  analogy  formation  as  a 
subroutine.  The  i n v e s t i g a t i o ns  of  K l i ng 
[15]  seem 

t h at 

f or 

i n to 
to  o f f er  the  best 
what  makes  an  analogy  "meaningful"  and  u s e f u l. 

i n s i g ht  so  f ar  a v a i l a b le 

C.  Uses  of  Analogy  Formation  in  Cognition 

We  may  d i s t i n g u i sh  two  major  functions  which 

analogies  can  perform  in  cognitive  processing: 
they  provide  a  means  of  dealing  w i th  novel  s i t u­
a t i o n s,  and  they  serve  to  arrange  semantic 
i n f o r­
mation  in  an  organized  structure  s u i t a b le  f or 
f u r t h er  processing.  These  two  uses  of  analogy 
formation  are  of  course  aspects  of  one  and  the  same 
process,  but  we  may  discuss  them  separately. 

Response  to  Novel  S i t u a t i o n s.  We  have  mentioned 

is  not 

f or  Rules 

If  we  pursue  such  a  n o t i o n,  we  soon 

(Section  I I . A)  t h at  a  Rule  may  be  regarded  as  a 
r o u t i ne  f or  behavior  w r i t t en  in  a  " p a t t e r n - o p e r a t i o n" 
language. 
r e a l i ze  t h at  " l e f t - h a lf  matching" 
at  a ll  a  s t r a i g h t f o r w a rd  process,  since  we  very 
seldom  encounter  the  same  s i t u a t i on  t w i c e,  and  we 
are  o f t en  c a l l ed  on  to  respond  to  s i t u a t i o ns  which 
are  only  vaguely  s i m i l ar  to  those  we  have  met 
before. 
s i t u a t i o n s"  can  be  made  precise  by  our  d e f i n i t i on 
of  Analogy  between  S i t u a t i o n s. 
This  suggests  the 
f o l l o w i ng  p r e d i c t i on  paradigm  f or  dealing  w i th 
novel  S i t u a t i o n s: 

idea  of  "vaguely  s i m i l ar 

Evidently  t h is 

Given  S i t u a t i o n:  

Predicted  S i t u a t i on 

(7) 

We  make  an  Analogic  mapping  M  between  the  given 
S i t u a t i on  and  the  Left  Half  of  a  Rule  taken  from 
memory.  We  then  apply  the  inverse  of  the  Analogy 
to  the  Right  Half  of  the  Rule, 
p r e d i c t i on  of  what  w i ll  happen  next. 

to  obtain  a 

Exactly  the  same  operation  can  be  applied  to 
derive  overt  responses,  as  soon  as  we  are  provided 
w i th  a  formalism  f or  representing  them.  That 
if  we  l et  " ( — - )"  denote  an  i n s t r u c t i on  to  a 
perceptor  or  e f f e c t o r, 

then  we  have: 

i s, 

Given  S i

t u a t

i o n :

: A c t

i on  Performed 

E x i s t i ng  Rule: 

I  

(8) 

We  might  consider  t h is  as  a  crude  model  of 
"Stimulus-Response"  behavior, 
phenomenon  of  "stimulus  g e n e r a l i z a t i o n ". 

i n c l u d i ng  the 

The 

-660-

paradigm  might  also  be  said  to  model  the 
"assimilation  of  schemata"  central  to  Piaget 
[23], 
where  we  identify  the  notion  of  "schema"  with  that 
of  "Rule". 

Organizing  Information  from  Memory.  As  can 
be  seen  from  Figure  6,  an Analogy,  once  formed, 
presents  a  goodly  amount  of  information  in  a  very 
organized  structure.  This  structure  grows  in  an 
orderly  way  as  levels  of  recursive  Analogies  are 
applied  to  the  Justifying  Information;  the  sets 
become  strung  out  in  what  we  may  call  the  Path  of 
the  Analogy.  For  example,  a  diagram  such  as 
Figure  6,  if  extended  by  two  levels  of  recursion, 
would  look  l i k e: 

(9) 
The  simplest  way  of  gleaning  information  from  such 
a  Path  is  to  take  the  unions 

and 

Note  that  semantically, 

has 

the  meaning  of 
since  a  Situation  is 
interpreted  as  the  conjunction  of  the  Kernels  it 
contains.  We  w i ll  call  the  process  of  taking  such 
unions  Path  Compression. 

The  information  provided  by  an  Analogy  is 

structured  enough  to  serve  as  a  starting  point  for 
many  cognitive  processes,  including  deduction. 
In 
the  next  section  we  w i ll  examine  in  detail  the 
role  played  by  Analogies  in  a  process  of  inductive 
generalization. 

IV.  The  Modeling  of  an  Inductive  Process 

A.  A  Sketch  of  the  Process 

The  cognitive  behavior  which  we  would  usually 

term  "generalization"  is  in  general  a  complex 
problem-solving  process,  involving  strategies  of 
guessing,  deductions  from  "general  principles", 
and  so  on. 
In  this  section  we  w i ll  be  discussing 
an  operation  which  is  very  much  simpler  and  more 
primitive,  but  which  nevertheless  seems  to  merit 
being  called  "inductive".  We  may  describe  this 
process  very  schematically  as  follows: 

Suppose  that 

and 

are  two  properties, 

behaviors,  etc.,  and  that  for  a  number  of  entities 
X we observe 

to  co-occur. 

If  enough 

and 

such  cases  accumulate,  and  especially  if  9  and  t 
are a.  priori  unlikely  individually,  we  might 
attempt  to  explain  their  co-occurrence  by  postu(cid:173)
lating  that  one  entails  the  other,  e.g.  that 

That  i s,  we  generalize  over  the 

individual  cases  X  to  postulate: 
This  proposed  law  may  be  tested  by  finding  new 
and  noting  whether  or  not 
cases  Y  for  which 
the  prediction  of  
is  satisfied.  The  formation 
and  testing  of  such  generalized  implications  w i ll 
be  called  the  Generalization-over-cases  process. 
If  the  induced  rule  is  in  fact  successful,  a 

logical  next  step  is  to  consider  the  two  new 
entities: 
generalization  may  now  be  rewritten  as 

The 

which  can  be  neatly  compressed 

and 

Since 

are  classes  of 

to: 
entities,  they  are  "concepts"  in  the  traditional 
psychological  sense,  and  the  process  we  have  just 
described  is  evidently  a  meaningful  form  of 
concept  formation.  Note  that  in  the  expression 
we  have  attained  a  "higher-order"  relation 
which  may  be  considered  without  reference  to  the 
individual  cases  from  which  it  arose.  This 
compression  of  an  implication  into  a  single 
higher-order  predicate  (in  this  case,  
mediated  by  an  equivalence  of  precisely  the  sort 
illustrated  in  Section  II.C  .  We  w i ll  not  discuss 
concept  formation  further  in  this  paper,  but  it 
clearly  can  be  represented within  our  formalism. 

is 

Although  the  above  description  may  seem  rather 

straightforward,  the  complete  modeling  of 
Generalization-over-cases  is  actually  a  very 
complex  matter.  Rather  than  attempt  to  present  an 
immense  algorithm  abstractly,  we  w i ll  content 
ourselves  with  following  in  detail  how  the  process 
might  work  in  a  particular  example.  This  form  of 
exposition  has  i ts  perils,  of  course.  The  example 
probably  would  not  work  as  described. 
It  is  some(cid:173)
times  d i f f i c u lt  to  distinguish  properties  of  the 
particular  example  from  the  general  behavior  of 
the  algorithm.  And  it  is  often  not  clear  why,  at 
a  given  point,  one  thing  is  done  next  and  not 
another.  For  these  deficiencies  we  can  only  beg 
the  reader's  indulgence.  With  respect  to  the  last 
objection  we  may  note  that  in  cognitive  processes 

-661-

the  factors  which  determine  p r e c i s e ly  what  is 
operated  on  next  need  not  be  closely  relevant  to 
the  operation  i t s e lf  (nor  very  i n t e r e s t i n g: 
e.g.  the  precise  connectivity  of  the  semantic 
memory  at  the  time  the  process  takes  p l a c e ). 

(Cyrus,Wilfred) 
say,  the  Kernels  <time  @  Thursday>  of  F2  and 

is  J u s t i f i ed  by

and 

 

Sad  to 

other  nor  i n to  anything  else. 

When  a  Kernel  is  not  immediately  matched  in 

map  neither  i n to  each 

B.  Example  of  Generalization-over-cases 

w h at 

is  an  other  wise  Promising  Analogy,  a  search  is 

For  the  purpose  of  c l a r i ty  in  our  example,  we 

i n s t i t u t ed  f or 

information  that  w i ll  correspond 

w i ll not i n d i c a te N o d e - C r i t e r i a l i t i es except where w i th "• we w o u ld f or e x a n p le s e a r ch m e m o ry 
we  have  p a r t i c u l ar  i n t e r e st  in  them.  Where  they 
are  omitted, 
the  reader  may  assume  they  have  the 
conventional  value  3  . 

not  F4
If  such 
information  is  unavailable  and  the  Kernel  must 
remain  unmatched, 
t h is  fact  must  duly  be  taken 
Phase  I:  The  f i r st  s t r u c t u r i ng  of  information. 
. 
. 
i n to  account  in  scoring  the  Analogy  ( r e c a ll 
Synopsis:  Three  F a c t s a nd  exist  in  Section  .  .  III.B  Even  ,  if  the  Analogy  .,  Analogy.  is  .accepted  , 

w as  ocurring  on  a  Thursday. 

possible, 

dtermine 

analogy 

the 

the 

or 

n, 

if 

^ 

. 

, 

. 

 

whether 

Synopsis 

memory.  A  new  Fact 

memory 
w i th 

and 

to 
serving  as  J u s t i f y i ng  I n f o r- 

is  found  to  be  Analogous  to  this  failure  ...  to,  matchc  ,  will  affect 
Analogous 

f a i l u re  to  match  w i ll 

t h is 

, further . 

f f e ct 

f u r t h er 

. 

(Sten 

3.3.) 

Let 

us 

. 

that 

processing  (Step  3.3).  Let  us  assume  that  in  our 

mation. By Path Compression two new Facts are example these two Kernels i unmatched . but 

Section  I I I . B ). 

Even  if  the  Analogy  is  accepted, 

F6 
f o l l o w i ng  The  mere  construction 

example  these  two  Kernels  go  unmatched,  but  the 
Analogy  is  accepted  anyhow. 

, 

.  of  „ 

the  Analogy  does 

, 

_ 

Steps  1.1-1.3:  At  various 

times 

the 

Steps 

three  Facts  f i nd  t h e ir  way  i n to  our  semantic  memory: 
way  into  our  memory  :  in 

The  mere  construction  of  the  Analogy  does  not 

in 

itself  „  produce  anvthiing 

that,  would 

. willing 

i t s e lf  produce  anything 

t h at  we  would  be  w i l l i ng 
to  c a ll  the  "understanding"  of  the  new  S i t u a t i o n. 
What 
is  the  s t r u c t u r i ng  of  the  four 
previously  unrelated  Facts  i n to  a  Path  of  Analogy: 

is  s i g n i f i c a nt 

Step1,4:  At  some  time,  presumably  while  v i s i t i ng 
Peoria,  we  notice  t h a t: 

(10) 

in  r e l a t i ng  F2 

Step  1.6:  Our  Analogy, 
suggests  that  these  two  Facts  about  W i l f r ed  may 
somehow  be  "relevant" 
It  seems 
reasonable  to  commemorate  t h is  r e l a t i o n s h ip  at 

to  each  other. 

to 

It  would  be  possible  simply  to  record  t h is  new  Fact conjuction .  . 

possible^ 

(11)  least  by  recording  a  new  Fact  which 
i o n : We  note 
. 

c o n j u n c t
_- 

that, 
s y n t a c t i c a l ly  F5  is  merely  the  union  of  F2  and 

.. 

is 
that 

t h e ir 

. 

f a r t h e r,  but  we  seldom  record  a nd 

so 

we  ^ 

j u st  p e r f o r m ed 

^ 
w r i t t en  e x p l i c i t l y, 

C o n 5 ) r e s s i on 

d e f i n ed 

in 
i s: 

t he  a p m t ±m 
S e c t i on 

I I II  c. 

it 

In  our 
t h is  means  to  f i nd  an  Analogy  w i th  some 

without  analyzing 
input  without  t r y i ng  to  "understand"  i t.  One 
aspect  of  understanding  a  novel  s i t u a t i on  is  to 
r e l a te  it  to  something  already  known. 
model, 
S i t u a t i on  already  in  memory. 
Step  1.5:  We  seek  an  Analogic  match  f or 
memory,  and  propose 
M  =  {(BB,AA);(Cyrus,Wilfred))  .  The  correspond- 
ence  (BB,AA)  is  j u s t i f i ed  by  member  BB 
and  <member  AA  suspenders 
property  of  redness),  v h i le  the  i d e n t i f i c a t i on 

as  a  candidate,  w i th 

(also  by  the  shared 

in 

of 

. 

(13) 

suspenders 

T he  Analogy  perpetuates  i t s e l f. 

Analogously,  we  form 
Phase; 
Synopsis: 

A  n ew  F a ct 

is  encountered  and  found 

^ 

s y n o p is 

A 

n ew 

^ 

f o r m a t l on 

of 

t he 

n ew 

-662-

Analogy  is  f a c i l i t a t ed  by  a  remnant  of  the  o ld 
Analogy  (namely  the  copy  of  
which  allows  the  p r e d i c t i on  of  a  Fact
serves  as  J u s t i f y i ng  Information.  A  new  Path 
Compression  forms 
Step  2 . 1:  At  some  point  we  record  t h a t: 

embedded  in  F  ), 
which 

 

(<member  Rupert  fireman>  :5) 

. 

Step  2 . 2:  Later,  at  the  Firemen's  B a l l,  we  are 
keeping  tabs  on  Rupert  when  we  suddenly  notice  t h a t: 

i t. 

is  s u f f i c i e n t ly  s t r i k i ng 

i t s e lf  as  a  candidate  f or 

In  constructing  an  Analogy  between  F8  and 

there  are  three  unmatched  Kernels: 

Presumably  t h is  observation 
that  we  w i ll  attempt  to  "understand" 
Step  23:  A  search  is  made  through  semantic  memory 
f or  Situations  resembling  F8  . 
Let  us  suppose  that 
F5.  happens  to  present 
matching. 
Step  2.4: 
F5 
<dances-with  Rupert  Maude> 
<time  @  Thursday>  and  member  Wilfred  fireman> 
in  F5 
induces  a  search  through  memory  f or  corresponding 
information. 
the  f i r st  two  l e f t­
overs  presumably  f i nd  no  match,  but  happily  the 
Kernel  <mnember  Wilfred  fireman>  does  r e t r i e ve  an 
item  from  memory,  namely  
j u s t i f i es  the 
t h e r e f o r e: 

.  As  noted  in  Step  1.5,  each  of  these 

i d e n t i f i c a t i on  (Rupert,Wilfred) 

The  Path  which 

In  t h is  case, 

in  F8,  and 

is 

■

«. 

In  "the 

improvement 

in  the  way  in 

in  contrast  w i th  Step  1.5  • 

the  Facts  r e l a t i ng  Cyrus  and 

There  is  a  s i g n i f i c a nt 
which  the  "firemanhood"  J u s t i f y i ng  Information  was 
found  here, 
Phase  I  Analogy, 
W i l f r ed  were  turned  up  by  a  poorly-guided  or  non-
guided  search. 
In  t h is  new  Analogy,  on  the  other 
hand, 
the  Kernel  <member  W i l f r ed  fireman>  served 
as  a  clue  to  search  f or  a  specific  item,  namely  the 
corresponding  Fact 
Recall  t h at  t h is  Kernel  was  descended  of  F1  v ia  the 

{<member  Rupert  fireman>} 

. 

Phase  I  Analogy.  Thus  the  old  Analogy  has  g r e a t ly 
f a c i l i t a t ed  the  formation  of  a  new  Analogy  similar 
to 
Step  2.5:  A  new  Path  Compression  gives  us  yet 
another  Fact: 

i t. 

Phase  I I I;  Conjunction  is  restructured  i n to 
i m p l i c a t i o n.  Synopsis:  The  successful  p r e d i c t i on 
of  F 

t r i g g e rs  a  re-examination  of  the  Facts 

which  are  found  to  be  mutually-

Analogous  conjunctions.  The  conjunction  is  s p l it 
up  and  reorganized  as  two  t e n t a t i ve  implications 
(Rules)  R..  and  R2,  one  going  each  way.  The 
C r i t e r i a l i t i es  w i t h in  R1  and  R2  are  based  on 
information  provided  by  the  Analogies  among 

in  Step 

Step  5 . 1:  The  successful  search  f or  
may  be  regarded  as  a  " p r e d i c t i o n"  that  Rupert  is  a 
fireman.  Since  "Rupert"  and  "fireman"  are  both 
low-frequency  concepts, 
p r e d i c t i on  may  be  so  surprising  as  to  cause  us  to 
re-examine  the  conjunctions  which  
represent. 
other  similar  (Analogous) 
Step  5 . 2:  We  reconstruct  the  three  Analogies  among 

In  p a r t i c u l a r,  we  search  memory  f or 

items,  and  t u rn  up  F6  . 

the  success  of  t h is 

and 

The  three  are  p a r a l l el  to  each 

and 
thus: 

other, 

(16) 

9 

Step  3.3"  Picking  one  of  these  Facts  as  t y p i c a l, 
say  F9,  we  now  convert  i ts  conjunction  i n to  a  p a ir 
of  implications, 
reasoning  of  Section  IV.A  •  These  implications 
w i ll  of  course  be  represented  as  Rules.  We  w i ll 
have  b a s i c a l l y,  but  not  exactly: 

i m p l i c i t ly  following  the 

thus 

and 

We  must  now  consider  the  m o d i f i­

cations  to  be  made 

to  

and 

before  they  are 

-<  The  a r b i t r a r i n e ss  of  t h is  choice,  and  of  many 
other  aspects  of  the  process  we  describe  here, 
r e f l e ct  the  almost  t o t al  lack  of  psychological 
data  on  which  to  base  the  algorithm.  Hopefully, 
future  studies  along  the  l i n es  of  Posner  and 
Keele 
[2k]  w i ll  eventually  enable  us  to  make 
f ar  more  accurate  models  of  when  and  how 
generalization  takes  place. 

-663-

combined  into  R1..  (the  story  is  identical  for  R 2). 

Analogies,  as  we  have  said,  are  a  superb  source 
of  information,  and  there  is  a  great  deal  of  infor 
mation  l e ft  in  the  Analogies  made  in  Step  3.2  that 
can  contribute  to  the  content  of  R., 
examination  of  these  Analogies  w i ll  determine  the 
Criterialities  of  the  various  parts  o f as 
follows. 

Node-Criterialities:  The  three  Facts  F, 

Fg  differ  significantly  only  in  the  two  t r i p l e ts 
of  corresponding  Nodes:  Wilfred,  Cyrus,  Rupert; 
and AA,  BB,  CC  .  Clearly  these  are  the  cases 
which  the  Analogies  generalize  over. 
that  the  presence  of  one  or  another  of  these  Nodes 
is  not  crucial  to  the  general  law  which  unites  the 
three  Facts.  Therefore,  by  definition  these  Nodes 
are  less  c r i t e r i al  to  
are  constant  over  a ll  three  Facts. 

than  those  Nodes  which 

It  appears 

Kernel-Criterialities:  The  Kernels  which  never 

found Analogic  matches  have  shown  themselves  to  "be 
dispensable  i n,  or  perhaps  even  irrelevant  to  the 
generalization  which  underlies  the  three  Facts. 
They  thus  are  less  c r i t e r i al  to  R]  than  those 
Kernels  which  found  mates  in  a ll  three  Analogies. 

Thus,  in  assembling  R 

from  F  and Fg we 

increase  the  Criterialities  of  those  structures 
which  through  their  constancy  give  evidence  of 
being  relevant  to  the  Rule,  and  decrease  the 
Criterialities  of  those  structures  whose  presence 
shows  signs  of  being  inessential.  Given  that  a ll 
of  the  Node-Criterialities  were  originally  3>  "the 
new  Rule  R  w i ll  be  as  shown  in  Figure  17  (above). 

5'  F6'  and 

Step  3.4:  The  data  structure  requires  that  the  new 
Rules  R1  and R2 be  assigned  Subjective  Probabilities, 
Since  we  have  as  yet  no  reason  to  prefer  one  of 
these  Rules  over  the  other,  their  i n i t i al  S.P.'s 
In  particular,  should be  equal.  We  might  assign  i n i t i al  values 
of  1/4  ,  and  thereafter  treat  the  S.P.  as  the  ratio 
number  of  successes  when  the  Rule  is  used 
of 
number  of  predictions 
predictively  (as  below).  This  particular  treat(cid:173)
ment  of  S.P.'s,  and  the  particular  scheme  we  use 
in  adjusting  C r i t e r i a l i t i e s,  were  concocted  for 
illustrative  purposes  in  presenting  this  example; 
the  actual  manipulations  must  of  course  be  more 
subtle. 
Phase  IV;  New  evidence  argues  for  a  generalization. 
Synopsis:  A  new  Fact  F 
with  the  Left  Half  of  R1  .  The  inverse  of  the 
Analogy  is  applied  to  the  Right  Half  of  R1  to 
obtain  a  predicted  Situation.  This  Situation  is  in 
fact  observed,  and  R1  is  rewarded  for  i ts  success. 
Step  4.1:  At  some  arbitrary  time  after  Phase  I II 
has  taken  place,  a  new  Fact  comes  to  our  attention: 
F 
Step  4.02:  In  an  attempt  to  understand  F10,  we  seek 
an  Analogic  match  for  it  in  memory.  Suppose  that 
the  Left  Half  of  R1  comes  up  as  a  candidate  for 
matching.  Although  we  have  no  Justifying  Infor(cid:173)
mation  for  the  identification  (Otis,Rupert),  the 
Situations  are  otherwise  identical,  so  we  may 
assume  that  the  Analogy  is  accepted. 

is  matched Analogically 

: 

We  are  now  in  a  position  to  follow  the 

"prediction  paradigm"  of  Figure  7.  That  i s,  we  may 
apply  the  inverse  of  our  Analogy,  namely  the  mapping 

to  the  Right  Half  of  

to 
obtain  a  Situation  which  we  may  expect  to  observe 
or  to  find  already  recorded  in  memory. 
to  the  Right  Half 
Step  4.3.  The  application  of 
of 
encounters  an  interesting  d i f f i c u l t y.  This 
Right  Half  contains  a  Node,  CC,  whose  low  Criter-
i a l i ty  indicates  that  it  has  been  generalized  over. 
We would expect  the Analogy 

again  to map CC 

-664-

We  should  mention  that  these  adjustments  of 

C r i t e r i a l i t i e s,  like  everything  else  in  l i f e,  are 
f a l l i b l e. 
It  might  have  happened,  for  instance, 
that  by  coincidence  both  Wilfred  and  Rupert  were 
observed  to  wear  red  suspenders  on  a  Thursday. 
We  assume  that  with  the  accumulation  of  evidence 
(as  in  Phase  IV  below),  such  coincidences  w i ll 
wash  out  of  the  inductions. 

into  some  other  Node,  but 
in  fact  provides  no 
such  Node.  Hence  in  this  and  similar  cases  we  are 
led  to  predict  the  existence  of  an  entity  in  the 
new  Situation,  corresponding  in  this  case  to  CC. 
(Note  that  the  translations  of  quantifiers  in  terms 
of  Dummies  (Figure  3)  arise  from  just  this  sort  of 
argument.)  We  may  optimistically  create  a  name 
for  our  new  entity,  say  XX.  We  thus  predict  a 
Situation  of  the  form: 

The  Kemel-Criterialities  here,  which  are 

assume  a 

t e l ls  us  that  our  main  job  is  to 

taken  from  those  in  the  Right  Half  of  
new  role:  they  indicate  the  zeal  with  which  we 
should  seek  a  realization  of  the  given  Kernel. 
That  i s,  the  dominant  C r i t e r i a l i ty  of 
<wears  Otis 
look  for  something  Otis  wears;  the  low  C r i t e r i a l i ty 
of  <dances-with  Otis  Maude>  suggests  that  we 
should  not  give  much  concern  to  finding  such  a 
condition,  since  this  Kernel  is  under  suspicion  of 
being  irrelevant  to  the  prediction. 
Step  4.4:  We  may  search  for  the  predicted  Situation 
in  our  semantic  memory  or  in  the  real  world. 
If  it 
is  in  fact  true  that  a ll  firemen  wear  red  suspenders, 
then  we  w i ll  indeed  find  such  a  Situation.  We  w i ll 
find  an  object  to  which  we  can  attach  the  name  XX, 
and  in  a ll  likelihood  there  w i ll  be  no  match  for 
the  Kernel  <dances-with  Otis  Maude>  . 
Step  4.5:  This  successful  prediction  gives  us 
valuable  information  with  which  we  may  adjust  the 
Rule  R1  .  We  may  raise  and  lower  Node-  and 
Kernel-Criterialities  in  accordance  with  the 

shown 

Analogy  formed  between  the  Right  Half  of  R1  and  the 
predicted  Situation. 
In  particular,  the  unmatched 
Kernel  <dances-with  Rupert  Maude>  attains  a 
C r i t e r i a l i ty  of  0  and  disappears,  since  a  Kernel  of 
zero  relevance  has  no  place  in  a  Situation.  The 
successful  prediction  of  course  increases  the 
Subjective  Probability  that  the  Rule  is  a  valid 
one.  Thus  from R1 we  derive  a  new  Rule 
in  Figure  19  (below). 
Steps  4.6+:  After  enough  recurrences  of 
Steps 
approach  the  form  shown  in  Figure  20  (below).  Here 
the  zero  Criterialities  of  the  Nodes  "Rupert"  and 
"CC"  indicate  that  these  occurrences  have  completely 
lost  their  identities  and  become  Dummies.  Like 
dummy  variables  in  mathematical  notation,  these 
Nodes  could  be  replaced  (consistently,  of  course) 
by  any  symbols,  e.g. 
In  view  of  the 
translation  between  Dummies  and  quantifiers  given 
in  Figure 
v 
XGfireman  yesuspenders 

expresses  precisely  the  proposition: 

our  successful  induction  w i ll 

and 

a 

Which  is  to  say,  "Firemen  wear  red  suspenders." 

was  formed 

is  that  " If  a  person  wears  red 

and  is  i ts  converse.  The  statement 

Phase  V:  New  evidence  may  argue  against  a 
generalization.  We  recall  that  a Rule  
along  with 
made by 
suspenders,  then  he  is  a  fireman".  Although  this 
proposition  is  false  in  the  absolute, 
worth  retaining  if  i ts  statistical  validity  is 
significantly  greater  than  zero.  Therefore  we  w i ll 
reward  this  Rule  as  per  Phase  IV  when  it  succeeds, 
simply  adjust  i ts  Subjective  Probability  when  it 
f a i l s,  and  expunge  it  if  the  Subjective  Probability 

it  w i ll  be 

In  t h is  way  our  model 

f a l ls  below  some  threshold. 
becomes  capable  of  r e t a i n i ng  " h a l f - t r u t h s"  -  a 
capacity  which  is  very  valuable  to  a  semantic 
memory  (among  other  t h i n g s, 
of  contradictory 

i n f o r m a t i o n ). 

it  allows  the  storage 

V.  Discussion 

A.  The  Relation  Between  Analogy  and  Generalization 

If  we  examine  the  Generalization-over-cases 

In  Step  3.3  we  saw 

in  f a ct  Analogous  to  previously-known 

process  closely,  we  f i nd  t h at  an  i n t e r e s t i ng 
statement  can  be  made  of  the  r e l a t i on  between 
analogy  and  g e n e r a l i z a t i o n. 
how  a  great  deal  of  information  supplied  by 
Analogies  was  incorporated  i n to  the  representation 
of  the  generalized  Rule.  Thus,  analogy  takes  part 
in  g e n e r a l i z a t i o n.  But  in  Phase  IV  we  found  t h at 
the  induced  Rule  l ed  to  the  search  f or  a  S i t u a t i on 
which  was 
Facts,  and  which  might  have  gone  unnoticed  if  the 
inductive  generalization  had  not  existed.  Thus, 
generalizations 
analogies. 
was  guided  by  p r e c i s e ly  that 
been  contributed  to  the  Rule  by  the  o ld  Analogy 
( i . e.  C r i t e r i a l i t i e s,  see  Steps  3.3  and  4. 3 ),  so  we 
might  say  t h at  analogies  perpetuate  themselves  v ia 
generalizations.  On  the  other  hand,  we  could  also 
summarize  Phase  IV  by  saying  t h at  generalizations 
perpetuate  themselves  v ia  new  analogies. 
In  any 
case,  we  have  c e r t a i n ly  shown  t h at  analogy  and 
generalization  are  mutually  r e i n f o r c i ng  processes 
which  can  hardly  be  separated  from  each  other. 

the  search  f or  the  new  Analogy 
information  which  had 

f a c i l i t a te  the  f i n d i ng  of  new 

In  f a c t, 

B.  Problems  in  Modeling  Cognitive  Processes 

We  are  at  present  attempting  to  construct  a 
computer  implementation  ( in  the  LISP  language)  of 
the  processes  o u t l i n ed  in  t h is  paper.  Such  an 
e f f o rt  necessarily  leaves  one  sadder  but  wiser 
w i th  regard  to  the  prospects  f or  formulating  and 
t e s t i ng  e x p l i c it  cognitive  models. 
we  w i ll  discuss  some  of  the  more  forbidding 
obstacles  we  have  encountered.  We  f e el  t h at  the 
problems  brought  out  below  correspond  not  to 
deficiencies  in  our  p a r t i c u l ar  model 
there  are  enough  of  those,  heaven  knows),  but 
rather  to  major  dilemmas  attending  the  construction 

In  t h is  section 

(although 

of  any  general  cognitive  model  in  a  large  semantic 
memory  system. 

We  have  already  mentioned  that  the  choice  of 
in  a  cognitive  process  is  often 

"what  to  do  next" 
poorly  s p e c i f i e d.  Because  of  the  extreme  scarcity 
of  psychological  data  regarding  such  choices, 
the 
model  b u i l d er  is  confronted  w i th  a  small  i n f i n i ty 
of  a r b i t r a ry  decisions 
in  designing  an  algorithm. 
The  cumulative  e f f e ct  of  these  l o w - l e v el  choices 
may  w e ll  wash  out  the  c e n t r al  t h e o r e t i c al  propo(cid:173)
s i t i o ns  that  the  model  was  designed  to  t e s t. 

There  are  other  factors  which  complicate  the 

Like 

issue  of  what  should  be  done  when  and  f or  how  long. 
In  the  f i r st  place,  many  cognitive  processes 
contain  no  inherent  termination  c o n d i t i o n. 
memory  search  or  the  construction  of  Analogies 
according  to  a  recursive  d e f i n i t i o n, 
they  are 
bounded  only  by  the  size  of  semantic  memory. 
In 
the  second  place,  a  cognitive  operation  is  seldom 
t o t a l ly  successful  or  t o t a l ly  unsuccessful.  As 
in 
our  discussion  of  Analogies,  success  must  be 
defined  by  a  scoring  function  and  threshold.  These 
considerations  would  seem  to  imply  that  a  general 
cognitive  process  cannot  be  represented  as  an 
orderly  succession  of  t i dy  operations,  but  instead 
must  be  couched  in  a  welter  of  e f f o r t - l i m i t i ng  and 
evaluation  h e u r i s t i c s. 

Of  a ll  of  the  issues  we  have  sidestepped  in 

Sections  I II  and  IV,  c e r t a i n ly  none  is  more 
worrisome  than  the  problem  of  memory  search.  Not 
only  must  relevant 
information  be  brought  f o r t h, 
but  t h is  must  be  done  without  exhaustive  search 
( i . e.  r a p i d l y ),  despite  the  f a ct  t h at  99%  of  the 
contents  of  memory  w i ll  be  i r r e l e v a nt  to  the  given 
search.  Moreover, 
" e f f e ct  of  context"  show  us  t h at  in  human  memory 
the  memory  structure  (or,  equivalently, 
the  means 
of  search  access  i n to  i t) 
is  continuously  adapting 
in  response  to  ongoing  cognitive  a c t i v i t y. 
Certainly  no  process  involving  a  l a r g e,  general 
semantic  memory  can  be  adequately  modeled  u n t il 
some  progress  is  made  on  t h is  most  r e f r a c t o ry  set 
of  problems. 

the  phenomena  of  " s e t"  and 

The  necessary  size  and  i n t r i c a cy  of  a  semantic 
memory  create  a  host  of  methodological  problems  in 
v a l i d a t i ng  the  algorithms  which  operate  in  such  a 

666-

is  to  be 

It  becomes  extremely  time-consuming  to 

in  being  99#  i r r e l e v a nt  to  the  t e st 
Sometimes  it  becomes  very  d i f f i c u lt  to 

system. 
construct  a  suitable  data-base  on  which  to  t e st  an 
algorithm  -  especially  if  that  data-base 
r e a l i s t ic 
problem. 
d i s t i n g u i sh  which  properties  of  a  program's 
behavior  are 
stem  from  i ts 
data-base  used. 
In  a d d i t i o n,  any  algorithm  w i ll 
contain  dozens  of  a r b i t r a r i l y - s et  parameters  and 
arbitrarily-made  decisions. 
I d e a l l y,  one  would 
evaluate  these  by  varying  them  one  at  a  time,  using 
a  large  number  of  t e st  data-bases,  but  such  a 
procedure 
is  out  of  the  question  in  p r a c t i c e. 

inherent 
in  i ts  algorithm,  and  which 
i n t e r a c t i on  w i th  the  p a r t i c u l ar  t e st 

The  ultimate  problems  in  v a l i d a t i on  arise 

when  one  s t r i v e s,  as  we  have  s t r i v e n,  to  charac(cid:173)
t e r i ze  general  "subroutines"  of  cognitive  behavior, 
rather  than  attempting  to  b u i ld  a  beginning-to-end 
model  of  a  p a r t i c u l ar  type  of  performance  in  a 
w e l l - d e f i n ed  cognitive  task.  The  processes  of 
Analogy  formation,  Generalization-over-cases,  and 
the  p r e d i c t i on  paradigm  of  Section  I I I .C  are  not 
by  themselves  s u f f i c i e nt  to  model  any  p a r t i c u l ar 
cognitive  behavior. 
They  are  intended  rather  to 
represent  elementary  sub-processes  which  may  be 
observed  to  p a r t i c i p a te  in  a  very  wide  range  of 
psychological  phenomena, 
from  sensory  perception 
to  n a t u r al  language  understanding.  Our  approach 
is  in  accord  w i th  the  venerable  programming  dogma 
that  the  best  and  often  the  only  way  to  come  to 
grips  w i th  a  complex  process  is  to  decompose 
it 
i n to  easily-conceptualized  subroutines.  Certainly 
t h is  law  must  apply  to  that  most  complex  of 
processes,  human  cognition.  But  the  question 
immediately  arises  of  how  one  is  to  validate  a 
proposed  algorithm  f or  a  "cognitive  subroutine'1. 
It 
techniques  to  provide  data  on  a  single  cognitive 
sub-process  taken  in  i s o l a t i on  from  a ll  others. 
But  w i th  no  data  as  to  how  the  subroutine  is 
supposed  to  perform,  one  cannot  even  debug  a 
proposed  algorithm,  much  less  v a l i d a te  it I 
in  a  s c i e n t i f ic 

it  not 
i n t o l e r a b l e, 
i n v e s t i g a t i o n, 
to  be  asked  to  consider  models  f or 
which  empirical  v a l i d a t i on  is  next  to  impossible? 
We  t h i nk  not.  Consider  the  s i t u a t i on  in 

is  e s s e n t i a l ly  impossible 

f or  experimental 

Is 

l i n g u i s t i c s.  The  l i n g u i st  (not  to  be  confused  w i th 
the  metatheorist,  or  prophet)  spends  h is  time 
t r y i ng  to  model  p a r t i c u l ar  aspects  of  a  p a r t i c u l ar 
language,  e.g.  negation  or  nominalization.  He 
does  not  have  a  complete  grammar  of  the  language 
available  to  him,  nor  does  he  attempt  to  construct 
one.  He  knows  that  h is  l i m i t ed  model  is  guaranteed 
not  to  be  f u l ly  consistent  w i th  empirical  obser(cid:173)
vations  of  language,  because  in  language  too  it 
impossible  in  r e a l i ty  to  i s o l a te  one  aspect 
from 
a ll  the  others. 
In  the  face  of  a  host  of  counter-
examples,  exceptions,  and  phenomena  not  covered  by 
his  model, 
the  worth  of  h is  theory  by  subjective  c r i t e r ia 
such  as  i n t e r n al  elegance  and  explanatory  power. 
He  is  happy  w i th  a  model  if  it  gives  him  a  b e t t er 
understanding  than  he  had  before. 

the  l i n g u i st  calmly  decides  to  judge 

is 

We  hope  that  the  model  presented  in  t h is 

paper  gives  the  reader  a  b e t t er  understanding  than 
he  had  before. 

Acknowledgment s 

I  would  also  l i ke  to 

Many  of  the  ideas  put  f o r th  in  t h is  paper 
r i g h t f u l ly  belong  either  to  Jerome  Feldman  of 
Stanford  University,  or  to  Ross  Q u i l l i an  of 
Bolt  Beranek  and  Newman  Inc. 
acknowledge  my  great  personal  indebtedness  to 
these  two  gentlemen.  This  research  was  o r i g i n a l ly 
inspired  by  Kenneth  Colby  of  Stanford,  and  he  has 
contributed  much  to  the  model. 
to  Daniel  Bobrow  of  Bolt  Beranek  and  Newman,  and 
to  N i ls  Nilsson,  Bertram  Raphael,  and  Charles 
Rosen  of  Stanford  Research  I n s t i t u te  f or  t h e ir 
encouragement  and  f or  the  opportunity  to  use  t h e ir 
computing  machines  in  developing  the  LISP  imple(cid:173)
mentation  of  the  model. 

I  am  most  g r a t e f ul 

References 

[1] 

[2] 

[3] 

Q u i l l i a n,  M.  Ross,  "Word  concepts:  a  theory 

and  simulation  of  some  basic  semantic 
c a p a b i l i t i e s ,"  Behavioral  Science,  12(5), 
Sept.  1967,  410-430 

Q u i l l i a n,  M.  Ross,  "The  Teachable  Language 

Comprehender:  a  simulation  program  and  theory 
of  language,"  Jan.  1969  (forthcoming) 

Simmons,  Robert  F.;  Burger,  John  F.;  and 

Schwarcz,  Robert  M.,  "A  computational  model  of 
verbal  understanding,"  SP-3132,  System 

-667-

Development  Corporation,  Santa  Monica,  C a l i f ,, 
A p r il  1968 

[17] 

[1*] 

Kellogg,  Charles  H.,  "A  n a t u r al  language 

compiler  f or  o n - l i ne  data  management," 
Proceedings,  F a ll  J o i nt  Computer  Conference, 
AFIPS,  Dec,  1968,  473-492 

Woods,  William  A .,  "Procedural  semantics 

f or  a  question-answering  machine," 
Proceedings,  P a ll  J o i nt  Computer  Conference, 
AFIPS,  Dec.  1968,  457-471 

Kochen,  Manfred,  "Automatic  question-

answering  of  E n g l i s h - l i ke  questions  about 
simple  diagrams,"  Journal  of  the  ACM, 
Jan.  1969,  26-1*8 

l 6 ( l ), 

Green,  C.  Cordell  and  Raphael,  Bertram, 
"The  use  of  theorem-proving  techniques 
in 
question-answering  systems,"  Proceedings, 
23rd  National  Conference,  ACM,  Aug.  1968, 
169-181 

McCarthy,  John,  "Programs  w i th  common  sense," 

Memo  No.  7,  Stanford  A r t i f i c i al  I n t e l l i g e n ce 
Project,  Stanford,  C a l i f .,  Sept.  1963 

Black,  Fischer,  "A  deductive  question-

answering  system," 
Processing,  Marvin  Minsky  e d .,  MIT  Press, 
Cambridge,  Mass.,  1968,  354-402. 

in  Semantic  Information 

Persson,  Staffan,  "Some  sequence  extrapo(cid:173)
l a t i ng  programs:  a  study  of  representation 
and  modeling  in  i n q u i r i ng  systems,"  Technical 
Report  No.  CS  50,  Department  of  Computer 
Science,  Stanford  U n i v e r s i t y,  Stanford, 
C a l i f .,  Sept.  1966 

Doran,  James  E.,  "Planning  and  g e n e r a l i(cid:173)

sation  in  an  automaton/environment  system," 
Presented  to  Fourth  Machine  I n t e l l i g e n ce 
Workshop,  Edinburgh,  Scotland,  Aug.  1968 

Hunt,  E a rl  B.;  Marin,  J .;  and  Stone,  F., 

Experiments  in  Induction,  Academic  Press,  New 
York,  1966 

Q u i l l i a n,  M.  Ross,  "A  notation  f or  repre(cid:173)

senting  conceptual  information:  an  a p p l i c a t i on 
to  semantics  and  mechanical  English  para(cid:173)
phrasing,"  SP-1395,  System  Development 
Corporation,  Santa  Monica,  C a l i f .,  Oct.  1963 

Isahley,  K a rl  S.,  "The  problem  of  s e r i al 
order  in  behavior," 
in 
in  Cerebral  Mechanisms 
Behavior,  L.  A.  Jeffress  e d .,  Wiley,  New  York, 
1951,  112-036 

Bendix,  Edward  H.,  "Componential  analysis 

of  general  vocabulary: 
of  a  set  of  verbs  in  English,  H i n d i,  and 
Japanese," 
L i n g u i s t i c s,  32(2),  Part  I I,  1966 

I n t e r n a t i o n al  Journal  of  American 

the  semantic  structure 

[18] 

[19] 

[20] 

[21] 

[22] 

[5] 

[6] 

[7] 

[8] 

[9] 

[10] 

[11] 

[12] 

[13] 

[14] 

[15] 

B a r t l e t t,  S ir  Frederic  C,  Remembering, 

Cambridge  U n i v e r s i ty  Press,  Cambridge, 
England,  1932 

[23] 

Piaget,  Jean,  The  Psychology  of  I n t e l l i g e n c e, 

Humanities  Press,  New  York,  F i r st  published 
1947 

O l d f i e l d,  R.  C,  "Memory  mechanisms  and  the 

theory  of  schemata,"  B r i t i sh  Journal  of 
Psychology,  45,  195U,"lE3g 

Colby,  Kenneth  M.,  "Computer  simulation  of 

change  in  personal  b e l i ef  systems,"  Behavioral 
Science,  1 2 ( 3 ),  May  1967,  248-253 

[21*] 

Posner,  Michael  I.  and  Keele,  Steven  W., 
"On  the  genesis  of  abstract  ideas,"  Journal 
of  Experimental  Psychology,  77 ( 3 ),  Part  1, 
J u ly  1968,  353-363 

Abelson,  Robert  P.  and  C a r r o l l,  J.  Douglas, 

"Computer  simulation  of 
systems,"  American  Behavioral  S c i e n t i s t,  8 ( 9 ), 
May  1965,  24-30 

i n d i v i d u al  b e l i ef 

Evans,  Thomas  G.,  "A  program  f or  the  s o l u t i on 

of  a  class  of  geometric-analogy  i n t e l l i g e n c e-
t e st  questions,"  AFCRL-61-884*,  A ir  Force 
Cambridge  Research  l a b o r a t o r i e s,  Hanscom 
F i e l d,  Mass.,  Nov.  1964 

K l i n g,  Robert  E.,  "Reasoning  by  analogy  w i th 

applications  to  l o g i c al  p a t t e rn  r e c o g n i t i o n ," 
Ph.D.  Thesis,  Department  of  E l e c t r i c al 
Engineering,  Stanford  U n i v e r s i t y,  Stanford, 
C a l i f, 

(forthcoming) 

[16] 

Simon,  Herbert  A.  and  Kotovsky,  Kenneth, 

"Human  a c q u i s i t i on  of  concepts  f or  sequential 
p a t t e r n s ,"  Psychological  Review,  7 0 ( 6 ),  1963, 
534~546 

-668-

