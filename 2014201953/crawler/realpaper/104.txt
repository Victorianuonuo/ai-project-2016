Learning with Labeled Sessions 

*Dept. of Computer Science and Engineering, Michigan State University, East Lansing, MI 48824  

† Department of Computer Science and Engineering, Arizona State University, Tempe, AZ85287-8809

Rong Jin*, Huan Liu† 

rongjin@cse.msu.edu 

hliu@asu.edu 

Abstract 

Traditional  supervised  learning  deals  with  labeled 
instances. In many applications such as physiologi-
cal data modeling and speaker identification, how-
ever,  training  examples  are  often  labeled  objects 
and each of the labeled objects consists of multiple 
unlabeled  instances.  When  classifying  a  new  ob-
ject,  its  class  is  determined  by  the  majority  of  its 
instance classes. As a consequence of this decision 
rule, one challenge to learning with labeled objects 
(or sessions) is to determine during training which 
subset of the instances inside an object should be-
long to the class of the object. We call this type of 
learning  ‘session-based  learning’  to  distinguish  it 
from the traditional supervised learning. In this pa-
per, we introduce session-based learning problems, 
give a formal description of session-based learning 
in the context of related work, and propose an ap-
proach  that  is  particularly  designed  for  session-
based learning. Empirical studies with UCI datasets 
and  real-world  data  show  that  the  proposed  ap-
proach is effective for session-based learning. 

1  Introduction 
A  typical  supervised  learning  problem  is  to  learn  a  model 
from  training  examples  that  are  usually  labeled  instances. 
But  for  many  applications,  training  examples  are  labeled 
objects  and  each  labeled  object  consists  of  multiple  unla-
beled instances. During classification, an object is labeled as 
class ‘a’ if the majority of its instances are classified as ‘a’.  
  One application is physiological data modeling, whose 
goal is to predict context activities of individual users based 
on their physiological data. Typically, physiological signals 
are  measured  and  recorded  continuously  for  every  other 
second.  Continuous  physiological  signals  are  then  divided 
into a number of sessions. Each session is of minutes long 
and  consists  of  hundreds  of  records  of  physiological  data. 
To  predict  the  user’s  activities  for  a  session,  prediction  is 
first  made  for  each  record,  and  the  dominant  activity  pre-
dicted for records in the session is then used as the activity 
for the session. Although each session is labeled as a single 
activity, a user may perform activities other than the labeled 
one.  For  example,  during  a  session  of  ‘watching  TV’,  the 

can 

be 

from 

found 

user  may  fall  into  sleep  for  a  short  period  of  time.  More 
information 
the  website 
http://www.cs.utexas.edu/users/sherstov/pdmc/. 

Another  application  is  speaker  identification.  To  deter-
mine the speaker for a speech sample that is a minute long, a 
typical strategy is to first divide the long speech sample into 
a  number  of  short  ones.  Then,  a  standard  classification 
model, such as Gaussian Mixture Model (GMM), is applied 
to determine the speaker identity for each short sample. Fi-
nally, the dominant speaker that is classified for short sam-
ples will be used as the predicted speaker for the long sam-
ple. Compared with the strategy that extracts a single set of 
features  for  the  whole  long  speech  sample,  this  majority 
vote  approach  is  usually  more  robust  and  accurate  [Rey-
nolds, 1995]. This is because features extracted from a long 
speech  sample  may  include  significant  amounts  of  back-
ground noise, while the noise can be reduced substantially 
when a long speech sample is divided into short ones.  

The  common  characteristics  of  the  above  two  applica-
tions are that (1) training examples are labeled objects (e.g., 
sessions of physiological records in physiological data mod-
eling,  and  a  long  speech  sample  in  speaker  identification); 
(2)  every  object  consists  of multiple  instances  that  are  not 
labeled;  and (3)  in  predicting  an  object’s class,  it  is  deter-
mined by the class that is assigned to the majority of its in-
stances.  To  distinguish  this  new  type  of  learning  from  the 
traditional  supervised  learning,  we  call  it  ‘session-based 
learning’. 

The  challenge  of  session-based  learning  arises  from  the 
majority vote strategy that is used to determine the label of 
an  object.  This  decision  rule  makes  it  ambiguous,  during 
training, as to which subset of the instances inside an object 
should  belong  to  the  class  of  the  object  –  we  name  it  the 
label  ambiguity  problem.  A  straightforward  strategy  to-
ward this problem is to treat every unlabeled instance within 
a  labeled  object  as  a  positive  example  for  the  class  of  the 
object. In physiological data modeling, every physiological 
record  within  a  labeled  session  is  treated  as  a  training  in-
stance  for  the  activity  assigned  to  the  session.  In  speaker 
identification,  every  short  sample  within  a  long  speech  is 
used  as  a  positive  training  instance  for  the  speaker  of  the 
long  speech.  We  call  this  simple  strategy  the  ‘naive  ap-
proach’. 

A 

D 

B 

C 

Figure 1: A toy example of session-based learning 
problem with four classes ‘A’, ‘B’, ‘C’, and ‘D’. 
One obvious problem with the naïve approach is that in-
stances within a single object often belong to multiple dif-
ferent  classes,  not  just  to  the  class  of  the  object.  Thus,  by 
treating every instance within an object as a positive exam-
ple for the class of the object, we likely introduce training 
examples with noisy labels, which, as a result, degrades the 
quality  of  classification  models.  To  further  illustrate  the 
problem with the naïve approach, let us consider a toy learn-
ing problem in Figure 1. It has four classes, with class ‘A’, 
‘B’, and ‘C’ centering on the vertices of a triangle, and the 
fourth class ‘D’ sitting on the center of the triangle. In tradi-
tional  supervised  learning,  training  examples  are  labeled 
instances.  Since  these  four  classes  are  well  separated,  we 
would expect that a simple Naïve Bayes model should work 
fine for this problem. But, for a session-based learning prob-
lem,  training  examples  are  labeled  objects  that  consist  of 
instances  from  different  classes.  In  particular,  consider  the 
case when training objects for classes ‘A’, ‘B’, and ‘C’ are 
mixtures of instances from these three classes, while train-
ing  objects  for  class  ‘D’  only  contain  instances  from  ‘D’. 
With  appropriate  mixtures,  the  input  means  of  instances 
from  labeled  objects  for  the  four  classes  can  stay  close  to 
each other, which makes it hard for the Naïve Bayes method 
to learn if assigning each instance with its object class. 

In the following, we first give a formal description of ses-
sion-based  learning,  and  elaborate  on  the  differences  be-
tween this new type of learning problem  and other related 
learning problems, such as multiple-instance learning. Then, 
we present a novel approach that is particularly designed for 
session-based learning. The key idea is to develop an inno-
vative  way  that  handles  the  label  ambiguity  problem.  Fi-
nally, we demonstrate the effectiveness of the proposed ap-
proach  for  session-based  learning  using  both  UCI  datasets 
and data from physiological data modeling. 

2  Formal Description of Session-based 

{
(

Learning 
Let 
training 
o y
D
o y
,
,
=
1
1
2
labeled object and 
ject 
problems, and  [1..

),(

io . Domain Y is  { 1,1}−

be 

o y
,
n

,  where  each  (

denoted 
o y
,
i
i

examples 
}
)
n

by 
  is  a 
),...,(
2
iy ∈ Y  is the class label assigned to ob-
 for binary-class classification 
]K  for multiple-class classification prob-

)

lems where K (K > 2) is the number of classes. Let 
( )c o  be 
an object-based  classification function,  which  takes  an ob-
ject  o  as  input  and  outputs  its  class  label.  In  general,  any 
supervised learning problem can be formulated as an opti-
mization problem: 

*

c

=

arg min

c

∑

n
i
1
=

(
L c o
(
i

),

y
i

)

 

(1) 

iy . 

)ic o  is different from 

where  L  is  a  loss  function  that  determines  the  amount  of 
punishment when prediction  (
  For a traditional supervised learning problem, each object 
only contains a single instance. As a result, training exam-
{
}
= x
ples can be simplified as 
, 
)
(
1
d
 is a vector in a d dimension 
where each instance 
space. Furthermore, the object-based classification function 
( )c o   becomes  an  instance-based  classification  function 
Y .  Thus,  a  traditional  supervised  learning 
f
problem is usually formulated as follows: 
)
y
i

D
i ∈ℜx

arg min

ℜ →

),...,(

(
L f

x
( ) :

),(

y
1

(1a)

),

=

x

x

x

y

y

 

(

f

,

,

,

n

n

d

*

2

2

i

∑

n
i
1
=

f

In session-based learning, each object consists of multiple 
unlabeled  instances.  Let  the  training  data  be  denoted  by 
D
,  where  each  object 

),...,(

X

X

y

y

,

,

}
)

n

n

2

2

  contains  mi  different  instances.  Given  an 

{
= X
(
1
{
=X

x

i

y
,
),(
1
},
im
j=
1

i j

c
s
i
( )δ ⋅

d

f

x
( ) :

ℜ →

Y ,  the 
instance-based  classification  function 
iX  
decision rule for session-based learning is that, an object 
is  labeled  as  class  ‘a’  if  the  majority  of  its  instances  are 
classified as ‘a’. Thus, in session-based learning, the object-
based classification function cs  can be written into the fol-
lowing form of the instance-based classification 
)
 

arg max

f x : 
( )

(2) 

X

i j
,

=

=

x

y

(

)

(

)

f

f

;

(
im
δ
j
1
=

∑Y

y
∈

 is a delta function that outputs 1 when the input 

where 
is positive and zero otherwise.  
  Compared  to  traditional  supervised  learning,  the  chal-
lenge of session-based learning is due to the label ambiguity 
problem.  Although  each  training  object  is  provided  with  a 
class label, the label information of instances within objects 
is not given. Hence, it is difficult to learn an instance-based 
classification  function  from  labeled  objects.  In  the  naïve 
approach, each instance within an object is treated as a posi-
tive example for the class of the object. As a result, a ses-
sion-based  learning  problem  is  simplified  as  a  traditional 
supervised learning problem: 
imn

*

f

=

arg min

f

(
∑∑ x
L f
(

i

1
=

j

1
=

),

y
i

i j
,

)

 

(1b)

  The most related work to session-based learning is multi-
ple-instance learning[Dietterich, et al.,1997]. Similar to ses-
sion-based learning, in multiple-instance learning, class la-

bels  are  assigned  to  objects  that  consist  of  multiple  in-
stances, which are called “bags” in multiple-instance learn-
ing. In the past, there have been many studies on multiple-
instance  learning,  including  the  approach  of  learning  axis-
parallel rectangles [Dietterich, et al.,1997], the diverse den-
sity  algorithm  [Maron  and  Lozano-Pérez,1998],  the  ap-
proaches  based  on  support  vector  machines  [Andrews,  et 
al.,2002,  Tao,  et  al.,2004],  the  nearest  neighbor  approach 
[Amar et.al. 2001; Wang and Zucker, 2000], and the boost-
ing approach [Andrews and Hofmann,2003]. 

Multiple-instance  learning  differs  from  session-based 
learning  in  its  decision  rule.  In  multiple-instance  learning, 
iX  is labeled as positive class when at least one of 
an object 
its  instances  is  classified  as  positive.  A  negative  class  is 
assigned to an object when all of its instances are classified 
as  negative.  Thus,  given  the  instance-based  classification 
Y ,  the  object-based  classification 
function 
function cm for multiple-instance learning is written as: 

ℜ →

x
( ) :

f

d

c
m

(

X

i

;

f

)

j
1
+
∃ ∈
= − ∀ ∈
i
1


[
1...
[
1...

]
m f
,
i
]
m f
,

i

x
(
i j
,
x
(

i j
,

)
)

1
= +
1
= −

 

(2’)

Examples for the three different types of learning are shown 
in  Figure  2  for  comparison.  The  first  column  shows  tradi-
tional  supervised  learning  with  instances  and  their  labels. 
The  columns  for  Multiple  Instance  Learning  and  Session-
based Learning show how these two different strategies ag-
gregate instances and assign labels to the aggregates. 

Session-based learning is more challenging than multiple-
instance  learning  in  the  following  sense:  in  multiple-
instance learning, when an object is labeled as ‘negative’, all 
of its instances will belong to the negative class. Thus, for 
multiple-instance  learning,  there  is  no  label  ambiguity  for 
negatively  labeled  objects. In  contrast,  the  label  ambiguity 
problem exists for session-based learning regardless of the 
sign  of  labels.  For  instance,  in  Figure  2,  for  session-based 
learning,  both  the  first  and  second  objects  are  labeled  as 
‘negative’.  However,  the  labels  of  instances  in  these  two 
objects are different. The two learning schemes also differ 
in  degrees  of  difficulty  when  deciding  positive  classes  for 
objects: multiple-instance learning adopts the “at-least one” 
strategy and session based learning uses the majority one.  

3  SBoost – An Algorithm for Session-based 

Learning 
In  this  session,  we  will  present  a  boosting-based  algo-
rithm for session-based learning problems of binary classes. 
The  key  for  designing  a  learning  algorithm  for  session-
based learning is to define a simple yet effective loss func-
tion 
simple 
is 
(
L c
.  However,  this  choice 
(
will lead to a non-smooth objective function, which is usu-
ally difficult for optimization. Hence, we choose to use the 
exponential  loss  function  to  approximate  classification  er-

(
L c
(
f
y
),
i

f
;
),
i
(
δ=

A 
y
≠
i

)
. 
X
;

choice 

y
i
c
(

X
)

X

)

)

f

;

i

i

-1 

-1 

…… 

Learning 

Learning 

Session-based 

Multiple-instance 

Trad. Super-
vised Learning
0.1 0.2 0.3 -1  0.1 0.2 0.3 
0.2 0.5 0.4 -1  0.2 0.5 0.4 
0.6 0.2 0.1 -1  0.6 0.2 0.1 
…… 
0.3 0.7 0.6 -1  0.3 0.7 0.6 
0.7 0.2 0.2 -1  0.7 0.2 0.2 
0.8 0.1 0.0 +1  0.8 0.1 0.0 
…… 
0.5 0.7 0.1 +1  0.5 0.7 0.1 
0.1 0.6 0.9 -1  0.1 0.6 0.9 
0.7 0.1 0.2 +1  0.7 0.1 0.2 
Figure  2:  Training  examples  for  traditional  super-
vised  learning,  multiple-instance  learning,  and  ses-
sion-based leaning. 

0.1 0.2 0.3
0.2 0.5 0.4
0.6 0.2 0.1
…… 
0.3 0.7 0.6
0.7 0.2 0.2
0.8 0.1 0.0
…… 
0.5 0.7 0.1
0.1 0.6 0.9
0.7 0.1 0.2

…… 

+1 

+1 

+1 

-1 

rors,  which  has  been  demonstrated  to  be  effective  in  the 
AdaBoost algorithm [Freund and Schapire, 1997]. 
In particular, in designing objective functions, two types 
 
of errors are considered: instance-based errors and session-
based errors. An instance-based error is a prediction mistake 
made for an instance, and a session-based error is a predic-
tion  mistake  made  for  a  session.  One  key  difference  be-
tween  session-based  learning  and  traditional  supervised 
learning is that the former is concerned with both session-
based errors and instance-based errors while the latter con-
cerns with only instance-based errors. To include both types 
of  errors,  given  an  instance-based  classification  function 
( )H x , we define the loss function as: 

i

;

=

L c X H y
),
( (
)
i
m

i
∑



Session-based error

H x
(



)
exp



(cid:8)(cid:11)(cid:11)(cid:11)(cid:11)(cid:9)(cid:11)(cid:11)(cid:11)(cid:11)(cid:10) (cid:8)(cid:11)(cid:11)(cid:11)(cid:11)(cid:9)(cid:11)(cid:11)(cid:11)(cid:11)(cid:10)

y
γ
i
m
i

 



 
 

∑

H x
(

1
=
Instance-based error

exp

y
i

i j
,

i j
,

−

−

(

m
i

1
=

)

)

j

j

 

(3) 

In  the  above  expression,  both  session-based  and  instance-
based  errors  are  approximated  by  an  exponential  function. 
The loss function is defined as the product of these two er-
rors.  In  other  words,  a  misclassified  instance  is  important 
only when its related session is also misclassified. Constant 
γ  in  (3)  determines  the  relative  importance  between  the 
session-based error and the instance-based error. In experi-
ment, a cross validation with 20/80 split of training data is 
used to determine appropriate values for  γ. In the follow-
( )H x   that 
ing,  we  will  discuss  how  to  efficiently  find 
minimizes the loss function in (3). 
 3.1  Boosting-based Optimization Algorithm 

With the loss function defined in (3), our goal is then to 
search for optimal H(x) that minimizes the overall cost for 
the training data, i.e., 

arg min

∑

n
i
1
=

(
L c

(

X

;

H y
),
i

i

)

*

H

=

arg min

H

err

=

=

arg min

H

n

∑

i

1
=

exp

−






H
y
γ
i
m
i

m
i

∑

j

1
=

H x
(

i j
,

)

 



 
 

m
i

∑

j

1
=

exp

(

−

H x
(

i j
,

)

y
i

(4)

)







Given: (X1, y1), …, (X m, ym) where 

X

i

=

x
, 

i j
,

d

∈ℜ

, 

y
i

{
∈ −

}
1,1

; Weighting constant γ 

{

x

im
j
1
=

i j
,

}
(
= ∑

D i

( , ) 1

j

0

n
m=
i
i
1

)

, 

H x =  
0( ) 0

Initialize the weight distribution 
For t = 1,…,T 

1.  Sample training instances {
x
1,1
x
th
2.  Train a weak classifier 
( ) :
y
γ
∑
i
m
i

3.  Compute 

im
j
1
=

exp


−


=

g

i

b
i

=

m
i

∑

j

1
=

y h
i

(

x

i j
,

)exp

(

−

H

(

x

t

1
−

i j
,

,...,

,...,
d

x
m
1,
1
{ 1,1}
ℜ → −



y a
γ
i
i
m
i

H

y
i

i j
,

+

)

x

1
−

)

(

)

t

m
i

∑

j

1
=

}

 according to 

1tD −  

x

,...,

x

n m
,
n

n
,1
 on sampled examples 

, 

a
i

=

∑

im
j
1
=

exp

(

−

H

(

x

i j
,

)

y
i

t

1
−

)

, and 

h

(

x

i j
,

)

 for each session. 

4.  Let 

α
t

=

1
2(1
+

)
γ

ln









n
∑
i
1
=
n
∑
i
1
=

g

i

g

i

[

[

(1

+

)
γ

a
i

+

b
i

(1

+

)
γ

a
i

−

b
i

 

]

]









5.  Update the weight distribution 

(
D i
t

,

j

)

=

(

g

i

exp

(

H
−−
t
1

(

x
i j
,
Z

t

)

y
i

)

+

γ

a m
i
i

)

, where 

tZ  is a normaliza-

tion factor (chosen so that 
x
( )

6.  Update the classifier 

H

t

1tD +  is sum to 1). 
x  
( )
=

x
( )

hα
t
t

H

+

1
−

t

Output the final hypothesis: 

F
T

x
( )

=

arg max
{
}
y
1,1
∈ −

∑

T
x
yα=
( )
t
1

h
t

t

 

Figure 3: Description of the SBoost algorithm.

An efficient approach for optimizing Eq. (4) is to divide it 
into  a  series  of  simple  learning problems  that  do not  have 
the  label  ambiguity  problem  and  thus  can  be  resolved  by 
traditional  supervised  learning  techniques.  We  solve  the 
label ambiguity problem by maintaining weights for differ-
ent instances such that only instances with large weights are 
assigned to the class of their objects and used for training. 
Since  boosting  [Freund  and  Schapire,  1997]  is  a  learning 
algorithm that uses weighted instances to efficiently update 
classification functions, we design a boosting-based learning 
algorithm for learning with labeled sessions below.   

T
hα=
t
t
t
1

= ∑x
( )

( )
x ,  where 
( )

th x  be the ‘weak’ classifier of the t-th iteration that 
is  learned  using  traditional  supervised  learning  techniques. 
TH x  for the first T iterations is 
The combined classifier 
H
tα  is  the  combination  con-
stant for the t-th iteration. Our goal is to find another ‘weak’ 
Th + x   and  a  constant 
classifier 
1Tα +   such  that  the  new 
x   will 
x
H
combined  classifier 
( )
( )
=
T
effectively  minimize  the  function  in  (4).  Given  classi-
fier

TH + x , the objective function in (4) is rewritten as: 

hα
T
1
+

1( )

1( )

Let 

x
( )

( )

H

+

1
+

1
+

T

T

T

err

=

n

∑

i

1
=

exp











∑
×




m
i

1
=

j

−

y
γ
i
m
i
(

exp

−

m
i

∑

j

1
=

H

(

x

i j
,




)

+

h
α

(

x

)




i j
,

H x
(

i j
,

)

+




α

h x
(

i j
,

)




y
i

)

 
















(5) 

In  the  above  expression,  for  the  convenience  of  presenta-
tion,  we  drop  the  index  for 
1Tα + . 
Using the convexity of an exponential function, we have  

Th + x ,  and 

TH x , 
( )

1( )

err

≤

im

n

∑ ∑

g
i
m
i

i

1
=

k j
,

1
=

exp

(


−
α


h

(

x

i j
,

)

+

h
γ

(

x

)




i k
,

y H
i

−

(

x

i j
,

)

y
i

)

(6)

where 

g

i

≡

exp


−

α
e

y
γ
i
m
i
1

im
j
1
=

∑ x
H
(
x
−
2

α−
, 

e

x

i j
,

)




[ 1,1]

x

1

+
2

x
α
e

≤

ity 
upper bound (6) by the following expression: 

∀ ∈ −

+

. Then, using inequal-

,  we  can  further 

err
err
≤
upper
(1
)
)
α γ
−
α γ
+
e
e
+
2

(1
+

=

−

(1
+

(1
)
)
α γ
+
−
α γ
e
e
−
2(1
)
+
γ

n

∑

i

1
=

a g
i

i

n

m
i

∑∑

i

1
=

j

1
=

y h
i

(

x

i j
,

)

g




+


i

g

(
exp
a
γ
i
m
i

i

−

H

(

x

)

y
i

i j
,

(7) 

 

 

)







,

j

)

g

≡

a
i

≡
(

where 

∑
(
exp

im
j
1
=
(
D i
H
(
second term in (7) as: 
)
(1
)
+
−
α γ
α γ
e
e
−
2(1
)
+
γ

(1
+

−

i

exp

(

−

H

x

)

y
i

i j
,

x

i j
,

)

y
i

)
a mγ
i

i

+

.  Define  weight 
)

  and  rewrite  the 

(
)

imn

∑∑ x
y h
(
i

i

1
=

j

1
=

)

D i

j
( , )

 

i j
,

(8) 

j
( , )

Clearly,  to  minimize  the  objective  err  in  (7),  we  need  to 
maximize the above expression (8). The best case is that the 
( )h x  is consistent with yi, for all 
output of weak classifier 
instances in an object. When this is not the case, the label 
ambiguity  problem  is  then  resolved  based  on  weight 
D i
.  In  particular,  instances  with  large  weights  are  as-
signed  with  the  class  of  their  objects,  while  the  labels  for 
instances with small weights remain unlabeled. This is be-
cause the contribution of an instance to (8) is mainly deter-
mined by its weight 
. When an instance has a small 
weight,  its  contribution  to  (8)  will  be  ignorable.  Further-
ig ,  which  is 
more,  notice  that 
related to session-based error. Thus, a misclassified instance 
will not be assigned with a large weight if the related ses-
sion error is small. Finally, the combination constant α can 
be obtained by setting the derivative of the upper bound in 
(7) w.r.t. to α to be zero. That is, 

  is  proportional  to 

j
( , )

j
( , )

D i

D i

α

=

1
2(1
+

)
γ

ln









n

i

∑
∑

1
=
n

i

1
=

g

i

[

(1

+

)
γ

a
i

+

b
i

g

i

[

(1

+

)
γ

a
i

−

b
i

 

]

]









(9) 

where
∑
b
i

≡

m
i
j
1
=

y h x
(
i

i j
,

)exp

(

−

H

(

x

)

y
i

i j
,

)

+

y a
γ
i
i
m
i

∑

m
i
j
1
=

h

(

x

i j
,

)

. 

For later reference, we name this algorithm SBoost for ‘ses-
sion-based boosting’. The details are given in Figure 3.  

4   Experiments 
The goal of this section is to examine the effectiveness of 
SBoost  for  session-based  learning.  We  compare  SBoost 
with  the  simple  naïve  approach  that  treats  each  instance 
within an object as a positive example for the class of the 
object.  In  particular,  the  naïve  approach  is  applied  to  ses-

Data Set 

# Examples 

# Features 

spam 
cmc 

german 

4600 
1470 
680 

58 
10 
24 

Table 1: Statistics of UCI datasets used for synthesized data

# Instances 
# Objects 

# Avg of instances 

per object 

Positive Class  Negative Class 

4343 
55 

69.3455 

3,6495 
186 

199.0538 

Table 2: Statistics for the physiological data 

sion-based 
AdaBoost using a Decision Tree as its base classifier. 

learning  with  both  a  Decision  Tree  and 

Two types of data are used in experiments to evaluate the 

effectiveness of SBoost:  
1)  Synthesized  data  that  are  generated  from  binary  UCI 
datasets [Blake and Merz,1998] by combining multiple in-
stances  into  objects.  Each  object  consists  of  ten  different 
instances. To create an object for the positive class, a ran-
dom number between 1 and 5 is first generated, and the cor-
responding number of instances from the negative class are 
randomly  chosen  and  added  to  the  object.  The  rest  of  the 
object  is  filled  out  with  instances  randomly  selected  from 
the positive class. A similar procedure is applied to generate 
objects  for  the  negative  class.  By  doing  so,  we  guarantee 
that  the  class  of  an  object  is  consistent  with  the  dominant 
class assigned to its instances. The details of UCI datasets 
used in this experiment are listed in Table 1. 
2)  Physiological  data  that  come  from  the  workshop  of 
physiological data modeling at the ICML 2004. We use the 
dataset  for  ‘watching  TV’  with  code  3004.  In  the  original 
problem,  the  number  of  instances  for  the  negative  class  is 
overwhelmingly larger than that for the positive class. Since 
we focus on the study of session-based learning, we inten-
tionally reduce the effect of rare class by randomly selecting 
parts  of  negative  instances.  The  resulting  data  set  has  241 
sessions  with  40,838  instances.  The  details  of  this  dataset 
are listed in Table 2.  

A  decision  tree  [Quinlan,1993]  is  used  as  the  baseline 
classifier  throughout  the  experiments.  The  session-based 
classification error, i.e., the percentage of sessions that are 
misclassified,  is  used  for  evaluation.  50%  of  data  are  ran-
domly selected for training and the rest is used for testing. 
The same experiment is repeated 10 times, and the average 
session-based classification errors are reported. Finally, for 
both SBoost and AdaBoost, the maximum number of itera-
tions is set to be 30. 
4.1  Results 
The  results  of  three  methods  (SBoost,  the  naïve  approach 
using a single decision tree, and with AdaBoost) are shown 
in Table 3. First, we compare the performance of AdaBoost 
with that of a decision tree as both adopting the naïve ap-
proach to session based learning. We observe that AdaBoost 

Data Set 

SBoost 

spam 
cmc 

AdaBoost 
0.189 (0.022)  0.258 (0.059) 
0.439 (0.044)  0.444 (0.070) 
german  0.342 (0.028)  0.424 (0.069) 
phys. 
0.163 (0.038)  0.191 (0.035) 

Decision Tree 
0.232 (0.051) 
0.519 (0.052) 
0.476 (0.081) 
0.176(0.030) 

Table  3:  Classification  errors  with  variances  for  the 
SBoost algorithm, the AdaBoost, and the decision tree  
does not guarantee to improve performance over the base-
line  classifier  (a  decision  tree  here).  In  fact,  for  the  spam 
dataset  and  the  physiological  data,  the  classification  errors 
of AdaBoost are even greater than those of a decision tree. 
This is because the naïve approach treats all instances in an 
object as positive examples for the class of the object, while 
in reality, some instances in an object may belong to a class 
other than the class of the object. Hence, the naïve approach 
introduces  noisy  labels  to  training  data,  which  will  likely 
cause  AdaBoost  to  overfit  as  observed  in  previous  study  of 
Boosting [Quanlin, 1996, Dietterich, 2000, Jin et al., 2003].   
Second, comparing SBoost with the decision tree, we ob-
serve that SBoost always outperforms its baseline classifier. 
According to t-test, it is statistically significantly better than 
the decision over all the UCI datasets with 
. Thus, 
SBoost  does  not  suffer  from  the  problem  of  overfitting  as 
AdaBoost does. To further investigate this issue, we obtain 
average  classification  errors  of  AdaBoost  and  SBoost  in 
different  iterations,  respectively,  as  shown  in  Figure  4. 
Clearly, AdaBoost tends to overfit the training data after the 
first several iterations whereas SBoost does not. 

0.05

p <

5. Conclusion 
In this paper, we formulate a new type of learning problem, 
session-based learning. It differs from the traditional super-
vised learning in that training examples are labeled objects 
and  each  object  consists  of  multiple  unlabeled  instances. 
Furthermore, session-based learning adopts a different deci-
sion rule from that of multiple-instance learning: an object is 
classified as class ‘a’ when the majority of its instances are 
classified as ‘a’. This majority vote decision rule causes the 

0.22

0.21

0.2

r
o
r
r

SBoost
AdaBoost

 

E
n
o

i
t

a
c
i
f
i
s
s
a
C

l

0.19

0.18

0.17

0.16

0.15

0

5

10

15

20

25

30

Figure 4: Classification errors for physiological data 

Iteration

label ambiguity problem and has made session-based learn-
ing very challenging. We formally describe this new learn-
ing problem and propose a novel boosting algorithm, named 
Sboost. Empirical studies have demonstrated the effective-
ness of the Sboost algorithm. 

References 
[Amar et.al. 2001] Robert A. Amar, Daniel R. Dooly, Sally 
A. Goldman, Qi Zhang, Multiple-Instance Learning of Real-
Valued Data, Proc. 18th ICML, 2001. 
[Andrews and Hofmann, 2003] Stuart Andrews and Thomas 
Hofmann, Multiple-Instance Learning via Disjunctive Pro-
gramming Boosting, NIPS, 2003. 
[Andrews, et al., 2002] Stuart Andrews, Thomas Hofmann 
and Ioannis Tsochantaridis, Multiple Instance Learning with 
Generalized  Support  Vector  Machines,  Proc.  18th  AAAI  , 
2002. 
[Blake and Merz,1998] C.L. Blake and C.J. Merz, UCI Re-
pository of Machine Learning Databases,1998. 
[Dietterich, et al.,1997] T. G. Dietterich, Richard H. Lathrop 
and  Tomas  Lozano-Perez,  Solving  the  Multiple-Instance 
Problem  with  Axis-Parallel  Rectangles,  Artificial  Intelli-
gence, 89(1-2), 31-71,1997. 
[Dietterich,  2000]  T.  G.  Dietterich,  An  experimental  com-
parison of three methods for constructing ensembles of de-
cision  trees:  Bagging,  boosting,  and  randomization.  Ma-
chine Learning, 40:139–157,2000. 
[Freund  and  Schapire,  1997]  Yoav  Freund  and  Robert  E. 
Schapire,  A  Decision-theoretic  Generalization  of  On-line 
Learning and an Application to Boosting, Journal of Com-
puter and System Sciences, 55(1), 119-139, 1997.  
[Maron  and  Lozano-Pérez,1998]  Oded  Maron  and  Tomás 
Lozano-Pérez,  A  Framework  for  Multiple-Instance  Learn-
ing, NIPS, 1998. 
[Jin  et  al.  ,2003]  Rong  Jin,  Yan  Liu  ,  Luo  Si,  Jaime  Car-
bonell,  Alexander  G.  Hauptmann,  A  New  Boosting  Algo-
rithm Using Input-Dependent Regularizer, Proc. 20th ICML, 
2003 
[Quinlan,1993]  R.J.  Quinlan,C4.5:  Programs  for  Machine 
Learning, Morgan Kaufmann,1993. 
[Tao,  et  al.,2004]  Qingping  Tao,  Stephen  Scott,  N.  V.  Vi-
nodchandran and Thomas Takeo Osugi, SVM-based Gener-
alized  Multiple-Instance  Learning  via  Approximate  Box 
Counting, Proc. 21st ICML, 2004. 
[Wang  and  Zucker,  2000]  Jun  Wang,  Jean-Daniel  Zucker, 
Solving  the  Multiple-Instance  Problem:  A  Lazy  Learning 
Approach, Proc. 17th ICML, 2000. 
[Quinlan,  1996]  Quinlan,  J.  R.  (1996).  Bagging,  Boosting, 
and  C4.5.  Proceedings  of  the  13th  National  Conference  on 
Artificial Intelligence, 322–330. 
[Reynolds, 1995] D. A. Reynolds, Speaker identification 
and verification using Gaussian mixture speaker models, 
Speech Communications, vol. 17, pp. 91–108, 1995. 

