Dynamic Bayesian modeling of the cerebral activity 

Vincent Labatut, Josette Pastor, Serge Ruff 

Inserm u455 

Pavilion Riser, CHU Purpan 

31059 Toulouse CEDEX 3, France 

{vincent.labatut; josette.pastor; serge.ruff}@toulouse.inserm.fr 

Abstract 

Conventional methods used for the interpretation 
of activation data provided by functional neuro-
imaging  techniques  provide  useful  insights  on 
what the networks of cerebral structures are, and 
when  and  how  much  they  activate.  However, 
they do not explain how the activation of these 
large-scale  networks  derives  from  the  cerebral 
information processing mechanisms involved in 
cognitive functions. At this global level of repre(cid:173)
sentation, the human brain can be considered as 
a dynamic biological system. Dynamic Bayesian 
networks  seem  currently  the  most  promising 
modeling  paradigm.  Our modeling  approach  is 
based on the anatomical connectivity of cerebral 
regions, the information processing within cere(cid:173)
bral  areas  and  the  causal  influences  that  con(cid:173)
nected regions exert on each other. The capabili(cid:173)
ties of the formalism's current version are illus(cid:173)
trated by the modeling of a phonemic categoriza(cid:173)
tion process, explaining the different cerebral ac(cid:173)
tivations  in  normal  and  dyslexic  subjects.  The 
simulation data are compared to experimental re(cid:173)
sults [Ruff et al, 2001]. 

1  Introduction 
In Neurology and Neuropsychology, the diagnosis of the 
neurological causes of cognitive disorders, as well as the 
understanding and the prediction of the clinical outcomes 
of  focal  or  degenerative  cerebral  lesions,  necessitate 
knowing the link between brain and mind, that is what 
the cerebral substratum of a cognitive or a sensorimotor 
function is and how the substratum's activity can be in(cid:173)
terpreted in cognitive terms, i.e. in terms of information 
processing. 

Studies  in humans  and animals  [Bressler,  1995; De-
monet et al, 1994] have shown that sensorimotor or cog(cid:173)
nitive  functions  are the  offspring of the  activity  of ori(cid:173)
ented  large-scale  networks  of  anatomically  connected 
cerebral regions (Figure 1). In humans, functional neuro-
imaging  techniques  provide  activation  data,  which  are 
indirect  measures  of the  brain's  electrical  or  metabolic 

activity during a task performance. Statistical analyses of 
the  activation  data  allow  determining  where  [Fox  and 
Raichle, 1985], i.e. in which areas, and/or when [Giard et 
al.,  1995]  during  the  task  performance,  the  activation 
reaches local extrema. Through the study of covariation 
between local activations, they give a sketch of what the 
network of cerebral areas involved in the cognitive func(cid:173)
tion  is  [Herbster et al. ,, 1996].  A  known  oriented  ana(cid:173)
tomical link between 2 areas allows determining why the 
activation of one area can affect the other one  [Buchel 
and Friston, 1997]. Above methods allow identifying the 
substratum  of  a  cognitive  function  and  the  activation 
level and dynamics of the substratum during the function 
performance. They do not give any clue of how the cog(cid:173)
nitive processes participating in the function are imple(cid:173)
mented by the substratum and how the activation derives 
from the processing. That is, they do not allow interpret(cid:173)
ing neuroimaging data as the result of information proc(cid:173)
essing at the integrated level of large-scale networks. 

Figure 1: Large-scale network involved in phoneme monitor(cid:173)
ing, according to results from [Demonet, et al., 1994] 

Interpretative  models,  linking  a  networked  structure 
activity to the realization of a function, are at the core of 
Computational Neurosciences. Most existing works in the 
domain are based on formal neural networks, with vary(cid:173)
ing  levels  of  biological  plausibility,  from  physiology 
[Wang and Buzsaki, 1996], hardly interpretable in terms 
of information  processing,  to  more  or  less  biologically 

COGNITIVE  MODELING 

169 

plausible  models  of  how  basic  cognitive 
functions 
emerge from neuronal activation [Grossberg et al, 2002], 
and to purely functional models [Cohen et al.,  1990], not 
concerned  with  cerebral  plausibility.  Although  these 
models  answer the how,  they do not meet two major re(cid:173)
quirements  for  an  interpretative  approach  of  functional 
neuroimaging data. The models are not explicit enough to 
be  directly  used  for  clinical  purpose,  and  they  cannot 
evolve quickly and easily with new  findings in neurosci-
ence, such as the integration of more detailed knowledge 
on  the  substratum,  which  often  necessitates  a  complete 
rebuilding of the formal network. 

The causal connectivity approach [Pastor et al. , 2000] 
aims at answering the how and satisfying the constraints. 
However,  the  underlying  formalism,  causal  qualitative 
networks  based  on  interval  calculus,  limits  severely  the 
biological  plausibility  of the  models,  since it cannot rep(cid:173)
resent  major  cerebral  features,  such  as  learning  or  the 
non-linearity  and  the  uncertainty  of  cerebral  processes. 
Dynamic  Bayesian  networks  only  meet  the  three  major 
constraints:  temporal  evolution,  uncertainty  and  nonlin-
earity [Labatut and Pastor, 2001]. The utility of graphical 
probabilistic  formalisms  for cognitive  modeling has  also 
been  demonstrated  in  the  representation  of  visuomotor 
mechanisms  with  Bayesian  networks  [Ghahramani  and 
Wolpert, 1997]. 

Hereafter,  we  describe  how  the  interpretation  of func(cid:173)
tional images for a clinical purpose can be tackled.  Sec(cid:173)
tion  2  presents  our  viewpoint  on  large-scale  cerebral 
networks. After a short introduction to dynamic Bayesian 
networks,  section  3  describes  the  characteristics  of our 
formalism. Section 4 illustrates the formalism's capabili(cid:173)
ties by an example. We conclude with some perspectives. 

2  Representation  of Large-Scale  Cere(cid:173)

bral  Networks 

three  properties: 

2.1  Structural  and  Functional  Nodes 
The  function  implemented  by  a  large-scale  network  de(cid:173)
pends  on 
the  network's  structure 
[Goldman-Rakic,  1988], the functional role of each node 
(E.g.  Wernicke's  area  (Figure  1),  which  is  supposed  to 
realize  the  early  stages  of phoneme processing),  and  the 
properties  of the links  (length, role:  inhibitory or excita(cid:173)
tory, ...). In each network, regions, which are the stride-
tural  nodes,  are  information  processors  and  connecting 
oriented  fibers  are  information  transmitters  [Leiner  and 
Leiner, 1997]. 

All neurons in a region do not have the same structure 
or  the  same  role.  Similar  neurons  constitute  generally 
local populations that realize a specific function. For ex(cid:173)
ample,  the  inhibitory  role  of  GABAergic  neurons  on 
other  neuronal  populations  may  explain  the  fact  that 
every  visual  stimulus  is not perceived  in high  frequency 
stimulation  [Pastor,  et al,  2000].  Therefore,  each region 
is itself a network of smaller neuronal populations {func(cid:173)
tional nodes),  connected  through  neuronal  fibers.  These 

nodes  are  information  processors  that  implement func(cid:173)
tional primitives, which may all be different. 

A  large-scale  network  has  therefore  neurophysiologi-
cally constrained, oriented edges and possibly differenti(cid:173)
ated  nodes.  The  explicit  representation  of  the  nodes' 
function  allows  the  direct  expression  of hypotheses  on 
cerebral processing, and  their easy modification  in order 
to  follow  the  evolution  of knowledge  in  neurosciences. 
This  cannot  be  dealt  with  by  formal  neural  networks' 
implicit modeling that requires modifying the whole net(cid:173)
work  architecture 
functional  changes. 
Hereafter,  a  structural  or  a  functional  structure  will  be 
indifferently named a cerebral zone. 
2.2 

Information  Representation  and 
Processing 

implement 

to 

The cerebral  information processed  by a neuronal popula(cid:173)
tion can be seen as the abstraction of the number and the 
pattern of the neurons firing for this information. It can be 
represented both by an energy level and by a category. En(cid:173)
ergy  is  indirectly  represented  by  the  imprecise  activation 
data  provided  by  neuroimaging  techniques.  The  category 
representation is in agreement with the "topical" organiza(cid:173)
tion of the brain, which reflects category maps of the input 
stimuli, and can persist from primary cortices to nonprimary 
cortices and subcortical structures  [Alexander et al,  1992], 
through transmission  fibers [Leiner and Leiner,  1997]. The 
energy  and  the  category  of a  stimulus  can  also  be  easily 
extracted from its psychophysical properties. 

Modeling cerebral processes necessitates an explicit and 
discrete representation of time, both for taking into account 
the dynamics of cerebral mechanisms (transmission delays, 
response  times...),  and  for complying with  sampled  func(cid:173)
tional neuroimaging data. 

According to a definition of causality inspired by Hume 
[Hume, 1740] and consistent with Pearl's probabilistic cau(cid:173)
sality [Pearl, 2001], information processing in a large-scale 
network  can  be  considered  as  mediated  through  causal 
mechanisms. Causality is defined by three properties: spatial 
and temporal contiguity, temporal consistency, and statisti(cid:173)
cal  regularity  [Labatut  and  Pastor,  2001].  In  other words, 
two entities A and B are causally linked if they are contigu(cid:173)
ous relatively to the system they belong to, if the beginning 
of A precedes temporally the beginning of B, and if most of 
the times, A provokes B.  In the brain, oriented anatomical 
links provide spatial and temporal contiguity between cere(cid:173)
bral nodes, cerebral events are temporally consistent (a fir(cid:173)
ing zone provokes the activation of downstream zones), and 
there is a statistical regularity in the response of a specific 
neuronal population to a given stimulus. 

3  Description  of the  Formalism 

3.1  Dynamic  Bayesian  Networks 
In summary, the brain can be viewed as a network whose 
nodes  are  differentiated  dynamic  and  adaptive  informa-

170 

COGNITIVE  MODELING 

tion  processors  and  oriented  edges  convey  causality. 
Moreover,  cerebral  mechanisms,  which  are  the  abstrac(cid:173)
tion, at the level  of a neuronal population, of the chemi(cid:173)
cal and electrical mechanisms at the cell levels, are often 
nonlinear.  Causal  dynamic  Bayesian  networks  are  the 
paradigm  that  meets  best  the  constraints  derived  from 
these properties [Labatut and Pastor, 2001]. 

A  causal  Bayesian  network  consists  of  a  directed 
acyclic  graph  where  nodes  represent  random  variables 
and  edges  represent  causal  relationships  between  the 
variables [Pearl,  1988]. A conditional probability is asso(cid:173)
ciated with each relationship between a node and its par(cid:173)
ents. If the node is a root, the probability distribution is a 
prior.  When  some nodes'  values  are observed, posterior 
probabilities  for  the  hidden  nodes  can  be  computed 
thanks  to  inference  algorithms  such  as  the junction  tree 
algorithm [Jensen, 1996]. 

In  a  dynamic  Bayesian network  (DBN),  the  evolution 
of random  variables through time  is  considered.  Time  is 
seen as a series of intervals called time slices [Dean and 
Kanazawa,  1988].  For each slice, a submodel represents 
the state of the modeled system. DBNs are used to model 
Markovian  processes,  i.e.  processes  where  a  temporally 
limited  knowledge  of the past  is  sufficient  to  predict  the 
future.  The  choice  of the  inference  algorithm,  generally 
an  extension  of  the  junction  tree  algorithm  [Murphy, 
1999], depends on  the DBN's structure, the nature of its 
variables (discrete or continuous), and relationships (lin(cid:173)
ear or nonlinear). 

Activation  data  and/or  the  subject's  responses  to  the 
stimuli are the only observable variables we have. There(cid:173)
fore,  they  must  be  integrated  in  our  models.  One  may 
reasonably consider that the hidden variables,  describing 
the successive states of the cerebral network, constitute a 
Markov chain, and that observable variables depend only 
on them. Moreover, the variables are continuous and their 
relationships  may  be nonlinear.  This  is  typically  the de(cid:173)
scription  of a  type  of DBNs  called  fully  nonlinear  state 
space  models.  Specific  and  recent  algorithms  allowing 
dealing with nonlinearity exist for this type of structures. 
Their general principle  is to  linearize the model  in order 
to apply the classic Kalman filter. These algorithms differ 
on  the  used  linearization  method:  first-order  Taylor  ap(cid:173)
proximations  for  the  extended  Kalman  filter  [Julier  and 
Uhlmann,  1997;  Norgaard  et  al,  2000]  or  polynomial 
approximations  for  the  unscented  Kalman  filter  [Julicr 
and Uhlmann,  1997], the divided difference  filter  (DDF) 
[Norgaard,  et al, 2000], and others [Van Der Merwe and 
Wan,  2001].  The  algorithms  based  on  polynomial  ap(cid:173)
proximations  seem 
results 
[Norgaard,  et al., 2000]. Their computational complexity 
is 0(L3), where L is the state dimension  [Van Der Merwe 
and  Wan,  2001].  They  offer  equivalent  qualities,  but 
those of the DDF are more accurate  according to  its au(cid:173)
thor [Norgaard,  et al, 2000]. 

to  give  more 

reliable 

3.2 

F o r m al  d e f i n i t i on 

Static  and  Dynamic  Networks 
A  static  network  is  the  graphical  representation  of  a 
large-scale  network,  whose  nodes  are  cerebral  zones  and 
edges  are  the  oriented  axon  bundles  connecting  zones. 
Due  to  anatomical  loops,  it  is  often  cyclic.  The  DBN  is 
the  acyclic  temporal  expansion  of  the  static  network. 
Each  node  of the  DBN  is  the processing  entity  related  to 
a  cerebral  zone,  i.e.  the  mathematical  expression,  at  a 
given  time  slice,  of  information  processing  in  the  zone. 
Each  edge  is  the propagation  entity,  whose  orientation  is 
its  corresponding  axon  bundle's  orientation.  When  deriv(cid:173)
ing  the  DBN  from  the  static  network,  values  are  given  to 
the  temporal  parameters,  according  to  known  physiology 
results  (e.g.  the  transmission  speed  in  some  neural  fi(cid:173)
bers).  That  is,  the  length  of the  time  slices  is  fixed,  and  a 
delay  representing  the  average  propagation  time  in  the 
bundle's fibers  is associated  to the propagation entity. 

I n f o r m a t i on  Representation 
Cerebral  information  is  the  flowing  entity  that  is  com(cid:173)
puted  at  each  spatial  (cerebral  zone)  and  temporal  (time 
slice)  step,  by  a  processing  entity. 
two-
dimensioned  data.  The  first  part,  the  magnitude,  stands 
for the  cerebral  energy  needed  to  process  the  information 
in  the zone.  It  is  represented  by  a real random  variable  in 
the  DBN.  For the  second  part,  the  type,  which represents 
the  cerebral  category  the  zone  attributes  to  the  informa(cid:173)
tion,  the  representation  is  based  on  the  symbol  and  cate(cid:173)
gorical  field  concepts. 

is  a 

It 

A  symbol  represents  a  "pure"  (i.e.  not  blurred  with 
noise  or  another  symbol)  category  of  information.  For 
example,  when  the  information  represents  a  linguistic 
stimulus,  a  symbol  may  refer  to  a  non  ambiguous  pho(cid:173)
neme.  For cerebral  information,  the symbol  represents,  in 
each  zone,  the  neuronal  subpopulation  being  sensitive  to 
(i.e.  that  fires  for)  the  corresponding  category.  It  may  be, 
in  the  primary  auditory  cortex,  the  subpopulation  sensi(cid:173)
tive  to  a  specific  frequency  interval.  A  categorical  field 
is  a  set  of symbols  describing  stimuli  of the  same  seman(cid:173)
tic  class.  The  "color"  categorical  field  contains  all  the 
color symbols,  but  it cannot  contain phonemes. 

A  type  concerns  several  symbols,  due  to  the  presence 
of noise  or  because  of some  compound  information.  Let 
S  be  the  set  of all  existing  symbols.  We  assume  that  a 
type  T  is  defined  for  only  one  categorical  field.  Let  S1 
be  the  subset  of  S,  corresponding  to  this  categorical 
field. The  type  T  is  an  application  from  ST  to  [0,1], with 
the property 
, i.e.  it describes a symbol reparti(cid:173)

tion  for  a  specific  categorical  field.  In  a  stimulus,  this 
repartition  corresponds  to  the  relative  importance  of each 
symbol  compounding 
the 
stimulus.  Inside  the  model,  T(s)  stands  for the proportion 
of  s-sensitive  neurons  in  the  population  that  fired  for  the 
information  whose  type  is  T.  Unlike  the  magnitude,  the 

information  carried  by 

the 

COGNITIVE  MODELING 

171 

type is not represented by a random variable. Indeed, it is 
not  necessary  to  represent  its  uncertainty  (and  hence  to 
make  the  computational  complexity  harder)  since  we 
cannot compare it to neuroimaging data. 

At time / and node X, the information is represented by 

at the output of X. 

the type 

and the magnitude 

Propagation  and  Processing 

For  a  zone  X,  both  the  cerebral  propagation  mecha(cid:173)
nisms  (i.e.  the  relationships  towards  the  zone)  and  the 
processing (spatial and temporal integration of the inputs, 
and processing as  such)  are  described by  a pair of func(cid:173)
tions, the type 
.  In 
the  general  case where n zones 
are  inputs  to  X, 
be  the  corresponding  delays  of  these  rela(cid:173)
let 
tionships.  In the DBN, the general  form of the magnitude 
functions is: 

and  the  magnitude  functions  fM 

(1) 
can  be  a  nonlinear  function.  The  random  vari(cid:173)
models  uncertainty  in  the  cerebral 

where 
able 
processing. 

The  type  function  is  any  combination  of the  incoming 
types and of the previous type that respects our type defi(cid:173)
nition.  If  all  types  are  defined  on  the  same  categorical 
field 5, the type function can be the linear combination: 

viants.  Each  block  contains  6  sequences  of 4  sounds,  3 
pivots and the block's deviant, in a random order. 

We focus on a single region, a part of the right tempo(cid:173)
ral  superior  gyrus  involved  in  the  early  processing  of 
auditory  stimuli  and  activated  differently  in  controls  and 
dyslexic  subjects.  Phylogeny  is  in  favor  of the  existence 
of specialized  phonemic  processors  in  this  area  (Figure 
2).  Since  their  location  is  unknown,  they  cannot  consti(cid:173)
tute separate structural nodes.  They are supposed to have 
the  same  building  functional  nodes.  According  to  our 
genericity  hypothesis,  the  processors'  structure  and  pa(cid:173)
rameters are based on a previously released visual cortex 
model  [Pastor,  et  al.,  2000].  The  Input  Gating  Nodes 
(IGN.)  express the phoneme processors'  sensitivity to the 
stimulus.  The  Output  Gating  Nodes  (OGN.)  send  infor(cid:173)
mation  to  the  downstream  areas.  Intra  and  inter  (lateral) 
inhibitions  (/TV.  and  LIN.)  are  assumed  between  the  /pa/ 
and  /ta/  processors.  LIN.  make  the  activation  of an  IGN. 
cause  an  inhibition  in  the  opposite  IGN..  Each  Firing 
Threshold  Node  (FTN.)  is  modulated  by  an  OGN.  that 
can  lower  it.  Since  only  one  activation  measure  is  pro(cid:173)
vided  by  fMRI  for  the  area,  it  is  represented  by  the  sole 
AN node in the static model. Stim stands for the stimulus. 

The  functions'  definition,  as  well  as  the  setting of the 
parameters1  values  (e.g.  the  value  of a  firing  threshold), 
utilize  mostly  results  in  neuropsychology  or  in  neuro(cid:173)
physiology. The existence of generic models, that is, non 
instantiated,  reusable,  models  of functional  networks,  is 
assumed.  For  example,  primary  cortices  may  implement 
the same mechanisms, although they arc parameterized so 
that they can process different types of stimuli  [Pastor,  et 
al., 2000]. 

4  Example 
The  model,  presented  hereafter,  is  based  on  an  experi(cid:173)
mental  study  [Ruff,  et  al,  2001]  that  focused  on  the  dif(cid:173)
ferences  between  normal  and  dyslexic  subjects  during  a 
passive phonemic categorization process. 

Six  patients  and  six  controls  were  submitted  to  a pas(cid:173)
sive hearing of stimuli  that are  mixes of the two phoneti(cid:173)
cally close syllables /pa/ and /ta/. The pivot is noted devO 
and  the  deviants  are  4  different  mixes  of /pa/  and  /ta/, 
noted dev2M, dev1M, dev1P, dev2P (Table  1). The meas(cid:173)
urements were made with fMRI. An experiment is consti(cid:173)
tuted of 5  blocks,  corresponding  to  the pivot and the de(cid:173)

Figure 2: Static network used to model the cerebral phonemic 
categorization process. 

Except  for  the  parameterization  of  the  IGN.  nodes, 
which  reflects  the  specialization  of each  phonemic  proc(cid:173)
essor to the phoneme category (/pa/ or /ta/), the  functions 
for  both  the  /pa/  and  /ta/  parts  share  exactly  the  same 
structure  and  parameters.  Thus,  only  the pa  part  will  be 
presented.  In the following equations,  the ith parameter of 
the function of a node X is noted  a  (1) 

The  refractory  period  of  the  processor's  neurons  is 
modeled in 
that makes 
the  node  sensitive  to  the  incoming  stimulus  only  if  the 
magnitude of the output is already close to zero: 

by a  sigmoid function 

The categorical field contains two symbols (pa and ta). 
The  type  of a  stimulus  represents  the  proportions  of the 
two symbols (Table  1). 

172 

COGNITIVE MODELING 

Table  1: Constants for both phonemic categorization models 

The  sensitivity  of each  1GN.  to  the  received  type  is  de(cid:173)

fined  by  a  constant  type  sens..  
the  symbol  pa,  and 

to  ta.  The  function 

is  more  sensitive  to 
in 

trols,  the  more  distant  (from  the  pivotal  stimulus,  cate(cid:173)
gorically  speaking)  the  deviant  is,  the  stronger  the  activa(cid:173)
tion  is  (Figure  3).  This  is  supposed  to  be  caused  by  a  ha(cid:173)
bituation  mechanism  that  lowers  the  activation,  followed 
by  an  activation  the  force  of  which  depends  on  the  "sur(cid:173)
prise"  caused  by  the  deviant.  Dyslexic  subjects  do  not 
correctly  categorize  the  different  phonemes,  both  the  pa 
and  the  ta  parts  of the  gyrus  activate  for  each  block.  This 
illustrates  how  activation  data  can  be  explained  thanks  to 
the  understanding  of  the  cerebral  information  processing 
mechanisms  expressed  in  the  models. 

equation  (3)  is  used  with  the  constant  
coming  stimulus'  type  
nitude  of 

and  the  in(cid:173)
in  order  to  modulate  the  mag(cid:173)

The  types  are  used  only  for  the  input  gating;  they  do 

not  intervene  in  the  rest  of the  model.  The  sigmoid 
in 
the  magnitude  coming  from  the  
firing  threshold's 

magnitude  function  allows  it  to  fire  only  if 
is  greater  than  the 

one: 

AN  consists  in  the  sum  of  the  successive  I G N s'  activa(cid:173)

tions  during  one  experimental  block: 

(8) 

Figure  3:  Compared  results  between  simulated  data  (±  2  stan(cid:173)
dard deviations) and experimental  measures. 

in 

This  is  a  gross  approximation  of  the  f M RI  data,  which 
models  only  the  part  of  the  information  processing  mecha(cid:173)
nisms 
the  activation  building  and  neglects  metabolic 
processes  at  the  level  of the  cerebral  blood  flow.  Since,  ex(cid:173)
cept  the  Stim  and  the  AN  nodes,  all  nodes  represent  neu(cid:173)
ronal  activities,  the  time  unit  is  set  to  1  ms.  We  used  the 
DD2  algorithm  [Norgaard,  ei  al.,  2000]  to  perform  the  simu(cid:173)
lations. 

The  hypothesis  is  that  the  difference  of  processing  be(cid:173)
tween  normal  and  dyslexic  subjects  is  caused  by  a  disorder 
in  the  inhibitory  mechanisms.  Thus,  the  two  models,  one  for 
the  average patient  and  the  other  for the  average  control,  use 
the  same  functions  and  share  the  same  parameters,  except 
for  the  inhibition  nodes  (IN.  and  LIN.).  There  are  no  lateral 
inhibitions  in  the  dyslexic  model.  It  can  be  interpreted  in 
cognitive  terms  as  the  fact  that  all  the  processors  compete 
for  each  stimulus  and  that  no  clear  category  can  be  built. 
Also,  the  dyslexic  model's  internal  inhibitions  are  slightly 
stronger  than  in  the  normal  one,  leading  to  a  slowing  in  the 
stimulus  perception.  These  two  tentative  interpretations  are 
good  starting  points  for new  experiments. 

The  differences  in  the  inhibition  parameters  are  suffi(cid:173)
cient  to  obtain  very  different  activation  data.  For  con(cid:173)

5  Conclusion 
Instead  of  building  a  specialized  model,  designed  for  a 
specific  function  or  cerebral  network,  we  have  presented 
a  general  framework,  allowing  the  interpretation  of  func(cid:173)
tional  neuroimaging  data.  This  framework  has  been  de(cid:173)
signed  to  be  open  to  evolutions  of the  knowledge  in  neu(cid:173)
ropsychology  and  neurophysiology.  Using  DBNs  allows 
modeling 
the  brain  as  a  dynamic  causal  probabilistic 
network  with  nonlinear  relationships.  We  have  illustrated 
this  with  an  example  concerning  a  language-related  proc(cid:173)
ess.  Currently,  our  framework 
to  automatic 
processing,  which  is  dominant  in  cerebral  functioning.  In 
function  of  the  stimulus  type,  nodes  can  react  differently 
and  different  networks  may  be  activated,  thus  implement(cid:173)
ing  different  functions.  Our  future  work  w i ll  focus  on  the 
integration  of  more  biological  plausibility  in  the  frame-
work.  The  representation  of  complex  relationships  be(cid:173)
tween  and  inside  the  zones  w i ll  allow  the  representation 
of  controlled  processes  and  contextual  modulation  of  the 
cerebral  activity.  The  combination  of types  from  different 
categorical  domains  and  the  search  for  regularities  in  the 
combinations  w i ll  allow  the  implementation  of  learning 
mechanisms.  Another  essential  topic  is  to  make  our  mod-

is  adapted 

COGNIT1VE MODELING 

173 

els  independent  of the  used  data  acquisition  technique, 
thanks to interface models,  able  to translate cerebral  in-
formation processing variables into neuroimaging results. 
Our  long-term  goal  is  to  progressively  include  in  our 
framework various validated models and to build a con(cid:173)
sistent and general brain theory based on large-scale net(cid:173)
works. 
References 
[Alexander,  etal.,  1992]  G.  E.  Alexander,  M.  R. 
Delong,  and  M.  D.  Crutcher.  Do  cortical  and  basal 
ganglionic motor area use "motor programs" to control 
movement? BBS, 15:656-65, 1992. 

[Bressler,  1995] S.  L.  Bressler.  Large-scale  cortical  net(cid:173)
works  and  cognition.  Brain  Res  Rev,  20(3):288-304, 
1995. 

[Buchcl and Friston, 1997]  C.  Buchcl and K. J. Friston. 
Modulation  of connectivity  in  visual  pathways  by  at(cid:173)
tention:  Cortical  interactions  evaluated  with  structural 
equation modelling and fMRI. Cereb Cortex, 7(8):768-
78,1997. 

[Cohen, et al,  1990]  J.  D.  Cohen,  K.  Dunbar,  and  J.  L. 
McClelland.  On the control  of automatic processes:  A 
parallel  distributed  processing  account  of  the  Stroop 
effect. Psychol Rev, 97(3):332-61, 1990. 

[Dean and Kanazawa,  1988]  T.  Dean  and  K.  Kana-
zawa. Probabilistic temporal reasoning. Proceedings of 
AAAI, Pages 524-528, 1988. 

[Demonet, et al., 1994] J. F. Demonet, C. Price, R. Wise, 
and R. S. Frackowiak. A PET study of cognitive strate(cid:173)
gies  in  normal  subjects  during  language  tasks.  Influ(cid:173)
ence of phonetic ambiguity and sequence processing on 
phoneme monitoring. Brain, 117 (Pt 4):671-82, 1994. 

[Fox and Raichle,  1985]  P.  T.  Fox  and  M.  E.  Raichle. 
Stimulus  rate  determines  regional  brain  blood  flow  in 
striate cortex. Ann Neurol, 17(3):303-5, 1985. 

[Ghahramani and Wolpert,  1997]  Z.  Ghahramani  and 
D. M.  Wolpert.  Modular decomposition  in  visuomotor 
learning. Nature, 386(6623):392-395, 1997. 

[Giard, et al,  1995]  M.H.  Giard,  J.  Lavikainen,  K. 
Reinikainen, F. Perrin, O. Bertrand, J. Pernier, and R. 
Naatanen.  Separate  representation  of  stimulus 
fre(cid:173)
quency,  intensity  and  duration  in  auditory  sensory 
memory:  An  event-related  potential  and  dipole-model 
analysis. J Cogn Neurosci, 7(2): 133-143, 1995. 

[Goldman-Rakic, 1988]  P.  S.  Goldman-Rakic.  Topog(cid:173)
raphy of cognition: Parallel distributed networks in pri(cid:173)
mate  association  cortex. Annu Rev Neurosci,  11:137-
56, 1988. 

[Grossberg, et al. , 2002]  S.  Grossberg,  S.  Hwang,  and 
E.  Mingolla.  Thalamocortical  dynamics  of 
the 
McCollough  effect:  Boundary-surface  alignment 
through perceptual learning. Vision Res, 42(10): 1259-
86,2002. 

[Herbster, et al,  1996]  A.  N.  Herbster, T. Nichols, M. B. 
Wiseman,  M.  A.  Mintun,  S.  T.  DeKosky,  and  J.  T. 
Becker.  Functional  connectivity 
in  auditory-verbal 
short-term  memory  in  Alzheimer's  disease.  Neuroi-
mage,4(2)'.61-ll,  1996. 

[Hume,  1740]  D.  Hume.  Treatise  of  human  nature, 

introduction  to 

Oxford University Press (2000), 1740. 
[Jensen,  1996]  Finn  V.  Jensen.  An 

Bayesian networks, Springer, New York, 1996. 

[Julier and Uhlmann,  1997]  S.  J.  Julier  and  J.  K. 
Uhlmann.  A  new  extension  of  the  Kalman  filter  to 
nonlinear  systems.  Proceedings  of  Int.  Symp.  Aero-
space/Defense  Sensing,  Simul.  and  Controls,  Orlando 
(FL), 1997. 

[Labatut and Pastor, 2001]  V.  Labatut  and  J.  Pastor. 
Bayesian  modeling of cerebral  information processing. 
Proceedings  of  A1ME,  Bayesian  models  in  medicine 
Workshop, Cascais (Po), 2001. 

[Leiner and Leiner,  1997] H.  C.  Leiner and A.  L.  Leiner. 
How  fibers  subserve  computing  capabilities:  Similari(cid:173)
ties  between  brains  and  machines,  lnt Rev Neurobiol, 
41:535-53, 1997. 

[Murphy,  1999]  K. Murphy. Filtering, smoothing and the 
junction tree algorithm. Technical Report, U.C. Berke(cid:173)
ley, Dept. Comp. Sci, 1999. 

[Norgaard,  et al, 2000]  Magnus  Norgaard,  Niels  K. 
Poulsen,  and  Ole  Ravn.  Advances  in  derivative-free 
state estimation  for nonlinear systems.  Technical  Rep-
port  1MM-REP-1998-15,  Technical  University  of 
Danemark, Lyngby, 2000. 

[Pastor,  etal, 2000]  J.  Pastor,  M.  Lafon,  L.  Trave-
Massuyes, J. F. Demonet, B. Doyon, and P. Celsis. In(cid:173)
formation  processing  in  large-scale  cerebral  networks: 
The  causal  connectivity  approach.  Biol  Cvbern, 
82(l):49-59,2000. 

[Pearl, 1988]  J. Pearl. Probabilistic reasoning in intelli-
gent systems: Networks of plausible inference, Morgan 
Kaufmann, 1988. 

[Pearl, 2001]  J.  Pearl.  Bayesianism  and  causality,  or, 
why  1  am  only  a  half-Bayesian.  In  Foundations  of 
Bayesianism, Kluwer, 2001. 

[Ruff,  et al, 2001]  S.  Ruff,  K.  Boulanouar,  D.  Carde-
bat,  P.  Celsis,  and J.  F.  Demonet.  Brain  correlates of 
impaired  categorical  phonetic  perception  in  adult  dys-
lexics. Neuroimage, 13(6):S595-S595, 2001. 
[Van DerMerwe and Wan, 2001]  R.  van  der  Merwe 
and E. A. Wan. Efficient derivative-free Kalman filters 
for  online  learning.  Proceedings  of  ESANN,  Pages 
205-210, Bruges, Belgium, 2001. 

[Wang and Buzsaki, 1996]  X. J. Wang and G. Buzsaki. 
Gamma  oscillation  by  synaptic  inhibition  in  a  hippo-
campal 
interneuronal  network  model.  J  Neurosci, 
16(20):6402-13, 1996. 

174 

COGNITIVE  MODELING 

