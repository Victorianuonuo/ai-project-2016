Face Recognition via the Overlapping Energy Histogram

Ronny Tjahyadi, Wanquan Liu, Senjian An and Svetha Venkatesh

Department of Computing

Curtin University of Technology, WA 6845 Australia

Email: {tjahyadi, wanquan, senjian, svetha}@cs.curtin.edu.au

Abstract

In this paper we investigate the face recognition
problem via the overlapping energy histogram of
the DCT coefﬁcients. Particularly, we investigate
some important issues relating to the recognition
performance, such as the issue of selecting thresh-
old and the number of bins. These selection meth-
ods utilise information obtained from the training
dataset. Experimentation is conducted on the Yale
face database and results indicate that the proposed
parameter selection methods perform well in se-
lecting the threshold and number of bins. Further-
more, we show that the proposed overlapping en-
ergy histogram approach outperforms the Eigen-
faces, 2DPCA and energy histogram signiﬁcantly.

1 Introduction
Face recognition has many potential applications in secu-
rity and surveillance. Over many years, several different
techniques have been proposed to mimic the inherent hu-
man ability to recognize faces using computers and some of
these techniques have been successfully deployed in numer-
ous surveillance systems, e-commerce application and com-
puter login systems [Zhao et al., 2000].

One successful approach to face recognition is to use the
Principal Component Analysis (PCA), originally proposed by
Sivorich and Kirby [Kirby and Sivorich, 1987]. PCA is an op-
timal signal representation that extracts the eigenvectors from
a covariance matrix constructed from an image database. This
technique reduces the number of dimensions to represent im-
ages in the database. In 1991, Turk and Pentland [Turk and
Pentland, 1991] incorporated PCA into a face recognition
system known as Eigenfaces, demonstrating promising re-
sults in recognizing frontal images of individuals. Experi-
mentation with a database of 2500 images of 16 individuals
generated 96% correct classiﬁcation over various light con-
ditions, 85% with orientation variations and 64% with size
variations.

PCA is an optimal signal representation, however this tech-
nique suffers from high computational cost in determining
the eigenspace for a large number of images [Kirby and
Sivorich, 1990]. In addition, the computational cost for PCA
increases when new images are added into the facial image

database as the eigenspace in PCA requires recompilation
due to its data dependent characteristic [Turk and Pentland,
1991]. Recently, the two dimensional PCA is proposed and it
has proven to be much better than Eigenfaces in terms of per-
formance and computational cost [Yang et al., 2004]. In or-
der to reduce the computational cost, fast transforms such as
Discrete Cosine Transform (DCT) has been used as an alter-
native. The DCT has been used for feature extraction and has
been demonstrated to be superior to PCA in terms of compu-
tation cost since recompilation is not required when adding or
removing new images into or from the facial image database
[Hafed and Levine, 2001]. Some face recognition algorithms
incorporating DCT can be found in [Zhao et al., 2000] and
most of them incorporate the DCT coefﬁcients directly into
Hidden Markov model and Neural Networks.

This paper is an extension of paper [Tjahyadi et al., 2004].
Compared to the previous paper, ﬁrst, we use the overlapping
method to extract the DCT coefﬁcients in order to enhance the
performance. Second, we introduce automatic threshold and
number of bins selection to the proposed overlapping energy
histogram. Finally, we do more comparisons with other tech-
niques, such as Eigenfaces, 2DPCA and energy histogram.

The overlapping energy histogram is based on the DCT
and it measures the distribution of the DCT coefﬁcients of an
image. The performance of energy histogram with varying
numbers of bins is investigated using six datasets constructed
from the Yale face database. In addition, a systematic thresh-
old selection method is proposed which utilises the distance
information obtained from the training dataset. The informa-
tion gathered from the threshold selection procedure is further
used to select a suitable number of bins. The performance
of overlapping energy histogram face recognition is analyzed
and discussed. To illustrate the effectiveness of the technique,
comparisons are made with the Eigenfaces, 2DPCA and en-
ergy histogram techniques.

2 Preliminaries

2.1 The Discrete Cosine Transform

DCT is a popular technique in imaging and video compres-
sion and was ﬁrst applied in 1974 by Ahmed et al. [Ahmed
et al., 1974] to transform image signals from a spatial repre-
sentation into a frequency representation. In 1992, the ﬁrst
international standard for image compression, JPEG, was es-

IJCAI-07

2891

tablished with the DCT as the encoder and decoder and it
uses the DCT to remove the redundancies from images. Each
image frame is divided into 8x8 blocks, where each block is
transformed independently using the two-dimensional DCT
(2D-DCT).

Figure 1 shows the zigzag pattern used to process the 8x8
DCT coefﬁcients blocks by JPEG compression. Although the
total energy remains the same in the 8x8 blocks, the energy
distribution changes with most energy being present in the
low frequency DCT coefﬁcients. The DC coefﬁcient, which
is located at the upper left corner, holds most of the image en-
ergy and represents the proportional average of the 64 blocks.
The remaining 63 coefﬁcients denote the intensity changes
among the block images and are referred to as AC coefﬁ-
cients.

Figure 1: The DCT coefﬁcients

The DCT was reported to be the second most optimal trans-
formation after PCA with an energy compaction. Although
PCA is the optimal transform in an energy packing sense,
most practical transform coding systems still apply the DCT
as it offers numerous advantages over PCA including good
computational efﬁciency whilst producing good quality im-
ages at suitable compression ratios.

2.2 Energy Histogram
Histograms are commonly used in computer vision. The ad-
vantages of color histograms are described in [Swain and Bal-
lard, 1990] and include invariance to image manipulations
such as rotations, translations and scale, angle of view or oc-
clusions. Despite these advantages, the histogram approach
performs poorly under different lighting conditions. It is also
ineffective in distinguishing different images that have sim-
ilar color distributions and suffers from inefﬁcient computa-
tion due to its high dimensionality.

An energy histogram is similar to color histogram but in-
stead of counting pixel color, an energy histogram accumu-
lates the DCT coefﬁcients in corresponding bins. In compar-
ison, energy histogram incurs less computational cost when
compared to the color histogram as its dimensions are greatly
reduced by the DCT. Lay and Guan [Lay and Guan, 1999]
investigated the energy histogram in image retrieval and pro-
posed feature sets identifying similarities of the images. The
feature set was obtained by applying the DCT to an individ-
ual subset of each facial image and it consisted of 6 feature
blocks, denoted F1, F2A, F2B, F3A, F3B, and F4 in Figure
2.

F 1 = [DC],
F 2A = [AC01, AC10, AC11],
F 2B = [DC, AC01, AC10, AC11],
F 3A = [AC01, AC02, AC10, AC11, AC12, AC20,
AC21, AC22],
F 3B = [DC, AC01, AC02, AC10, AC11, AC12,
AC20, AC21, AC22],
F 4 = [DC, AC01, AC02, AC03, AC10, AC11, AC12
AC13, AC20, AC21, AC22, AC23, AC30, AC31, AC32, AC33]

Figure 2: The feature sets for energy histogram

Lay and Guan [Lay and Guan, 1999] reported that the com-
bination of the DC and AC coefﬁcients (F2B, F3B and F4)
yield the best performance results in image retrieval. The
feature sets F2B and F3B were shown to be more ideal than
the F4 feature set, due to the fact that as the feature block
grows, more coefﬁcients are involved in creating the energy
histogram, thus possibly, introducing more errors. The F1
feature set was observed to perform well when retrieving im-
ages that have high color similarity, whilst the F2A and F3A
feature sets were shown to have adequate retrieval perfor-
mance due to the contribution of the AC coefﬁcients which
carry the texture and edge information. However, they did
not investigate the threshold selection issue.

3 Face Recognition System Design

3.1 Face Recognition System with the Overlapping

Energy Histogram

Research on face recognition has been conducted to solve
three distinct scenarios: face veriﬁcation, face identiﬁcation
and the watch list [Lu, 2003]. The aim of face veriﬁcation
is to verify that an individual is who he or she claims to be,
whereas the face identiﬁcation attempts to identify an indi-
vidual in a database with the assumption that the individual
is known. The watch list scenario is similar to face identiﬁ-
cation, except that the individual to be identiﬁed may not be
in the database. Of these scenarios, the watch list is gener-
ally considered to be the most difﬁcult, as face recognition
under this scenario confronts a large number of false alarms
[Phillips et al., 2003].

In this section we will use the overlapping energy his-
togram to design a face recognition system for the watch list
scenario (Figure 3). It consists of feature extraction using the
energy histogram algorithm, and a classiﬁer which recognizes
images based on their feature vectors. In the training stage,
we will obtain all the DCT coefﬁcients for each training im-
age with overlap blocks and then select the number of bins
and threshold as outlined in the next section. In the recogni-
tion stage, we will only use the selected number of bins to ex-
tract features from the testing images and classify the testing
images based on the selected threshold and generated feature
set.

In feature extraction, each facial image is divided into 8x8
blocks with 75% overlapping (6 column pixels overlapped)
and the DCT is then computed on each block. The 75% over-
lapping was reported to perform better recognition rates com-

IJCAI-07

2892

Training
Images

DCT

Energy
Histogram

Threshold, Feature 
Set and Histogram 
Bin Size Selection

Database

Training Stage

Unknown
Image

Selected Feature 
Set and Bin Size

Threshold

DCT

Energy
Histogram

Similarity
Measurement

Match or 
Unmatched
Face Image

Recognition Stage

Figure 3: The overlapping energy histogram face recognition
system

pared to others [Kohir and Desai, 1998]. In this paper, we
only use the F2 feature set (Figure 4). Preliminary inves-
tigations have shown that the F2 feature sets achieve better
recognition rates in comparison to other feature sets (F1, F3
and F4) [Tjahyadi, 2004]. The energy histogram is built by
counting the number of times each DCT coefﬁcient occurs in
the domain of the corresponding bin. This energy histogram
is then used as the feature vector (Ω). The threshold and bin
number selection approaches are outlined in the next section.

F 2 = [DC, AC01, AC10, AC11]

Figure 4: The F2 feature set for overlapping energy histogram

To recognize a face image, the system compares the im-
age’s feature vector (Ω) to each of the feature vectors in
the database. A straightforward pattern classiﬁcation ap-
proach to recognition is to ﬁnd a face image n that minimises
the corresponding Euclidean distance.
In experimentation
[Tjahyadi, 2004], it is discovered that the Euclidian distance
performs better than neural networks on the original energy
histogram. Further, the Euclidean distance has been used in
many face recognition techniques [Turk and Pentland, 1991;
Yang et al., 2004].

n = (cid:2)(Ω − Ωn)(cid:2)2

(1)

where Ωn is a feature vector describing the nth face image.

If n is below some chosen classiﬁcation threshold (θ),
then the new image is classiﬁed as belonging to a face im-
age n, and classiﬁed as “unknown” otherwise.

3.2 Threshold Selection
The proposed threshold selection is computed via intra and
inter class information gathered from the training dataset.
The intra-class (D) is a set where the distances between the
images of the same individual are calculated as shown in Al-
gorithm 1. This class gives an indication of how similar the
images of the same individual are. The inter-class (P ) is a
set where the distances between the images of an individual

are measured against the images of other individuals in the
training dataset as described Algorithm 1. This class indi-
cates how different each image of an individual is when com-
pared to images of other individuals in the training dataset.
The classiﬁcation threshold (θ) is then calculated from intra-
and inter-class information, and described in Algorithm 2.
The training dataset requires a suitable number of images per
individual in order to obtain sufﬁcient distance information.
From [Tjahyadi, 2004], every individual should have at least
4 images for training. A large training dataset should result in
better estimation of thresholds. The proposed algorithm for
threshold selection is as follows:
Denote

= number of individuals
= number of images per individual

I (cid:2)
K (cid:2)
I = {1,. . . ,I (cid:2)}
K = {1,. . . ,K (cid:2)}

Algorithm 1: Finding the Intra and inter Classes
for each image Mik where i ∈ I and k ∈ K do

Compute hik for kth

individual, where
hik is the feature vector obtained with the selected feature set
and histogram bin size.

image of the ith

Compute the intra distances

ik = (cid:2)hik − hik(cid:2) (cid:2)2 where i ∈ I, k(cid:2) ∈ K and k (cid:4)= k(cid:2)
dik(cid:2)

and the inter distances

pjl
ik = (cid:2)hik − hjl(cid:2)2 where j ∈ I, j (cid:4)= i and l ∈ K

end

Get the intra class (D) = {dik(cid:2)
Get the inter class (P ) = {pjl
and sort the D and P in ascending order

ik | k (cid:4)= k(cid:2), k, k(cid:2) ∈ K, i ∈ I}
ik | j ∈ I, j (cid:4)= i, k, l ∈ K}

Compute Dmax = max {dik(cid:2)

ik | k (cid:4)= k(cid:2), k, k(cid:2) ∈ K, i ∈ I},

Dmax is a measure of generalization among images for

all individuals
Compute Pmin = min
j∈I

{pjl

ik | j ∈ I, j (cid:4)= i, k, l ∈ K},

Pmin is a measure of differences between one individual

against others.

Algorithm 2: Finding the Classiﬁcation Threshold

The classiﬁcation threshold (θ) can be deﬁned through
Dmax and Pmin. If Dmax < Pmin, then T P (cid:2)
rates
deﬁned below can reach 100% and 0% respectively. Thus, θ
is directly deﬁned as:

and F P (cid:2)

θ =

Dmax + Pmin

2

(2)

If Dmax > Pmin, then one needs to ﬁnd the θ that maximizes
the T P (cid:2)

and minimizes the F P (cid:2)

with the following steps:

Now, we have obtained D and P from the training dataset
) and False
which will be used to calculate True Positive
measure the percentage
Positive
of correct classiﬁcation and misclassiﬁcation respectively and
are deﬁned as follows:

). The T P (cid:2)

and F P (cid:2)

(F P (cid:2)

(T P (cid:2)

(cid:2)

(cid:2)

T P (cid:2) = Q
F P (cid:2) = L

(cid:4)D(cid:4) × 100%
(cid:4)P (cid:4) × 100%

where Q is the number of elements in D that are less than a

IJCAI-07

2893

given threshold. (cid:2)D(cid:2) is the number of elements in D which is
calculated by (K (cid:2) −1)×K (cid:2) ×I (cid:2)
. L is the number of elements
in P that are less than a given threshold. (cid:2)P (cid:2) is the number
of elements in P which is calculated by K (cid:2)2 × (I (cid:2) − 1) × I (cid:2)
.
Next, we will select a threshold to balance the correct clas-
siﬁcation and misclassiﬁcation ratio. The idea is to separate
D as N parts evenly and draw a curve of F P (cid:2)
with
different thresholds. We intend to ﬁnd the balanced point on
this curve. The detail is as below.

and T P (cid:2)

From the Algorithm 1, we have obtained D =
{d1, d2, . . . , d(cid:4)D(cid:4)} where d1 ≤ d2 ≤ . . . ≤ d(cid:4)D(cid:4). Then
we need to ﬁnd the index x1, x2, . . . , xN such that D is
=
grouped into D = {Dx1
} for j = 1, 2, . . . , N with xN = (cid:2)D(cid:2),
{dxj−1+1, . . . , dxj

} where Dxj

, . . . , DxN

, Dx2

−

−
xj] where

−
xj satisﬁes

−
xj] refers to rounding the number (

xj
(cid:4)D(cid:4) × N = j
x0 = 0. Further, xj = [
−
and [
xj) to the nearest in-
teger. This process is to divide D into N groups where N is
chosen subjectively depending on the database. In the exper-
iments of this paper, N is chosen as 10, which gives us very
good performance.

Now, we

have

(θj ) =
, dx2
and
with each element in (θj ). Then, the derivative (Tj) is

}, and we can compute the T P (cid:2)

, . . . , dxN

threshold

obtained

the

{dx1
F P (cid:2)
calculated as:

(cid:2)

(cid:3)

Tj =

ΔT P (cid:2)
j
ΔF P (cid:2)
j

×

max(F P (cid:2))

100%

In this section we present a systematic approach in select-
ing a suitable feature set and number of bins for face recog-
nition. We explore the number of bins ranging from 20 to 40
with an increment of 1. The selection algorithm for feature
set and number of bins is as follows:
Let

W = {2}
Fi is the feature set where i ∈ W
B = number of bins ranging from 20 to 40 with incre-

ment of 1: {21, 22, . . . , 40}

for each histogram F j

i with feature set Fi and j ∈ B do

Compute the classiﬁcation threshold (θj

i ) with the algo-

rithm deﬁned in Algorithm 2.
end

i , F P (cid:2)j

following information
Now, we have obtained the
{T P (cid:2)j
i These values
are the balanced correct classiﬁcation and misclassiﬁcation
ratios with the chosen threshold.

i } for i ∈ W, j ∈ B with θj

for each histogram F j

i with i ∈ W and j ∈ B do

//Get number of bins that maximize the T P (cid:2)

for each

i ∈ W

Si = {j | T P (cid:2)j
//Get number of bins from Si that minimize the F P (cid:2)

i = αi, j ∈ B, αi = max

(T P (cid:2)j

i )}

j

for

(3)

each i ∈ W

Mi = {j ∈ Si | F P (cid:2)j

i = βi, βi = min
j∈Si

(F P (cid:2)j

i )}

where max F P (cid:2)
ΔT P (cid:2)

j = T P (cid:2)

is the maximum value of F P (cid:2)

;
j for j = 1, 2, . . . , N − 1;

j+1 − T P (cid:2)

and ΔF P (cid:2)
j and F P (cid:2)

j = F P (cid:2)
j are the T P (cid:2)

T P (cid:2)

j+1 − F P (cid:2)

j for j = 1, 2, . . . , N − 1;

and F P (cid:2)

values respectively when

we choose the threshold θj with j = 1, 2, . . . , N ;

If ΔF P (cid:2)

j = 0 then we deﬁne Tj = 0.

end

The above procedure is to choose the bin size which max-
imizes the correct classiﬁcation ratio while minimizing the
misclassiﬁcation ratio. Alternatively, we can also minimize
F P (cid:2)

ﬁrst and then maximize T P (cid:2)

.

To ﬁnd the classiﬁcation threshold (θ), we have to search
for a j0 ∈ {2, 3, . . . , N − 1} such that Tj0−1 > 1 and Tj0
<
1. The threshold θ is chosen as the value in dθj0 −1 . If none of
the Tj values is less than 1, then θ is set as dN . Mathemati-
cally, we intend to ﬁnd a point on the curve (F P (cid:2)
) with
Tj = 1, which can balance the rates of correct classiﬁcation
and misclassiﬁcation. The above algorithm gives us a rough
approximation for this selection due to the nature of discrete
discontinuity.

-T P (cid:2)

3.3 Selection of the Number of Bins

Lay and Guan [Lay and Guan, 1999] empirically discussed
the performance of six feature sets in retrieving images and
identiﬁed that the F2B and F3B feature sets yielded the best
performance. However, the effect of varying the number of
bins was not investigated. The effectiveness of histogram in-
dexing depends on the number of bins used. Brunelli and
Mich [Brunelli and Mich, 1999] suggested that an image re-
trieval system can rely on small numbers of bins without se-
vere degradation of retrieval performance and showed that a
bin number of 16 was sufﬁcient for image retrieval using the
City-Block (L1) distance.

4 Experimental Results

Experimentation was carried out on six datasets created from
Yale database [Database, 2004]. This database contains 15
individuals, (mostly male), with 8 images each, since face
images in the original database with strong light conﬁgura-
tions were excluded as the excessive light cast shadow on the
background requires to be preprocessed in practice. The total
number of images used in this experiment is 120. In all the
dataset, the number of individuals for training is set to be 10
and the number of individuals for testing is set to be 15. Table
1 shows a brief description of all datasets. For each dataset
we created 10 subsets via randomly selecting the training im-
ages per individual. The remaining images, not included in
each training subset, were used to construct the correspond-
ing testing subsets.

These datasets were used to evaluate the proposed face
recognition algorithm in two scenarios. In the ﬁrst scenario,
the experiments were carried out on four datasets with ﬁxed
threshold value. The results were then compared to the Eigen-
faces [Turk and Pentland, 1991], 2DPCA [Yang et al., 2004]
and energy histogram [Tjahyadi et al., 2004]. In the other
scenario, we investigated the performance of the proposed au-

IJCAI-07

2894

tomatic threshold and number of bins selection algorithms on
the remaining datasets. The query effectiveness is evaluated
using precision and recall statistics.

Scenario

Dataset

# of

training images
per individual

# of

training
images

# of

testing
images

1

2

1
2
3
4
5
6

1
2
3
4
4
5

10
20
30
40
40
50

110
100
90
80
80
70

Table 1: Training and testing datasets

4.1 Evaluation on the Overlapping Energy

Histogram Face Recognition System

In this subsection we compare the overlapping energy his-
togram with the Eigenface, 2DPCA and energy histogram
with all datasets in Scenario 1 where each dataset consists
of 10 subsets. The threshold for each dataset (Table 2) was
selected via trial and error method such that precision and
recall rates are balanced. The average results in Table 4 in-
dicate that the overlapping energy histogram outperforms the
Eigenface, 2DPCA and energy histogram in all datasets with
higher precision and recall rates. In dataset 4, the recall rate
of energy histogram is slightly higher than the overlapping
method, however, the precision rates are much lower. Signiﬁ-
cant performance of the overlapping energy histogram can be
seen in dataset 1 where only 1 image per individual was used
as a training image while the remaining images were used as
testing images.

Overlapping EH

Dataset

Prec. % Recall %

1
2
3
4

93.9
96.2
97.7
98.4

92.6
95.2
96.7
95.4

Table 4: Overlapping Energy Histogram Performance com-
parisons (average rates)

4.2 Evaluation on Automatic Threshold and

Number of Bins Selection Algorithms

In this subsection we will examine the proposed threshold and
number of bins selection algorithms with 2 datasets in Sce-
nario 2 where each dataset consists of 10 subsets. We select 2
subsets from dataset 5 and 6 to demonstrate the effectiveness
of the proposed number of bins selection algorithm. Table
5 shows the selected number of bins and their corresponding
accuracies for the subsets. From Figure 5, one can see that the
proposed number of bins selection performs well in selecting
number of bins where the precision and recall are balanced
with high rates.

Selected

Precision Recall

Dataset

Subset Number of Bins

5
6

10
10

37
32

%
97.4
100

%
94.9
100

Table 5: Numbers of Bins Selected Via Proposed Bin Selec-
tion Algorithm

Data
set

Eigenfaces

(* 107)
8.75
9.50
10.00
10.50

1
2
3
4

2DPCA
(* 104)
3.10
2.90
2.80
2.60

EH
(* 10)
5.3
4.8
4.8
4.7

Overlapping

EH

(* 102)

7.0
6.4
6.0
5.6

Table 2: Classiﬁcation Thresholds for Datasets on Scenario 1

)

%

(
 
y
c
a
r
u
c
c
a

100

90

80

70

60

50

40

30

20

10

0
20

)

%

(
 
y
c
a
r
u
c
a

100

90

80

70

60

50

40

30

20

10

0
20

25

30

number of bins

35

40

precision
recall

25

30

number of bins

35

40

precision
recall

Data

set

1
2
3
4

Eigenfaces

2DPCA

EH

Prec. Recall
(%)
75.5
78.8
84.0
81.6

(%)
74.9
79.3
82.3
84.2

Prec. Recall
(%)
83.0
86.9
90.8
85.4

(%)
82.7
87.3
91.0
87.8

Prec. Recall
(%)
87.5
92.4
94.1
95.6

(%)
82.2
87.7
93.5
95.6

Table 3: Performance comparisons (average rates)

(a) Dataset 5 (subset 10)

(b) Dataset 6 (subset 10)

Figure 5: Performance over Various Numbers of Bins

The selected classiﬁcation thresholds and their correspond-
ing accuracies are shown in Figures 6 and 7 respectively. The
numbers of bins and classiﬁcation thresholds are calculated
from the proposed approaches. From these ﬁgures one can
see that the threshold selection approach performs more sta-
ble with dataset 6. This is due to the fact that dataset 6 has
more training images, hence, it provides more intra and inter
distances for selecting the threshold. Overall, these results in-

IJCAI-07

2895

dicate that the selected classiﬁcation thresholds are very sta-
ble with regard to the subsets.

tional Conference on Multimedia Computing and Systems,
2:143–147, 1999.

700

600

500

400

300

200

100

l

d
o
h
s
e
r
h

t
 
n
o
i
t

a
c
i
f
i
s
s
a
c

l

700

600

500

400

300

200

100

l

d
o
h
s
e
r
h

t
 
n
o
i
t

a
c
i
f
i
s
s
a
c

l

0

1

2

3

4

5
6
subset

7

8

9

10

0

1

2

3

4

5
6
subset

7

8

9

10

(a) Dataset 5

(b) Dataset 6

Figure 6: Selected Classiﬁcation Thresholds via the Proposed
Threshold Approach

100

90

80

70

60

50

40

30

20

10

)

%

(
 
y
c
a
r
u
c
c
a

precision
recall

0

1

2

3

4

5
6
subset

7

8

9

10

(a) Dataset 5

(b) Dataset 6

Figure 7: Performance of Overlapping Energy Histogram
with Automatic Parameters Selection Algorithms on Dataset
5 and 6

5 Conclusions

In this paper we proposed a new approach to feature extrac-
tion with the overlapping energy histogram of the DCT coef-
ﬁcients for face recognition. Some important issues related to
the recognition performance were investigated, in particular,
the issue of selection of threshold and number of bins. Ex-
perimentation was conducted on Yale face database. Results
have shown that the threshold selection provides a balance in
precision and recall rates. The number of bins selection ap-
proach has produced convincing results. In addition, the over-
lapping energy histogram approach has shown to outperform
the Eigenfaces, 2DPCA and energy histogram in all selected
datasets.

References
[Ahmed et al., 1974] N. Ahmed, T. Natarajan, and K. Rao.
Discrete cosine transform. IEEE Transaction on Comput-
ers, 23(1):90–93, 1974.

[Brunelli and Mich, 1999] R. Brunelli and O. Mich. On the
IEEE Interna-

use of histograms for image retrieval.

[Database, 2004] YALE University Face Database. [Online]

http://vismod.media.mit.edu/vismod/classes/mas622-
00/datasets, 2004.

[Hafed and Levine, 2001] Z.M. Hafed and M.D. Levine.
Face recognition using the discrete cosine transform. In-
ternational Journal of Computer Vision, 43(3):167–188,
2001.

[Kirby and Sivorich, 1987] M. Kirby and L. Sivorich. Low-
dimentional procedure for the characterization of human
faces. Journal of the Optical Society of America, 4:519–
524, 1987.

[Kirby and Sivorich, 1990] M. Kirby and L. Sivorich. Ap-
plication of the karhunen-loeve procedure for the charac-
terization of human faces. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 12(1):103–108, 1990.
[Kohir and Desai, 1998] V. V. Kohir and U. B. Desai. Face
recognition using a DCT-HMM approach. Fourth IEEE
Workshop on Applications of Computer Vision, pages 226–
231, 1998.

[Lay and Guan, 1999] J. A. Lay and L. Guan. Image retrieval
based on energy histogram of the low frequency DCT co-
efﬁcients.
IEEE International Conference on Acoustics,
Speech and Signal Processing, 6:3009–3012, 1999.

[Lu, 2003] X. Lu.

Image analysis

for

face recog-
lvxi-

nition.
aogu/publications/ImAna4FacRcg lu.pdf, 2003.

http://www.cse.msu.edu/

[Online]

[Phillips et al., 2003] P.

J. Phillips, P. Grother, R.

J.
Micheals, D. M. Blackburn, E. Tabassi, and J. M.
Bone. FRVT 2002: Overview and summary.
[Online]
http://www.frvt.org/FRVT2002/documents.htm, 2003.

[Swain and Ballard, 1990] M. J. Swain and D. H. Ballard.
Indexing via color histograms. Proceedings of 3rd Inter-
national Conference of Computer Vision, pages 390–393,
1990.

[Tjahyadi et al., 2004] R. Tjahyadi, Wanquan Liu,

and
S. Venkatesh. Application of dct technique in facial recog-
nition. In Proceedings of 2nd International Conference on
Information Technology and Applications, pages 305–310,
2004.

[Tjahyadi, 2004] R. Tjahyadi. Investigations on pca and dct
based face recognition algorithms, 2004. Master Thesis,
Curtin University of Technology.

[Turk and Pentland, 1991] M. Turk and A. Pentland. Eigen-
faces for recognition. Journal of Cognitive Neuroscience,
13(1):71–86, 1991.

[Yang et al., 2004] J Yang, D Zhang, AF Frangi, and J Yang.
Two-dimensional pca: A new approach to appearance-
based face representation and recognition.
IEEE Trans-
actions on Pattern Analysis and Machine Intelligence,
26:131–137, 2004.

[Zhao et al., 2000] W. Zhao, R. Chellappa, A. Rosenfeld,
and P. Phillips. Face recognition: A literature survey.
UMD CfAR Technical Report CAR-TR-948, 2000.

IJCAI-07

2896

