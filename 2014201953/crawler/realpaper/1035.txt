Observation Reduction for Strong Plans

Wei Huang1, Zhonghua Wen1, 2, Yunfei Jiang1, Lihua Wu1

1. Software Research Institute, School of Information Science and Technology,

Sun Yat-sen University, Guangzhou, China

2. College of Information Engineering, Xiangtan University, Xiangtan, China

Email: huangbodao@yahoo.com.cn

Abstract

Strong planning under full or partial observability
has been addressed in the literature. But this re-
search line is carried out under the hypothesis that
the set of observation variables is ﬁxed and compul-
sory. In most real world domains, however, obser-
vation variables are optional and many of them are
useless in the execution of a plan; on the other side,
information acquisition may require some kind of
cost. So it is signiﬁcant to ﬁnd a minimal set of
observation variables which are necessary for the
execution of a plan, and to best of our knowledge,
it is still an open problem. In this paper we present
a ﬁrst attempt to solve the problem, namely, we de-
ﬁne an algorithm that ﬁnds an approximate minimal
set of observation variables which are necessary for
the execution of a strong plan under full observabil-
ity (i.e. a state–action table); and transforms the
plan into a strong plan under partial observability
(i.e. a conditional plan branching on the observa-
tions built on these observation variables).

1 Introduction
In recent years, increasing interest has been devoted to plan-
ning in non–deterministic domains. Strong planning (i.e.
ﬁnding automatically a plan which is guaranteed to achieve
the goal regardless of nondeterminism) is an important prob-
lem in this research ﬁeld. Under full observability or partial
observability, this problem has been addressed in the litera-
ture: in the frame for full observability proposed in [Cimatti
et al., 1998b; 2003], a plan is a state-action table; in the frame
for partial observability proposed in [Bertoli et al., 2001;
2006], a plan is a conditional plan branching on the values
of observation variables.

The cases of full observability, see e.g., [Cimatti et al.,
1998b; 2003], where the whole status of the domain is ob-
served at every step, and the cases of partial observability, see
e.g., [Boutilier, 2002; Eiter et al., 2003; Herzig et al., 2003;
Bertoli et al., 2001; 2006], where the plan executor cannot
access the whole status of the domain, are both under the
assumption that the set of observation variables is ﬁxed and
compulsory. In real world domains (e.g., many robotics, con-
trol, and scheduling domains), however, observation variables

are optional and many of them are useless in the executions
of the plans; on the other side, information acquisition may
require some kind of cost (e.g. time, money, and power etc.).
So it is signiﬁcant to ﬁnd a minimal set of observation vari-
ables that are necessary for the execution of a plan, and to
best of our knowledge, it is still an open problem.

In this paper we present a ﬁrst attempt to solve the problem.
Under the hypothesis that any two distinct states of the do-
main can be distinguished by an observation variable at least,
we deﬁne an algorithm that ﬁnds an approximate minimal set
(written as Vobs) of observation variables that are necessary
for the execution of a strong plan under full observability (i.e.
a state-action table), and transforms the plan into a strong plan
under partial observability (i.e. a conditional plan branching
on the observations built on Vobs). This algorithm ﬁrst ex-
ploits the belief state [Bonet and Geffner, 2000] (i.e. the set
of possible current states) at every step to compute Vobs; then,
it transforms the given state–action table into a conditional
plan branching on the observations built on Vobs. The algo-
rithm is based on the frameworks for strong planning under
full observability proposed in [Cimatti et al., 2003] and par-
tial observability proposed in [Bertoli et al., 2006].

The paper is organized as follows. We ﬁrst recap the frame-
works proposed in [Cimatti et al., 2003] and [Bertoli et al.,
2006] (Section 2); then, we introduce the key notions of the
algorithm and describe the algorithm in detail (Section 3); ﬁ-
nally, Section 4 draws some conclusions and discusses future
research directions.

2 Domains, Observations, Plans, and

Problems

In this section, we brieﬂy review some deﬁnitions of strong
planning in non-deterministic domains under full observabil-
ity and partial observability that are relevant to our work. Fur-
ther details and examples of these deﬁnitions can be found in
[Cimatti et al., 2003; Bertoli et al., 2006].

A planning domain is a model of a generic system with its

own dynamics.
Deﬁnition 1 A planning domain is a tuple Σ = (cid:2)S, A, R(cid:3),
where S is a ﬁnite set of states, A is a ﬁnite set of actions, and
R : S × A → 2S is the transition function. The transition
function associates to each state s ∈ S and to each action
a ∈ A the set R(s, a) ⊆ S of next states.

IJCAI-07

1930

The set of actions that are applicable in state s is ACT(s) =

{a|∃s(cid:2) ∈ R(s, a)}.

In practice, a domain may have many observation vari-

ables, whose value can be observed at run–time.
Deﬁnition 2 Let Σ = (cid:2)S, A, R(cid:3) be a planning domain. Let V
be a ﬁnite set of observation variables. An observation func-
tion over S and V is a function X : S × V → {(cid:8), ⊥}.

From Deﬁnition 2, for each state, there is a corresponding

complete set of assignments to observation variables.

Plans can control the evolutions of the domain by trigger-
ing actions. A plan under full observability is a set of state–
action pairs.
Deﬁnition 3 A plan πF for Σ is a set of pairs (cid:2)s, a(cid:3) (i.e. a
state–action table), where: s ∈ S, a ∈ ACT(s), and there is
at most one action a such that (cid:2)s, a(cid:3) ∈ πF for any state s.

The execution of a state–action table πF in Σ can be rep-
resented as execution structure, i.e. a directed graph in which
the nodes are all of the states of the domain that can be
reached by executing actions in the state–action table, and
the arcs represent possible state transitions caused by actions
in πF .
Deﬁnition 4 Let πF be a state–action table for Σ. The ex-
ecution structure induced by πF from the set of initial states
I ⊆ S is a tuple K = (cid:2)Q, T (cid:3), where Q ⊆ S and T ⊆ S × S
are the minimal sets satisfying the following rules:

1. if s ∈ I, then s ∈ Q, and
2. if s ∈ Q and there exists a state–action pair (cid:2)s, a(cid:3) ∈ πF

such that s(cid:2) ∈ R(s, a), then s(cid:2) ∈ Q and T (s, s(cid:2)).

A state s ∈ Q is a terminal state of K if there is no s(cid:2) ∈ Q
such that T (s, s(cid:2)). A path of K from s0 ∈ I is a possi-
bly inﬁnite sequence s0, s1, . . . of states in Q such that, for
every state si in the sequence, either si is the last state of
the sequence (in which case si is a terminal state of K) or
T (si, si+1) holds.

A planning problem for a given domain is described by a

set of possible initial states, and a set of goal states.
Deﬁnition 5 Let Σ = (cid:2)S, A, R(cid:3) be a planning domain. A
planning problem for Σ is a triple P = (cid:2)Σ, I, G(cid:3), where I ⊆
S and G ⊆ S.

In the following discussion, Σ = (cid:2)S, A, R(cid:3), V, X , P =
(cid:2)Σ, I, G(cid:3), πF , and K represent a planning domain, a ﬁnite set
of observation variables, an observation function over S and
V, a planning problem for Σ, a state–action table for Σ, and
the execution structure induced by πF from I, respectively.
In many cases, we are interested in strong solutions to P,
i.e. plans that are guaranteed to achieve the goal in spite of
nondeterminism.
Deﬁnition 6 πF is a strong solution to P if K is acyclic and
all terminal states of K are in G.

In fact, any state–action table πF for Σ is a strong solution
to some planning problems for Σ, if its execution structure
K is acyclic and all terminal states of K are in G. So in
the following discussion, we use interchangeably the terms
strong solution and strong plan.

+

,

-

4

5

+

6+

6,

6-

,

6.

6/

60

-

61

62

63

6+

6.

61

6,

6/

62

Figure 1: A simple domain and the execution structure in-
duced by πF from I

In the following example, we illustrate the deﬁnitions given

the domain: S = {s0, . . . , s8}.

in this section.
Example 1 A simple robot navigation domain Σ is
shown on the left of Figure 1.
The robot can be in
nine positions of a room, corresponding to the states
of
It can move
in the four directions, corresponding to actions A =
{GoNorth, GoSouth, GoEast,GoWest}. An action is ap-
plicable only if there is no wall in the direction of mo-
tion, e.g. R(s0, GoSouth) = ∅. All the actions are de-
terministic (e.g., R(s7, GoWest) = {s6}), except for ac-
tion GoEast when on s0 (or s3), where the robot may
slip and end up either in s1 or s4 (or in s1, s4, or s7),
i.e. R(s0, GoEast) = {s1, s4} and R(s3, GoEast) =
{s1, s4, s7}.
Let I = {s0, s3} and G = {s6}.
Then πF = {(cid:2)s0, GoEast(cid:3), (cid:2)s1, GoSouth(cid:3), (cid:2)s3, GoEast(cid:3),
(cid:2)s4, GoSouth(cid:3), (cid:2)s7, GoWest(cid:3)} is a strong plan to P =
(cid:2)Σ, I, G(cid:3), and its execution structure K is shown on the right
of Figure 1.

Suppose that the sensors of the robot can detect walls in
the current position. This can be formalized with four obser-
vation variables, i.e. W allN , W allS, W allW and W allE.
In addition, there are six responders (i.e. X0, X1, X2, Y0,
Y1, and Y2) located at the north or west border of the room.
They work as the X–axis and Y–axis of the nine positions (let
1 ≤ n ≤ 3):

1. The robot sends n pulses north (or west) via the ground.
2. If the responder Xn−1 (or Yn−1) receives n pulses then
it sends a responsive pulse south (or east), else it does
nothing.

3. The robot can detect whether its X-coordinate (or Y-
coordinate) is n by receiving a responsive pulse or not
in a appointed time.

i.e.

So the

Y 1

can

be

formalized

with

X0, X1, X2,

observation
and
set of observation variables V is

This
variables,
Y 2.
{W allN, W allS, W allW, W allE, X0, X1, X2, Y 0, Y 1,
Y 2};
and the observation function X is
X (s0, W allE) = ⊥, X (s2, X2) = (cid:8), and so on.

six
Y 0,

such that

IJCAI-07

1931

3 Observation Reduction for Strong Plans
In most real world domains, observation variables are op-
tional and many of them are useless in the execution of a plan
(e.g. consider the situation represented in Example 1, the re-
sponder X2 can be turned off before the execution of πF );
on the other side, information acquisition may require some
kind of cost (e.g. time, money, and power etc.). So it is sig-
niﬁcant to ﬁnd a minimal set of observation variables which
are necessary for the execution of a plan.

In this paper, it is assumed that any two distinct states of
the domain can be distinguished by an observation variable
at least. So state–action tables are acceptable at execution
level. In the execution of a state–action table πF , the execu-
tor is required to observe the values of all the observation
variables; consequently, it can know what the current state
is and execute the appropriate action at every step. But in
many cases, there is much observation information that is
useless in the execution of a plan. For example, it makes no
sense to observe the value of an observation variable v, where
X (s, v) = (cid:8) (or X (s, v) = ⊥) for any possible current state
s (hereafter, B denotes the set of possible current states, i.e.
the current belief state); and there is no need to do any de-
tection if there exists a ∈ A such that (cid:2)s, a(cid:3) ∈ πF for any
s ∈ B.

In this section, we deﬁne an algorithm that ﬁnds an approx-
imate minimal set of observation variables (i.e. Vobs) which
are necessary for the execution of a strong plan, and trans-
forms the strong plan into a conditional plan branching on
the observations built on these observation variables. Before
explaining the algorithm in detail, we introduce some notions
used in it.

In the execution of πF , the action that should be exe-
cuted on s is written as ACTION(s, πF ). That is to say,
if ∃a ∈ A. (cid:2)s, a(cid:3) ∈ πF then ACTION(s, πF ) = a, else
ACTION(s, πF ) = nop (nop means doing nothing).

Let ∅ ⊂ Vobs ⊆ V. For each s ∈ S, we represent the
corresponding set of assignments to the observation variables
of Vobs with CODE(s, Vobs, X ), where:

• if Vobs = {v} and X (s, v) = (cid:8),

CODE(s, Vobs, X ) = v.

• if Vobs = {v} and X (s, v) = ⊥,

CODE(s, Vobs, X ) = ¬v.

then

then

• if |Vobs| > 1 and v ∈ Vobs, then

CODE(s, Vobs, X )
=
CODE(s, Vobs − {v}, X ).

CODE(s, {v}, X ) ∧

The above representation naturally extends to any ∅ ⊂ Q ⊆ S
as follows:

(cid:2)

CODE(Q, Vobs, X ) =

CODE(s, Vobs, X )

s∈Q

The set of observations built on V and X is O(V, X ) =
{CODE(Q, Vobs, X ) | ∅ ⊂ Q ⊆ S, ∅ ⊂ Vobs ⊆ V}.

The deﬁnition of conditional plans branching on O(V, X )
is given as follows. In fact, it is an extension of the one pro-
posed in [Bertoli et al., 2006].
Deﬁnition 7 The set of conditional plans Π for (cid:2)Σ, V, X (cid:3) is
the minimal set such that:

• ε ∈ Π, ε is the empty plan;
• if a ∈ A and π ∈ Π, then a ◦ π ∈ Π;
• if o
and π1, π2

∈ O(V, X ),

if o then π1 else π2 ∈ Π.

∈ Π,

then

In general, we are interested in applicable plans, i.e. plans
whose execution guarantees that an action is never attempted
unless it is applicable, regardless of nondeterminism.
Deﬁnition 8 A plan π for (cid:2)Σ, V, X (cid:3) is applicable in state s iff
either

• π is the empty plan ε; or
• π is a ◦ π(cid:2), a is applicable in s, and π(cid:2) is applicable in

every s(cid:2) ∈ R(s, a); or

• π is if o then π1 else π2, and:

– if the formula CODE(s, V, X ) → o is a tautology,

π1 is applicable in s; and

– if the formula CODE(s, V, X ) → ¬o is a tautology,

π2 is applicable in s.

The execution of a conditional plan is deﬁned in terms
of the runs associated to it.
Intuitively, a run contains the
states, observations and actions encountered while executing
the plan.
Deﬁnition 9 A run is a sequence σ = (s0, o0) ◦ a1 ◦ (s1, o1) ◦
. . . ◦ an ◦ (sn, on), where si ∈ S, oi ∈ O(V, X ), and
ai ∈ A. A sequence σ is a run of π (π is a conditional plan
for(cid:2)Σ, V, X (cid:3)) from state s iff either

• π = ε, and σ = (s, o) with o = CODE(s, V, X ); or
• π = a ◦ π1 and σ = (s, o) ◦ a ◦ σ1 with o =
CODE(s, V, X ), and σ1 is a run for π1 from some s1 ∈
R(s, a) (cid:15)= ∅; or

• π = if o then π1 else π2, CODE(s, V, X ) → o
is a tautology, and σ is a run of π1 starting from
(s, CODE(s, V, X )); or

• π = if o then π1 else π2, CODE(s, V, X ) → ¬o
is a tautology, and σ is a run of π2 starting from
(s, CODE(s, V, X )).

In the following, we write RUNS(s, π) to denote the set of
runs of π starting from s. We write FINALSTATES(s, π) to
indicate the set of the ﬁnal states of the runs of RUNS(s, π).
The deﬁnition of strong plans to (cid:2)P, V, X (cid:3) is given as fol-
lows. In fact, it is similar to the one proposed in [Bertoli et
al., 2006].
Deﬁnition 10 A conditional plan π for (cid:2)Σ, V, X (cid:3) is a strong
plan to (cid:2)P, V, X (cid:3) iff

• π is applicable in every state of I, and
• every run of π from a state in I ends in G,

(cid:3)

s∈I FINALSTATES(s, π) ⊆ G.

i.e.

Now we can introduce the algorithm for observation reduc-

tion of strong plans in detail.

The basic algorithm (i.e. STRONG–FO–PO) is presented
in Figure 2. Given a planning problem P, a strong plan πF to
P, a ﬁnite set of observation variables V, and an observation
function X , the algorithm transforms πF into a strong plan

IJCAI-07

1932

1.
2.
3.
4.
5.

function STRONG–FO–PO(P, πF , V, X )

dis ← FINDSTATEPAIRS(P, πF );
Vobs ← REDUCTION(dis, V, X );
return TRANSFORM(P, πF , Vobs, X );

end

Figure 2: STRONG–FO–PO algorithm

function FINDSTATEPAIRS(P, πF )

// Suppose P = (cid:2)Σ, I, G(cid:3)
parts ← DIVIDE(I, πF );
if (parts = ∅) then

return ∅;

ﬁ;
dis ← ∅;
for each (a, Q) ∈ parts

1.

2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.

16.
17.
18.
19.
20.
21.

Inext ← EXECUTE(Σ, Q, a);
P (cid:2) ← (cid:2)Σ, Inext, G(cid:3);
dis ← dis ∪ FINDSTATEPAIRS(P (cid:2), π);

endfor;
if (I ∩ G (cid:15)= ∅) then

parts ← parts ∪ {(nop, I ∩ G)};

ﬁ;
for any (a1, Q1), (a2, Q2) ∈ parts,

where a1 (cid:15)= a2
for any s1 ∈ Q1, s2 ∈ Q2
dis ← dis ∪ {(s1, s2)};

endfor;

endfor;
return dis;

end

Figure 3: FINDSTATEPAIRS procedure

1.

2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.

function REDUCTION(dis, V, X )

// Suppose V = {v1, . . . , vn}
for n ≥ i ≥ 1 do di[i] ← 0;
for all (s1, s2) ∈ dis

for n ≥ i ≥ 1

if (X (s1, vi) (cid:15)= X (s2, vi)) then

di[i] ← di[i] + 1;

ﬁ;

endfor;

endfor;
Vobs ← ∅;
while (dis (cid:15)= ∅)

let di[i] = max{di[k] | n ≥ k ≥ 1};
Vobs ← Vobs ∪ {vi};
for all (s1, s2) ∈ dis

if (X (s1, vi) (cid:15)= X (s2, vi)) then

delete (s1, s2) from dis;

ﬁ;

endfor;
di[i] ← 0;

endwhile;
return Vobs;

end

Figure 4: REDUCTION procedure.

empty set is returned by FINDSTATEPAIRS.

• Third (lines 6–11), the elements of dis corresponding
to the next belief state are computed by simulating the
strong plan’s execution for one step and an application
of FINDSTATEPAIRS itself. The simulation of a plan
is realized through the function EXECUTE. Formally,
EXECUTE(Σ, Q, a) =

s∈Q R(s, a).

(cid:3)

to (cid:2)P, Vobs, X (cid:3), where Vobs is an approximate minimal set of
observation variables which are necessary for the execution of
πF . The STRONG–FO–PO algorithm has two main phases:
(1) an observation reduction phase (lines 2–3), in which Vobs
is computed by applications of FINDSTATEPAIRS and RE-
DUCTION, and (2) a transform phase (line 4), in which πF
is transformed into a conditional plan for (cid:2)Σ, Vobs, X (cid:3) by an
application of TRANSFORM.

In order to compute Vobs, we calculate dis ⊆ S × S: if
(s1, s2) ∈ dis, then {s1, s2} ⊆ B (i.e.
the set of possi-
ble current states) at some step of the execution of πF and
ACTION(s1, πF ) (cid:15)= ACTION(s2, πF ). This task is accom-
plished by the FINDSTATEPAIRS procedure, which is pre-
sented in Figure 3.

Now let us introduce the FINDSTATEPAIRS procedure in

detail:

• First (line 2), the set of possible current states (i.e. I)
are divided into some divisions according to the ac-
tions speciﬁed by πF . The partition is realized through
Formally, DIVIDE(I, πF ) =
the function DIVIDE.
{(a, Q) | a ∈ A, ∅ ⊂ Q ⊆ I, s ∈ Q iff (cid:2)s, a(cid:3) ∈ πF }.

• Second (lines 3–5), if parts = ∅ (i.e. I ⊆ G), then an

• Finally (lines 12–19), if the actions speciﬁed by πF for I
are not consistent (i.e. |parts| > 1), then any two states
(e.g. s1 and s2) from different divisions of I should be
distinguished from each other, i.e. (s1, s2) or (s2, s1)
should be included in dis if a1 (cid:15)= a2, (a1, Q1) ∈ parts,
(a2, Q2) ∈ parts, s1 ∈ Q1, and s2 ∈ Q2.

Figure 4 shows the REDUCTION procedure. Given dis ⊆
S × S, V, and X as input, the REDUCTION procedure returns
an approximate minimal set of observation variables Vobs
such that ∀(s1, s2) ∈ dis. ∃v ∈ Vobs. X (s1, v) (cid:15)= X (s2, v). It
starts with Vobs = ∅ and iteratively adds some v ∈ V into
Vobs until d = dis, where d = {(s1, s2) ∈ dis | ∃v ∈
Vobs. X (s1, v) (cid:15)= X (s2, v)}.

The TRANSFORM procedure is presented in Figure 5. Its
role is to transform πF (i.e. a strong plan to P) into a strong
plan π to (cid:2)P, Vobs, X (cid:3).

Now let us introduce the TRANSFORM procedure in detail.
At ﬁrst (line 2), the belief state (i.e. I) is divided into some
divisions according to the actions speciﬁed by πF . The parti-
tion is realized through the function DIVIDE. And then:

1. If I ⊆ G (lines 3–4), then an empty plan ε is returned.
2. Else if I ∩ G (cid:15)= ∅ (lines 5–8), then if o then ε else

TRANSFORM(P (cid:2), πF , Vobs, X ) is returned, where:

IJCAI-07

1933

1.

2.
3.
4.
5.
6.
7.
8.

9.
10.
11.
12.
13.
14.
15.
16.
17.

18.
19.

function TRANSFORM(P, πF , Vobs, X )

// Suppose P = (cid:2)Σ, I, G(cid:3)
parts ← DIVIDE(I, πF );
if I ⊆ G then

return ε;

else if I ∩ G (cid:15)= ∅ then

o ←MAKECODE(I ∩ G, I − G, Vobs, X );
P (cid:2) ← (cid:2)Σ, I − G, G(cid:3);
return if o then ε

else TRANSFORM(P (cid:2), πF , Vobs, X );
else if parts = {(a, Q)} then // i.e. |parts| = 1

Inext ←EXECUTE(Σ, Q, a);
P (cid:2) ← (cid:2)Σ, Inext, G(cid:3);
return a ◦ TRANSFORM(P (cid:2), πF , Vobs, X );

else

select an element (a, Q) from parts;
o ←MAKECODE(Q, I − Q, Vobs, X );
P (cid:2) ← (cid:2)Σ, Q, G(cid:3), P (cid:2)(cid:2) ← (cid:2)Σ, I − Q, G(cid:3);
return if o then TRANSFORM(P (cid:2), πF , Vobs, X )

else TRANSFORM(P (cid:2)(cid:2), πF , Vobs, X );

ﬁ;
end

Figure 5: TRANSFORM procedure.

• o is an observation that can distinguish the states in

I ∩ G from the states in I − G.

• P (cid:2) = (cid:2)Σ, I − G, G(cid:3).

o is computed by MAKECODE(I ∩ G, I − G, Vobs, X ).
Figure 6.
shows the MAKECODE subroutine. Given
Q1 ⊆ S, Q2 ⊆ S, Vobs, and X as input, the MAKE-
CODE subroutine ﬁnds an approximate minimal set of
observation variables Vnow ⊆ Vobs such that ∀(s1, s2) ∈
Q1 × Q2. ∃v ∈ Vnow. X (s1, v) (cid:15)= X (s2, v), and re-
turns the observation of Q1 built on Vnow and X (i.e.
CODE(Q1, Vnow, X )).

3. Else if the actions speciﬁed by πF for I are con-
sistent,
then
a ◦ TRANSFORM(P (cid:2), πF , Vobs, X ) is returned, where:
• a is the action speciﬁed by πF for all the possible

|parts| = 1 (lines 9–12),

i.e.

current states.

• P (cid:2) = (cid:2)Σ, Inext, G(cid:3). Inext is the belief state at next

step, and it is computed by EXECUTE(Σ, Q, a).

4. Else (lines 13–17) (a, Q) is selected from parts, and if

o then π1 else π2 is returned, where:

• o is an observation that can distinguish the states in
Q from the states in I − Q, and it is computed by
MAKECODE(Q, I − Q, Vobs, X ).

• π1 =TRANSFORM((cid:2)Σ, Q, G(cid:3), πF , Vobs, X ).
• π2 =TRANSFORM((cid:2)Σ, I − Q, G(cid:3), πF , Vobs, X ).

From Deﬁnition 6, Deﬁnition 10 and the algorithms pre-

sented above, we can get Theorem 1 and Theorem 2.
is a strong plan to P,
Theorem 1 If πF
STRONG–FO–PO(P, πF , V, X ) terminates.

then

1.
2.
3.
4.
5.
6.
7.
8.

function MAKECODE(Q1, Q2, Vobs, X )

dis ← ∅;
for any s1 ∈ Q1, s2 ∈ Q2
dis ← dis ∪ {(s1, s2)};

endfor;
Vnow ← REDUCTION(dis, Vobs, X );
return CODE(Q1, Vnow, X );

end

Figure 6: MAKECODE subroutine.

In fact, Theorem 1 can be proved by showing that all the
paths of the execution structure K induced by πF from I are
ﬁnite. According to Deﬁnition 6, all the paths of K are ﬁnite
(i.e. K is acyclic) because πF is a strong plan to P.
Theorem 2 Let πF be a strong plan to P. Let Qt be the set
of terminal states of K (i.e. the execution structure induced
by πF from I). Suppose π is the conditional plan returned by
STRONG–FO–PO(P, πF , V, X ). Then:
• π is a strong plan to (cid:2)P, V, X (cid:3), and
•

s∈I FINALSTATES(s, π) = Qt ⊆ G.

(cid:3)

In the following example, we illustrate the algorithms de-

scribed in this section.

Example 2 Consider the situation depicted in Exam-
ple 1. We apply STRONG–FO–PO to (P, πF , V, X ).
Firstly, dis is computed by FINDSTATEPAIRS(P, πF ), and
it is {(s1, s7), (s4, s7)}; and then, Vobs is computed by
REDUCTION(dis, V, X ), and it is {W allS}; lastly, π is re-
turned by TRANSFORM(P, πF , Vobs, X ), where:

• π = π0 = GoEast ◦ π1, and
• π1 = if W allS then (GoWest ◦ ε) else π2, and
• π2 = GoSouth ◦ π3, and
• π3 = if W allS then (GoWest ◦ ε) else π4, and
• π4 = GoSouth ◦ GoWest ◦ ε.

(cid:3)
It is easy to ﬁnd that π is a strong plan to (cid:2)P, V, X (cid:3), and G =
the set of terminal

s∈I FINALSTATES(s, π) = {s6} (i.e.

states of the execution structure induced by πF from I).

In fact, the observation variables of V − Vobs are useless in
the whole executions of π and πF . So the sensors and the re-
sponders that correspond to these observation variables (i.e.
W allN , W allW , W allE, X0, X1, X2, Y 0, Y 1, and Y 2)
can be turned off before executing π. Furthermore, it is not
necessary to observe all the values of observation variables
of Vobs at every step: for instance, π requires the plan execu-
tor to execute GoEast at ﬁrst, regardless of the observation
information about the current state.

4 Conclusions

This paper presents an algorithm (i.e. STRONG–FO–PO) for
observation reduction of strong plans under full observability,
which take the form of state–action tables. To the best of
our knowledge, no other work has discussed and tackled this
problem.

IJCAI-07

1934

Given a planning problem P = (cid:2)Σ, I, G(cid:3), a strong plan
πF to P, a ﬁnite set of observation variables V, and an obser-
vation function X as input, the STRONG–FO–PO algorithm
ﬁnds Vobs, i.e. an approximate minimal set of observation
variables which are necessary for the execution of πF , and
transforms πF into a conditional plan π branching on the ob-
servations built on Vobs and X , such that:

(cid:3)

• π is a strong plan to (cid:2)P, Vobs, X (cid:3), and
•

s∈I FINALSTATES(s, π) = Qt ⊆ G, where Qt is the
set of terminal states of the execution structure induced
by πF from I.

The STRONG–FO–PO algorithm always terminates.

In the STRONG–FO–PO algorithm, there are two levels of

the meaning of observation reduction:

1. The observation variables which are useless in the whole
execution of a plan πF , are discarded as more as possi-
ble. That is to say, the algorithm computes Vobs and
discards the observation variables of V − Vobs.

2. At every step of the execution of πF , values of the ob-
servation variables that are useless in choosing the ap-
propriate action, are discarded as more as possible. That
is to say, the algorithm computes Vnow (see Figure 6,
line 6) for every step of the execution of πF , and dis-
cards the values of observation variables of Vobs − Vnow
temporarily.

In the future, we plan to extend this work along the follow-

ing directions.

• We will investigate the problem under the situation that:
– observation variables may relate to different data

types (symbolic, numeric, ordinal, etc.), and

– noisy observations or missing values may be al-

lowed.

• Considering the costs corresponding to observation vari-
ables may be different, we will investigate the problem
of observation reduction for some plans, in which some
preferences should be taken into account.

• We will investigate observation reduction for plans to
other kinds of planning problems, in particular strong
cyclic planning problems [Cimatti et al., 1998a; Daniele
et al., 1999], and planing problems for temporally ex-
tended goals [Pistore and Traverso, 2001; Lago et al.,
2002].

References
[Bertoli et al., 2001] Piergiorgio

Bertoli,

Alessandro
Cimatti, Marco Roveri, and Paolo Traverso. Planning
in nondeterministic domains under partial observability
via symbolic model checking.
In Proceedings of the
17th International Joint Conference on Artiﬁcial Intelli-
gence, pages 473–478, Seattle, WA, USA, 2001. Morgan
Kaufmann.

[Bonet and Geffner, 2000] Blai Bonet and Hector Geffner.
Planning with incomplete information as heuristic search
in belief space.
In Proceedings of the 5th International
Conference on AI Planning Systems, pages 52–61, Breck-
enridge, Colorado, USA, 2000. AAAI Press.

[Boutilier, 2002] Craig Boutilier. A POMDP formulation of
preference elicitation problems. In Proceedings of the 18th
National Conference on Artiﬁcial Intelligence, pages 239–
246, Edmonton, Canada, 2002. AAAI Press.

[Cimatti et al., 1998a] Alessandro Cimatti, Marco Roveri,
and Paolo Traverso. Automatic OBDD-based generation
of universal plans in non-deterministic domains. In Pro-
ceedings of the 15th National Conference on Artiﬁcial
Intelligence, pages 875–881, Madison, Wisconsin, USA,
1998. AAAI Press.

[Cimatti et al., 1998b] Alessandro Cimatti, Marco Roveri,
and Paolo Traverso. Strong planning in non–deterministic
domains via model checking. In Proceedings of the 4th
International Conference on AI Planning Systems, pages
36–43, Pittsburgh, USA, 1998. AAAI Press.

[Cimatti et al., 2003] Alessandro Cimatti, Marco Pistore,
Marco Roveri, and Paolo Traverso. Weak, strong, and
strong cyclic planning via symbolic model checking. Arti-
ﬁcial Intelligence, 147:35–84, 2003.

[Daniele et al., 1999] Marco Daniele, Paolo Traverso, and
Moshe Y. Vardi. Strong cyclic planning revisited.
In
Proceedings of the 5th European Conference on Planning,
pages 35–48, Durham, United Kingdom, 1999. Springer-
Verlag.

[Eiter et al., 2003] Thomas Eiter, Wolfgang Faber, Nicola
Leone, Gerald Pfeifer, and Axel Polleres. A logic pro-
gramming approach to knowledge–state planning, II: The
DLV K
system. Artiﬁcial Intelligence, 144(1–2):157–211,
2003.

[Herzig et al., 2003] Andreas Herzig, Jerome Lang, and
Pierre Marquis. Action representation and partially ob-
servable planning using epistemic logic. In Proceedings of
the 18th International Joint Conference on Artiﬁcial Intel-
ligence 2003, pages 1067–1072, Acapulco, Mexico, 2003.
Morgan Kaufmann.

[Lago et al., 2002] Ugo Dal Lago, Marco Pistore, and Paolo
Traverso. Planning with a language for extended goals.
In Proceedings of the 18th National Conference on Ar-
tiﬁcial Intelligence, pages 447–454, Edmonton, Canada,
2002. AAAI Press.

Pistore

[Pistore and Traverso, 2001] Marco

Paolo
Planning as model checking for extended
Traverso.
goals in non-deterministic domains.
In Proceedings of
the 17th International Joint Conference on Artiﬁcial
Intelligence, pages 479–484, Seattle, WA, USA, 2001.
Morgan Kaufmann.

and

[Bertoli et al., 2006] Piergiorgio

Alessandro
Cimatti, Marco Roveri, and Paolo Traverso. Strong plan-
ning under partial observability. Artiﬁcial Intelligence,
170:337–384, 2006.

Bertoli,

IJCAI-07

1935

