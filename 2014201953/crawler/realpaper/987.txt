Named Entity Translation with Web Mining and Transliteration 

Long Jiang*, Ming Zhou*, Lee-Feng Chien+, Cheng Niu* 

*Microsoft Research Asia 

*5F Sigma Center, No. 49, Zhichun Road, Haidian District, Beijing 100080, PRC 

+Institute of Information Science, Academia Sinica, Taiwan 

*{longj, mingzhou, chengniu}@microsoft.com, +lfchien@iis.sinica.edu.tw 

Abstract 

This paper presents a novel approach to improve the 
named  entity  translation  by  combining  a  translit-
eration  approach  with  web  mining,  using  web  in-
formation as a source to complement transliteration, 
and  using  transliteration  information  to  guide  and 
enhance web mining. A Maximum Entropy model 
is employed to rank translation candidates by com-
bining  pronunciation  similarity  and  bilingual  con-
textual  co-occurrence.  Experimental  results  show 
that our approach effectively improves the precision 
and recall of the named entity translation by a large 
margin. 

1  Introduction 
Named entity (NE) translation accepts a named entity from a 
source language as input and outputs its translations into a 
” (Eng-
target language. For instance, 
lish  to  Chinese).  Large  quantities  of  new  named  entities 
appear each day in newspapers, web sites and technical lit-
erature,  but  their  translations  normally  cannot  be  found  in 
translation dictionaries. Improving named entity translation 
is  important  to  translation  systems  and  cross-language  in-
formation  retrieval  applications.  Moreover,  it  benefits  bi-
lingual  resources  acquisition  from  the  web  and  translation 
knowledge  acquisition from  corpora. While  named  entities 
normally  refer  to  a  range  of  concepts  like  people  names, 
place  names,  organization  names,  product  names  etc.,  the 
focus of this paper is the translation of people names from 
English to Chinese. 
  Many of the previous works extract named entity transla-
tion dictionaries from bilingual corpora [Kupiec, 1993; Feng 
et al., 2004]. To alleviate the strong dependency on parallel 
corpora,  [Rapp,  1999;  Fung  and  Yee,  1998]  try  to  obtain 
named entity translations from nonparallel, comparable texts, 
or unrelated bilingual corpora.  
  Since a large proportion of English named entities can be 
translated by transliteration, many works try to build trans-
literation  models  with  a  rule-based  approach  [Wan  and 
Verspoor, 1998]  and  statistics-based  approach [Knight  and 
Graehl,  1998;  Lin  and  Chen,  2002;  Virga  and  Khudanpur, 
2003; Gao, 2004]. Both approaches, however, still have room 
for  improvement.  Rule-based  approaches  adopt  linguistic 

  and 

rules for a deterministic generation of translation. However, 
it is hard to systematically select the best Chinese character 
from  multiple  Chinese  characters  that  have  the  same  pro-
.  Statistics-based  trans-
nunciation,  such  as 
literation  approaches  select  the  most  probable  translations 
based  on  knowledge  learned  from  the  training  data.  This 
approach, however, still may not work perfectly when there 
are multiple standards [Gao, 2004]. For example, “ford” at 
  in 
the  end  of  an  English  NE  is  transliterated  into 
),  but  some-
most  cases  (e.g., 
times, it is transliterated into 

(e.g., 

).  Obviously,  there  is  significant  flexibility  in  translit-
eration generation of foreign names in real world, and trans-
literation  selection  is  somewhat  subjective.  Hence,  transla-
tion  relying  on  the  statistical  machine  transliteration  only 
may not work well. 
  The web contains an enormous dataset of languages, many 
of  which  are  instantly  available  and  up  to  date.  In  recent 
years, some researchers, like [Wang et al., 2004; Cheng et al., 
2004; Nagata et al., 2001; Zhang et al, 2005] have used it to 
extract  translations  with  promising  results.  In  particular, 
[Wang et al., 2004; Cheng et al, 2004] propose a novel ap-
proach.  They  search  target  language  web  pages  using  the 
source term or NE. Then it extracts the translation candidates 
1   score  +  Local  Maxima  algorithm  and 
based  on 
ranks the generated candidates with Chi-Square method and 
context vector method. This approach gets excellent results 
for high-frequency terms and NEs. However, it cannot han-
dle  the  low-frequency  words  or  ambiguous  words  (e.g. 
) well, because their translations scarcely 

appear in the search results.  
  Other efforts have been made to undertake combinations 
of  transliteration  and  corpora  mining [Shao  and  Ng, 2004; 
Huang et al., 2004] or web mining [Al-Onaizan and Knight, 
2002].  In  particular,  [Al-Onaizan  and  Knight,  2002]  use 
                                                 
...1(

1 

)

...1(

)

)
...1(

...1(
(

)

1

1

1
1

Where 

 is the n-gram to be estimated,

number of unique left adjacent characters. 
number of unique right adjacent characters.
frequency of the N-gram 

. [Cheng et al, 2004]. 

...1

)
 is the 

 is the 

is the 

IJCAI-07

1629

statistical machine transliteration model to generate transla-
tion candidates, and use the web for translation identification. 
This  method  demonstrates  positive  results  when  using  the 
web for selecting correct translation from candidates, but not 
for helping generate translation candidates. 
 
In this paper, we are interested in the question of : how to 
and to what extent the NE translation can benefit from the 
combination of transliteration and web mining in both can-
didate generation and translation identification. Specifically, 
we  are  concerned  with  how  to  enhance  the  transliteration 
results with web information. That means, for example,

(output of transliteration system for 

) could 

be corrected as

(the correct translation of 

”),  and  how  to  guide  web  mining  with  transliteration 
information,  rather  than  using  statistical  association  alone. 
To do this, we propose a novel framework of NE translation 
that effectively incorporates approaches of transliteration and 
web  mining.  Specifically,  we  build  a  transliteration  model 
first, and the transliteration result is used to guide web min-
ing  for  generating  translation  candidates.  Furthermore,  a 
Maximum  Entropy  (ME)  model  is  designed  to  rank  the 
translation candidates with various relevant features.  
  Benchmarks  are  performed  on  each  component  and  the 
overall system to reveal our improvement to previous works. 
Experimental results show that NE translation can be con-
sistently improved with our new approach by a large margin.  
1.  Using  transliteration-guided  web  mining,  the  trans-
lation candidate coverage is improved from 54.5% to 
74.5%.  
2.  By including pronunciation similarity and bilingual 
contextual co-occurrence features, a ME model help 
to  improve  the  overall  translation  precision  from 
18.5% to 47.5% in top 1 answer.  

  The remainder of this paper is structured as follows. Sec-
tion  2  presents  steps  of  our  approach.  In  Section  3,  the 
transliteration model is described. Section 4 introduces our 
new approach to provide translation candidates by combining 
transliteration  with  web  mining.  The  ranking  method  for 
translation candidates with a ME model is presented in Sec-
tion 5. Experiments and performance comparison with pre-
vious works are reported in Section 6. The last section points 
out the directions of future work and concludes our study. 

2  Our Approach  
Specifically,  the  translation  process  we  proposed  can  be 
described as follows: 
1.  Transliteration:  To  transliterate  English  NE  into  Chi-
nese word base on their pronunciation similarity. In this 
step, a three-level transliteration model is built: English 
surface string to Chinese Pinyin string, Chinese Pinyin 
string to Chinese character string and Chinese character 
language model.  
2.  Web  mining  for  translation  candidates  enhanced  by 
transliteration:  Compared  with  [Wang  et  al.,  2004; 
Cheng  et  al,  2004],  transliteration-based  similarity  is 
used to improve the translation candidate generation for 
low-frequency words. The Chinese pages are searched 
using the input English NE as query. The n-gram strings 

are selected from the snippets as translation candidates 
if they are pronounced similarly to the input NE. 
3.  Web  mining  for  translation  candidates  using  queries 
expanded  by  transliteration:  The  input  English  NE  is 
combined with each Chinese character (anchor) in the 
transliteration results  to form  expanded queries.  Then 
the  expanded  queries  are  used  to  search  web  pages. 
From  the  returned  snippets,  we  select  the  n-grams 
which contain the anchors and have strong pronuncia-
tion similarity to the input NE as additional translation 
candidates. This approach aims to deal with ambiguous 
words whose majority usage is not a proper name (e.g.
4.  Finally,  all  the  translation  candidates  generated  from 
the step 2 and step 3 are ranked by a ME model that has 
features covering pronunciation similarity and bilingual 
contextual co-occurrences. 

).  

3  Transliteration 
Given an English NE, denoted as 
a “syllable” sequence 
linguistic rules we defined: 

, we first syllabicate it into 
 with the following 

1. 

2.  Duplicate the nasals 

 are defined as vowels. 

 is defined as a 
vowel when it is not followed by a vowel. All other 
characters are defined as consonants;  

 whenever they are sur-
rounded by vowels. And when they appear behind a 
vowel, they will be combined with that vowel to form 
a new vowel; 

 and 

3.  Consecutive consonants are separated;  
4.  Consecutive vowels are treated as a single vowel;  
5.  A consonant and a following vowel are treated as a 
6.  Each  isolated  vowel  or  consonant  is  regarded  as  an 

syllable;  

individual syllable. 

  For example, 

 is split into 

. 

, 

|

*

arg

(max

 is split into 

 is split into 
. 

 is split 
into
. 
  Then a generative  model is used to transliterate the syl-
labicated English name into Chinese character string, which 
follows  [Knight  and  Graehl,  1998].  Specifically,  for  the 
, we seek a 
generated “syllable” sequence 
Chinese Character sequence 
 that maxi-
mizes the product of 
, 
 
)()

 and 
|

  is  a  Chinese  Pinyin  sequence,

  is  the 
 is the prob-
  is  the  generative 

 
where 
probability of translating 
ability  of  translating 
probability of a character-based Chinese language model. 
  Different from [Knight and Graehl, 1998; Virga and Khu-
danpur, 2003] whose transliteration model is based on pho-
neme, we use “syllable” as translation units (TU). 
  Here, a Chinese “syllable” means a Chinese Pinyin string 
that  is  corresponding  to  a  Chinese  character.  And  English 
“syllable” means a combination of several English letters that 
can generate a corresponding Chinese Pinyin “syllable”. 

  into 

 into 

  and 

()

 

 

, 

IJCAI-07

1630

  Using  syllables  as  TU  has  the  following  advantages:  1) 
compared with phoneme-based approach, a syllable has far 
less ambiguity in finding the corresponding Chinese Pinyin 
 has fewer corresponding Chinese 
string. For instance, 
Pinyin  strings  than  the  phoneme  sequence  /
/;  2)  a 
syllable always corresponds to a legal Pinyin sequence. 
  The  translation  model 
  can  be  trained  with 
GIZA++2 on  parallel  English  names  and  the  Pinyin  repre-
sentation of Chinese names. The translation model 
 
can  be  approximately  obtained  from  a  pronunciation  dic-
tionary. In our experiment, we used an in-house dictionary. 
The language models 
 is approximated by using a tri-
gram model and trained with a list of Chinese transliterated 
names. 

4  Web Mining  
After we get the transliteration result of source NE, we want 
to use it to help finding the translation candidates on the web. 
The specific methods are as follows.  
4.1  WM-NE: Candidate Collection by Searching 

the Web with NE  

Same with [Wang et al., 2004], we use the input English NE 
as a query to search for the Chinese pages and extract can-
didates in the returned top 100 snippets. In our experiments, 
Google search engine3  is used for obtaining the snippets.  
 
It is noticed that usually the results of statistical translit-
eration model are not exactly correct, but very similar with 
the  correct  translation.  If  we  use  web  data  to  correct  the 
transliteration result, the accuracy would be improved a lot. 
Based on this insight, the n-grams that have similar pronun-
ciation with the transliteration results are collected from the 
search engine snippets, and are used for transliteration cor-
rection. 
  Suppose 
 is the best transliteration result output by pre-
vious transliteration model. We define the score of an n-gram 
 

 being a translation candidate as the product of 

and

, 

, 
Score(wn)

TL(wn,

W)

p(wn)
 

 

 

 

where, 
between  the  n-gram 

  indicates  the  pronunciation  similarity 
  and  the  source  English  NE,  and 
 being a transliterated 
name  which  is  the  generative  probability  of  the  Chinese 
character-based  language  model  used  in  Section  3.  And 

 indicates the probability of 

 can be computed using the following formula. 

(

,

1)

(

)

(

,
(

)

 

)

 
 

 
 

. 

.  

 and 

 and 

  and 

  is  the  Pinyin  sequence  of 

and 
 respectively, and 

where 
Pinyin sequence of 
of 
Edit Distance between 
  Based on the formulas above, we compute the scores for 
all n-grams in the snippets. And then select those n-grams as 
candidate whose score of being a translation candidate is over 
a threshold. 

  is  the 
 are the lengths 
 is the 

transliterated 

 This approach can make adequate use of the translitera-
tion  information  obtained  in  the  previous  model  and  hand 
those 
is  a 
low-frequency word in the snippets. By the way this method 
is also independent of NE tagger. 
4.2  WM-NE-Anchor: Enhancing Web Mining 

translation  even 

though 

it 

Using Transliteration Result as Anchors 

In addition to WM-NE, the result of transliteration 

, 

  is  used  as  anchor  information  to  guide  the  web 
mining to obtain additional translation candidates by using 
the following steps.  
1.  Search the web with an anchor character and the input 
, is combined with source Eng-
NE. Each character, 
lish NE as a query to search for web pages. The first 
30 snippets are selected; 

2.  Surrounding the position of 

 in a snippet, we extract 
and its 
all the n-gram character strings that contain 
score  of  being  a  translation  candidate  described  in 
Subsection 4.1 is over a threshold as candidates.  

 is transliterated into 

 by 
  For example, 
our transliteration model in Section 3. Then the Chinese word 
and 
. Each of 
is split into three characters: 
these characters is combined with 
 to form a Boolean 
query to search for web pages. For each query, we select the 
top 30 returned snippets to form a small corpus, e.g. for the 
query 

, we get a corpus {

}. In the 
 appears, and select 
corpus we search the position where 
 and has score higher 
all n-gram strings that contains 
than the threshold to be a translation candidate, and the re-
sults are {
  This  approach  can  effectively  enhance  WM-NE.  In 
WM-NE, the returned snippets may not contain the anchor + 
NE cases within 100 snippets. One of the reasons is that the 
source NE may be quite ambiguous. It can be used as a per-
son name sometimes, but this is not its majority usage. For 
” when used 
example, “Spain” can be translated into “
as a person name, but more popularly, it should be translated 
”. When we search web using only “Spain” as 
into “
query, all returned snippets by Google do not contain “

}. 

”, but when we search web using “
” ({

returned snippets contain “

”, the top 30 

find the specific translation of many ambiguous words. 

 

}). So the WM-NE-Anchor method can 

                                                 

2 http://www-i6.informatik.rwth-aachen.de/Colleagues/och/soft

ware/GIZA++.html. 

3 http://www.google.com 

5  Ranking Translation Candidates 
A ME model is used to rank the translation candidates ob-
tained  above,  which  contains  the  following  four  features 

IJCAI-07

1631

. Where, 

 denotes the source English NE. 

functions 
 denotes a Chinese 
candidate, 
1.  Same  with  [Cheng  et  al.,  2004],  the  Chi-Square  of 
  and  the  input  English  named 
 is used as one of our features. The Chi-Square is 

translation  candidate 
entity 
computed using the formula below: 

,1

2

 

 

 

 
 
 
 
 

 = the number of pages containing both 
 = the number of pages containing 
 = the number of pages containing 
 = the number of pages containing neither 
 = the total number of pages, 

 but not 
 but not 

 and 
 
 

, 

 nor 
 

 

 

  and 

In our experiments, 

 is set to 4 billion. Actually, the value 
of 
 doesn't affect the ranking once it’s positive. To get the 
value of parameters in the formula above, we combine 
 and 
 as a query to search with Google for web pages. And the 
returned page contains the number of total pages containing 
  which  is  corresponding  to  a  in  the  formula 
both 
above. Then we use 
 as queries respectively to search 
the web and we can get the two numbers 
, which 
represent the number of pages contain 
 respectively. 
Then we can compute 
.  
2.  Contextual feature 

 and 

 and 

 and 

 and 

, 

, where   is the number of 
 is in a 

occurrence, in any of the snippets selected, that 
bracket following 
3.  Contextual feature 

 is in a bracket following 

 where 

 or 

;  

 is the number of 
 are 

 and 

occurrence, in any of the snippets selected, 
immediate neighbors;  

 and 

,  which  is  equal  to 

 in terms of transliteration similar-
  described  in 

4.  Similarity of 

ity 
Subsection 4.1. 

 
With these features, the ME model is expressed as:  
 
 

exp[

,(

])

4

(

|

)

(

4
1

|

)

 
 
 
To estimate the parameters 

'

exp[

 

1
4

1

,'(

])

erative Scaling algorithm of [Darroch and Ratcliff, 1972]. 

 we use the Generalized It-

6  Experiments  
We  use  the  same  method  as  [Gao,  2004]  to  collect  the 
training data, 
, we extract all named entity pairs from the 
LDC Chinese-English Name Entity Lists Version 1.04, which 
also  appear  in  CMU  pronunciation  dictionary5.  We  finally 
obtain 25,718 person names. Out of these name pairs, 200 are 
selected as development set, 200 as testing set, and the rest is 
for training. 

                                                 

4 Catalog Number by LDC: LDC2003E01 
5 http://www.speech.cs.cmu.edu/cgi-bin/cmudict 

6.1  Transliteration Evaluation  
To  evaluate  our  transliteration  model  using  syllables  as 
translation  units,  we  compare  its  performance  with  [Virga 
and Khudanpur, 2003] which is also on English to Chinese 
transliteration.  The  measures  are  Pinyin  error  rate  (Pinyin 
ER) and Chinese character error rate (Char ER). Here, Pinyin 
ER is the Edit Distance between the “correct” Pinyin repre-
sentation  of  the  correct  transliteration  and  the  Pinyin  se-
quence output by the system [Virga and Khudanpur, 2003]. 
Char  ER  is  defined  similarly, 
,  it  is  the  Edit  Distance 
between the character sequence of the “correct” translitera-
tion and the character sequence output by the system. The 
results are listed below: 

 
[Virga and Khudanpur, 2003] 
Our transliteration model 

Pinyin ER 

Char ER 

42.5% 
39.6% 

N/A 
46.1% 

Table 1 Transliteration model evaluation 

From  Table  1,  we  can  see  that  our  model  outperforms 
[Virga  and  Khudanpur,  2003].  The  results  support  using 
“syllable” as translation unit in both sides in transliteration 
model. In our experiments, the TU on English side contains 
about 1,260  English  syllables  and  the  TU on  Chinese  side 
contains 370 Pinyin syllables. 
6.2  Effectiveness of Candidate Generation by 

Combining Transliteration with Web Mining  
We want to know whether our new web mining approach,
, WM-NE and WM-NE-Anchor, improves the coverage of 
translation  candidates.  So  we  made  some  experiments  to 
compare  our  method  with  [Al-Onaizan  and  Knight,  2002] 
and [Wang et al., 2004]. Because they used non-public data 
set for evaluation and [Al-Onaizan and Knight, 2002] per-
formed  Arabic-English 
instead  of  Eng-
lish-Chinese translation, which make the direct comparison 
difficult.  Instead,  we  reimplemented  their  methods  and 
benchmarked  our  improvement  using  LDC  data  set.  The 
results are listed below: 

translation 

 
[Al-Onaizan 
Knight, 2002] 
[Wang 

, 2004] 

WM-NE 
WM-NE 
WM-NE-Anchor 

+ 

Candidates 
coverage 
46.5% 

and 

54.5% 

58% 

74.5% 

Average number of 

candidates 

100 

295.1 

64.0 

144.0 

Table 2 Candidates coverage comparison with previous approaches 
 
In  [Al-Onaizan  and  Knight,  2002],  N-best  outputs  of 
transliteration  model  are  used  as  translation  candidates  for 
re-ranking.  Obviously,  when 
  increases,  the  coverage  of 
translation candidates increases. So which number should we 
 to make a fair comparison? In our reimplemen-
assign to 

IJCAI-07

1632

5

10

20

1

e
g
a
r
e
v
o
C

Candidate Coverage

tation experiment of their algorithm, we found that after N 
increases  over  100,  the  increment  of  candidate  coverage 
becomes negligible (see Figure 1). So we finally decide to set 
N equal to 100 for our comparison experiment.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

3
30
Number of Candidates

50.0
40.0
30.0
20.0
10.0
0.0

 
Figure 1 Candidates coverage of N best transliteration output 
In [Wang et al., 2004], candidates are extracted by 

 
 
+ Local Maxima Algorithm. This method is good at handling 
high-frequency words, but worse for low-frequency words. 
In  our  testing  data,  the  average  frequency  of  the  correct 
translation appearing in the search result is about eight, and 
for 40.5% of NEs, the frequency of its correct translation is 
less  than  three.  So 
  +  Local  Maxima  Algorithm  is 
hard  to  extract  these  translations.  From  Table  2,  we  also 
notice that WM-NE-Anchor improved the coverage signifi-
cantly. That means our WM-NE-Anchor method does work 
for many ambiguous NEs. 
6.3  ME Model Evaluation  
To  test  the  effectiveness  of  each  feature  used  in  our  ME 
model,  we  conduct  four  experiments.  Like  [Cheng  et  al., 
2004], the metric is 
 which is defined as the 
percentage of the NE whose translations could be found in 
the first   extracted translations.  

50

100

 

Chi-Squ

are 
7.5% 
23.0% 
33.0% 
49.0% 

TL 

34.0% 
55.5% 
63.5% 
69.5% 

Chi-Square 

+ TL 
43.0% 
59.0% 
63.5% 
66.5% 

All features 

47.5% 
61.5% 
66.0% 
69.5% 

Table 3 Candidate ranking experiment result 

  Table 3 shows that incrementally adding features is effec-
tive  in  improving  the 
.  Ranking  with 
Chi-Square  method  alone,  the  precision  is  7.5%.  Ranking 
with TL score alone, the precision is 34.0%. Combining these 
two  features  together,  precision  reaches  up  to  43.0%,  and 
using all features mentioned in Section 5, it reaches a 47.5% 
precision rate.  
  We further analyze the reasons. Chi-Square, as the statis-
tical association of the English NE and the translation can-
didates, is effective mainly on high-frequency candidates, but 

less  effective  on  low-frequency  candidates.  Moreover, 
Chi-Square  cannot  differentiate  candidates  based  on  con-
tents.  However,  transliteration  scores  bring  information  on 
linguistic association between NE and candidates. Therefore, 
they can improve ranking effects. In addition, from our re-
sults we can see that contextual features are also helpful in 
improving rankings with about 4.5% for the 
. 
6.4  Comparing Previous Approaches 
To compare with the previous approaches for transliteration 
and web mining, three experiments are conducted: 
1.  Exp_1  (Based  on  [Al-Onaizan  and  Knight,  2002]): 
uses transliteration model to generate candidates and 
then  combine  straight  web  counts  of  candidates  to 
select correct translations. 
2.  Exp_2  (Based  on  [Wang  et  al.,  2004])  provides 
translation  candidates  via 
  +  Local  Maxima 
Algorithm and ranks them by Chi-Square method and 
Context vector method. 
3.  Exp_3 (Our approach) gets translation candidates via 
WM-NE  and  WM-NE-Anchor  and  ranks  them  with 
all of the four features mentioned in Section 5.  

  Table 4 indicates our new approach surpasses the previous 
approaches of transliteration and web mining by a substantial 
margin.  

 

Exp_1 
18.0% 
35.5% 
41.5% 

Exp_2 
18.5% 
35.0% 
39% 

Exp_3 
47.5% 
66.0% 
69.5% 

Table 4 Comparing previous approaches 

” and “

”  and  “

”. Our system outputs “ 

  To  analyze  errors,  we  checked  a  sample  of  50  NEs.  24 
(48%)  NEs  provide  a  correct  translation.  In  the  remaining 
data, 10 (20%) NEs acquired translations different from the 
ones defined in LDC data though they are acceptable. Further 
study  shows  that  most  are  actually  more  popular  than  that 
LDC data. For instance, the translation of “Dockery” in LDC 
”.  We check 
data is “
”  co-occurs  in  119 
with  Google,  “
” co-occurs in only three 
pages, but “
”  is  also  a  popular 
pages.  This  may  indicate  that  “
translation.  
  We further analyze the error sources for the remaining 16 
(32%)  incorrect  NE  translations.  For  five  NEs,  the  correct 
translations do not co-occur in any Chinese web page. For 
eight  NEs,  the  correct  translations  are  not  ranked  high 
enough in the candidate sets by TL score. For the other three 
NEs, the translation errors result from mistakenly identifying 
lexical boundaries in the candidate generation stage. It should 
be  noted  that,  since  our  testing  data  is  randomly  selected 
from a large LDC data set, and many of them are scarcely 
used in real world, the performance of our system should not 
be compared directly to those work based on their specific 
testing data. 

IJCAI-07

1633

 [Lin  and  Chen,  2002]  Wei-Hao  Lin  and  Hsin-Hsi  Chen. 
2002.  Backward  Machine  Transliteration  by  Learning 
Phonetic  Similarity.  In  Proc.  of  the  6th  CoNLL,  pp. 
139-145. 

[Nagata  et  al.,  2001]  Masaaki  Nagata,  Teruka  Saito,  and 
Kenji Suzuki. 2001. Using the Web as a Bilingual Dic-
tionary. In Proc. of ACL 2001 Workshop on Data-driven 
Methods in Machine Translation, pp. 95-102. 

[Rapp, 1999] Reinhard Rapp. 1999. Automatic identification 
of word translations from unrelated English and German 
corpora. In Proc. of ACL-99, pp. 519-526. 

[Shao  and  Ng,  2004]  Li  Shao  and  Hwee  Tou  Ng.  2004. 
Mining new word translations from comparable corpora. 
In Proc. of Coling 2004,  pp. 618–624 

[Virga  and  Khudanpur,  2003]  Paola  Virga  and  Sanjeev 
Khudanpur.  2003.  Transliteration  of  proper  names  in 
cross-lingual information retrieval. In Proc. of the ACL 
Workshop  on  Multi-lingual  Named  Entity  Recognition. 
pp. 57-64. 

[Wan and Verspoor, 1998] Stephen Wan and Cornelia Ver-
spoor. 1998. Automatic English-Chinese Name Translit-
eration  for  Development  of  Multilingual  Resources.  In 
Proc. of COLING-ACL 1998, pp. 1352-1356. 

[Wang et al., 2004] Jenq-Haur Wang, Jei-Wen Teng, Pu-Jen 
Cheng,  Wen-Hsiang  Lu,  Lee-Feng  Chien.  2004.  Trans-
lating unknown cross-lingual queries in digital libraries 
using a web-based approach. In Proc. of JCDL 2004, pp. 
108-116. 

[Zhang et al., 2005] Ying Zhang, Fei Huang, Stephan Vogel. 
2005.  Mining translations  of  OOV  terms  from  the  web 
through  cross-lingual  query  expansion.  SIGIR  2005: 
669-670. 

7  Conclusions 
In this paper, we present a new approach to combine trans-
literation and web mining for NE translation. Experimental 
results show that our approach effectively improves the pre-
cision and recall of the named entity translation by a large 
margin.  

Our approach has the following contributions:  
1. Translation  candidate  generation  is  enhanced  by 
combining  transliteration-based  similarity  and  web 
mining.  Transliteration  is  especially  helpful  for 
low-frequency word translation. 

2. Using queries expanded by transliteration, web min-
ing  can  further  improve  the  coverage  of  candidate 
generation. 

3. A  ME  model  incorporating  different  knowledge  is 

effective in ranking translation candidates.  

In  the  future,  we  want  to  extend  this  approach  to  NE 
translation for other language pairs. We are also interested in 
adapting the method to translate terminologies. 

References 
[Al-Onaizan and Knight, 2002] Yaser Al-Onaizan and Kevin 
Knight.  2002.  Translating  named  entities  using  mono-
lingual and bilingual resources. In Proc. of ACL-02. pp: 
400-408. 

[Cheng et al., 2004] Pu-Jen Cheng, Wen-Hsiang Lu, Jer-Wen 
Teng, and Lee-Feng Chien. 2004. Creating Multilingual 
Translation  Lexicons  with  Regional  Variations  Using 
Web Corpora. In Proc. of ACL-04. pp. 534-541. 

[Darroch  and  Ratliff,  1972]  J.N.  Darroch  and  D.  Ratcliff. 
1972. Generalized iterative scaling for log-linear models. 
The  Annals  of  Mathematical  Statistics.  Vol  43.  pp. 
1470-1480 

[Feng  et  al.,  2004]  Donghui  Feng,  Yajuan  Lv,  and  Ming 
Zhou.  2004.  A  New  Approach  for  English-Chinese 
Named Entity Alignment. In Proc. of EMNLP-2004. pp. 
372-379 

[Fung and Yee, 1998] Pascale Fung and Lo Yuen Yee. 1998. 
An IR Approach for Translating New Words from Non-
parallel, Comparable Texts. In Proc. of the 36th Annual 
Conference of the ACL, pp 414-420. 

[Gao,  2004]  Wei  Gao.  2004.  Phoneme-based  Statistical 
Transliteration of Foreign Names for OOV Problem. A 
Thesis of Master. The Chinese University of Hong Kong. 
[Huang  et  al.,  2004]  Fei  Huang,  Stephan  Vogel  and  Alex 
Waibel.  2004.  Improving  Named  Entity  Translation 
Combining  Phonetic 
and  Semantic  Similarities. 
HLT-NAACL 2004: 281-288. 

[Knight  and  Graehl,  1998]  Kevin  Knight  and  Jonathan 
Graehl.  1998.  Machine  Transliteration.  Computational 
Linguistics 24(4): 599-612. 

[Kupiec, 1993] Julian Kupiec. 1993. An algorithm for find-
ing noun phrase correspondences in bilingual corpora. In 
Proc. of the 31st Annual Meeting of the ACL. pp. 17-22. 

IJCAI-07

1634

