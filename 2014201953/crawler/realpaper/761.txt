From Generic Knowledge to Speciﬁc Reasoning for Medical Image Interpretation

using Graph based Representations

Jamal Atif, C´eline Hudelot, Geoffroy Fouquier, Isabelle Bloch, Elsa Angelini

GET - Ecole Nationale Sup´erieure des T´el´ecommunications - Dept TSI - CNRS UMR 5141 LTCI

46 rue Barrault, 75013 Paris, France – isabelle.bloch@enst.fr

Abstract

In several domains of spatial reasoning, such as
medical image interpretation, spatial relations be-
tween structures play a crucial role since they are
less prone to variability than intrinsic properties of
structures. Moreover, they constitute an important
part of available knowledge. We show in this pa-
per how this knowledge can be appropriately rep-
resented by graphs and fuzzy models of spatial re-
lations, which are integrated in a reasoning process
to guide the recognition of individual structures in
images. However pathological cases may deviate
substantially from generic knowledge. We propose
a method to adapt the knowledge representation to
take into account the inﬂuence of the pathologies
on the spatial organization of a set of structures,
based on learning procedures. We also propose
to adapt the reasoning process, using graph based
propagation and updating.

1 Introduction
Several domains, such as anatomy, can beneﬁt from a
strongly structured knowledge, that can be expressed for in-
stance by an ontology. This knowledge is of great help for
interpreting particular cases or instantiations (e.g. individual
anatomy). As a typical application, we consider in this paper
the problem of knowledge-based recognition of anatomical
structures in 3D brain images. The available knowledge in-
cludes generic descriptions of structures, and their spatial or-
ganization, in particular their spatial relations, usually formu-
lated in natural language or formalized in medical ontologies.
This knowledge involves complex textual descriptions, which
are difﬁcult to translate into an operational model assisting
image segmentation and recognition algorithms. Towards this
aim, we propose to model this type of anatomical knowledge
using graphs, as a natural representation of both objects and
relations and a powerful reasoning tool (Section 2). Spa-
tial reasoning in medical image interpretation strongly relies
on spatial relations, that are less subject to inter-individual
variability than properties of anatomical structures such as
size or shape, as described in Section 3. A generic graph
model is used in a reasoning process guiding the recognition
of anatomical structures in brain magnetic resonance images

and is then instantiated in order to account for speciﬁcities
of the patient. However, speciﬁc cases can exhibit signiﬁcant
deviations from the generic model. This is typically the case
in medical applications when pathologies (such as brain tu-
mors) may appear as additional objects in the images, which
are not represented in the generic model. Another contribu-
tion of this paper, detailed in Sections 4 and 5, is the adap-
tation of the reasoning process to deal with speciﬁc cases,
according to both generic knowledge about pathologies and
their potential impact on normal structures, and speciﬁc pa-
tient’s information derived from the images. We propose to
learn the variability of the spatial relations in the presence of
a tumor by using a database of pathological cases (Section 4).
The adaptation of the reasoning procedure relies on knowl-
edge about the pathologies, through the exploitation of a brain
tumor ontology, the learning results and a graph based prop-
agation process which consists in updating the graph struc-
ture and attributes based on image segmentation results (Sec-
tion 5).

The proposed approach, illustrated in Figure 1, contributes
to ﬁll the gap between two widely addressed problems: seg-
mentation and recognition of objects in images on the one
hand, and knowledge representation on the other hand. Re-
cently, few approaches for AI based image interpretation
have been developed exploiting knowledge and generic in-
formation [Crevier and Lepage, 1997], in particular structural
knowledge represented with graphs, to drive speciﬁc recogni-
tion procedures (see e.g. [Mangin et al., 1996; Deruyver et
al., 2005; Colliot et al., 2006] among others). However, these
methods mainly deal with normal cases, and cannot be ap-
plied directly to pathological cases. Noticeably, very little
work uses ontology-based approaches for automatic image
interpretation, while they are more developed for image re-
trieval [Smeulders et al., 2000]. Unfortunately, no modeling
approach of spatial relations in the image domain has been
proposed, and segmentation tasks are not addressed. This pa-
per proposes an original method towards these aims.

2 Generic Knowledge Representation
In several domains, scene interpretation beneﬁts from knowl-
edge about its structural organization and its context. This is
typically the case in medical image interpretation. As an ex-
ample, we consider the case of brain imaging. The brain is
usually described as a hierarchical organization. Each level

IJCAI-07

224

Figure 1: Overview of our framework, illustrating the ontological, graph-based representations, learning and updating proce-
dures. The schematic representation of the generic anatomy is from [Hasboun, 2005].

of the hierarchy is composed of a set of objects, at a given
level of granularity. These objects are organized in space in
a roughly persistent way. This hierarchical and spatial or-
ganization is an important component of linguistic descrip-
tions of anatomical knowledge [Bowden and Martin, 1995;
Hasboun, 2005]. Recent developments in the ontology com-
munity have shown that ontologies can efﬁciently encode
generic and shared knowledge of a domain. For instance, the
Foundational Model of Anatomy (FMA) [Rosse and Mejino,
2003] provides an ontology of the canonical anatomy of the
human body.

Based on both linguistic and ontological descriptions, we
propose to model the spatial organization of the brain as an
hypergraph. Each vertex represents an anatomical structure,
while edges or hyperedges carry information about the spatial
relations between the vertices they link. The choice of hyper-
graphs is motivated by the importance of complex relations
of cardinality higher than two, such as “between”. Moreover
this type of structural representation is appropriate for model-
based recognition.

Model-based recognition requires a second level of knowl-
edge representation, related to the semantics of the spatial re-
lations in images. Fuzzy representations are appropriate in
order to model the intrinsic imprecision of several relations
(such as “close to”, “behind”, etc.), the potential variability
(even if it is reduced in normal cases) and the necessary ﬂexi-

bility for spatial reasoning [Bloch, 2005]. Two types of ques-
tions are raised when dealing with spatial relations: (i) given
two objects (possibly fuzzy), assess the degree to which a re-
lation is satisﬁed; (ii) given one reference object, deﬁne the
area of space in which a relation to this reference is satis-
ﬁed (to some degree). In this paper, we deal mainly with the
second question (see Section 3). Therefore we rely on spa-
tial representations of the spatial relations: a fuzzy set in the
spatial domain deﬁnes a region in which a relation to a given
object is satisﬁed. The membership degree of each point to
this fuzzy set corresponds to the satisfaction degree of the re-
lation at this point [Bloch, 2005]. An example is illustrated
in Figure 2.

Figure 2: Left: a fuzzy reference object. Right: fuzzy region
representing the relation “to the left of” the reference object.
Membership degrees vary from 0 (black) to 1 (white).

We now describe the modeling of the main relations that
we use: adjacency, distances and directional relative posi-
tions.

IJCAI-07

225

A distance relation can be deﬁned as a fuzzy interval f of
trapezoidal shape on R+, as illustrated in Figure 3. A fuzzy
subset μd of the image space S can then be derived by com-
bining f with a distance map dA to the reference object A:

∀x ∈ S, μd(x) = f (dA(x)),

(1)

where dA(x) = inf y∈A d(x, y).

f(d)

1

0

n1

n2

n3

n4

distances

Figure 3: Fuzzy interval representing a distance relation. For
instance the relation “close to” can be modeled by choosing
n1 = n2 = 0.

Directional relations are represented using the “fuzzy
landscape approach” [Bloch, 1999]. A morphological dila-
tion δνα by a fuzzy structuring element να representing the
semantics of the relation “in direction α” is applied to the ref-
erence object A: μα = δνα
(A), where να is deﬁned, for x in
S given in polar coordinates (ρ, θ), as:

να(x) = g(|θ − α|),

(2)
where g is a decreasing function from [0, π] to [0, 1], and
|θ − α| is deﬁned modulo π. This deﬁnition extends to 3D
by using two angles to deﬁne a direction. The example in
Figure 2 has been obtained using this deﬁnition.

Adjacency is a relation that is highly sensitive to the seg-
mentation of the objects and whether it is satisﬁed or not may
depend on one point only. Therefore we choose a more ﬂex-
ible deﬁnition of adjacency, interpreted as “very close to”. It
can then be deﬁned as a function of the distance between two
sets, leading to a degree of adjacency instead of a Boolean
value:

μadj(A, B) = h(d(A, B))

(3)
where d(A, B) denotes the minimal distance between points
of A and B: d(A, B) = inf x∈A,y∈B d(x, y), and h is a de-
creasing function of d, from R+ into [0, 1]. We assume that
A ∩ B = ∅.

In all these deﬁnitions, the satisfaction degree of a relation
depends on a function (f , g or h) which is chosen as a trape-
zoidal shape function for the sake of simplicity. A learning
step, presented in Section 4, deﬁnes the parameters of these
functions based on a set of segmented images.

3 Spatial Reasoning for Model-Based

Recognition

For the sake of completeness, we summarize in this section
previous work on structure recognition using spatial relations
and graph based knowledge representations. Details can be
found in [Colliot et al., 2006]. The approach is progres-
sive, in the sense that objects are recognized sequentially and

their recognition makes use of knowledge about their rela-
tions with respect to other objects. This knowledge is read
in the graph representing generic knowledge. The graph also
drives the order in which objects are searched. Relations with
respect to previously obtained objects have generally differ-
ent natures and have to be combined in a fusion procedure, at
two different levels. First, fusion of spatial relations occurs in
the spatial domain, using spatial representations of relations.
The result of this fusion allows to build a fuzzy region of in-
terest in which the search of a new object will take place, in
a process similar to focalization of attention. In a sequential
procedure, the amount of available spatial relations increases
with the number of processed objects. Therefore, the recog-
nition of the most difﬁcult structures, usually treated in the
last steps, will be focused in a more restricted area. Another
fusion level occurs during the ﬁnal decision step, i.e. segmen-
tation and recognition of a structure. For this purpose, it was
suggested in [Colliot et al., 2006] to introduce relations in the
evolution scheme of a deformable model, in which they are
combined with other types of numerical information, usually
edge and regularity constraints. This approach leads to very
good results in normal cases.

4 How to Deal with Speciﬁc Cases

The method presented so far is not well adapted to cases that
greatly differ from the generic model. Particularly, in med-
ical images, the presence of a tumor may induce not only
an important alteration of the iconic and morphometric char-
acteristics of its surrounding structures but also a modiﬁca-
tion of the structural information. We propose a pathology-
dependent paradigm based on the segmentation of the pathol-
ogy and on the use of the extracted information to adapt both
the generic graph representation and the reasoning process to
speciﬁc cases. In this paradigm, ontologies and fuzzy mod-
els convey important information to deal with complex sit-
uations. In this section, we address the following question:
given a pathology, which spatial relations do remain stable,
and to which extent?

4.1 A Brain Tumor Ontology

In addition to canonical anatomy, image interpretation in dis-
eased cases can beneﬁt from knowledge on pathologies. For
example, brain tumor classiﬁcation systems are highly used
in clinical neurology to drive the selection of a therapeuti-
cal treatment. Brain tumors are classiﬁed according to their
location, the type of the tissue involved, their degree of ma-
lignancy and other factors. The main brain tumor classiﬁ-
cation system is the WHO grading system [Smirniotopoulos,
1999] which classiﬁes brain tumors according to histologi-
cal features and radiologic-pathologic considerations. Dif-
ferential diagnosis of brain tumor based on the location of
the tumor was also proposed1. In this paper, we propose a
brain tumor ontology which encodes these different kinds of
knowledge. Named tumors (e.g. Gliomas, Astrocytoma) are
hierarchically organized according to the type of the tissue
involved in the tumor. Then for each type of tumors, the

1http://rad.usuhs.mil/rad/location/location frame.html

IJCAI-07

226

ontology describes their possible locations, their spatial be-
havior (i.e.
inﬁltrating vs. circumscribed), their composi-
tion (i.e. solid, cystic, necrotic, with surrounding edema),
their modality-based visual appearance and their grade in the
WHO grading system, as shown in Figure 4.

Localisation

Intracranial
Brain Tumor

Infiltrating
Brain Tumor

Cortical

Brain Tumor

Subcortical
Brain Tumor

Cystic
I Tumor

Not Necrotic

I Tumor

Necrotic
I Tumor

Glioblastoma
Multiforme

Brain Tumor

Named

Brain Tumor

Glioma

Astrocytoma

Behavior

Circumscribed

Tumor

Grade

Necrotic
C Tumor

Brain Tumor

WHO1

Juvenile Pylocityc

Astrocytoma

Composition

Not Necrotic

C Tumor

Cystic
C Tumor

Figure 4: Overview of a subpart of the brain tumor ontology.

This ontology was developed in the framework of Prot´eg´e2
and can be obtained on demand. We show in the next sections
how to use this ontology.

4.2 Learning Spatial Relation Stability in Presence

of Pathologies

The presence of a pathology can affect the generic structural
information in several ways: (1) a spatial relation between
two anatomical structures can be invalidated; (2) a spatial re-
lation between two anatomical structures can be validated but
with more variability; (3) new relations between anatomical
structures and pathological structures can be added; and (4)
an anatomical structure can be destroyed by the pathology.

These modiﬁcations depend on the type of the relations,
on their stability, on the precision or vagueness of the avail-
able knowledge. Intuitively, topological relations imply less
unstability than metric ones. The nature of the deformation
itself (i.e.
the nature of the tumor in our case: inﬁltrating,
destroying...) has also an impact on the stability of the spatial
relations.

However, these considerations remain intuitive and do not
lead to deﬁnite conclusions on the nature of the impact.
Therefore, we propose to learn the stability of the spatial re-
lations in the presence of tumoral pathologies on a set of ex-
amples.

Learning Database
The database is constituted of 18 healthy MRI and 16 patho-
logical MRI where the main anatomical structures were man-
ually segmented. The healthy cases are the images of the
widely used IBSR database3 (real clinical data). The patho-
logical cases include intracranial brain tumors belonging to n
different classes. We focus our study on the stability of spa-
tial relations between internal brain structures, namely: ven-

2http://protege.stanford.edu/
3available at http://neuro-www.mgh.harvard.edu/cma/ibsr/

tricles, caudate nuclei, thalami and putamen, which is a clin-
ically relevant choice, according to medical experts’ opinion.
The ﬁrst step concerns the structuration and clustering of
the database according to the brain tumor ontology. A key
point is the representativity of the database according to pre-
dominant spatial behaviors of brain tumors, i.e.
their ten-
dency to spread, to destroy (necrotic or not), to stem (cystic
tumor, edema presence) and their location.

Learning procedure
From this database, the parameters involved in the construc-
tion of the fuzzy representations of spatial relations (for func-
tions f , g, h in particular) are learned. Let us ﬁrst introduce
some notations and deﬁnitions: K = (K N , K P1, ...K Pn ) is
the learning database with K N
the set of healthy instances
and K Pi , i ∈ 1...n, the set of pathological instances of class
i. Let c be an instance of K (an image), Oc the set of seg-
mented objects in c and R a spatial relation. We denote by
μN
R the fuzzy subset in the image space corresponding to the
Pi
relation R for a healthy case, and by μ
R the fuzzy subset in
the image space corresponding to the relation R for a patho-
logical case of class i.

A leave-one-out procedure is used to learn, for a given
spatial relation R, the parameters of its fuzzy formulation
μR. Since μR is deﬁned in the spatial domain, we can di-
rectly compare μR and the target objects. The parameters
are optimized so as to maximize the inclusion of the tar-
get object in μR (i.e.
the object has to fulﬁll the relation
with the highest possible degree). For all c ∈ K k, k ∈
{N, P1, ...Pn}, (Ac, Bc) ∈ Oc, we compute the fuzzy set μk
R
with respect to Ac, and for a given inclusion measure I, we
compute I(Bc, μk
R). The fuzzy set optimizing this criterion
is denoted by μc
R.

In order to learn functions f , g and h (Equations 1, 2 and
3), the minimum or maximum of the values (distances, an-
gles...) are computed for all instances, from which the func-
tion parameters are then determined. Let us detail the ex-
ample of the relation “close to”. The training consists in the
computation of the maximum distance from a point x of the
target object Bc to the reference object Ac:
(x)).

(dAc

c
max = max
d
x∈Bc

(4)

and standard deviation σk

Then the mean mk
of the values
max}c∈K k are computed. The fuzzy interval f is then de-
{dc
ﬁned as a fuzzy subset of R+, with kernel [0, mk] and support
[0, mk + 2σk]. This allows taking into account the variability
of the parameters in the training set. An example is illustrated
in Figure 5.

A similar approach is applied for adjacency and directional

relations.

Stability assessment
The stability of the spatial relations can now be assessed by
comparing the learned parameters for speciﬁc cases and for
healthy ones. A suitable choice for such a comparison is a M-
measure of resemblance, according to the classiﬁcation pro-
posed in [Bouchon-Meunier et al., 1996].

We use a set-theoretic derived M-measure of resemblance
deﬁned as the cardinality of the intersection of two fuzzy sets

IJCAI-07

227

f(d)

normal cases

1

0

pathological cases

distances

Figure 5: Learning the relation “close to” between putamen
and caudate nucleus μd on normal cases and on pathological
cases for a class Pi (here high grade gliomas that shift the
putamen away from the caudate nucleus).

μ and μ(cid:3), normalized by the cardinality of their union:

(cid:2)
(cid:2)

R(μ, μ(cid:3)) =

min(μ(d), μ(cid:3)(d))
max(μ(d), μ(cid:3)(d))

d∈D

d∈D

the tumor has a strong impact on the putamen for instance.
Table 2 shows that the distance relations between the putamen
and other structures have a high variability between healthy
cases and pathological ones (i.e.
low resemblance values).
These results are in agreement which visual observations on
the images, as illustrated in Figure 6. Note that the learning
process in not symmetrical in Ac and Bc and depends on the
reference object (Equation 4), which explains that the tables
are not symmetrical.

tumor

caudate nucleus

putamen

thalamus

ventricles

where D denotes the deﬁnition domain of the fuzzy sets. This
choice is motivated by the properties of this measure (reﬂex-
ive, symmetrical, increases with the overlapping between the
two fuzzy sets, decreases with their difference).

This resemblance measure is applied on the fuzzy sets
learned for each type of spatial relations, as the ones illus-
trated in Figure 5 (in this case D is the distance space, i.e.
R+).

Results
In this section, we show some results for an instance of a
pathological class (here, high grade glioma, which are spread
and destroying). For each spatial relation, we compute the
fuzzy resemblance between the learned fuzzy sets in the
pathological class and in the healthy one as explained before.

caudate

ventricle

thalamus

putamen

caudate
ventricle
thalamus
putamen

1.000
0.573
0.537

1.000

0.689
0.426

0.713
0.834

0.653

0.594
0.416
0.597

Table 1: Degree of resemblance between the fuzzy represen-
tations of the the adjacency relation for the healthy class and
for a pathological class Pi (high grade gliomas).

caudate

ventricle

thalamus

putamen

caudate
ventricle
thalamus
putamen

0.639
0.559
0.530

0.454

0.537
0.349

0.211
0.490

0.219

0.194
0.598
0.379

Table 2: Degree of resemblance for the relation “close to” .

Table 1 shows that the adjacency relation exhibits high re-
semblance values for structures that have a high degree of
adjacency, such as caudate nuclei and ventricles (i.e. the ad-
jacency relations between two structures in a healthy case are
similar as those in a pathological case), which conﬁrm our
assumption that the adjacency remains stable even in patho-
logical conﬁgurations. The spatial relation “close to” is more
prone to unstability, in particular for structures that are more
affected by the tumor. In the considered pathological class,

Figure 6: A normal case and a pathological one. The caudate
nuclei and the ventricles are adjacent in both cases (hence
a high resemblance value for this relation). The putamen is
deformed in the pathological case, thus modifying its distance
to the caudate nuclei, which explains the low value of the
resemblance in Table 2.
5 Knowledge and Reasoning Adaptation for

Speciﬁc Cases

In this section, we propose an original approach to reason on
speciﬁc cases based on three steps: (1) detection and seg-
mentation of the tumor from the speciﬁc image as described
in [Khotanlou et al., 2005]; (2) adaptation of the generic
model to the speciﬁc case. The idea is to exploit the ontol-
ogy, enhanced by the learning results, and then add tumor
information extracted from images in the graph. Due to the
variability of individual cases, this knowledge is only a guide
for the recognition of image structures. The real speciﬁcity
of the processed case is computed by a graph based propaga-
tion segmentation process which evaluates the tumor impact
on surrounding structures; (3) updating of the database using
this new processed case.

5.1 Generic Knowledge Adaptation
The knowledge adaptation process depends on the available
knowledge. If we have expert knowledge about the processed
case, such as the diagnosis associated with the pathological
image, then it can be used to extract its characteristics from
the brain tumor ontology and then use the learned relations
corresponding to its class in the segmentation process. If we
do not have any information about the current case, we can
use image matching procedures through a similarity measure
to ﬁnd the best matching class in the database.

The knowledge adaptation process is based on the modi-
ﬁcation of the generic graph: we ﬁrst segment the brain tu-
mor, add a tumor node in the graph and localize it in the
brain, based on segmentation results; we then modify edge
attributes with the learned spatial relation parameters for the
class of this particular tumor.

IJCAI-07

228

5.2 A Graph Based Propagation Process

The aim of the graph based process is to quantify the real
impact of the pathology on surrounding structures by using
a progressive model based recognition approach as described
in Section 3. The model used is the one which results from
the knowledge adaptation step described in the previous sec-
tion. Starting from a reference structure (usually the lateral
ventricle), we propagate the tumor impact in the graph until
a behavior which is similar to the healthy case is reached, i.e.
until structures which are not affected by the tumor.

The knowledge is read in the graph representing the spe-
ciﬁc learned knowledge for this class. The graph drives the
order in which objects are searched but contrary to the generic
case, the choice of the structure to segment is also driven by
the stability of the learned relations. More precisely, starting
from a previously recognized object Ac, all objects Bj
c linked
with an edge to Ac are potential candidates for the next object
to be found. The choice of one of these is based on the maxi-
mum of resemblance. Usually several relations are shared by
Ac and Bj
c . The maximum is then deﬁned based on a lexi-
cographic order on the relations: 1. adjacency, 2. direction,
3. distance. Then we segment the corresponding structure
in a similar way as in Section 3. The only difference is that
each relation is taken into account with a weight given by the
resemblance degree. At last we update segmented structure
properties and relations with known structures in the speciﬁc
graph by edge and node attribute modiﬁcations. The pro-
cess stops when the computed attributes do not widely deviate
from the generic model (hence no more updating is required).
An illustrative example of segmentation results obtained
using the proposed approach on a pathological case is shown
in Figure 7. On this example, once the tumor is segmented,
the procedure leads to sucessful segmentation of ventricles,
caudate nuclei, thalamus and putamen (in this order). Note
that these results would have been very difﬁcult to obtain
based on the generic knowledge only.

putamen

tumor

thalamus

Figure 7: An axial slice of a 3D MRI, with segmented tumor
and some anatomical structures.

6 Conclusion

This paper is a contribution to AI based methods for image in-
terpretation. An important feature of the proposed approach
is the adaptation of generic knowledge to speciﬁc cases taking
into account information extracted from individual images,

as illustrated in the domain of pathological brain imaging.
The method combines in an original way graph representa-
tions, fuzzy models of spatial relations, learning procedures
and graph propagation. Further work aims at developing the
last step, which consists in updating the database with the
new processed cases. This includes adapting the shape of the
membership functions as in the learning step. Evaluation of
the proposed models and the whole approach by medical ex-
perts will also be performed.

Acknowledgments
This work has been partly supported by grants from R´egion
Ile-de-France, GET and ANR.

References
[Bloch, 1999] I. Bloch. Fuzzy Relative Position between Objects
in Image Processing: a Morphological Approach. IEEE Transac-
tions on Pattern Analysis and Machine Intelligence, 21(7):657–
664, 1999.

[Bloch, 2005] I. Bloch. Fuzzy Spatial Relationships for Image Pro-
cessing and Interpretation: A Review. Image and Vision Comput-
ing, 23(2):89–110, 2005.

[Bouchon-Meunier et al., 1996] B. Bouchon-Meunier, M. Rifqi,
and S. Bothorel. Towards general measures of comparison of
objects. Fuzzy Sets and Systems, 84(2):143–153, 1996.

[Bowden and Martin, 1995] D. M. Bowden and R. F. Martin. Neu-

ronames brain hierarchy. NeuroImage, 2:63–83, 1995.

[Colliot et al., 2006] O. Colliot, O. Camara, and I. Bloch. Integra-
tion of Fuzzy Spatial Relations in Deformable Models - Applica-
tion to Brain MRI Segmentation. Pattern Recognition, 39:1401–
1414, 2006.

[Crevier and Lepage, 1997] D. Crevier and R. Lepage. Knowledge-
based image understanding systems: a survey. Computer Vision
and Image Understanding, 67(2):160–185, 1997.

[Deruyver et al., 2005] A. Deruyver, Y. Hod´e, E. Leammer, and J.-
M. Jolion. Adaptive pyramid and semantic graph: Knowledge
driven segmentation. In Graph-Based Representations in Pattern
Recognition: 5th IAPR International Workshop, volume 3434 /
2005, pages 213–223, Poitiers, France, 2005.

[Hasboun, 2005] D. Hasboun. Neuranat.

http://www.chups.jussieu.fr/ext/neuranat/index.html, 2005.

[Khotanlou et al., 2005] H. Khotanlou, J. Atif, O. Colliot, and
I. Bloch. 3D Brain Tumor Segmentation Using Fuzzy Classiﬁ-
cation and Deformable Models. In WILF, volume LNCS 3849,
pages 312–318, Crema, Italy, sep 2005.

[Mangin et al., 1996] J.-F. Mangin, V. Frouin, J. R´egis, I. Bloch,
P. Belin, and Y. Samson. Towards Better Management of Cortical
Anatomy in Multi-Modal Multi-Individual Brain Studies. Phys-
ica Medica, XII:103–107, 1996.

[Rosse and Mejino, 2003] C. Rosse and J. L. V. Mejino. A Refer-
ence Ontology for Bioinformatics: The Foundational Model of
Anatomy. Journal of Biomedical Informatics, 36:478–500, 2003.
[Smeulders et al., 2000] A.W.M. Smeulders, M. Worring, S. San-
tini, A. Gupta, and R. Jain. Content-based image retrieval at the
end of the early years.
IEEE Transactions on Pattern Analysis
and Machine Intelligence, 22(12):1349–1380, 2000.

[Smirniotopoulos, 1999] J.G. Smirniotopoulos. The new WHO
Neuroimaging Clin N Am,

classiﬁcation of brain tumors.
9(4):595–613, 1999.

IJCAI-07

229

