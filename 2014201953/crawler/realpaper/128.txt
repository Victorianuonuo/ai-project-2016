Goal Change

Yves Lesp´erance

Hector J. Levesque

Dept. of Computer Science

Dept. of Computer Science

York University

Toronto, ON

M3J 1P3 Canada

University of Toronto

Toronto, ON

M5S 3G4 Canada

hector@cs.toronto.edu

Steven Shapiro

Computer Science Inst.
University of Leipzig

Leipzig 04109

Germany

shapiro@informatik.uni-leipzig.de

lesperan@cs.yorku.ca

Abstract

Although there has been much discussion of belief
change (e.g., [G¨ardenfors, 1988; Spohn, 1988]),
goal change has not received much attention.
In
this paper, we propose a method for goal change in
the framework of Reiter’s [2001] theory of action in
the situation calculus [McCarthy and Hayes, 1969;
Levesque et al., 1998], and investigate its prop-
erties. We extend the framework developed by
Shapiro et al. [1998] and Shapiro and Lesp´erance
[2001], where goals and goal expansion were mod-
elled, but goal contraction was not.

1 Introduction

One of the commonsense abilities people possess is the abil-
ity to predict the behaviour of others. We attribute goals
and beliefs to others and assume they will act on their be-
liefs to achieve their goals. One strategy for endowing ma-
chines with a similar ability is to explicitly model the beliefs
and goals of agents and assume they are acting to achieve
their goals in accordance with their beliefs.
In dynamic
environments, the beliefs and goals of agents are likely to
change. Although there has been much discussion of be-
lief change (e.g., [G¨ardenfors, 1988; Spohn, 1988]), goal
change has not received much attention.
In this paper, we
propose a method for specifying and reasoning about goal
change in the framework of Reiter’s [2001] theory of ac-
tion in the situation calculus [McCarthy and Hayes, 1969;
Levesque et al., 1998]. We thus inherit Reiter’s solution to the
frame problem, and iterated goal change is achieved seam-
lessly using sequences of actions. Our approach to goal con-
traction is simpler than most approaches to belief revision and
relies on using the history of requests rather than a speciﬁca-
tion of entrenchment. This work extends the framework de-
veloped by Shapiro et al. [1998] and Shapiro and Lesp´erance
[2001], where goals and goal expansion were modelled but
goal contraction was not.

We model agents that adopt goals if they are requested to
do so and they do not already have a conﬂicting goal. They
maintain their goals unless they are explicitly requested to
drop them by the agent who requested the goal in the ﬁrst

place. We ﬁrst deﬁne goals using an accessibility relation,
W , which picks out the situations that the agent wants to be
the case. We then give a successor state axiom for W that
is affected by two communicative actions: REQUEST actions,
which cause agents to adopt goals, and CANCELREQUEST ac-
tions, which cause agents to drop goals that had been adopted
following prior requests. We then consider some properties of
our axiomatization: expansion, contraction, and persistence.
Finally, we identify the restrictions on the accessibility rela-
tions that give us positive and negative introspection of goals,
and show that these restrictions persist, if they are asserted of
the initial situations.

The remainder of the paper is organized as follows.

In
Sec. 2, we give a brief review of the situation calculus, Re-
iter’s theory of action, and Shapiro et al.’s [1998] framework
for representing knowledge expansion in the situation calcu-
lus. In Sec. 3, we introduce our framework for goal change,
and in Sec. 4, we investigate properties of this framework. In
Sec. 5, we present an example, and in Sec. 6, we conclude,
discuss related work, and suggest avenues for future work.

2 Representation of Action and Knowledge
The basis of our framework for goal change is an action the-
ory [Reiter, 2001] based on the situation calculus [McCarthy
and Hayes, 1969; Levesque et al., 1998]. The situation calcu-
lus is a predicate calculus language for representing dynam-
ically changing domains. A situation represents a possible
state of the domain. There is a set of initial situations cor-
responding to the ways the agents believe the domain might
be initially. The actual initial state of the domain is repre-
sented by the distinguished initial situation constant, S0. The
term do(a; s) denotes the unique situation that results from
the agent doing action a in situation s. Thus, the situations
can be structured into a set of trees, where the root of each
tree is an initial situation and the arcs are actions. The se-
quence of actions that produces a situation is called the his-
tory of the situation. s (cid:22) s0 (s (cid:30) s0, resp.) means there is a
(nonempty, resp.) path from situation s to situation s0. The
initial situations are deﬁned as those having an empty history:
Init(s)

def
= :9a; s0:s = do(a; s0):

Predicates and functions whose value may change from
situation to situation (and whose last argument is a situa-
tion) are called ﬂuents. For instance, we might use the ﬂuent

INROOM(Agt; R1; S) to represent the fact that agent Agt is in
room R1 in situation S. The effects of actions on ﬂuents are
deﬁned using successor state axioms [Reiter, 2001], which
provide a succinct representation for both effect axioms and
frame axioms [McCarthy and Hayes, 1969].

We will be quantifying over formulae, so we assume that
we have an encoding of formulae as ﬁrst-order terms (we can
adapt De Giacomo et al.’s [2000] axioms for this purpose, but
we omit the details here). Therefore, we will freely quantify
over formulae here. To simplify notation, we ignore the de-
tails of the encoding and use formulae directly instead of the
terms that represent them. We use   to denote a formula that
can contain the situation constants Now and Then, and (cid:30) to
denote a formula that can contain Now but not Then. We use
(cid:30)[s] ( [s; s0], resp.) to denote the formula that results from
substituting s for Now in (cid:30) (s for Now and s0 for Then, resp.).
To axiomatize a dynamic domain in the situation calculus,
we use Reiter’s [2001] action theory, which consists of (1)
successor state axioms for each ﬂuent (including K and W
introduced below); (2) initial state axioms, which describe
the initial state of the domain and the initial mental states of
the agents; (3) precondition axioms, which specify the con-
ditions under which the distinguished predicate Poss(A; S)
holds, i.e., when it is physically possible to execute an action
A in situation S; (4) unique names axioms for the actions, and
domain-independent foundational axioms (we adopt the ones
given by Levesque et al. [1998] which accommodate multiple
initial situations, but we do not describe them further here);
and (5) the axioms to encode formulae as terms.

Moore [1985] deﬁned a possible-worlds semantics for a
logic of knowledge in the situation calculus by treating situa-
tions as possible worlds. Scherl and Levesque [2003] adapted
this to Reiter’s theory of action. Scherl and Levesque gave a
successor state axiom for K that states how actions, includ-
ing sensing actions, affect knowledge. Shapiro et al. [1998]
adapted this axiom to handle multiple agents and INFORM
actions, which we adopt here. K(agt; s0; s) will be used to
denote that in situation s, agt thinks that situation s0 might be
the actual situation. Note that the order of the situation argu-
ments is reversed from the convention in modal logic for ac-
cessibility relations. INFORM(infr ; agt ; (cid:30)) is the action of the
agent infr informing another agent, agt, that (cid:30) holds. Here
is Shapiro et al.’s [1998] successor state axiom for K.1

Axiom 2.1

K(agt ; s00; do(a; s)) (cid:17)
9s0:K(agt; s0; s) ^ s00 = do(a; s0) ^ Poss(a; s0) ^
8infr ; (cid:30):a = INFORM(infr ; agt ; (cid:30)) (cid:27) (cid:30)[s0]

First note that for any action other than an INFORM ac-
tion directed towards agt, the speciﬁcation ensures that the

1Since we are using terms for formulae in our underlying repre-
sentation, INFORM(infr ; agt ; (cid:30)) = INFORM(infr ; agt ; (cid:30)0), only if
(cid:30) and (cid:30)0 are the same term. It would not be difﬁcult to modify our
representation so that the equality holds only if (cid:30) and (cid:30)0 are the rep-
resentations of equivalent formulae. We adopt the convention that
unbound variables are universally quantiﬁed in the widest scope.

only change in knowledge that occurs in moving from s
to do(a; s) is that it is known (by all agents) that the ac-
tion a has been successfully executed. This is true because
the K-alternative2 situations to do(a; s) are the situations
that result from doing a in a K-alternative situation to s
where a is possible to execute (denoted by Poss(a; s0)). For
the action INFORM(infr ; agt ; (cid:30)); the idea is that in mov-
ing from s to do(INFORM(infr ; agt ; (cid:30)); s), agt not only
knows that the action has been executed (as above), but it
also knows that (cid:30) holds.
In this case, the K-alternative
situations to do(a; s) for agt are the situations that result
from performing a in a K-alternative situation to s where
a is possible to execute, except the ones where (cid:30) is false.3
As usual, we say that an agent knows a formula (cid:30) in
s,
i.e.,
Know(agt ; (cid:30); s)

if (cid:30) holds in all situations K-accessible from s,

def
= 8s0:K(agt ; s0; s) (cid:27) (cid:30)[s0].

Following Shapiro et al. [1998], we say that an agent can
only execute an inform action if it knows that the content of
the action is true.

Axiom 2.2

Poss(INFORM(infr ; agt ; (cid:30)); s) (cid:17) Know(infr ; (cid:30); s):

Since we are dealing with knowledge here, not belief, we

assert that K is (initially) reﬂexive.4

Axiom 2.3 Init(s) (cid:27) K(agt ; s; s):

Following Scherl and Levesque, we also assert that initial
situations can only be K-related to other initial situations. We
use an initial state axiom for this purpose:

Axiom 2.4 K(agt ; s0; s) ^ Init(s) (cid:27) Init(s0):

This axiom and the successor state axiom for K imply that
only situations with the same history can be K-related. Intro-
spection will be discussed in Sec. 4.

3 Goal Change
Just as an agent’s beliefs can change, its goals should also be
able to change. For example, if an agent’s owner requests it to
do something, the agent’s goals should change to reﬂect the
request. We extend the framework developed by Shapiro et
al. [1998] and Shapiro and Lesp´erance [2001], where goals
and goal expansion were modelled but not goal contraction.
Following Cohen and Levesque [1990], we model goals us-
ing an accessibility relation over possible worlds (situations,

2We say that S 0 is a K-alternative situation to S for Agt or S 0
is K-related to S for Agt, if K(Agt; S 0; S) holds. We may drop Agt
when it is understood from the context.

3Note that here all agents are aware of all actions that occur, in-
cluding inform actions, so we have a broadcast model of commu-
nication. In Shapiro and Lesp´erance [2001], encrypted speech acts
were introduced, ensuring that only the intended recipient of a mes-
sage could know its contents.

4We do not handle belief revision here, but a treatment of belief

revision in our framework was discussed in [Shapiro et al., 2000].

in our case). The accessible worlds are the ones that are com-
patible with what the agent wants to be the case. Cohen and
Levesque’s accessibility relation for goals, G, was a subset
of their accessibility relation for beliefs. This constraint pre-
cludes an agent wanting something that it believes is impossi-
ble (unless its goals are inconsistent). In our case, we deﬁne
G in terms of a more primitive accessibility relation, which
we call W and is intended to model what the agent wants in-
dependently of what it knows. We can then deﬁne Cohen and
Levesque’s goal accessibility relation, G, to be the intersec-
tion5 of W and K.

An agent’s goals are future oriented. For example, an
agent might want some property to hold eventually, i.e., the
agent’s goal is of the form Eventually( ), for some formula
 . We evaluate formulae such as these with respect to a path
of situations rather than a single situation, and we call such
formulae path formulae. Cohen and Levesque used inﬁnite
time-lines to evaluate such formulae, but for simplicity, we
evaluate path formulae with respect to ﬁnite paths of situa-
tions which we represent by pairs of situations, (Now; Then),
such that Now (cid:22) Then. Now corresponds to the “current
time” on the path of situations deﬁned by the sequence of
situations in the history of Then. Path formulae may con-
tain two situation constants, Now and Then. For exam-
ple, 9r:INROOM(JOHN; r; Now)^:INROOM(JOHN; r; Then)
could be used to denote the goal that John eventually leaves
the room he is in currently.

Our W relation, like our K relation, is a relation on situa-
tions. While K only relates situations with the same histories,
W can relate situations with different histories. Intuitively,
W (Agt; S 0; S) holds if in situation S, Agt considers that in S 0
everything that it wants to be true is actually true. For exam-
ple, if the agent wants to become a millionaire in S, then in
all situations W -related to S, the agent is a millionaire, but
these situations can be arbitrarily far in the future.

Recall that the situations in the W accessibility relation are
the ones that the agent wants to actualize independently of
what it knows. Following Cohen and Levesque, we want the
goals of the agent to be compatible with what it knows. The
situations that the agent wants to actualize should be on a path
from a situation that the agent considers possible. Therefore,
the situations that will be used to determine the goals of an
agent will be the W -accessible situations that are also com-
patible with what the agent knows, in the sense that there is
K-accessible situation in their history. We will say that S 0
KAgt;S-intersects S 00 if K(Agt; S 00; S) and S 00 (cid:22) S 0. We will
suppress Agt or S if they are understood from the context. We
deﬁne the goals of agt in s to be those formulae that are true
in all the situations s0 that are W -accessible from s and that
K-intersect some situation, s00:

Goal(agt ;  ; s)
8s0; s00:W (agt ; s0; s) ^ K(agt ; s00; s) ^ s00 (cid:22) s0 (cid:27)  [s00; s0]:

def
=

Note that s00 corresponds to the “current situation” (or the
current time) in the path deﬁned by s0.

5As we will see below, the operation used on W and K to obtain

G is not quite intersection, but a related operation.

As noted by Konolige and Pollack [1993], one has to be
careful when using this deﬁnition of a goal. Suppose an agent
has a conjunctive goal,   ^   0. According to this deﬁnition
of Goal, both   and   0 are also goals. Therefore, we could
imagine a rational agent working to achieve one of the con-
juncts as a subgoal. But it is easy to think of circumstances
where achieving only one component of a conjunctive goal is
undesirable. For example, I may have as a goal to be hold-
ing the bomb and that the bomb be defused. However, I want
these to be true simultaneously and I do not have the goal to
be holding the bomb if it is not also defused. As Konolige
and Pollack did for their intention modality (I), we consider
formulae that are an agent’s “only goals”, i.e., formulae that
are true in all and only the W -paths:

OGoal(agt ;  ; s)

def
=

8s0; s00:K(agt ; s00; s) ^ s00 (cid:22) s0 (cid:27)

(W (agt ; s0; s) (cid:17)  [s00; s0]):

We now give the successor

state axiom for W .
W +(agt ; a; s0; s) (W (cid:0)(agt ; a; s0; s), resp.), which is deﬁned
below, denotes the conditions under which s0 is added to
(dropped from, resp.) W due to action a:

Axiom 3.1
W (agt ; s0; do(a; s)) (cid:17)
(W +(agt ; a; s0; s) _ (W (agt ; s0; s) ^ :W (cid:0)(agt ; a; s0; s))):

by

another

agent.

do

something

An agent’s goals are expanded when it
is requested
to
the
REQUEST(requester ; agt ;  ) action occurs, agt
should
adopt the goal that  , unless it currently has a conﬂicting
goal (i.e., we assume agents are maximally cooperative).
Therefore,
the REQUEST(requester ; agt ;  ) action should
cause agt to drop any paths in W where   does not hold.
This action is taken into account in the deﬁnition of W (cid:0):

After

def
=

W (cid:0)(agt ; a; s0; s)
9requester ;  ; s00:a = REQUEST(requester ; agt ;  ) ^

:Goal(agt ; : ; s) ^ K(agt ; s00; s) ^ s00 (cid:22) s0 ^
: [do(a; s00); s0]:

According to this deﬁnition, s0 will be dropped from W , if for
some requester and  , a is the REQUEST(requester ; agt ;  )
action and agt does not have a conﬂicting goal, i.e., the goal
that :  in s6, and s0 K-intersects some s00 such that   does
not hold on the path (do(a; s00); s0). The reason that we check
whether :  holds at (do(a; s00); s0) rather than at (s00; s0) is
to handle goals that are relative to the current time. If, for
example,   states that the very next action should be to get
some coffee, then we need to check whether the next action
after the request is getting the coffee. If we checked :  at
(s00; s0), then the next action would be the REQUEST action.
If the agent gets a request for   and it already has the goal
that : , then it does not adopt the goal that  , otherwise its

6Note that according to the deﬁnition of Goal, if the agent has
a goal that implies : , then it also has the goal that : , i.e., if
Goal(Agt;   0; S) holds and 8s; s0:  0[s; s0] (cid:27) : [s; s0] holds, then
Goal(Agt; : ; S) also holds. In other words, if the agent has a con-
ﬂicting goal that implies : , then   will not be adopted as a goal.

goal state would become inconsistent and it would want ev-
erything. This is a simple way of handling goal conﬂicts. A
more interesting method would be to give more credence to
requests from certain individuals, or requests of certain types.
For example, if an agent gets a request from its owner that
conﬂicts with a previous request from someone else, it should
drop the previous request and adopt its owner’s request in-
stead. We reserve a more sophisticated handling of conﬂict-
ing requests for future work.

We assume that request actions are always possible to exe-
cute, although executability conditions could easily be added.

CANCELREQUEST (Requester; Agt;  )

A(cid:3)

Axiom 3.2 Poss(REQUEST(reqr ; agt ;  ); s):

REQUEST(Requester; Agt;  )

W

S 0

W

S

S(cid:3)

S1

the agent

the owner of an agent asks it

We now turn our attention to goal contraction.

Sup-
to do   and
pose that
The owner should be able to
later changes his mind.
tell
to stop working on  . We use the ac-
tion CANCELREQUEST(requester ; agt ;  ) for this purpose.
This action causes agt
A
CANCELREQUEST action can only be executed if a corre-
sponding REQUEST action has occurred in the past.

to drop the goal

that  .

Axiom 3.3 Poss(CANCELREQUEST(reqr ; agt ;  ); s) (cid:17)

do(REQUEST(reqr ; agt ;  ); s0) (cid:22) s

We handle CANCELREQUEST actions by determining
what the W relation would have been if the correspond-
ing REQUEST action had never happened.
Suppose a
CANCELREQUEST(Requester; Agt;  ) action occurs in situa-
tion S. We restore the W relation to the way it was before the
corresponding REQUEST occurred. Then, starting just after
the REQUEST, we look at all the situations do(A(cid:3); S (cid:3)) in the
history of S and remove from W any situation S 0 that satisﬁes
W (cid:0)(Agt; A; S 0; S (cid:3)); such situations S 0 should be removed
to reﬂect the adoption of a subsequent request. We ﬁrst de-
ﬁne the predicate CANCELS(a; a0), which says that action a
cancels the action a0. In our case, only CANCELREQUEST
actions cancel the corresponding REQUEST’s:

CANCELS(a; a0)

def
=

9reqr ;  :a = CANCELREQUEST(reqr ; agt ;  ) ^

a0 = REQUEST(reqr ; agt ;  ):

We now deﬁne W + which states the conditions under

which s0 is added to W + after a is executed in s:

W +(agt ; a; s0; s)

def
=

(9si:W (agt ; s0; si) ^

(9a1:do(a1; si) (cid:22) s ^ CANCELS(agt ; a; a1) ^

8a(cid:3); s(cid:3):do(a1; si) (cid:30) do(a(cid:3); s(cid:3)) (cid:22) s (cid:27)

:W (cid:0)(agt ; a(cid:3); s0; s(cid:3))))

To help explain this deﬁnition, we will refer to Fig. 1, where
a segment of a situation forest is shown. The situation S 0
is not W -related to S. However, S 0 was W -related to S1,
which is in the history of S. The next action after S1 in the
history of S was REQUEST(Requester; Agt;  ). We suppose
S 0 was dropped from W after the REQUEST. If none of the
actions between do(REQUEST(Requester; Agt;  ); S1) and

Figure 1: An example of goal contraction.

is

In

the

in S.

executed

S also cause S 0 to be dropped from W , then S 0 is returned
the CANCELREQUEST(Requester; Agt;  )
to W after
action
other words,
W +(Agt; CANCELREQUEST(Requester; Agt;  ); S 0; S)
holds because
following hold: W (Agt; S 0; S1),
S,
do(REQUEST(Requester; Agt;  ); S1)
CANCELREQUEST(Requester; Agt;  )
cancels
REQUEST(Requester; Agt;  )),
every situation
do(A(cid:3); S (cid:3)) between do(REQUEST(Requester; Agt;  ); S1)
and S, :W (cid:0)(Agt; A(cid:3); S 0; S (cid:3)) holds. Note that for our
deﬁnition of W + to work properly, we must assume that
there is only one REQUEST action in the history that is
cancelled by each CANCELREQUEST. This assumption will
be relaxed in future work.

and for

(cid:22)

4 Properties
We now consider some properties of goal change. Let (cid:6) con-
sist of the foundational, encoding, and unique names axioms,
and the axioms from Sections 2 and 3. First, we show that
our theory supports goal expansion. If an agent does not have
:  as a goal, then a request for   causes it to adopt   as a
goal.
Theorem 4.1
(cid:6) j= 8agt ;  ; requester ; s::Goal(agt ; : ; s) (cid:27)

Goal(agt ;  ; do(REQUEST(requester ; agt ;  ); s))

We also show the conditions under which an agent’s only
goals are expanded. If an agent has the only goal that  ,   0 is
requested of the agent, the agent knows that the request does
not affect the truth value of  , and   0 does not conﬂict with
the agent’s goals, then its only goals expand to include   0.

Theorem 4.2
(cid:6) j= 8a; agt ;  ;   0; reqr ; s:

OGoal(agt ;  ; s) ^ a = REQUEST(reqr ; agt ;   0) ^
Know(agt ; [8then:Poss(a; Now) (cid:27)

( [Now; then] (cid:17)  [do(a; Now); then])]; s) ^

:Goal(agt; :  0; s) (cid:27)

OGoal(agt ;   ^   0; do(a; s)):

Next, we examine the persistence of goals. A goal   per-
sists over an action a, if a is not a cancel request, and the
agent knows that if   holds then a does not change its value.

W . We will need the following deﬁnitions of transitivity and
Euclideanness, starting in a situation s. Note that the order of
the situations is reversed from the traditional deﬁnitions.

Theorem 4.3

(cid:6) j= 8a; agt ;  ; s:

Goal(agt ;  ; s) ^
(8reqr ;   0:a 6= CANCELREQUEST(reqr ; agt ;   0)) ^
Know(agt ; [8then:Poss(a; Now) ^  [Now; then] (cid:27)

 [do(a; Now); then]]; s) (cid:27)

Goal(agt ;  ; do(a; s)):

We have a similar result for “only goals”.

Theorem 4.4

(cid:6) j= 8a; agt ;  ; s:

OGoal(agt ;  ; s) ^
[8requester ;   0:

(a = REQUEST(requester ; agt ;   0) (cid:27)

Goal(agt ; :  0; s)) ^

a 6= CANCELREQUEST(requester ; agt ;   0)] ^

Know(agt ; [8then:Poss(a; Now) (cid:27)

( [Now; then] (cid:17)  [do(a; Now); then])]; s) (cid:27)

OGoal(agt ;  ; do(a; s)):

We now show a property about only goal contraction. Sup-
pose that an agent only has the goal that   in s, and just after
s, reqr requests   0 of the agent. In some future situation s00,
reqr cancels its request that   0, yielding the situation s0. We
assume that there was only one request of the agent for   0
from reqr, and that no other REQUEST or CANCELREQUEST
actions occurred between s and s0. We also assume that   al-
ways persists (this condition can be weakened; we assumed it
to simplify the proof). Then, we can show that the agent only
has the goal that   in s. In other words, the request for   0
was indeed cancelled, and the other “only goals” persisted.

Theorem 4.5
(cid:6) j= 8agt ;  ;   0; reqr ; s; s0; s00: OGoal(agt ;  ; s) ^

do(REQUEST(reqr ; agt ;   0); s) (cid:22) s0 ^
s0 = do(CANCELREQUEST(reqr ; agt ;   0); s00) ^
[8s1; s2:do(REQUEST(reqr ; agt ;   0); s1) (cid:22) s00 ^
do(REQUEST(reqr ; agt ;   0); s2) (cid:22) s00 (cid:27)

s1 = s2] ^

[8s(cid:3); a(cid:3):

do(REQUEST(reqr ; agt ;   0); s) (cid:30) do(a(cid:3); s(cid:3)) ^
do(a(cid:3); s(cid:3)) (cid:22) s00 (cid:27)

(:9reqr 0;  00:

a(cid:3) = CANCELREQUEST(reqr 0; agt ;  00) _
a(cid:3) = REQUEST(reqr 0; agt ;  00))] ^
[8a; s1; s2: (s1; s2) (cid:17)  (do(a; s1); s2)] (cid:27)

OGoal(agt ;  ; s0):

Ktrans(agt ; s)

def
= 8s1; s2:K(agt ; s1; s) ^ K(agt; s2; s1) (cid:27)

Keuc(agt ; s)

def
= 8s1; s2:K(agt ; s1; s) ^ K(agt ; s2; s) (cid:27)

K(agt ; s2; s):

K(agt ; s2; s1):

Theorem 6 of Scherl and Levesque [2003] showed that if
K is initially reﬂexive, and transitive or Euclidean, then the
successor state axiom for K guarantees that the properties
are preserved over executable sequences of actions. This re-
sult carries over here. First, we show that reﬂexivity is pre-
served. Recall that we asserted that K was initially reﬂexive
in Axiom 2.3. Our successor state axiom for K preserves
reﬂexivity over all executable sequences of actions.

Theorem 4.6

(cid:6) j= 8agt ; s:Executable(s) (cid:27) K(agt; s; s);

where Executable(s)

def
= 8a; s0:do(a; s0) (cid:22) s (cid:27) Poss(a; s0):

Similarly, if K is initially transitive and Euclidean, then it

remains so over any executable sequence of actions.

Theorem 4.7

(cid:6) j= (8agt ; s:Init(s) (cid:27) Ktrans(agt ; s) ^ Keuc(agt ; s)) (cid:27)

(8agt ; s:Executable(s) (cid:27) Ktrans(agt ; s)) ^
(8agt ; s:Executable(s) (cid:27) Keuc(agt ; s));

For positive introspection of goals, we need a constraint
similar to transitivity, but that involves both K and W . We
call this constraint cross-transitivity:

CrossTrans(agt ; s)

def
=

8s1; s2; s3:K(agt ; s1; s) ^ K(agt; s2; s1) ^

W (agt; s3; s1) ^ s2 (cid:22) s3 (cid:27)

W (agt ; s3; s):

If this constraint is satisﬁed, and K is transitive, then the
agents will have positive introspection of goals:

Theorem 4.8

(cid:6) j= 8agt ; s;  :Ktrans(agt ; s) ^ CrossTrans(agt ; s) (cid:27)

(Goal(agt ;  ; s) (cid:27)

Know(agt ; Goal(agt ;  ); s)):

For negative introspection of goals, we need a constraint
similar to Euclideanness, which we call cross-Euclideanness:

Just as agents introspect their knowledge, we want agents
to be able to introspect their goals, i.e., if an agent has a goal
(does not have a goal, resp.) that  , it should know that it has
(does not have, resp.)   as a goal. We identify constraints
that yield these properties. They are constraints on K and

CrossEuc(agt ; s)

def
=

8s1; s2; s3:K(agt; s1; s) ^ K(agt; s2; s) ^

W (agt; s3; s) ^ s2 (cid:22) s3 (cid:27)

W (agt; s3; s1):

If this constraint is satisﬁed, and K is Euclidean, then the

agents will have negative introspection of goals:

adopted the goal that its owner attend the meeting, i.e., that it
declines the meeting request.

Theorem 4.9

(cid:6) j= 8agt ; s:Keuc(agt ; s) ^ CrossEuc(agt ; s) (cid:27)

(:Goal(agt;  ; s) (cid:27)

Know(agt ; :Goal(agt ;  ); s)):

CrossTrans and CrossEuc persist if they hold of the initial

situations, and K is initially transitive and Euclidean.

Theorem 4.10

(cid:6) j= [8s0:Init(s0) (cid:27)

(Ktrans(agt ; s0) ^ Keuc(agt ; s0) ^
CrossTrans(agt ; s0) ^ CrossEuc(agt ; s0))] (cid:27)
8agt ; s:Executable(s) (cid:27) CrossTrans(agt ; s) ^

CrossEuc(agt ; s):

It follows that positive and negative goal introspection persist,
if these constraints hold initially.

5 Meeting Scheduler Example

To illustrate how such a formalization of goal change is useful
in specifying multiagent applications, we now summarize the
meeting scheduler example from Shapiro [2005] that is based
on the one given by Shapiro et al. [1998], but was modiﬁed
to include goal contraction using CANCELREQUEST.

We specify the behavior of agents with the notation of the
programming language ConGolog [De Giacomo et al., 2000],
the concurrent version of Golog [Levesque et al., 1997]. Here
are the ConGolog constructs we will use:

a,
(cid:30)?,
(cid:14)1; (cid:14)2,
(cid:14)1 j (cid:14)2,
if (cid:30) then (cid:14)1 felse (cid:14)2g endIf,
for x 2 L do (cid:14) endFor,
while (cid:30) do (cid:14) endWhile

primitive action
wait for a condition
sequence
nondeterministic choice of programs
conditional
for loop
while loop

In the above, a denotes a situation calculus action; (cid:14), (cid:14)1, and
(cid:14)2 stand for programs; and L is a ﬁnite list.

In the meeting scheduler example [Shapiro et al., 1998;
Shapiro and Lesp´erance, 2001; Shapiro, 2005], there are
meeting organizer agents, which are trying to schedule meet-
ings with personal agents, which manage the schedules of
their (human) owners. To schedule a meeting, an organizer
agent requests of each of the personal agents of the partici-
pants in the meeting to adopt the goal that its owner attend
the meeting during a given time period. If a personal agent
does not have any goals that conﬂict with its owner attending
the meeting (i.e., it has not previously scheduled a conﬂicting
meeting), it adopts the goal that its owner attend this meet-
ing and informs the meeting organizer that it has adopted this
goal, i.e., that it accepts the meeting request. Otherwise, the
personal agent informs the meeting organizer that it has not

The procedure that deﬁnes the behaviour of meeting or-
ganizer agents (organizeMeeting) is given in Fig. 2.7 Their
task is to organize a meeting for a given period and set of
participants on behalf of the chair of the meeting. They do
this by asking the personal agent of each participant to have
their owner meet during the given period. The participants’
personal agent will then reply whether they have declined the
meeting. The behaviour of the personal agents is speciﬁed
by the MANAGESCHEDULE procedure which is not shown
here, due to space constraints. In that procedure, a personal
agent responds to a meeting request by adopting the goal
that its owner be at the requested meeting, unless it has al-
ready scheduled a conﬂicting meeting, and then informs the
requester whether it has adopted the requested goal. The
meeting organizer waits until it knows whether one of the
participants’ agent declined the meeting. This will happen
when either someone has declined the meeting or everyone
has agreed to it. If the organizer discovers that someone de-
clined the meeting, it cancels its request for a meeting with
the personal agents of all the participants in the meeting. The
personal agents that agreed to the meeting will then drop the
goal that their owners be at the requested meeting.

6 Conclusions and Future Work
In this paper, we deﬁned the goals and “only goals” of an
agent, and examined properties of these deﬁnitions: expan-
sion, contraction, and persistence. We identiﬁed the re-
strictions on K and W that give us introspection of goals,
and showed that these restrictions persist, if they hold ini-
tially. Note that our approach is quite different and sim-
pler than most existing approaches to belief change. These
require a speciﬁcation of the plausibilities of alternate sit-
uations. Our approach avoids this and instead relies on
the history to undo previous goal expansions. However,
we do not handle arbitrary goal contractions, only cancella-
tions of previous requests. Note there are some related ap-
proaches in the belief change literature [Booth et al., 2005;
Roorda et al., 2003]. This raises the question of using be-
lief change frameworks to handle goal change, or applying
our goal change approach to belief change. It would be in-
teresting to investigate whether there are essential differences
between belief revision and goal revision that warrant differ-
ent solutions, or whether the same solutions can be applied to
both problems. Also, it would be interesting to identify postu-
lates for goal change and examine how they differ from belief
change postulates [G¨ardenfors, 1988]. Our handling of the
cancelling of requests needs further work and analysis. First
of all, it does not properly handle nested requests for the same
goal. For the successor state axiom to work properly for goal
contraction, we must assume that there is only one REQUEST

7Note that for us (unlike De Giacomo et al.) procedures are
simply program deﬁnitions and cannot be recursive.
In the deﬁ-
nition of this procedure, PAG(p) is a function that maps an owner
to its personal agent, MEMBER(p; parts ) holds if p is a member
def
of the list parts, and KWhether(agt ; (cid:30); s)
= Know(agt ; (cid:30); s) _
Know(agt ; :(cid:30); s).

INFORMWHETHER(agt ; agt 0; (cid:30))

def
= [Know(agt ; (cid:30))?; INFORM(agt ; agt 0; (cid:30))] j

[Know(agt ; :(cid:30))?; INFORM(agt ; agt 0; :(cid:30))] j [:KWhether(agt ; (cid:30))?; INFORM(agt ; agt 0; :KWhether(agt ; (cid:30)))]

SomeoneDeclined(per ; chair ; parts; s)

9p:MEMBER(p; parts) ^ :Goal(PAG(p); During(per ; ATMEETING(p; chair )); s)

organizeMeeting(oa; chair ; parts; per )

for p 2 parts do

def
=

def
=

REQUEST(oa ; PAG(p); During(per ; ATMEETING(p; chair ))) endFor;

KWhether(oa; SomeoneDeclined(per ; chair ; parts))?;
if Know(oa; SomeoneDeclined(per ; chair ; parts)) then
for p 2 parts do

cancelRequest(oa; PAG(p); During(per ; ATMEETING(p; chair ))) endFor endIf;

INFORMWHETHER(oa; chair ; SomeoneDeclined(per ; chair ; parts))

Figure 2: Procedure run by the meeting organizer agents.

action in the history that is cancelled by each CANCELRE-
QUEST. This would not be too difﬁcult to remedy, but it leads
us to another difﬁculty. The deﬁnition of W + is already quite
complex, which makes proving properties about it somewhat
awkward. Since the deﬁnition refers to a sequence of situa-
tions, the proofs will often involve inductions. We would like
to investigate the possibility of simplifying the deﬁnition.

References

[Booth et al., 2005] R. Booth, S. Chopra, A. Ghose, and T.
Meyer. Belief liberation (and retraction). Studia Logica,
79:47–72, 2005.

[Cohen and Levesque, 1990] P. R. Cohen

J.
Intention is choice with commitment.

and H.

Levesque.
Artiﬁcial Intelligence, 42:213–261, 1990.

[De Giacomo et al., 2000] G. De Giacomo, Y. Lesp´erance,
and H. J. Levesque. ConGolog, a concurrent program-
ming language based on the situation calculus. Artiﬁcial
Intelligence, 121(1–2):109–169, 2000.

[G¨ardenfors, 1988] P. G¨ardenfors. Knowledge in Flux. The

MIT Press: Cambridge, MA, 1988.

[Konolige and Pollack, 1993] K. Konolige and M. E. Pol-
In Proc.

lack. A representationalist theory of intention.
IJCAI-93, pages 390–395, 1993.

[Levesque et al., 1997] H.

J. Levesque, R. Reiter, Y.
Lesp´erance, F. Lin, and R. B. Scherl. GOLOG: A logic
programming language for dynamic domains. Journal of
Logic Programming, 31:59–84, 1997.

[Levesque et al., 1998] H. J. Levesque, F. Pirri, and R. Re-
iter. Foundations for a calculus of situations. Electronic
Transactions of AI (ETAI), 2(3–4):159–178, 1998.

[McCarthy and Hayes, 1969] J. McCarthy and P. J. Hayes.
Some philosophical problems from the standpoint of ar-
tiﬁcial intelligence. In B. Meltzer and D. Michie, editors,
Machine Intelligence 4. Edinburgh University Press, 1969.

[Moore, 1985] R. C. Moore. A formal theory of knowledge
and action. In J. R. Hobbs and R. C. Moore, editors, For-
mal Theories of the Common Sense World, pages 319–358.
Ablex Publishing, Norwood, NJ, 1985.

[Reiter, 2001] R. Reiter. Knowledge in Action: Logical
Foundations for Specifying and Implementing Dynamical
Systems. MIT Press, Cambridge, MA, 2001.

[Roorda et al., 2003] J.-W. Roorda, W. van der Hoek, and J.-
Iterated belief change in multi-agent systems.

J. Meyer.
Logic Journal of the IGPL, 11(2):223–246, 2003.

and H.

[Shapiro and Lesp´erance, 2001] S.

[Scherl and Levesque, 2003] R. B. Scherl

J.
Levesque. Knowledge, action, and the frame problem.
Artiﬁcial Intelligence, 144(1–2):1–39, 2003.
Shapiro

Y.
Lesp´erance. Modeling multiagent systems with the
cognitive agents speciﬁcation language — a feature
interaction resolution application. In C. Castelfranchi and
Y. Lesp´erance, editors, Proc. ATAL-2000, pages 244–259.
Springer-Verlag, Berlin, 2001.

and

[Shapiro et al., 1998] S. Shapiro, Y. Lesp´erance, and H. J.
Levesque. Specifying communicative multi-agent sys-
tems. In W. Wobcke, M. Pagnucco, and C. Zhang, editors,
Agents and Multi-Agent Systems — Formalisms, Method-
ologies, and Applications, volume 1441 of LNAI, pages
1–14. Springer-Verlag, Berlin, 1998.

[Shapiro et al., 2000] S.

Shapiro, M.

Pagnucco, Y.
Lesp´erance, and H. J. Levesque. Iterated belief change in
the situation calculus. In A. G. Cohn, F. Giunchiglia, and
B. Selman, editors, Proc. KR-2000, pages 527–538, 2000.

[Shapiro, 2005] S. Shapiro. PhD thesis. To appear, 2005.
[Spohn, 1988] W. Spohn. Ordinal conditional functions: A
dynamic theory of epistemic states.
In W. Harper and
B. Skyrms, editors, Causation in Decision, Belief Change,
and Statistics, pages 105–134. Kluwer Academic Publish-
ers, 1988.

