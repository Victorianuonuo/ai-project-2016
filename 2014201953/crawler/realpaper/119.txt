From knowledge-based programs to graded belief-based programs, part II:

off-line reasoning

Noël Laverny

IRIT

Université Paul Sabatier

31062 Toulouse Cedex, France

laverny@irit.fr

Abstract

Belief-based programs generalize knowledge-
based programs [Fagin et al., 1995] by allowing
for
incorrect beliefs, unreliable observations,
and branching conditions that refer to implicit
graded beliefs, such as in “while my belief about
the direction to the railway station is not strong
enough do ask someone”. We show how to
reason off-line about the possible executions of a
belief-based program, which calls for introducing
second-order uncertainty in the model.

Introduction

if Kϕ then π else π0

1
Knowledge-based programs, or KBPs [Fagin et al., 1995]
are a powerful notion for expressing action policies in
which branching conditions refer to knowledge (an agent
acts according to what he knows), such as,
typically,
where K is an epistemic (usually S5) modality, and π, π0
are subprograms. However, branching conditions in KBPs
cannot refer to possibly erroneous beliefs or to graded be-
lief, such as in “repeat ask to someone about the way to
the railway station until my belief about the direction to
take is strong enough”. Recently, [Laverny and Lang, 2004]
made a ﬁrst step towards reasoning with belief-based pro-
grams (BBPs), where knowledge modalities of KBPs are re-
placed by graded belief modalities, whose semantics relies
on belief states deﬁned as ranking functions, which can be
revised by observations and progressed by physical actions,
which enables the agent to maintain his current belief state
about the world while executing a BBP. Note that BBPs ex-
tend a restricted class of KBPs, in which (a) there is a single
agent, (b) the agent has perfect recall and (c) branching con-
ditions concern the agent’s knowledge about the present state
of the world.

However, [Laverny and Lang, 2004] cannot deal with off-
line reasoning about the effects of a belief-based program.
Assume for instance that agent A is looking for the way to
the railway station in a foreign town; her initial belief state is
void, and she follows a plan consisting in sequentially asking
to several pedestrians about the direction to follow, until she
has acquired a sufﬁcient level of certainty. Assume moreover

Jérôme Lang

IRIT

Université Paul Sabatier

31062 Toulouse Cedex, France

lang@irit.fr

that answers, although not fully reliable, are normally cor-
rect. Each time A gets a direction conﬁrming (resp. contra-
dicting) her current belief, this belief becomes stronger (resp.
weaker). Now, the assumption that answers are normally cor-
rect implies, for instance, that if A has already got 3 “right”
and no “left” then the next answer is more likely to be “right”
again than “left”: the plausibility of getting an observation
depends on the current state.

Coping with this issue results in a natural way in second-
order uncertainty when projecting a belief state by a BBP: in
our example,
the agent is able to predict beforehand some-
thing like “after asking 5 pedestrians, normally I’ll have a
very ﬁrm belief about the direction to the station, although
I cannot totally exclude the possibility that I’ll have only a
weak, or even a totally void belief”. Such a complex belief
state is a belief state about (future) belief states, that is, a
second-order belief state. Thus, the main concern of this pa-
per is how to do a priori reasoning about the possible states of
belief produced by executing the program: uncertainty about
which of these states of belief will result is itself represented
as a ranking over states of belief.

After recalling some background in Section 2, belief-based
programs are introduced in Section 3. Section 4 deals with
complex belief states and their progression by actions and
programs. In Section 5 we show how to compute progres-
sion syntactically. Related work is discussed in Section 6.

2 Background
In this Section we brieﬂy recall some notions from [Laverny
and Lang, 2004]. Let P S be a ﬁnite set of propositional sym-
bols. LP S is the (non-modal) propositional language gener-
ated from P S, the usual connectives and the Boolean con-
stants > and ⊥. S = 2P S is the set of states associated with
If ϕ ∈ LP S
P S.
then M od(ϕ) = {s ∈ S|s |= ϕ}. For A ⊆ S, F orm(A) is
the objective formula (unique up to logical equivalence) such
that M od(F orm(A)) = A.

Formulas of LP S are said objective.

Belief states are identiﬁed with ordinal conditional func-
tions (OCF) [Spohn, 1988]: a belief state is a function κ :
S 7−→ N, where N = N∪{+∞}, such that mins∈S κ(s) = 0.
κ is lifted from S to LP S by κ(ϕ) = min{κ(s) | s |= ϕ},
with the convention min(∅) = +∞ (we will use this conven-
tion throughout the paper without recalling it). κ(s) can be
seen as the exceptionality degree of s. In particular, κ(s) = 0

(cid:26) 0

means that s is a normal state and κ(s) = +∞ that s is to-
tally impossible. For any ϕ ∈ LP S, the belief state κϕ is
if s |= ϕ
deﬁned by κϕ(s) =
+∞ if s |= ¬ϕ . In particular, κ>
is the void belief state: ∀s, κ>(s) = 0.
Beliefs are expressed syntactically in a graded extension
KD45G of KD45, whose language LP S is deﬁned as fol-
lows:

(a) if ϕ ∈ LP S then B1ϕ, B2ϕ, . . . , B∞ϕ are in LP S;
(b) if Φ and Ψ in LP S then ¬Φ, Φ ∨ Ψ, Φ ∧ Ψ in LP S.
Note that LP S considers only subjective and ﬂat formulas1.
Formulas of LPS are denoted by capital Greek letters Φ, Ψ
etc. while objective formulas are denoted by small Greek let-
ters ϕ, ψ etc. Biϕ intuitively means that the agent believes ϕ
with strength i. The larger i, the stronger the belief expressed
by Bi, and B∞ is a knowledge (true belief) modality.
The truth of a formula of LPS in an belief state κ is deﬁned
(a) for ϕ objective and i ∈ N, κ |= Biϕ iff κ(¬ϕ) > i;
(b) κ |= Φ ∨ Ψ iff κ |= Φ or κ |= Ψ;
(b) κ |= Φ ∧ Ψ iff κ |= Φ and κ |= Ψ;
(c) κ |= ¬Φ iff κ 6|= Φ.
Thus, κ |= Biϕ holds as soon as any countermodel of ϕ
is exceptional at least to the degree i, or, equivalently, that
all states such that κ(s) < i are models of ϕ. In particular,
B1ϕ is satisﬁed when all normal states satisfy ϕ, and B∞ϕ is
satisﬁed when all possible states (to any degree) are models
of ϕ.

by:

An observation is a belief state κobs, representing all we
observe when getting the observation. Observations can be
incomplete and partially unreliable (see [Laverny and Lang,
2004] for examples). The agent revises her current belief state
by an observation by combining both: the revision of κ by
κobs is undeﬁned when minS(κ + κobs) = ∞, and otherwise
is the belief state deﬁned by
∀s ∈ S, (κ ⊕ κobs)(s) = κ(s) + κobs(s) − min
(κ + κobs)
In particular, κ> ⊕ κobs = κobs and (κ ⊕ κϕ) = κ(.|ϕ),
where κ(.|ϕ) is Spohn’s conditioning [Spohn, 1988].

A physical action α is a feedback-free action (that is, it
possibly changes the state of the world but does not give any
feedback), deﬁned by a transition model consisting of a col-
lection of belief states {κα(.|s), s ∈ S}. κα(s0|s) is the ex-
ceptionality degree of the outcome s0 when performing α in
state s. The progression of a belief state κ0 by α is the belief
state κ (cid:5) α = κ(.|κ0, α) deﬁned (cf. [Boutilier, 1998]) by
∀s ∈ S, (κ (cid:5) α)(s) = κ(s|κ0, α) = min
s0∈S

{κ(s0) + κα(s|s0)}

S

A positive formula of LPS is a formula where no Bi
appears in the scope of negation. A positive conjunctive
(PC) formula of LPS is a formula of the form B∞ϕ∞ ∧
1This restriction is made for the sake of simplicity; it would be
possible to consider nested modalities, and then prove, as it is the
case in KD45, that each formula is equivalent to a ﬂat formula, but
this issue has no relevance to the issues dealt with in this paper.
Likewise, combinations of objective and subjective formulas do not
play any role either for expressing belief-based programs.

Bnϕn ∧ . . . ∧ B1ϕ1; without loss of generality we can as-
|= ϕi+1, since B∞ϕ∞ ∧ Bnϕn ∧ . . . ∧ B1ϕ1 is
sume ϕi
equivalent to B∞ϕ∞ ∧ Bn(ϕ∞ ∧ ϕn) ∧ . . . ∧ B1(ϕ∞ ∧
ϕn ∧ . . . ∧ ϕ1). There is a one-to-one correspondance be-
tween belief states and satisﬁable PC formulas (modulo log-
ical equivalence): for each κ, the PC formula G(κ) = Φκ
is deﬁned as B∞ϕ∞ ∧ Bnϕn ∧ . . . ∧ B1ϕ1, where n =
max{k < ∞,∃s such that κ(s) = k}, and for every i ∈ N∗
,
ϕi = F orm({s, κ(s) < i}). (Note that n is ﬁnite, because
S is ﬁnite and min κ = 0.) For instance, let κ([a, b]) = 0,
κ([a,¬b]) = 1, κ([¬a, b]) = 3 and κ([¬a,¬b]) = ∞, then
Φκ = B∞(a∨b)∧B3a∧B2a∧B1(a∧b) – which is equivalent
to B∞(a ∨ b) ∧ B3a ∧ B1b. Conversely, for each satisﬁable
PC formula Ψ there is a belief state κΨ = H(Ψ) such that
G(H(Ψ)) ≡ Ψ. G(κ) represents all the agent believes in κ2.
We will sometimes make the following slight abuse of nota-
tion: when a PC formula Ψ is equivalent to a shorter (but not
PC) formula Ψ0, we write κΨ0 instead of κΨ. For instance, the
PC formula Ψ = B∞ϕ∞> ∧ B3> ∧ B2r ∧ B1r is equivalent
to B2r, therefore we write κB2r instead of κΨ.

3 Belief-based programs
Belief-based programs (BBP) are built up from a set of ac-
tions ACT and program constructors:

• the empty plan λ is a BBP;
• for any α ∈ ACT , α is a BBP;
• if π and π0 are BBPs then (π; π0) is a BBP;
• if π and π0 are BBP and Φ ∈ LPS,

then
(if Φ then π else π0) and (while Φ do π)
are BBPs.

Thus, a BBP is a program whose branching conditions are
doxastically interpretable: the agent can decide whether she
believes to a given degree that a formula is true (whereas she
is generally unable to decide whether a given objective for-
mula is true in the actual world). For instance, the agent per-
forming the BPP

π = while ¬(B2r ∨ ¬B2¬r) do ask;

if B2r then goright else golef t

performs the sensing action ask until she has a belief
ﬁrm enough (namely of degree 2) about the way to follow
(whether π is guaranteed to stop is a good question!).

Progression and revision in [Laverny and Lang, 2004] are
used for maintaining the agent’s current belief state while the
program is being executed. However, predicting the future
possible states resulting from the execution of a BBP before it
has started to be executed (off-line evaluation) cannot be done
in a satisfactory way. Consider π = ask; ask; ask; ask, con-
sisting in asking in sequence to 4 pedestrians about the way
to the station. Assume that each occurrence of ask can send

2This could be formalized by extending our language with
graded doxastic versions O1, . . . , O∞ of the only knowing modality
(e.g. [Levesque and Lakemeyer, 2000]), Oiϕ meaning that all the
agent believes to the degree i is ϕ. Due to space limitations we must
omit the details.

back obs1 = κB1r or obs2 = κB1¬r, corresponding respec-
tively to a pedestrian telling that the station is on the right
(resp. left), taken with some limited reliability (for the sake
of simplicity we exclude “don’t know” answers). Then all
we can predict is that after doing π the agent will be in one
of the 5 belief states κB4r, κB4¬r, κB2r, κB2¬r, κ>3. The
point now is that obs1 and obs2 cannot always be considered
as likely as each other: for instance, we may wish to express
that accurate observations are more frequent than inaccurate
ones. Therefore, observations should be ranked by their plau-
sibility of occurrence given the current state and the sensing
action performed. Then, the projection of an initial belief
state by a program results in a second-order (or complex) be-
lief state: in our example, one would expect to obtain that
after asking to two persons, then normally the agent is the be-
lief state κB2r or in the belief state κB2¬r, and exceptionally
in the void belief state κ>. This issue is developed in next
Section.

4 Complex belief states and progression
4.1 Complex belief states
Deﬁnition 1 Let BS be the set of all belief states on S. A
complex belief state (CBS) is an ordinal conditional func-
tion µ on BS, i.e., a function µ : BS → N such that
minκ∈BS µ(κ) = 0
µ is a second-order belief state expressing the beliefs, before
executing some given program π, about the (future) possible
belief states resulting from its execution.
Example 1 Let S = {r,¬r}.



κ0 :

κ3 :

κ4 :

¬r : 0

(cid:20) r : 0
(cid:20) r : 0
(cid:20) r : 2

¬r : 2

¬r : 0

(cid:21)
(cid:21)
(cid:21)

µ :



: µ(κ0) = 1

: µ(κ3) = 0

: µ(κ4) = 0

is a CBS (by convention, for any belief state κ not mentioned
we have µ(κ) = +∞); it intuitively represents a situation
where the agent expects the resulting belief state to be either
κ0, κ3 or κ4, these last two being normal results and κ0 being
exceptional. Note that κ0 = κ>, κ3 = κB2r and κ4 = κB2¬r.
We deﬁne µκ as the (degenerated) CBS deﬁned by
µκ(κ) = 0 and µκ(κ0) = ∞ for all κ0 6= κ.

Note that since, unlike S, BS is not ﬁnite, some CBSs can-
not be ﬁnitely represented. We say that µ has a ﬁnite support
iff only a ﬁnite number of belief states have a ﬁnite plau-
sibility, i.e., {κ ∈ BS|µ(κ) < ∞} is ﬁnite; in this case
we deﬁne nµ (or simply n where there is no ambiguity) as
max{i < ∞ | ∃κ such that µ(κ) = i}.
4.2 Progression by sensing actions
Consider a ﬁnite set ACTS of sensing actions, that send feed-
back to the agent, under the form of observations. Each sens-
ing action is deﬁned by a state-dependent plausibility assign-
ment on possible observations.

3The notation κΦ has been introduced at the end of Section 2.

Deﬁnition 2 Let OBS ⊆ BS be a ﬁnite set of possible ob-
servations (recall that observations are belief states). An ob-
servation model is a collection of functions
κOBS(.|s, α) : OBS → N

minobs∈OBS κOBS(obs|s, α) = 0

α ∈ ACTS, κOBS(obs|s, α) = ∞.

for every α ∈ ACTS and every s ∈ S, such that:
1. for every α ∈ ACTS and every s ∈ S,
2. for every obs ∈ OBS, if obs(s) = ∞ then for every
κOBS(obs|s, α) is the exceptionality degree of getting ob-
servation obs as feedback when executing the sensing action
α in state s. This deﬁnition ﬁrst appears in [Boutilier et al.,
1998], and is similar in spirit to correlation probabilities be-
tween states and observations in partially observable Markov
decision processes. Condition 1 expresses that there is always
at least one normal observation; Condition 2 is a weak con-
sistency condition between states and observations (an obser-
vation totally excluding a state cannot occur in that state).
Example 2
Let S = {r,¬r}, obs1 = κB1r, obs2 = κB1¬r, and let
κOBS(obs1|r, ask) = 0
κOBS(obs2|r, ask) = 1
κOBS(obs2|¬r, ask) = 0 κOBS(obs1|¬r, ask) = 1

(all other observations being impossible, i.e., for obs 6=
obs1, obs2, κ(obs|s, α) = ∞; by convention we omit these
when specifying κ(.|s, α)). This means that accurate obser-
vations are the normal ones, whereas incorrect obervations
are 1-exceptional.
Deﬁnition 3 Let κ0 be a belief state and α ∈ ACTS. Given
obs ∈ OBS, the plausibility of obtaining obs after α in belief
state κ0 is deﬁned by

κOBS(obs|κ0, α) = min
s∈S

[κ0(s) + κOBS(obs|s, α)]

µ(κ|κ0, α)

The progression of κ0 by α is the complex belief state
prog(κ0, α) = µ(.|κ0, α) deﬁned by: for all κ ∈ BS,
= min{κOBS(obs|κ0, α) | obs ∈ OBS and κ = κ0 ⊕ obs}
Thus, κ is all the more normal in the projected CBS
µ(.|κ0, α) as there exists a normal state s and a normal ob-
servation obs (given s) such that κ is the revision of κ0 by
obs. Condition 2 in Deﬁnition 2 guarantees that κ0 ⊕ obs is
deﬁned whenever κOBS(obs|κ0, α) < ∞, which ensures that
µ(.|κ0, α) is a CBS.
Example 3 The ﬁgure on the left (resp. right) shows the pro-
gression of κ0 (resp. κ1) by ask.

(cid:21)

(cid:20) r : 0¬r : 0
(cid:21)

κ2 :

obs2

(cid:20) r : 1¬r : 0

κ0 :

obs1

(cid:20) r : 0¬r : 1

κ1 :

(cid:21)

(cid:20) r : 0¬r : 1
(cid:21)

κ0 :

obs2

(cid:20) r : 0¬r : 0

(cid:21)

κ1 :

(cid:21)

obs1

(cid:20) r : 0¬r : 2

κ3 :

µ(κ1) = 0

µ(κ2) = 0

µ(κ3) = 0

µ(κ0) = 1

(cid:20) κ1

κ2

(cid:21)

:
:

0
0

µ(.|κ0, ask) =

(cid:20) κ3

κ0

(cid:21)

:
:

0
1

µ(.|κ1, ask) =

4.3 Progression by physical actions
In addition to sensing actions we consider a ﬁnite set ACTP
of physical, feedback-free actions4. In Section 2, the progres-
sion of a belief state by a physical action was deﬁned as a
belief state. For the sake of homogeneity, we have now to
deﬁne it as a CBS: the progression µ(.|κ0, α) of a belief state
κ0 by α ∈ ACTP is deﬁned by µ(.|κ0, α) = µκ0(cid:5)α, i.e.,

(cid:26) 0

µ(κ|κ0, α) =

if κ = κ0 (cid:5) α

∞ otherwise

4.4 Progression by belief-based programs
The progression of a belief state κ by a BBP π is the complex
belief state µ(.|κ, π) deﬁned inductively by

• if π = λ then µ(.|κ, π) = µκ;
• if π = α then µ(.|κ, π) is deﬁned in Section 4.3 if α ∈
• if π = (π1; π2) then
• if π = if Φ then π1 else π2 then

ACTP and in Section 4.2 if α ∈ ACTS;
µ(κ0|κ, π) = minκ00∈BS(µ(κ00|κ, π1) + µ(κ0|κ00, π2))

µ(κ0|κ, π) =

µ(κ0|κ, π2)
• if π = while Φ do π0 then

(cid:26) µ(κ0|κ, π1)
(cid:26) µ(κ0|κ, (π0; π))

µ(κ0|κ, π) =

µκ(κ0)

if κ |= Φ
otherwise

if κ |= Φ
otherwise

If π contains no while construct then this deﬁnition is
well-founded (it can be proved that it results a SBS which
moreover does not depend on the order in which the above
rules are applied). This is not so with while constructs,
since the (recursive) deﬁnition leads to a ﬁxpoint equation
whose solution, when deﬁned, is taken to be its least ﬁxpoint
when the latter is a CBS, which is not necessarily the case:
consider κ0 = κ> and π = while > do ask; applying the
above deﬁnition leads to µ(κ|κ0, π) = ∞ for all κ, which is
not a CBS. Moreover, when µ(.|κ0, π) is deﬁned, it does not
necessarily have a ﬁnite support.
Example 4

• µ(.|κ>, (ask; ask)) = [κ3 : 0 ; κ4 : 0 ; κ0 : 1];
• µ(.|κ>, (ask; ask; ask; ask))
= [κB4r : 0 ; κB4¬r : 0 ; κ3 : 1 ; κ4 : 1 ; κ0 : 2];
• π1 = (ask; ask; if B2r ∨ B2¬r then λ else ask).
Then µ(.|κ>, π1) = [κ3 : 0 ; κ4 : 0; κ1 : 1 ; κ2 : 1];
• π2 = while ¬(B2r ∨ B2¬r) do ask. Applying the
deﬁnition gives a ﬁxpoint equation whose solution is
µ(.|κ0, π2) = [κ3 : 0 ; κ4 : 0].5
4Such a partition between purely sensing and purely physical ac-

tions is usual and does not induce a loss of generality.

5The question whether this program can run forever is similar to
that of whether it is possible that a fair coin tossed repeatedly always
turns up heads, and this is thus related to an OCF version of the law
of large numbers.

4.5 Two particular cases
An unobservable environment consists of a set of physical
actions only (ACTS = ∅).

A fully observable environment is somewhat harder to de-
ﬁne formally because of the separation between physical and
sensing actions, which prevents us to say that all actions send
a full feedback. To cope with this, we assume that ACTS
contains one action sense(x) for each propositional variable,
which returns the truth value of x with full certainty, and we
require that in a program, any physical action α should be fol-
lowed by all actions sense(x) – which means that after α and
this sequence of sensing actions, the state is known with full
certainty. Any program of this kind is said to be admissible.
The initial state is also required to be known with certainty.

Proposition 1

1. in an unobservable environment, for any κ0 and any pro-
gram π for which µ(.|κ0, π) is deﬁned, there exists a be-
lief state κ such that µ(.|κ0, π) = µκ;
2. in a fully observable environment, for any belief state
κ0 and any admissible program π such that µ(.|κ0, π)
is deﬁned, µ(κ|κ0, π) < ∞ implies that κ is a precise
belief state, i.e., κ = κs for some s ∈ S.

5 Progression: syntactical computation
Applying progression as it is deﬁned above has a prohibitive
complexity, since it amounts at iterating over all belief states,
states, and observations.
In this Section we give a more
friendly, syntactical way of computing progression, based on
a compact representation of complex belief states.

So as to be able to reason about the resulting belief states,
we now introduce a new family of modalities P1, P2, . . . ,
P∞ in addition to B1, . . . , B∞. While the Bi modalities deal
with uncertainty (about the current state), P1 , P2, . . . , P∞
deal with second-order uncertainty, i.e., uncertainty about the
projected belief state (with respect to some program).

L2
P S is the language deﬁned by:
• if Φ is a formula of LP S then for all i, PiΦ is a formula
of L2
• if Θ and Θ0 are formulas of L2
P S then Θ ∧ Θ0, Θ ∨ Θ0
P S.

and ¬Θ are formulas of L2

P S;

Like for Bi modalities, we need not consider nested Pi
modalities, neither heterogeneous combinations of Pi and Bi
modalities (resp. objective formulas). Satisfaction of a L2
P S
formula by a CBS is deﬁned by

• µ |= PiΦ iff for all κ ∈ BS, κ |= ¬Φ implies µ(κ) > i;
• µ |= Θ ∧ Θ0 iff µ |= Θ and µ |= Θ0

(and similarly for the other connectives).

Validity, satisﬁability and logical consequence are deﬁned in
the usual way. Intuitively, P1Φ means that all belief states
that do not satisfy Φ are exceptional at least to the degree i.
When reasoning about CBS, we are mainly concerned with
inferring positive formulas – inferring negative formulas such
as ¬PiΦ is somewhat derivative. We deﬁne a positive L2
formula as follows:

P S

P S formula;

• if Φ is a positive LP S formula and i ∈ N then PiΦ is a
positive L2
P S formulas then Θ1 ∧ Θ2
• if Θ1 and Θ2 are positive L2
and Θ1 ∨ Θ2 is a positive L2
P S formula.
P S formula is a L2

Moreover, a canonical L2
P S formula of the
form Θ = P1Φ1 ∧ P2Φ2 ∧ . . . ∧ PnΦn ∧ P∞Φ∞, where Φ1,
. . . , Φn, Φ∞ are positive LP S formulas6.

Given a CBS µ with ﬁnite support, the canonical L2

P S for-

mula G+(µ) = Θµ associated with µ is deﬁned by

 _

µ(κ)<i

i=n^

i=1

 ∧ P∞

 _

G(κ)

µ(κ)<∞



Θµ =

Pi

G(κ)

where n = nµ and G(κ) is the canonical LP S formula cor-
responding to κ (cf. Section 2).
Proposition 2 For any CBS µ with ﬁnite support and any
positive conjunctive L2
P S formula Θ, µ |= Θ if and only if
Θµ |= Θ, that is, Θµ is the strongest positive conjunctive
L2
P S formula satisﬁed by µ.
Example 1 (continued)
Θµ = P1(B2r ∨ B2¬r) ∧ P∞(B2r ∨ B2¬r ∨ B∞>)

≡ P1(B2r ∨ B2¬r)

We are now in position to give a syntactical characteriza-
tion of progression.
Deﬁnition 4 Let Φ be a positive conjunctive LP S formula
and α be any action. The progression of Φ by α is the
canonical L2
P S formula P rog(Φ, α) corresponding to the
CBS µ(.|κΦ, α), i.e.,

P rog(Φ, α) = G+(µ(.|κΦ, α)) = Θµ(.|κΦ,α)

We now show how the formula P rog(Φ, α) can be com-

puted without ﬁrst generating the corresponding µ.
Proposition 3
Let α be a sensing action and Φ = B1ϕ1∧. . .∧Bpϕp∧B∞ϕ
a positive conjunctive LP S formula. We deﬁne:

ψi,obs,α = F orm{s ∈ S | µOBS(obs|s, α) < i};
ψ1,obs,α) 6≡ ⊥};

• for any obs ∈ OBS and i ∈ N,
• Xi,Φ,α = {obs ∈ OBS | (ϕ1 ∧ ψi,obs,α) ∨ . . . ∨ (ϕi ∧
• X∞,Φ,α = {obs ∈ OBS | ϕ ∧ ψ∞,obs,α 6≡ ⊥};
• n is the largest integer i such that Xi,Φ,α   X∞,Φ,α.

Then

P rog(Φ, α) =

i=n^

Pi(

i=1

∧P∞(

_
_

obs∈Xi,Φ,α

obs∈X∞,Φ,α

Φ ⊗ Φobs)

Φ ⊗ Φobs)

where ⊗ is the syntactical revision operator (Proposition 1
of [Laverny and Lang, 2004]), which satisﬁes Φ ⊗ Φobs =
G(H(Φ) ⊕ obs).

6Notice that canonical L2

P S formulas are positive L2

P S formulas
in which there is no disjunction at the level of the Pi modalities (but
disjunctions may appear in the scope of a Pi modality, and of course
in the scope of a Bi modality too).

Let Φ = B1r. We get
Example 2 (continued)
X1,Φ,ask = {obs1}, X2,Φ,ask = {obs1, obs2} and for
all n > 2, Xn,Φ,ask = {obs1, obs2}. Proposition 3 gives
P rog(Φ, ask) = P1(B1r ⊗ B1r) ∧ P∞((B1r ⊗ B1r) ∨
(B1r ⊗ B1¬r)) ≡ P1B2r ∧ P∞(B2r ∨ B∞>) ≡ P1B2r.

The characterization for physical actions is much easier.
Proposition 4 For any physical action α and any PC LP S
formula Φ, P rog(Φ, α) ≡ P∞G(κΦ (cid:5) α).

Moreover, G(κΦ (cid:5) α) can be computed efﬁciently using
Lastly, the progression of a positive conjunctive LP S for-
P S formula P rog(Φ, π)

Proposition 2 of [Laverny and Lang, 2004].
mula Φ by a BBP π is the canonical L2
deﬁned inductively as follows:

• P rog(Φ, λ) = P∞Φ;
• P rog(Φ, α) is deﬁned at Deﬁnition 4 if α is an action;
• P rog(Φ, if Ψ then π1 else π2)

if Φ |= Ψ
otherwise

=

(cid:26) P rog(Φ, π1)
P rog(Φ, π2)
• P rog(Φ, π1; π2) =
i=n^
_
(cid:26) P rog(Φ, π0; π)

u+v=i+1

Pi(

i=1

• P rog(Φ, while Ψ then π0) =
if Φ |= Ψ
otherwise

P rog(Φ, λ)

[P rog([P rog(Φ, π1)]u, π2)]v)
∧P∞([P rog([P rog(Φ, π1)]∞, π2)]∞)

where
1. for any canonical L2

P S formula Θ, [Θ]i is the strongest
positive LP S formula Ψ (unique up to logical equiva-
lence) such that Θ |= PiΨ .
2. for any positive conjunctive LP S formulas Φ1 and
[P rog(Φ1 ∨ Φ2, π)]i = [P rog(Φ1, π)]i ∨

Φ2:
[P rog(Φ2, π)]i.

Proposition 5 P rog(Φκ, π) = Θµ(.|κ,π)
Example 5
Let π = (ask; ask; if B2r ∨ B2¬r then λ else ask)
and π0 = (while ¬(B2r ∨ B2¬r) do ask).

• P rog(B∞>, ask) ≡ P∞(B1r ∨ B1¬r)
• P rog(B∞>, ask; ask) ≡ P1(B2r ∨ B2¬r).
• P rog(B∞>, π) ≡ P1(B2r∨B2¬r)∧P∞(B1r∨B1¬r)
• P rog(B∞>, π0) ≡ P∞(B2r ∨ B2¬r)

6 Related work
Partially observable Markov decision processes
POMDPs are the dominant approach for acting under partial
observability (including nondeterministic actions and unreli-
able observations). The relative plausibility of observations
given states, as well as the notion of progressing a belief state
by an action, has its natural counterparts in POMDPs. Now,

there are two important differences between POMDPs and
our work.

First, in POMDPs policies, branching is conditioned by
the observation sequence that has lead to the current belief
state; the policy is therefore directly implementable, without
the need for an on-line reasoning phase. In our framework,
branching conditions are expressed logically, which may al-
low for much more compact policies than branching on ob-
servations. In this view, BBPs can be seen as high-level, com-
pact speciﬁcations of POMDP policies (the policy being the
implementation of the program). Our work can thus be seen
as a ﬁrst step towards bridging knowledge-based programs
and POMDPs.

p∈P BS

ciple: ˆp(s) =P

Second, we allow for second-order uncertainty whereas
if pproj(p|p0, π) is the probability
POMDPs get rid of it:
of obtaining the probabilistic belief state p after executing π
in p0, this second-order belief state is systematically reduced
into the ﬁrst-order one ˆp, following the lottery reduction prin-
pproj(p).p(s) (where P BS is the set
of probability distributions on S). This is a loss of expressiv-
ity, as seen on the following example: consider the action α of
tossing a coin and the action β of sensing it. The agent knows
that after performing α only, she will be for sure in a belief
state where p(heads) = p(tails) = 0.5. This differs from
projecting the effects of α; β:
then she knows that he will
reach either a belief state where she knows heads or a belief
state where she knows tails, with equal probability. After re-
duction, these two plans and their projections can no longer
be distinguished – whereas our CBS do distinguish them7.

Cognitive robotics
Another fairly close area is that of cognitive robotics, es-
pecially the work around Golog and the situation calculus
(e.g., [Reiter, 2001]), which is concerned with logical speciﬁ-
cations of actions and programs, including probabilistic ex-
[Bacchus et al., 1999]
tensions and partial observability.
gives an account for the dynamics of probabilistic belief states
when perceiving noisy observations and performing physical
[Grosskreutz and Lakemeyer,
actions with noisy effectors.
2000] considers probabilistic Golog programs with partial ob-
servability, with the aim of turning off-line nondeterministic
plans into programs that are guaranteed to reach the goal with
some given probability. In both works, branching conditions
involve objective formulas and there is no account for second-
order uncertainty. Bridging belief-based programs and the
situation calculus (and Golog) is a promising issue.

Belief revision with unreliable observations
[Boutilier et al., 1998] might be the closest work to ours,
as far as the dynamics of belief states in the presence of
noisy observations is concerned. Our notion of an observa-
tion model (Deﬁnition 3) owes a lot to theirs (which also
makes use of ranking functions). Now, their objectives de-
part from ours, as they focus on a general ontology for belief

7Incidentally, we can reduce a CBS in a similar way: the reduc-
tion of the CBS µ of the is the belief state ˆκµ ∈ BS deﬁned by
ˆκµ(s) = minκ∈BS µ(κ) + κ(s). It is readily checked that ˆκ is a be-
lief state. Reducing µ into ˆκµ results in a much simpler (and shorter)
structure, which, on the other hand, is much less informative than µ.

revision and do not consider physical actions nor programs,
nor do they give a syntactical way of computing their revision
functions.
Counterfactual belief-based programs
[Halpern and Moses, 2004] consider belief-based programs
with counterfactuals whose semantics, like ours, is based on
ranking functions. They do not allow for graded belief in
branching conditions, nor unreliable observations (ranking
functions are used for evaluating counterfactuals), but they
allow for counterfactual branching conditions, possibly refer-
ring to future belief states, such as “if I believe that if I were
not sending this message now then my partner might not get
this important information, then I should send it”. Adding
counterfactuals and beliefs about future states to our frame-
work is worth considering for further research.

Acknowledgements
Thanks to the anonymous referees for many relevant and
helpful suggestions.

References
[Bacchus et al., 1999] F. Bacchus,

and
H. Levesque. Reasoning about noisy sensors and ef-
fectors in the situation calculus. Artiﬁcial Intelligence,
111:171–208, 1999.

J. Halpern,

[Boutilier et al., 1998] C. Boutilier, N. Friedman,

and
J. Halpern. Belief revision with unreliable observations.
In Proceedings of AAAI-98, pages 127–134, 1998.

[Boutilier, 1998] C. Boutilier. A uniﬁed model of qualitative
belief change: A dynamical systems perspective. Artiﬁcial
Intelligence, 98(1-2):281–316, 1998.

[Fagin et al., 1995] R. Fagin, J. Halpern, Y. Moses, and
M. Vardi. Reasoning about Knowledge. MIT Press, 1995.
and
Turning high-level plans into robot
In Proceedings of

[Grosskreutz and Lakemeyer, 2000] H. Grosskreutz

G. Lakemeyer.
programs in uncertain domains.
ECAI-2000, pages 548–552, 2000.

[Halpern and Moses, 2004] J. Halpern and Y. Moses. Using
counterfactuals in knowledge-based programming. Dis-
tributed Computing, 17(2):91–106, 2004.

[Laverny and Lang, 2004] N. Laverny and J. Lang. From
knowledge-based programs to graded belief based pro-
grams, part i: on-line reasoning. In Proceedings of ECAI-
04, pages 368–372, 2004.

[Levesque and Lakemeyer, 2000] H. Levesque and G. Lake-

meyer. The logic of knowledge bases. MIT Press, 2000.

[Reiter, 2001] R. Reiter. Knowledge in Action: Logical
Foundations for Specifying and Implementing Dynamical
Systems. MIT Press, 2001.

[Spohn, 1988] W. Spohn. Ordinal conditional functions: a
dynamic theory of epistemic states. In William L. Harper
and Brian Skyrms, editors, Causation in Decision, Belief
Change and Statistics, volume 2, pages 105–134. Kluwer
Academic Pub., 1988.

