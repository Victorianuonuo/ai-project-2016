Detecting Changes in Unlabeled Data Streams using Martingale

Shen-Shyang Ho and Harry Wechsler

George Mason University
Department of Computer Science
{sho, wechsler}@cs.gmu.edu

Abstract

The martingale framework for detecting changes
in data stream, currently only applicable to labeled
data, is extended here to unlabeled data using clus-
tering concept. The one-pass incremental change-
detection algorithm (i) does not require a sliding
window on the data stream, (ii) does not require
monitoring the performance of the clustering algo-
rithm as data points are streaming, and (iii) works
well for high-dimensional data streams. To en-
hance the performance of the martingale change de-
tection method, the multiple martingale test method
using multiple views is proposed. Experimen-
tal results show (i) the feasibility of the martin-
gale method for detecting changes in unlabeled
data streams, and (ii) the multiple-martingale test
method compares favorably with alternative meth-
ods using the recall and precision measures for the
video-shot change detection problem.

Introduction

1
The problem of detecting changes in low-dimensional se-
quential data has been studied by statisticians for more than
ﬁfty years. Methods of change detection ﬁrst appeared in the
1940s based on Wald’s sequential analysis [Wald, 1947], in
particular the sequential probability sequential test (SPRT)
[Basseville and Nikiforov, 1993], and later, Page introduced
the cumulative sum method [Page, 1954]. Recently, the ma-
chine learning and the data mining communities become in-
terested in the change detection problem due to the need to
discover changes in data, such as customer click streams,
high-dimensional multimedia data, and retail chain transac-
tions, generated from online processes that are not stationary
[Domingos and Hulten, 2001]. The target concepts change
over time. It is, hence, vital to detect the changes in the data
generating processes so that timely decisions can be made.

One real-world problem that requires detecting changes is
the video segmentation problem which corresponds to video-
shot change or video break detection. Many algorithms
[Gargi et al., 2000; Lefevre et al., 2003; Zhai and Shah, 2005]
have been proposed to perform video-shot change detection.
The range of existing methods includes pixel and histogram-
based difference methods and motion-based methods (e.g.

optical ﬂow). Threshold selection, a critical step for success-
ful change detection, is required by methods using global or
local thresholds. For video sequences with clear and distinct
shots, a single global threshold would be sufﬁcient. For video
sequences that have both abrupt and gradual changes between
shots, however, a global threshold cannot be found. To ad-
dress such concerns [Gargi et al., 2000] argued for the use of
local thresholds. The use of local thresholds requires choos-
ing appropriate window size. Alternatively, Zhai and Shah
[Zhai and Shah, 2005] proposed that video breaks should be
detected using the deviation from some current model.

Recently, [Ho, 2005] proposed a martingale method for
change detection for high-dimensional labeled data streams.
An adaptive support vector machine for time-varying data
streams was proposed based on the martingale method [Ho
and Wechsler, 2005a]. The main contributions of the present
paper are: (i) the extension of the martingale methodology
to unlabeled data stream, and (ii) the multiple-martingale test
based on multiple views (features). We show empirically that
the martingale method works well for unlabeled data stream
and the multiple-martingale test compares favorably with al-
ternative video-shot change detection methods for unlabeled
video stream.

The paper is organized as follows.

In Section 2, we re-
view the concept of exchangeability and martingale. In Sec-
tion 3, we introduce the concept of strangeness and p-values,
and propose the strangeness measure for unlabeled data us-
ing clustering concept. In Section 4, we state the theorem on
the martingale method for change detection which is applica-
ble to both labeled and unlabeled data stream. In Section 5,
we show the feasibility of the martingale method for change
detection on an unlabeled synthetic data stream. In Section
6, we propose the multiple-martingale test for change detec-
tion. In Section 7, we apply the multiple-martingale test to
video-shot change detection.

2 Exchangeability and Martingale
Let {Zi
: 1 ≤ i < ∞} be a sequence of random vari-
ables. A ﬁnite sequence of random variables Z1,··· , Zi is
exchangeable if the joint distribution p(Z1,··· , Zi) is invari-
ant under any permutation of the indices of the random vari-
ables. The satisfaction of exchangeability condition indicates
that the distribution that the sequence of random variables is
drawn from is stationary.

IJCAI07

1912

[Vovk et al., 2003] introduced the idea of testing exchange-
ability online using the martingale. A martingale is a se-
quence of random variables {Mi : 0 ≤ i < ∞} such that Mn
is a measurable function of Z1,··· , Zn for all n = 0, 1,···
(in particular, M0 is a constant value) and the conditional ex-
pectation of Mn+1 given M0,··· , Mn is equal to Mn, i.e.

E(Mn+1|M1,··· , Mn) = Mn

(1)
After each new data point is received, an observer outputs a
positive martingale value reﬂecting the strength of evidence
found against the null hypothesis of data exchangeability. The
testing of exchangeability is used to detect changes in time-
varying labeled data streams [Ho and Wechsler, 2005b].

3 Strangeness and p-values
To apply the martingale method one needs to rank the data
points according to their differences. Towards that end, one
deﬁnes a strangeness measure that scores how much a data
point is different from the other data points. Consider the set
of labeled data points Z = {z1,··· , zn−1} and the new la-
beled data point zn. Each data point is assigned a strangeness
value based on the classiﬁer, such as the support vector ma-
chine (SVM) or the nearest neighbor rule, used to classify the
data points Z

(cid:2){zn} [Vovk et al., 2005].

To deﬁne a valid strangeness value for each data point, the
simple assumption that at any time instance the strangeness
value of each data point seen so far should be independent of
the order these data points are used in the strangeness com-
putation must be satisﬁed [Vovk et al., 2005]. For instance,
when a k-nearest neighbor rule is used, the strangeness value
of a particular data point is the ratio of the sum of the k-
nearest data points with similar label (Ss) to the sum of the
k-nearest data points with difference label (Sd). Hence, the
higher Ss is, the higher the strangeness value, and vice versa.
On the other hand, when Sd is high, the strangeness value is
low. This is clearly a method that constructs valid strangeness
values for labeled data points.

For unlabeled data, the strangeness measure is derived us-
ing clustering algorithm such as K-mean/median clustering
with K = 1. Consider the set of unlabeled data points
Z = {z1,··· , zn−1} and the new unlabeled data point zn.
The strangeness value si of zi for i = 1,··· , n is
si(Z, zn) =(cid:4) zi − C(Z ∪ {zn}) (cid:4)

(2)
where C(·) is some cluster representation and (cid:4) · (cid:4) is some
distance measure. The strangeness value for a data point is
high when it is further away from the cluster representation,
e.g. the cluster center.

Next, a statistic is constructed to rank the strangeness value
of the new data point zn with respect to the strangeness values
of all the observed data points. The statistic, called the p-
value of zn, is deﬁned as

p-value = V (Z ∪ {zn}, θn) =
#{i : si > sn} + θn#{i : si = sn}

(3)
where si is the strangeness measure for zi, i = 1, 2,··· , n
and θn is randomly chosen from [0, 1].

n

The random number θn in (3) ensures that

the p-
values p1, p2,··· output by the p-value function V are dis-
tributed uniformly in [0, 1], provided that the input examples
z1, z2,··· are generated by an exchangeable probability dis-
tribution in the input space [Vovk et al., 2003]. This property
of output p-values no longer holds when the exchangeability
condition is not satisﬁed.
4 Change Detection using Martingale
Intuitively, we assume that a sequence of data points with a
change consists of concatenating two data segments, S1 and
S2, such that the data distribution of S1 and S2 are P1 and
P2 respectively and P1 (cid:6)= P2. Switching a data point zi from
S2 to a position in S1 will make the data point stand out in
S1. The exchangeability condition is, therefore, violated. Ex-
changeability is a sufﬁcient condition for a stable data stream.
The absence of exchangeability suggests the occurrence of
change.
A family of martingales, indexed by  ∈ [0, 1], and referred

to as the power martingale, is deﬁned as
(cid:5)

n(cid:3)

(cid:4)

()
n =

M

i=1

−1
p
i

(4)

()
0 = 1. We note that M

where the pis are the output p-values from the function V ,
()
with the initial martingale M
n =
p−1
()
n−1. Hence, it is not necessary to store the previous
n M
p-values.
In our experiments, we use  = 0.92, which is
within the desirable range where the martingale value is more
sensitive to a violation of the exchangeability condition [Vovk
et al., 2003].

The following theorem is applicable to both labeled and
unlabeled data streams as long as the assumption (stated in
Section 3) on the strangeness measure is satisﬁed.
: 0 ≤
Theorem 1 ([Ho and Wechsler, 2005b]) Let {M
i < ∞} be a martingale sequence of the form (4) constructed
using p-values {pi : 1 ≤ i < ∞} computed from (3) based
on a valid strangeness measure for a given data stream:
1. If no change occurs in the given data stream, then

()
i

(cid:6)

(cid:7)

k ≥ λ
where λ is a positive number.

max

M

()

P

k

≤ 1
λ

,

(5)

2. Let α be the size of the test deciding in favor of the al-
ternative hypothesis “change occurs in the data stream”
when the null hypothesis “no change occurs in the data
stream” is true and 1− β be the power of the test decid-
ing in favor of the alternative hypothesis when it is true,
the martingale test according to (5) is an approximation
of the sequential probability ratio test (SPRT), with

λ ≤ 1 − β

α

,

(6)

and the mean delay time E(m), i.e. the expected number
of data points, m, observed before a change is detected,
is approximated from the SPRT as follows:

E(m) ≈ (1 − β) log λ

E(L)

(7)

IJCAI07

1913

(a)

(b)

Figure 1:
(a) Left: A sketch of four overlapping 2-
dimensional Gaussian distributions and the way the data se-
quence changes in distribution; Right: The trajectory of the
center of the 1-mean cluster as data points are observed one
by one; (b) The martingale values of the 10-D synthetic unla-
beled data stream with 3 change points.

where

L = log p

−1
i

(8)
A user selects a desirable threshold λ for the martingale
test (5) based on (6). To estimate the start of the change, (7)
is used .

5 Experimental Result: Synthetic Unlabeled

Data Stream

We construct an artiﬁcial unlabeled data stream as follows:

1. Randomly generate four sets of 1050 data points S1, S2,
S3, and S4 from four overlapping Gaussian distributions
with randomly generated mean with variance 1.

2. Concatenate S1, S2, S3, and S4 to form a sequence
D consisting of 4200 data points such that D =
{S1; S2; S3; S4}.

Left graph in Figure 1(a) shows a sketch of four overlap-
ping 2-dimensional Gaussian distributions generated by Step
1 of the above procedure. The data distribution of the data
sequence D changes with 3 change points.

In the experiment, the ﬁrst 50 points from D is ﬁrst used
to compute the center of the initial 1-mean cluster with
strangeness of each data point computed using (2) with the

Figure 2: The martingale values of the 10-D synthetic unla-
beled data stream with 3 change points.

Euclidean distance. The threshold λ value for the martin-
gale test is set to 10. The data points from the data stream
D are observed sequentially. The cluster center is updated.
Strangeness for all seen data points are computed. The mar-
tingale at each instance is computed using (4) based on the
computed p-values from (3). When the martingale value is
greater than λ, a change in the mean of the Gaussian distribu-
tion is detected. All previously seen data points are removed.
The martingale is reset to 1. The next 50 data points are used
to construct a new 1-mean cluster. The process repeats till the
data points in D are exhausted.

Right graph in Figure 1(a) shows the trajectory of the cen-
ter of 1-mean cluster in the experiment. The theoretical basis
for signaling a change is (5). Figure 1(b) shows the mar-
tingale values. Detection occurs when the martingale value
is greater than λ = 10. The true change points are at data
points 1000, 2000 and 3000. The dimension of the Gaussian
distribution is then increased to 10. Figure 2 shows that the
changes in mean parameter of the high-dimensional Gaussian
distribution are detected as well.

We note that in some real-world problems, more than one
data feature is good in representing the data. In order to utilize
this observation to improve the sensitivity and performance of
the martingale test, one can perform a number of martingale
tests constructed based on different characteristics or features
of the data.

6 Multiple-Martingale Test using Multi-Views
In the multi-view learning problem, an example z is repre-
sented by a number of feature subsets. Each feature subset
describes a view of the example [Muslea et al., 2002]. The
multi-view setting is closely related to co-training [Blum and
Mitchell, 1998].

For the multiple-martingale test, we consider the multi-
view setting such that each constructed martingale attempts
to identify changes with respect to the particular feature sub-
set. Besides the fact that the features are extracted from the
original data, the feature subsets should be independent of
one another to minimize redundancy.

We note that according to the martingale theory, the data
representation does not affect the probability bound (5). On
the other hand,
Corollary 1 When the multiple martingale test with M-

IJCAI07

1914

views is used for change detection, the expected number of
data points, m, observed before a change point is detected,

angle is converted into an index by dividing the orientation
angle by 10 and rounding to the nearest integer.

M(m) ≤ E(m)
∗

E

(9)

Algorithm 1 is the multiple-martingale test with two views.

Obviously, one can conclude that the number of miss detec-
tion using the multiple-martingale test is upper-bounded by
the number of miss detection using the original martingale
method. Moreover, the number of false alarm using the mul-
tiple martingale test is lower-bounded by the number of false
alarm using the original martingale method.
The algorithm can be trivially extended to M > 2.
Algorithm 1 : Multiple-Martingale Test with M-View,
M = 2
Initialize: M1(0) = M2(0) = 1; i = 1; T = {}.
Set: λ.
1: loop
2:
3:

A new unlabeled example xi is observed.
Construct the two views/features from xi, i.e., ¯xi =
{fi1, fi2}.
Compute the strangeness measure (cid:7)s1 and (cid:7)s2 (vectors
containing strangeness for seen examples) using (2)
from {f11,··· , fi1} and {f12,··· , fi2}.
Compute the p-values p1 and p2 from (cid:7)s1 and (cid:7)s2, re-
spectively, using (3).
Compute M1(i) and M2(i) from p1 and p2 using (4).
if M1(i) > λ OR M2(i) > λ then

4:

5:

CHANGE DETECTED
Set M1(i) and M2(i) to 1;
Re-initialize T to an empty set.

6:
7:
8:
9:
10:
11:
12:
13:
14:
15: end loop

else

Add xi into T .

end if
i := i + 1;

e , H 3

e , H 4

e , H 5

c , H 5

c , H 4

c , H 3

c , H 2

To capture local information from an image frame, the im-
age frame is partitioned such that a histogram is constructed
for each area partitioned along either the horizontal or the ver-
tical axis. For example, for a 352×240 image, histograms are
constructed on 3 areas of 88 × 240 by partitioning along the
horizontal axis and 3 areas of 352 × 80 by partitioning along
the vertical axis. Using this construction, we have two im-
age representations: one consisting of six color histograms,
Rcc = {H 1
c}, and one consisting of
c , H 6
e}.
six edge histograms, Ree = {H 1
e , H 6
e , H 2
The two image representations are used as the two views in
Algorithm 1.
Strangeness Measure of the Image Representations, Rcc
and Ree
Consider the set of image representations,
Z =
{R1,··· , R(n−1)} and a new image representation Rn in the
form of either Rcc or Ree. First, we deﬁne
Ω = max (Z ∪ {Rn})

(10)
which contains the maximum value for each bin in the his-
tograms of the image representation.
We note that as the number of observed image frames in-
creases, ||Ω||, where ||·|| is some distance measure, is mono-
tonically increasing. Ω ensures that the cluster center will
maintain information from previously observed image frames
and not be affected by a small drift in image content when a
new image frame is observed. The effect of a small drift in
image content is signiﬁcant when the mean, median or mini-
mum value is used. Ω assumes the role of the cluster center
for the images.
We are interested in the difference between the image rep-
resentation Ri, i = 1,··· , n and Ω. Using the Euclidean
norm, the strangeness value for Ri is

i.e.

si(Z, Rn) =

(Ri(k) − Ω(k))2

.

(11)

(cid:8)(cid:9)(cid:9)(cid:10)No. of bins(cid:11)

7 Video-Shot Change Detection Problem
In Section 7.1, we describe the method of constructing valid
strangeness for video stream.
In Section 7.2, we analyze
the martingale test method and motivate using the multiple-
martingale test on detecting changes in video stream. In Sec-
tion 7.3, we compare the multiple martingale test method with
alternative video-shot change detection methods.
7.1 Strangeness Measure for Video Stream
We describe the representation and the strangeness measure
for the unlabeled video image in this subsection.
Image Representation Using Color and Edge Histograms
The image representations are based on the color and edge
histograms. The color histogram is constructed with 4096
bins. [(r/16) ∗ 256 + (g/16) ∗ 16 + b/16] is used to convert
RGB values of a pixel into an index, with integer division
where r, g and b are red, green and blue values respectively.
The edge histogram consists of 36 bins such that a gradient

k=1

This strangeness measure is valid for an image representation
Ri in the form of either Rcc or Ree as it satisﬁes the assump-
tion in Section 3. The set of computed strangeness values
{s1,··· , sn} for Ri, i = 1,··· , n is used to compute the p-
value of Rn using (3).
7.2 Characteristics of the Martingale Method for

Video Stream

Consider the example shown in Figure 3, we use the image
representation Rcc and the threshold value λ = 10 to demon-
strate some characteristics of the martingale method.

The characteristic of Ωc (for color histogram representa-
tion, Rcc) is shown in Figure 4. The shot change is de-
tected at Frame 158 and all previous information is removed
from the memory. Unlike labeled data stream where the
data-generating process changes at some particular time in-
stances [Ho, 2005; Ho and Wechsler, 2005b], the unlabeled
video sequence is usually non-stationary, with constant small
changes. The “cluster” representation Ωc should be either (i)

IJCAI07

1915

Figure 3: Example: Starting at (Left Image) Frame 80 to
(Center Image) Frame 200: Human starts appearing in Frame
98 and appearing completely at around Frame 150. The shot
change is detected at Frame 158 (Right Image).

insensitive to small changes or (ii) maintain most informa-
tion from the previously observed data. Ωc satisﬁes the two
criteria.

Figure 4: Using the example shown in Figure 3: The char-
acteristic of Ωc using the image representation Rcc when the
video sequence is nearly stationary and after a shot change is
detected at Frame 158.

We perform the Kolmogorov-Smirnov test (KS-Test) to see
whether the p-values computed using (3) is uniformly dis-
tributed when the video content is nearly stationary. This im-
portant property of p-values computed using (3) does not hold
when the video sequence no longer satisﬁes the exchangeabil-
ity condition. The mean of the p-values lowers and the mar-
tingale values start to increase. In this experiment, we per-
form the martingale method without reacting to shot change
detected, removing data points and resetting variables.
In
Figure 5, we observed that with high conﬁdence (based on
p-values obtained from the KS-Test) the p-values computed
using (3) is uniformly distributed before Frame 163. After
Frame 163, the p-values are no longer uniformly distributed
at 0.05 signiﬁcance level.

In Figure 6, we show the martingale values computed using
the color feature, Rcc and the edge feature, Ree. One notes
that for this particular example shown in Figure 3, the edge
feature is more sensitive than the color feature. The martin-
gale values computed using the edge feature increase faster
and higher than the ones computed using the color feature
near the image frame where the change occurs. Hence, by
using the multiple-martingale test with 2 views, the number
of image frames observed before detecting the change point
is lowered. Hence, the sensitivity of the martingale method
can be increased using multiple views.

Figure 5: Using the example shown in Figure 3: The char-
acteristics of the p-values computed using (3) and the im-
age representation Rcc on the video sequence. We perform
the Kolmogorov-Smirnov Test (KS-Test) starting at Frame
100. Frame 177 has the lowest p-value using the KS-Test
at 0.000598 signiﬁcance level and a signiﬁcance level of less
than 0.05 is observed after Frame 163.

7.3 Comparison with Alternative Methods
Experiments were performed to compare the multiple-
martingale test with alternative methods. Four sets of videos,
consisting of two documentary video streams (anni, ugs) 1
and two video streams from hand-held digital video camera
(outdoor, indoor), are used. The “anni” video stream con-
sists of 9 shots and 8 gradual transitions between shots. The
“ugs” video stream consists of 13 shots with some fast transi-
tions and moving camera. The “outdoor” and “indoor” video
streams consist of continuous changes due to the motion of
the camera. The two video streams are captured from the top
of a hill and from an apartment, respectively.

The performance of the methods is measured based on the
number of detections, miss detections and false detections.
They are summarized using the recall, precision and the F1
measure:

Precision =

Recall =

F1 =

Number of Correct Detections

Number of Detections

Number of Correct Detections
Number of True Changes
2 × Recall × Precision
Recall + Precision

Precision is the probability that a detection is actually cor-
rect, i.e. detecting a true change. Recall is the probability
that a change detection system recognizes a true change. F1
measure represents a harmonic mean between recall and pre-
cision. A high value of F1 measure ensures that the precision
and recall are reasonably high.

In the experiment, we use λ = 20 which corresponds to
the fact that the computed martingale values are unlikely to
be higher than 20 with probability bound of 0.05 if no change

1The documentary videos can be obtained freely from

http://www.open-video.org

IJCAI07

1916

while the alternative methods are not.

8 Conclusions
In this paper, we extend the martingale methodology [Ho, 2005]
to be used on unlabeled data. We also proposed the multiple-
martingale test based on building different martingales using mul-
tiple views (features) to enhance the performance of the martingale
methodology. We apply this multiple martingale test method to the
video-shot change detection and show that it compares favorably
with alternative methods.

References
[Basseville and Nikiforov, 1993] Mich`ele Basseville and Igor V.
Nikiforov. Detection of Abrupt Changes: Theory and Applica-
tion. Prentice Hall, 1993.

[Blum and Mitchell, 1998] Avrim Blum and Tom M. Mitchell.
Combining labeled and unlabeled sata with co-training. In COLT,
pages 92–100, 1998.

[Domingos and Hulten, 2001] Pedro Domingos and Geoff Hulten.
Catching up with the data: Research issues in mining data
streams. In DMKD, 2001.

[Gargi et al., 2000] Ullas Gargi, Rangachar Kasturi, and Susan H.
Strayer. Performance characterization of video-shot-change de-
tection methods.
IEEE Trans. Circuits Syst. Video Techn.,
10(1):1–13, 2000.

[Ho and Wechsler, 2005a] Shen-Shyang Ho and Harry Wechsler.
Adaptive support vector machine for time-varying data streams
using martingale. In Leslie Pack Kaelbling and Alessandro Saf-
ﬁotti, editors, IJCAI, pages 1606–1607. Professional Book Cen-
ter, 2005.

[Ho and Wechsler, 2005b] Shen-Shyang Ho and Harry Wechsler.
On the detection of concept change in time-varying data streams
by testing exchangeability. In Proc. 21st Conference on Uncer-
tainty in Artiﬁcial Intelligence, pages 267–274, 2005.

[Ho, 2005] Shen-Shyang Ho. A martingale framework for concept
change detection in time-varying data streams. In Luc De Raedt
and Stefan Wrobel, editors, ICML, pages 321–327. ACM, 2005.
[Lefevre et al., 2003] S´ebastian Lefevre, J´erˆome Holler, and Nicole
Vincent. A review of real-time segmentation of uncompressed
video sequences for content-based search and retrieval. Real-
Time Imaging, 9:73–98, 2003.

[Muslea et al., 2002] Ion Muslea, Steven Minton, and Craig A.
Knoblock. Active + semi-supervised learning = robust multi-
view learning. In Claude Sammut and Achim G. Hoffmann, edi-
tors, ICML, pages 435–442. Morgan Kaufmann, 2002.

[Page, 1954] E. S. Page.

Biometrika, 41:100–115, 1954.

Continuous

inspection schemes.

[Vovk et al., 2003] Vladimir Vovk, Ilia Nouretdinov, and Alexan-
der Gammerman. Testing exchangeability on-line.
In Tom
Fawcett and Nina Mishra, editors, ICML, pages 768–775. AAAI
Press, 2003.

[Vovk et al., 2005] Vladimir Vovk, Alex Gammermann, and Glenn
Shafer. Algorithmic Learning in a Random World. Springer, New
York, 2005.

[Wald, 1947] A. Wald. Sequential Analysis. Wiley, N. Y., 1947.
[Zhai and Shah, 2005] Y. Zhai and Mubarak Shah. A general
framework for temporal video scene segmentation. In Proc. 10th
International Conference on Computer Vision, Beijing, China,
2005.

Figure 6: The characteristics of martingale values Mn using
both the image representations Rcc and Ree on the example
in Figure 3. The edge feature is more sensitive than the color
feature in this particular example.

occurs. We compare the multiple-martingale test (MT (20))
with the alternative methods. For the alternative methods,
the color histogram is used as the image representation and
the local threshold is selected based on window averaging
[Gargi et al., 2000] on three similarity measures: histogram
intersection (HI), chi-square measure (χ2) and Euclidean dis-
tance (ED), to measure the similarity between any two image
frames for all the image frames in a video sequence. The pa-
rameters, such as the window size, are varied so that the best
results can be obtained from the alternative methods. The ex-
perimental results on the four video sequences are shown in
Table 1.

Method

MT (20)

HI

χ2

ED

Video
Length
Frames
Shots

Precision
Recall

F1

Precision
Recall

F1

Precision
Recall

F1

Precision
Recall

F1

anni
0:30
913
17

0.933
0.824
0.875
0.813
0.765
0.788
1.000
0.765
0.807
0.765
0.765
0.765

ugs
1:11
2145
13

0.857
0.923
0.889
0.733
0.846
0.785
0.706
0.923
0.800
0.520
1.000
0.684

outdoor

1:20
1202
18

0.824
0.778
0.800
0.889
0.889
0.889
0.553
0.889
0.682
0.524
0.647
0.579

indoor
2:27
2210
26

0.686
0.923
0.787
0.622
0.885
0.731
0.648
0.923
0.761
0.548
0.885
0.677

Table 1: Experimental Results.

Based on the F1 measure, the multiple-martingale test performed
the best three out of the four video sequences. The main difference
between the alternative methods and ours is the fact that our thresh-
old is chosen a prior with theoretical consideration while the thresh-
olds selected by the alternative methods are heuristics such that the
window size and other parameters need to be tuned to achieve good
result. Moreover, the martingale method is a one-pass algorithm

IJCAI07

1917

