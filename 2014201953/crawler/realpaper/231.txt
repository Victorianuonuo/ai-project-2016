Improved Knowledge Acquisition for High-Performance Heuristic Search

J.P. Bekmann(1,2) and Achim Hoffmann(1)

(1) School of Computer Science and Engineering,

fjbekmann,achimg@cse.unsw.edu.au

University of New South Wales, NSW 2052, Australia.

(2) National ICT Australia (NICTA), A.T.P, NSW 1430, Australia.

Abstract

We present a new incremental knowledge acquisi-
tion approach that incrementally improves the per-
formance of a probabilistic search algorithm. The
approach addresses the known dif(cid:2)culty of tuning
probabilistic search algorithms, such as genetic al-
gorithms or simulated annealing, for a given search
problem by the introduction of domain knowledge.
We show that our approach is effective for develop-
ing heuristic algorithms for dif(cid:2)cult combinatorial
problems by solving benchmarks from the industri-
ally relevant domain of VLSI detailed routing.
In this paper we present advanced techniques for
improving our knowledge acquisition approach.
We also present a novel method that uses domain
knowledge for the prioritisation of mutation opera-
tors, increasing the GA’s ef(cid:2)ciency noticeably.

Introduction

1
Searching for good or even optimal solutions for complex
combinatorial problems has been a challenge in Arti(cid:2)cial In-
telligence research ever since AI’s earliest days.

While it has been long recognized that the effectiveness
of a particular search approach depends on the chosen rep-
resentation as well as certain characteristics of the problem
to be solved, to date there is no systematic approach avail-
able that allows one to ef(cid:2)ciently engineer a special-purpose
search strategy for a given search problem.

In this paper we present an approach that allows humans
to articulate their intuition about how to search effectively for
a given search problem. This appears to be a promising ap-
proach as humans often have good intuitions about how to
(cid:2)nd acceptable or good solutions to search problems, if they
had to search manually.

We embedded our approach in the probabilistic search
framework of Genetic Algorithms (GA). While GAs have a
reputation as being general purpose, in practice it requires
usually substantial adaptation effort to the search problem
at hand. For complex problems this process may well take
months in order to allow the GA to (cid:2)nd an acceptable solu-
tion within reasonable time.

We chose a probabilistic search algorithm in which to em-
bed the problem speci(cid:2)c knowledge about effective search

strategies as this allows one to stop the knowledge acquisi-
tion process at any time. A smaller knowledge base (KB)
results in a less effective search process, but may still (cid:2)nd a
satisfactory or near satisfactory solution for less challenging
problem instances. Incremental additions to the KB improve
the effectiveness of the search.

As part of our discussion, we present a novel technique
of varying GA mutation strategy based on execution history,
having implications beyond our work for GAs in general.

For the knowledge acquisition process we build on the idea
of Ripple Down Rules [3], which allows us to incrementally
re(cid:2)ne the given (initially empty) knowledge base. Ripple
Down Rules (RDR) ensure that a knowledge base is only
amended in a way that does not deteriorate its accuracy on
previously seen instances.

Our variant of RDR is a signi(cid:2)cant extension of the RDR
approach. We also introduce an expanded knowledge acqui-
sition process in which we help the expert (cid:2)nd examples in
past search history where the quality of the KB needs atten-
tion. This work is based on [1].

In section 2 we provide a short overview of genetic algo-
rithms and RDR. This is followed by section 3 where we de-
scribe our framework HeurEAKA!. Section 4 introduces a
case study of how HeurEAKA! was applied to detailed rout-
ing, an industrially relevant problem in VLSI design. We dis-
cuss our experiments and results to these in section 5, demon-
strating that our approach is successful. The conclusions fol-
low in section 6.

2 Background
Before we discuss our approach to combining GAs and
Knowledge Acquisition, we start with a brief summary of
these two areas:
2.1 Probabilistic Search with Genetic Algorithms
A number of evolutionary algorithms exist; we base our ap-
proach on genetic algorithms which is one such algorithm.
Basic GAs are relatively easy to implement. A solution candi-
date for the given problem instance is encoded into a genome.
A set of genomes makes up a population of potential solu-
tions. The GA performs a search through the solution space
by modifying a population of genomes, guided by an evolu-
tionary heuristic. When a suitable solution has been identi-
(cid:2)ed, the search terminates.

GAs usually start with a randomly initialized population
of individuals, and guide their search by a (cid:2)tness function of
the individuals. In a probabilistic fashion, using operators for
selection, mutation and crossover, the GA attempts to direct
the search to promising areas. I.e. the GA maintains a certain
population size by replacing less (cid:2)t individuals by newly gen-
erated ones. The new individuals are generated by mutation
or cross-over based on parent individuals of high (cid:2)tness.

Due to their generality and (cid:3)exibility, GAs have been ap-
plied in many domains, demonstrating their effectiveness on
hard problems [4; 6]. In very complex domains there are sig-
ni(cid:2)cant challenges where generic GA techniques do not scale
well. This includes high sensitivity to problem encoding and
operator formulation, selection strategies, as well as selection
of operator weightings, population size and running time[7;
13; 6]. Thus in practice substantial tuning of the GA is nec-
essary to augment the generic algorithms.

In our approach, we do not use an encoding of our prob-
lem into a binary code as is often seen with conventional GAs.
Instead, our encoding is a direct representation of a solution
(see below for a better description). Our crossover operator
is designed for this representation and thus is very effective
in maintaining sub-solution coherence in the genome, and
also identifying which areas of the genome appear (cid:2)tter than
others. We have a simple yet effective crossover operator,
and chose to concentrate our work on the mutation operator
- mainly because it was better suited to our the knowledge
acquisition approach.

Our approach integrates with the GA a knowledge base
where humans can codify their intuition about useful search
steps and strategies for the given type of problem.

In addition, we present a novel method that uses domain
knowledge for the prioritisation of mutation operators, in-
creasing the GA’s ef(cid:2)ciency noticeably. Because we have
suf(cid:2)cient domain knowledge in our (cid:2)tness function, we can
identify parts of the genome that are desirable or undesirable
and use that knowledge to in(cid:3)uence mutation strategy. We
also show how using the mutation history of these identi(cid:2)ed
characteristics to change mutation selection strategy.
2.2 Knowledge Acquisition using Ripple Down

Rules

RDR [3] allows one to add rules to a knowledge base in-
crementally without compromising the previously shown sat-
isfactory performance of the KB. An extension of RDR
allows hierarchical structuring of RDRs - (cid:147)nested RDR(cid:148)
(NRDR) [2]. NRDR allows the re-use of de(cid:2)nitions in a KB,
as well as the abstraction of concepts, which allows for more
compact KBs.

Single Classi(cid:2)cation Ripple Down Rules (SCRDR) use a
binary tree where the root node is also called the default node.
To each node in the tree a rule is associated, with a condition
part and a conclusion which is usually a class - in our case
it is an operator application though. A node can have up to
two children, one is attached to an except link and the other
one is attached to the so-called if-not link. The condition of
the default rule in the default node is always true and the con-
clusion is the default conclusion. When evaluating a tree on
a case (the object to be classi(cid:2)ed), a current conclusion vari-

able is maintained and initialised with the default conclusion.
If a node’s rule condition is satis(cid:2)ed, then its conclusion over-
writes the current conclusion and the except-link, if it exists,
is followed and the corresponding child node is evaluated.
Otherwise, the if-not link is followed, if it exists, and the cor-
responding child node is evaluated. Once a node is reached
such that there is no link to follow the current conclusion is
returned as a result.

If <true> then ...
except

If 

a

then

V

except

If 

d

then

W

false
X

then

If 

ef

except

If 

g

then

Y

false
Z

then

If 

hij

Figure 1: A simple RDR structure. The dashed line
indicates the path taken & rule executed (V ) for ade,
the bold box indicates how action Z would be added for
adghij.

Figure 2.2 shows a simple RDR tree structure. In bold is
a rule that a user might have added for the case where con-
ditions adghij hold, causing action Z to be executed, instead
of W.

For the purpose of integrating with the Genetic Algorithm,
in our approach each case is a genome and conclusions are ac-
tually a sequence of actions that can be applied to the genome.
In typical RDR implementations, any KB modi(cid:2)cation
would be by adding exception rules, using conditions which
only apply to the current case for which the current knowl-
edge base is inappropriate. By doing this, it is ensured that
proper performance of the KB on previous cases is main-
tained.

Nesting RDRs allows the user to de(cid:2)ne multiple RDRs in
a knowledge base, where one RDR rule may use another,
nested RDR tree in its condition, (and in HeurEAKA! as part
of an action, see section 3). I.e. the nested RDR tree is eval-
uated in order to determine whether the condition is satis(cid:2)ed.
A strict hierarchy of rules is required to avoid circular de(cid:2)ni-
tions.

3 HeurEAKA! - Our Framework for

Improving Search with Domain Knowledge
The HeurEAKA! (Heuristic Evolutionary Algorithm with
Knowledge Acquisition) framework is composed of a general
GA scheme and a knowledge acquisition (KA) component.

Each genome in the GA population represents a potential
solution to the problem to be solved. While searching, the
GA needs to perform a (cid:2)tness evaluation and the mutation
of a genome. For this it uses the two knowledge bases, the
Mutation KB and Fitness KB. The GA presents a genome to
the relevant KB, which responds by suggesting a mutation or
(cid:2)tness score. (The crossover function is handled differently,
more details below).

The KA module handles maintenance of the KBs, which
contain collections of NRDRs. The NRDRs are incremen-
tally developed by the expert through the addition of rules

(the next section contains a detailed description of this pro-
cess).

The Fitness KB contains rules based on past examples
given by the expert about desirable and undesirable traits of
genomes. The GA requires a (cid:2)tness value, so the rules con-
tain various calculations the expert adds to re(cid:3)ect these traits.
The Mutation KB similarly contains rules accumulated
from expert recommendations. Each rule contains an action
to be executed under certain conditions. Each action is one
or more commands which can modify the genome. The KB
contains a set of NRDRs which contain these rules. When
a genome is presented to the Mutation KB, it is evaluated
against these NRDRs. In accordance to the RDR algorithm,
actions which satisfy the relevant conditions are selected for
execution. A non-deterministic element is introduced by let-
ting the expert attach probabilistic weights to selected NR-
DRs and letting a random procedure pick which one to exe-
cute. This allows the expert leeway to speculate about what
the best actions might be, effectively letting the GAs heuris-
tics (cid:147)decide(cid:148) the most appropriate action.

As opposed to other methods related to case-based reason-
ing and GAs (e.g. [12] or
[11]), the expert uses past cases
to formulate rules to explain improvements, rather than using
past examples or similar solutions injected into the evolution-
ary process, or trying to extract the rules automatically.

The overall architecture of HeurEAKA! is domain neutral.
The implementation contains KB management modules, GA,
a graphical user interface as well as range of utilities support-
ing the expert evaluate past searches. This is complemented
with a smaller component that needs to be implemented for
each problem domain containing a relevant solution repre-
sentation. The user interface also requires a small addition to
translate this representation for visualisation.

A general purpose language is extended with primitives to
make it suitable for describing the domain speci(cid:2)c represen-
tation. Rules entered by the expert are speci(cid:2)ed using this
simple language, which is loosely based on (cid:147)C(cid:148) syntax. The
rule conditions use logical expressions while actions include
a range of commands, including variables, loops and refer-
ences to other NRDRs which are evaluated analogously to
function calls. Section 5 gives examples of rule speci(cid:2)cation.
3.1 The Knowledge Acquisition process in

HeurEAKA!

The overall approach allows the user to run the Genetic Al-
gorithm with the current KBs and monitor or inspect after-
wards whether the (cid:2)tness function computed for an individ-
ual as well as the applied mutation operator where appropri-
ate/promising steps to do.

To do that, the genetic algorithm can be started, stopped
and reset via a graphical user interface. A snapshot of the GA
population is presented visually, from which the user can pick
an individual for closer inspection.

Figure 2 shows an individual genome being inspected. A
user can step through the process of mutation and evaluation
of that genome as if the solution was part of the GA popu-
lation. Given non-deterministic elements of operator selec-
tion, the interactive debugger maintains complete state de-
scriptions, allowing the user to step forward and backwards in

execution history and also recreating conditions for repeated
testing.

The expert can review actions applied to the genome and
make modi(cid:2)cations to the KB if he/she feels they are needed.
The modi(cid:2)cations are typically done by adding exceptions to
the NRDR (in accordance with RDR methodology described
above), but may also be an edit of an existing rule or the ad-
dition of a new NRDR.

In the traditional Ripple Down Rules approach it is as-
sumed every rule entered is correct and has its reason to be
there, modi(cid:2)cation of a rule may have undesirable side ef-
fects which are often dif(cid:2)cult to control. While these are valid
reasons for not modifying rules, our experiments suggest that
it is sensible to modify rules at the beginning of building a
knowledge base. In particular, for the de(cid:2)nition of mutation
operators it proved useful to have this option to modify rules.

Figure 2: The interactive screen allows the user to inspect the
individual genome, step through rule application, and amend
the KB as needed.

3.2 Advanced features for supporting Knowledge

Acquisition

Once a suf(cid:2)ciently large KB has been created based on small-
scale evaluation, more automated methods are needed to sup-
port a user’s interaction:

Genome Visualisation: One of the strengths of using RDR
is that the approach is successful in eliciting tacit knowl-
edge [3], since rules are formulated while the system is in
use and with the justi(cid:2)cation of an example. With complex
problems (such as is described in section 4), the visualisation
of a solution is very important in allowing the user to form
an intuitive understanding. In the evaluation module, there is
immidiate visual feedback when rules are applied.

Trigger functions: During the execution of the GA, thou-
sands or even hundreds of thousands of rule applications to all
manner of genomes are made. It is not possible for the expert
to supervise each case. The user can de(cid:2)ne a trigger func-
tion which is applied to each genome during the execution
of the GA. If the function’s condition is met, an exception is

thrown, halting the GA’s execution, providing a pointer to the
individual along with an execution trace of recently applied
rules.

100

s
t
c
i
l
f
n
o
C

80

60

40

20

0

0

Comparing different KBs
(avg. run for: layout: 30 pin, 25 tracks, density 20)

Minimal KB
Small KB
Large KB

400

600

800

1000

200

Total Mutations / Population Size
(note: this axis is abridged for compactness;

 only the Large KB reaches 0 conflicts)

Figure 3: NRDR usage in
genome. The legend shows the
number of con(cid:3)icts (less is bet-
ter). Arrow: an NRDR which
is much less useful after an er-
ror was introduced by the expert
(the top graph is before the error,
the lower one after).

Figure 4: The (cid:147)minimal(cid:148) KB
and (cid:147)small(cid:148) KB are unable to
solve problem. The more mature
KB can solve it effectively.

NRDR usage pro(cid:2)le: Execution statistics are kept for each
NRDR execution, recording the frequency of use over many
GA runs. Comparing the pro(cid:2)le of aggregate use of NR-
DRs by successful vs less successful genomes (judging by
their (cid:2)tness function and how soon they were eliminated from
the GA population), provides some impression of an NRDRs
(cid:147)usefulness(cid:148) and role in GAs lifetime. Figure 3 shows the
frequency of a few selected NRDRs relative to the genome’s
age (the examples are from the VLSI case study discussed in
the next section).

In the less (cid:2)t genomes, some operators have a high count
compared to the (cid:2)tter genomes. These operators turn out to
be (cid:147)high churn(cid:148) operators - they can affect large sections of a
genome. In the earlier stages of a GA these NRDRs support
high entropy and thus allow the search to cover more search
space. When the genome is closer to the ideal solution, i.e.
has more desirable characteristics in place, these NRDRs dis-
rupt established (cid:147)good(cid:148) con(cid:2)gurations. Their relative usage
frequency in (cid:2)tter populations is thus lower.

The characterisation of NRDR utility can only provide the
expert with a rough idea of its (cid:147)usefulness(cid:148). In that context
it did contribute somewhat to the intuition the expert devel-
oped when doing KA. Where it was found to be quite useful
though, was when the expert introduced some modi(cid:2)cation
to the NRDR which inhibited it from functioning as well as
previously - meaning that it was much less used in arriving
at (cid:2)t genomes. This helped catch at least a few of errors. In
(cid:2)gure 3 the arrow indicates such an NRDR.

Tuning probabilistic weighting of NRDRs: In section 3
we mentioned the notion of using probabilistic weightings to
affect the GA’s selection of NRDRs. This allows the expert
to (cid:147)tune(cid:148) the KB when he/she has a good intuition as to what
action might be useful, but is not entirely sure.

In our experiments we identi(cid:2)ed a set of NRDRs which
would probably be useful for various types of problems. For

these we created weightings giving preference to the relevant
NRDRs. This was in the (cid:2)nal stages of re(cid:2)ning our KB,
where we allowed 1/4 of all modi(cid:2)cations to be decided ran-
domly, and 3/4 based on the probabilistic weightings based
on problem classi(cid:2)cations. With this we saw a measurable
improvement in our search results.

In the experiments conducted in our test domain, we saw a

measurable improvement in our search.

Identifying genome modi(cid:2)cations of interest: Some-
times a genome mutation plays a role in the long term success
of that genome, but the immediate result of the mutation is a
reduction or no change in its (cid:2)tness. In general, GAs cope
with this by having a large enough population pool and pre-
venting premature (cid:2)tness convergence, so as not to throw out
such genomes too soon. In traditional GAs it is hard to oth-
erwise account for these cases. Given that we have an expert
who can make judgment on individual examples using intu-
ition and hindsight, the (cid:2)tness function can be augmented to
bridge the interval needed to see a promising mutation come
to fruition.

The problem comes with identifying these candidate muta-
tions in order to present them to the expert. We identi(cid:2)ed
all the mutations falling into a window size of 10 actions
prior to a (cid:2)tness improvement exceeding a given threshold.
These were collected for review for the expert’s considera-
tion. In practice we found there was too much data to effec-
tively judge the cases by hand.

We then tried using a discounted reward scheme, and some
other methods to help reduce the candidate space, but have
not yet been able to improve matters. This aspect of the
project are currently being worked on.

3.3 Advanced features for use in Knowledge

Acquisition

Preferences in choosing parts of the genome to mutate:
As hinted at in the genetic algorithms section (2.1), we have
introduced a novel method of choosing parts of a genome for
mutation. In our (cid:2)tness function we are able to identify parts
of the genome that are undesirable.

We keep track of the modi(cid:2)cation of those parts over time,
and give a higher preference weighting to newly arising prob-
lem areas. This is done by keeping a list of existing problem
areas and discounting their preference weighting after each
(cid:2)tness evaluation. When it comes to choosing a part of the
genome to mutate, we normalise these weights and make a
probabilistic choice of the identi(cid:2)ed problems. This results in
newer problem areas having a higher chance of being picked.
With this scheme we allow some continuity in search direc-
tion, potentially overcoming local minima in the search space.
In the context of our experimental domain, we empirically
found a 65% discount factor gave the best results. Compared
with no discount scheme (giving all identi(cid:2)ed problem areas
equal chance) the number of successful GA trials was 85%
higher, and the successful trials took on average half the time
to complete.

Mutation look-ahead: We added a feature that allows the
expert to make use of a (cid:147)mutation look-ahead(cid:148) function in

the rule speci(cid:2)cation. This function allows for the compari-
son of a genome before and after a mutation has been made.
This effectively allows a local search in the mutation NRDR
(similar to a Lamarckian learning mechanism in evolutionary
algorithms).

Our knowledge base incorporated local search by com-
paring the (cid:2)tness of a genome before and after a candidate
mutation. This can be used in an RDR at any point, but
was most successfully used for a generalised mutation look-
ahead. Here, for each mutation a series of 10 steps, each rec-
ommended by the mutation KB was used, while the (cid:2)tness
values were recorded. The point of highest (cid:2)tness value in
the sequence was picked as the (cid:2)nal mutation.

When using the look-ahead mechanism, GA trials had a
signi(cid:2)cantly higher success rate. Each successful trial was
also faster to converge on a solution (as measured in overall
execution time).

4 Case Study - Detailed VLSI Routing
In order to demonstrate that genetic algorithms enhanced with
knowledge acquisition can be used to develop algorithms for
solving complex combinatorial problems, detailed channel
routing as well as switchbox routing, both industrially rele-
vant problems within the realm of VLSI design, were chosen
to demonstrate the approach.
4.1 Domain Speci(cid:2)cs
A channel routing problem (CRP) is given by a channel of a
certain width. On both sides of the channel are connection
points. Each connection point belongs to a certain electrical
net and all connection points of the same net need to be phys-
ically connected with each other by routing a wire through
the channel and, of course, without two nets crossing. The
width of the channel determines how many wires can run in
parallel through the channel. The length of the channel de-
termines how many connection points on both sides of the
channel there may be. Furthermore, the layout is done on
a small number of different layers (e.g. 2 to 4 layers), to
make a connection of all nets without crossing possible at all.
Two adjacent layers can be connected at any point using a
so-called via.

The switchbox routing problem (SRP) is similar to the CRP
but usually more dif(cid:2)cult, as it deals with connections on all
four sides rather than only two. A solution to the CRP and
SRP will be referred to as a layout.

Genome Encoding: A genome describes the layout of a
CRP or SRP solution. This takes the form of a list of straight
wire segments.

Initially, a genome will usually not represent a valid solu-
tion as some wires are usually crossing. Only when all those
crossings have been eliminated and not more than the pre-
scribed number of layers are used would the (cid:2)tness value of
a genome reach a satisfactory level.

Genome Operations: Individuals in the GA are initialised
with a random wire layout without regard to con(cid:3)icts. The
GA operates on a genome by crossover, mutation and eval-
uation. However, the GA’s crossover operation is currently
not controlled by a knowledge base. The crossover for our

layout problems groups wires into mutually exclusive sets,
one of those sets is exchanged between parents (i.e. the cor-
responding wires are exchanged). The crossover operator is
thus highly sensitive to the structure of the problem, as well
as interaction between its elements. The formulation of the
crossover operator is domain speci(cid:2)c, and we plan to make it
part of the knowledge acquisition cycle in future versions.

Evaluation is done using the evaluation KB. Typically the
user uses as a (cid:2)tness criteria the number of layers and con-
(cid:3)icts in a layout. The length of wires, number of vias and
possible cross-talk (electronic interference occurring in par-
allel wires) are also useful (cid:2)tness criteria.

The mutation KB contains rules designed to manipulate the
layout, typically they would describe the resolution of a con-
(cid:3)ict identi(cid:2)ed using the .(cid:2)ndcon(cid:3)ict command (a primitive
function returning a con(cid:3)ict found in the layout).

Example of rules applied to the Switchbox Routing
problem: Initially, a KB is built up de(cid:2)ning operators us-
ing primitives based on node and wire manipulation. These
form the foundation for more high-level concepts which can
be used intuitively by an expert.

Assuming we start with a KB with relatively high-level
actions de(cid:2)ned, e.g. MoveVerticalSegmentRight, and Move-
HorizontalSegmentUp. When applied to the example in (cid:2)g-
ure 5, it seems that the action MoveVerticalSegmentRight is
unlikely to lead to a promising solution. The expert can
amend the KB to suggest an alternative action. (see nodes
labeled N1 and N2 in (cid:2)gure 5). In this case, the user will (cid:2)nd
that MoveVerticalSegmentRight is undesirable, and formulate
a rule with condition is Vertical(N1) && is Horizontal(N2)
&& right of(N2.next,N1), and action MoveHorizontalSeg-
mentUp(N1.prev). This rule would be added as an exception
in the KB. The operators referenced here are de(cid:2)ned as RDRs
elsewhere in the KB. is Vertical(N1) returns true if the seg-
ment between N1 and its succeeding node is vertical (change
in row), is Horizontal(N2) returns true if the segment be-
tween N2 and its successor is horizontal (change in column).
right of(N2.next,N1) will return true if the node succeeding
N2 lies to the right of N1.

Figure 5: An exception is created by the expert, replacing the ac-
tion MoveVerticalSegmentRight suggested by the KB, with the ac-
tion MoveHorizontalSegmentUp(N1.prev). (The tags N1 and N2 are
referenced in the text).

5 Experiments and Results
Experiments: In order to test our approach and the imple-
mented tool, a KB was created. Initial tests were done with a
KB containing 2 RDRs and 10 rules, later tests were run with
50 RDRs and 167 rules and 53 RDRs and 182 rules.

In order to show that the introduction of domain knowledge
improved the search, we tested three different KBs: A (cid:147)mini-
mal(cid:148) KB with 5 rules, a (cid:147)small(cid:148) KB containing 10 rules, and
a (cid:147)large(cid:148) KB containing 167 rules. Using the (cid:2)rst two, the
GA was unable to solve the given problem, while using the
third, it was. Fig.4 shows progressive improvement in search
with KB size.

A KB containing 53 RDRs and 182 rules was created. Ini-
tial rules were low-level in nature, dealing with manipulation
of nodes and wires. This technical work required frequent
editing and debugging. Using the validation module with trig-
ger functions (described above) was helpful at this stage.

After the low level rules were de(cid:2)ned, rules could be de-
(cid:2)ned at a higher level of abstraction. Because this was a more
intuitive abstraction level, it was easier to formulate rules and
required less revision. The high level NRDRs were used by
the mutation KB, for what the probabilistic algorithm was in-
tended: choosing from the different high level strategies in an
attempt to resolve con(cid:3)icts.

Results: We were able to solve well recognised bench-
marks from the domain of switchbox and channel routing.
These included Burstein’s dif(cid:2)cult channel routing problem,
Burstein’s switchbox routing problem, the DENSE switchbox
and the JOO 6 16 problem, amongst others. The solutions
found were comparable to others’ attempts, including those
of the WEAVER, Silk, Packer and Monreale routers [9], [5],
[10].

While GAs have been successfully used in many domains,
in practice they often require considerable augmentation to
make the generic architecture effective in complex domains.
The unconventional KA technique of RDR formalises this
adaptation process, allowing an expert to intuitively develop a
domain-speci(cid:2)c solution. In order to use RDR for integration
with GAs, we have introduced new methods to make them
work with probabilistic search.

We have also presented a number of advanced techniques
that enhance the KA process. These include the use of trig-
ger functions, NRDR usage pro(cid:2)les and weightings, mutation
look-aheads and automatic case identi(cid:2)cation.

As part of our mutation operators, we have identi(cid:2)ed a
promising technique for improving probabilistic search by us-
ing the mutation history of a genome to bias the search into
more recent areas of exploration. We have found this heuris-
tic to return promising results.

The application of our framework in the well understood
domain of detailed channel routing and switchbox routing,
enables us to compare our results against industrially used
algorithms. We have shown that we are able to solve accepted
benchmarks competitively, using far less effort than needed
for the development of conventional algorithms.

In future work we will investigate the application of our
techniques to a different domain. Another worthwhile direc-
tion would be to explore the applicability of our advanced KA
techniques to more traditional KA domains outside of search.

Figure 6: Solution to Burstein’s
switchbox problem.

A sample channel routing

Figure 7:

solution.

We found it initially dif(cid:2)cult to complete some of the more
challenging benchmarks until we used the techniques listed
in sections 3.2 and 3.3

On average rules took approximately 10 minutes each to
formulate, taking about 30 hours for the formulation of a
viable knowledge base. The formulation of effective CRP
and SRP algorithms has been the subject of much study and
industry-standard algorithms took many years to develop [8].
In our case KA was done by a novice, using mainly intuition
and being able to incrementally specify rules in a natural way
on the knowledge level. Thus the effort and expertise required
was signi(cid:2)cantly less than commercial routing solutions.

6 Conclusion
We have presented an approach to solving complex combina-
torial problems by using a generic search algorithm and incre-
mentally introducing domain knowledge in order to make the
search tractable. We use knowledge acquisition that supports
the exploratory development of solutions, which, when com-
bined with a GA, makes it easier to tackle dif(cid:2)cult problems
than having to design a conventional algorithm.

[2]

[3]

[4]

[5]

[6]

[7]

[8]

[9]

[10]

[11]

[12]

[13]

References
[1]

Incremental Knowledge Acquisition for Im-
Bekmann, J.P., Hoffmann, A.:
proving Probabilistic Search Algorithms. In: 14th International Conference on
Knowledge Engineering and Knowledge Management (2004) 248(cid:150)264.
Beydoun, G., Hoffmann, A.: Theoretical basis for hierarchical incremental
knowledge acquisition. In: International Journal in Human-Computer Studies.
(2001) 407(cid:150)452
Compton, P., Jansen, R.: Knowledge in context: A strategy for expert system
maintenance. In: 2nd Australian Joint Arti(cid:2)cial Intelligence Conference. Vol-
ume 1. (1989) 292(cid:150)306
De Jong, K., Spears, W.: Using genetic algorithm to solve NP-complete prob-
lems. In Schaffer, J.D., ed.: Proc. of the Third Int. Conf. on Genetic Algorithms,
San Mateo, CA, Morgan Kaufmann (1989) 124(cid:150)132
Gockel, N., Pudelko, G., Drechsler, R., Becker, B.: A hybrid genetic algorithm
for the channel routing problem. In: International Symposium on Circuits and
Systems, volume IV. (1996) 675(cid:150)678
Goldberg, D.E.: The Design of Innovation: Lessons from and for Competent
Genetic Algorithms. Volume 7, Kluwer Series on Genetic Algorithms and Evo-
lutionary Computation. Kluwer Academic Publishers (2002)
Holland, J.: Adaptation in Natural and Arti(cid:2)cial Systems. University of Michi-
gan Press. (1975)
Lengauer, T.: Combinational Algorithms for Integrated Circuit Layout. B.G.
Teubner/John Wiley & Sons (1990)
Lienig, J., Thulasiraman, K.: A new genetic algorithm for the channel routing
problem.
In: 7th International Conference on VLSI Design, Calcutta (1994)
133(cid:150)136
Lin, Y., Hsu, Y., Tsai, F.: Silk: A simulated evolution router. In: IEEE Transac-
tions on CAD. Volume 8.10. (1989) 1108(cid:150)1114
Liu, X.: Combining genetic algorithm and case-based reasoning for struc-
ture design. Masters Thesis (1996), Department of Computer Science, Univ.
of Nevada.
Perez, E.I., Coello, C., Aguirre, A.H.: Extraction and reuse of design patterns
from genetic algorithms using case-based reasoning. In: Soft Computing 9(1)
(2005) Springer 44(cid:150)53.
Rothlauf, F.:
Springer Verlag (2002)

Representations for Genetic and Evolutionary Algorithms.

