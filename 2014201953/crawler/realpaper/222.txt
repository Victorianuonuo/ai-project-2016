Inferring Useful Heuristics from the Dynamics of Iterative Relational Classiﬁers

Aram Galstyan and Paul R. Cohen
USC Information Sciences Institute
4676 Admiralty Way, Suite 1001
Marina del Rey, California 90292

fgalstyan,coheng@isi.edu

Abstract

In this paper we consider dynamical properties of
simple iterative relational classiﬁers. We conjec-
ture that for a class of algorithms that use label–
propagation the iterative procedure can lead to non-
trivial dynamics in the number of newly classiﬁed
instances. The underlaying reason for this non–
triviality is that in relational networks true class la-
bels are likely to propagate faster than false ones.
We suggest that this phenomenon, which we call
two-tiered dynamics for binary classiﬁers, can be
used for establishing a self–consistent classiﬁca-
tion threshold and a criterion for stopping iteration.
We demonstrate this effect for two unrelated binary
classiﬁcation problems using a variation of a itera-
tive relational neighbor classiﬁer. We also study an-
alytically the dynamical properties of the suggested
classiﬁer, and compare its results to the numerical
experiments on synthetic data.

1 Introduction
Recently there has been a growing interest in relational learn-
ing and classiﬁcation. While traditional learning approaches
assume different data instances are independent and identi-
cally distributed, relational classiﬁcation methods allows for
the study of more complex data structures because it explic-
itly takes into account their existing links and relations. Re-
cently developed algorithms for relational classiﬁcation have
been used for learning probabilistic relational models [Fried-
man et al., 1999], hypertext classiﬁcation [Getoor et al.,
2001], web page classiﬁcation [Slattery and Craven, 2000;
Macskassy and Provost, 2003], link prediction [Taskar et
al., 2004], discovery of authoritative information [Kleinberg,
1999], studying relational structures in scientiﬁc publica-
tions [McGovern et al., 2003], etc.

Most of the existing methods for relational classiﬁcation
are iterative in nature [Neville and Jensen, 2000; Macskassy
and Provost, 2003]. The intuitive assumption behind the it-
erative approach is that information inferred about one entity
can be used to make inferences about other entities that are
related to it. This allows class labels (or associated probabil-
ities) to propagate throughout the system as newer instances
are classiﬁed. Although iterative classiﬁers have been shown

to enhance prediction accuracy [Neville and Jensen, 2000;
Macskassy and Provost, 2003], there is an associated risk:
a few false inferences sometimes lead to a “snow-ball” effect
[Neville and Jensen, 2000] cascading the number of misclas-
siﬁed entities as iteration proceeds. As a consequence, the
ﬁnal results will depend strongly on the accuracy of initially
assigned class labels and on the classiﬁcation criteria, i.e.,
model parameters. More generally, it is known that many
classiﬁcation algorithms are sensitive to parameter settings.
For example, [Keogh et al., 2004] found that few popular
data mining algorithms performed well on multiple problems
without parameter adjustments.

In this paper we argue that for a class of iterative classiﬁers
the issue of parameter sensitivity can be addressed in a self
consistent and elegant manner by examining the dynamics of
the iterative procedure more closely. We illustrate this point
for a simple iterative classiﬁer that uses a threshold–based
criterion for labelling data–instances, and propose a meta–
heuristic for setting the optimal threshold value. Our heuristic
is based on the assumption that in relational networks true
class labels are likely to propagate faster than false ones. We
demonstrate that this phenomenon, which we call two-tiered
dynamics, can serve as a natural criterion for both setting a
threshold value and stopping the iteration. Hence, our method
reduces the dependency of iterative classiﬁcation on model
parameters.

To illustrate our approach, we introduce a simple algo-
rithm for relational binary classiﬁcation. We consider the
case when the relation between two data–instances is char-
acterized by the weight of the link connecting them, so that
the relational structure is fully determined by an adjacency
matrix M. Given an initial set of known instances of a class
A, our algorithm then deﬁnes an iterative scheme with a sim-
ple threshold based rule: an instance will be classiﬁed as type
A if it is connected to super–threshold number of classiﬁed
or initially known instances of type A. The novelty of our
approach is that we suggest a self–consistent way of setting
the parameter of our model, the threshold: namely, we set it
automatically to the value that produces the most pronounced
two-tiered dynamics. We present empirical results that illus-
trate the use of this approach. We also develop an analytical
framework for describing the dynamics of iterative classiﬁca-
tion of our algorithm, and compare its predictions with results
obtained for synthetic, randomly generated networks.

The rest of the paper is organized as follows. In the next
section we provide a more detailed description of our algo-
rithm. In Section 3 we present results for two case studies that
demonstrate the two–tier dynamics. In Section 4 we present
an analytical framework for studying the dynamical proper-
ties for a binary iterative classiﬁer. Discussion on our results
and future developments are presented in Section 5.

2 Dynamics of for Iterative Classiﬁcation
To understand the main idea behind our approach, we ﬁnd
it illustrative to frame the classiﬁcation problem as an epi-
demic process. Speciﬁcally, let us consider a binary classi-
ﬁcation problem deﬁned on a network where data–instances
(from classes A and B) correspond to nodes and the rela-
tions between them are represented by (weighted) links. We
are given the correct classiﬁcation of a small subset of nodes
from class A and want to classify other members of this class.
Assume that we are using a simple, threshold based iterative
relational classiﬁer (such as one described below in Fig. 1),
for assigning class labels and propagating them through the
system. Now, if we treat the initially labelled data–instances
as “infected”, then the iterative scheme deﬁnes an epidemic
model where at each time step new instances will be infected
if the super–threshold classiﬁcation criterion is met. Clearly,
the ﬁxed point of this epidemic process will depend both on
the value of the threshold and both inter– and intra–class link
structure of the network. In the case where two classes are
totally decoupled (i.e., there are no cross–links between two
sub–classes) the epidemics will be contained on the set A ,
and one can relax the classiﬁer threshold to guarantee that all
the instances of A will be correctly classiﬁed.
If there are
links between data–instances in different sub–classes, then
there is a chance that the nodes from class B will be infected
too (i.e., misclassiﬁed). However, if the link patterns between
two subclasses are sufﬁciently different, we can hope that the
process of epidemic spreading in two systems will be sepa-
rated in time. Moreover, by tuning the classiﬁcation thresh-
old, we can control the rate of epidemic spreading in sub–
population A, hence affecting the epidemic spread in sub–
population B. The main idea of our approach is to tune the
threshold parameter in order to achieve maximum temporal
separation of epidemic peaks in two classes.

We characterize the dynamics of an iterative classiﬁer by
the number of newly classiﬁed instances at each time step,
e.g., if N (t) is the total number of classiﬁed A–instances at
time t, then the relevant variable is (cid:1)N (t) = N (t)(cid:0)N (t(cid:0)1).
As it will be clear later, two–tiered dynamics arises whenever
(cid:1)N (t) has two temporally separated peaks.

To proceed further, we now formally deﬁne our binary clas-
siﬁcation algorithm. Let S be the set of data–instances to be
classiﬁed, and let assume that S is composed of two subsets
SA (cid:26) S and S(cid:0)A = S n SA. Initially, we know the cor-
rect class labels of a (small) subset of the instances of type A,
A, and the problem is to identify other members of class SA
S0
given the characterizing relations between the entities across
both types. We deﬁne Mij as the weight of the link between
the i-th and j–th entities.

We associate a state variable with each entity, si = 0; 1

so that the state value si = 1 corresponds to type A. Ini-
tially, only the entities with known class labels have si = 1.
At each iteration step, for each non–classiﬁed instance we
calculate the cumulative weight of the links of that instance
with known instances of type A. If this cumulative weight
is greater or equal than a preestablished threshold H, that in-
stance will be classiﬁed as a type A itself. This is shown
schematically in Figure 1. Note that our algorithm differs
slightly from other simple relational classiﬁers (such as Re-
lational Neighbor classiﬁer [Macskassy and Provost, 2003])
in two aspects: First, it directly assigns class labels and not
probabilities, and second, it is asymmetric in the sense that if
an instance was classiﬁed as type A it will remain in that class
for the remainder of the run. This later property implies that
the total number of classiﬁed A–instance is a monotonically
non–decreasing function of time. If the number of iterations

input adjacency matrix M
initialize si = 1, for initially known instances, si = 0 for the rest
initialize a threshold H
iterate t = 0 : Tmax

for i–th node with si(t) = 0

calculate the weight wi of adversary nodes connected to it:
wi = P Mij sj(t)
if wi (cid:21) H ) si(t + 1) = 1

end for loop

end

Figure 1: Pseudo–code of the iterative procedure

Tmax is large enough, then a steady state will be achieved,
i.e., no instance will change its state upon further iterations.
As we mentioned above, the ﬁnal state of the system will de-
pend on the threshold value and the adjacency matrix. If the
threshold value is set sufﬁciently low then the system will
evolve to a state where every instance has been classiﬁed as
type A. On the other hand, if it is set too high, then no ad-
ditional instances will be classiﬁed at all. As we will show
below, for intermediary values of the threshold H the system
will demonstrate two–tier dynamics.

3 Case Studies
In this section we test our hypothesis empirically on two dis-
tinct and unrelated data–sets: The ﬁrst is a synthetic data gen-
erated by the Hats Simulator [Cohen and Morrison, 2004],
and the second is Cora [McCallum et al., 2000], a large col-
lection of research papers in computer science.

3.1 Results for the Hats Simulator Data
The Hats simulator is a framework designed for developing
and testing various intelligence analysis tools. It simulates a
virtual world where a large number of agents are engaged in
individual and collective activities. Each agent has a set of el-
ementary capabilities which he can trade with other agents if
desired. Most of the agents are benign while some are covert
adversaries that intend to inﬂict harm by destroying certain
landmarks called beacons. There also are agents known to
be adversaries. Agents travel for meetings that are planned

by an activities generator. Each agent belongs to one or more
organizations that can be of two types, benign or adversary.
Each adversary agent belongs to at least one adversary or-
ganization, while each benign agent belongs to at least one
benign organization and does not belong to any adversary or-
ganization. When a meeting is planned, the list of participants
is drawn from the set of agents that belong to the same orga-
nization. Hence, a meeting planned by an adversary organi-
zation will consist of only adversary (either known or covert)
agents, whereas a meeting planned by a benign organization
might contain all three types of agents.

The type of data from the Hats simulator is a sequence of
lists containing unique hat ID-s that have met with each other.
Given this sequence, one can unequivocally construct a graph
(adjacency matrix) M of hats’ meeting activities, where each
entry Mij describes the number of meetings between the i–
th and j–th agents (note that the graph is not directed so the
matrix is symmetric). In the simulations presented here we
used Hats data for N = 1200 agents, (Nk = 50 known ad-
versaries, Nb = 1000 benign, and Nc = 150 covert) which
was collected for the ﬁrst 2500 ticks of simulations.

We tested our algorithm for small, large, and intermediate
values of the threshold H. For small H most of the nodes in
the network are infected after a short time, as expected (see
Fig. 2). Similarly, for large values of H (not shown here)
the epidemic spreads through only a very small subset of
nodes. In both cases the epidemics are characterized by one–
tier dynamics. The situation is drastically different for inter-
mediate values of the threshold, as the behavior of epidemic
spreading demonstrates two-tiered structure. Namely, after a
sharp initial spread the epidemic seems to be saturated. How-
ever, upon further iterations, the number of infected nodes
increases sharply, and all the nodes in the network are in-
fected shortly thereafter. Clearly, this corresponds to some
kind of threshold–phenomenon in the whole network, where
infection of certain nodes causes an epidemic in the whole
system. This is illustrated in Fig. 2(a) where we plot the
number of infected actors vs time for H = 4 and H = 6.
As we mentioned in the introduction, this behavior suggests
a natural criterion for stopping the iteration. More precisely,
in Fig. 2(b) we plot the number of newly infected nodes at
each times step versus time, i.e., (cid:1)N (t) = N (t) (cid:0) N (t (cid:0) 1).
For the threshold value H = 4 (not plotted) there is only a
single peak in (cid:1)N (t). However, for H = 6 one can distin-
guish two well–separated peaks, denoted Pa and Pb which
are indicative of two–tier dynamics in epidemic spreading. If
we assume that Pa corresponds to the epidemic spreading in
the ﬁrst (covert) sub–population, and Pb corresponds to the
rest of the network, then the iteration should be stopped right
before the infection starts to spread in the rest of the system
(i.e., at t = 5). In this particular example, we established that
if the above mentioned criterion is used, then the algorithm
correctly identiﬁes 118 out of 150 covert adversaries, while
at the same time misidentifying only 8 of the 1000 benign
nodes as adversaries. This is a surprising result especially
taking into account the simplicity of the algorithm.

More generally, our experiments with the Hats data indi-
cate that although the detection error rate of the algorithm
varies depending on the particular structure of the network,

1200

1000

800

)
t
(

N

600

400

200

0

0

350

300

250

200

)
t
(

N

150

100

50

0

0

2

4

6

P
 
a

2

4

6

(a)

H=4
H=6

8

10

Iteration Number

(b)

P
 
b

8

10

Iteration Number

12

14

16

18

12

14

16

18

Figure 2: (a) Total number of infected nodes N (t) for H = 4
and H = 6. (b) The number of newly infected instances vs
time, (cid:1)N (t) for H = 6. Two separated peaks are a clear
indication of two–tier dynamics.

the amount of the available data, as well as the presence of
noise, its performance is rather robust as long as the two–tier
dynamics is observed.

3.2 Results for Cora Data
The Cora data [McCallum et al., 2000] contains a set of com-
puter science research papers that are hierarchically catego-
rized into topics and subtopics. Each paper includes a la-
bel for a topic/subtopic/sub–subtopic, and a list of cited arti-
cles. Following the previous studies [Macskassy and Provost,
2003], we focused on the papers on Machine Learning cat-
egory, that contained seven different subtopics: Case-Based,
Theory, Genetic Algorithms, Probabilistic Methods, Neural
Networks, Rule Learning and Reinforcement Learning. Two
papers are linked together by using common author (or au-
thors) and citation.

Since our algorithm is for binary classiﬁcation, we con-
structed separate classiﬁcation problem for each topic. We
varied the fraction of known instances from as high as 50%
to as low as 2%. For each classiﬁcation task, we did up to 10
different runs using random subsets of classiﬁed hats. Note,
that initially labelled set contained papers that belong to a
class other than one we wanted to identify (the class label of
all the papers in the initially labelled sets were ﬁxed through-
out iteration.

After pruning out the isolated papers from the data–set, we
were left with 4025 unique titles. Since we observed a large
dispersion in the node connectivity ranging from 1 to more

D
than 100, we revised our threshold–based rule a little so that
the threshold condition was established not only for the total
weight, but also on the fraction of that weight.

We observed that the structure of dynamics (i.e., two–
tier vs single–tier) varied from topic to topic. From the
seven subtopics, the data that demonstrated the best mani-
festation of two–tiered dynamics was Reinforcement Learn-
ing subtopic:
it robustly demonstrated two separate peaks
from run to run for various fraction of initially known data
as shown in Fig 3(a). What is more striking, however, is
that the accuracy of classiﬁcation was remarkable even if
the fraction of initially known instances were as low as 2%
of the total number.
Indeed, as illustrated in Fig 3(b), for
2% of initially known class–labels, and from which only 7
in the Reinforcement Learning Topic, the F –Measure at the
iteration–stopping point t = 8 is FM (cid:25) 0:66. Moreover, our
experiments also suggest that increasing the number of ini-
tially labelled data does not necessarily improve the perfor-
mance. Although this seems counterintuitive, it makes sense
from the perspective of our algorithm: Indeed, the more la-
belled instances we have at the start, the better the chances
that the epidemics will leave the sub–network and start to in-
fect nodes from other classes. One could think of increasing
the threshold would help, but it did not, probably because of
large dispersion in node connectivity. Of course, one can al-
ways sample from available known instances and choose to
include only an appropriate number of them.

We observed two–tier structures in most of the other topics
too. Although some of them were not as pronounce as for
the previous case, they were robust in the sense that uprise of
the second peak almost surely corresponded with the spread
of label–propagation outside of that class. However, in some
instances, notably for the Neural Networks subtopic, we did
not observe any clear sign of this dynamics at all. Our ex-
planation is that this subcategory was vastly larger than the
RL–one (1269 compared to 344) so it was easier for the ini-
tial infection to propagate outside. This suggests that perhaps
our method is best when one wants to identify a sub-class
that is considerably smaller compared to the total number of
instances.

4 Analysis
In this section we present an analysis of our classiﬁcation al-
gorithm. Speciﬁcally, we study the epidemics spreading as
described by our algorithm. For the sake of simplicity, we
consider a case of an unweighed graph when the entries in the
adjacency matrix are either 0 or 1. Generalization to the case
of the weighed networks is straightforward. Also, for clarity
purposes we will retain the language of section 3.1 and refer
to instances as agents.

Let us start by considering only one of the subnetworks in
the system. Namely, we neglect benign agents for now and
consider a network consisting of covert and known adver-
saries only. We want to examine how the epidemic spreads
through the covert population.

We now consider the iterative procedure more closely. Ini-
tially, all of the agents except known adversaries are classiﬁed
as not–infected, si(t = 0) = 0; i = 1; 2; ::N. We deﬁne a

(a)

P
 
2

P
 
1

F

» 0.66 
M

120

100

80

60

40

20

)
t
(

N

0
0

2

4

6

0.7

0.6

0.5

0.4

0.3

0.2

0.1

e
r
u
s
a
e
M
−
F

0
0

2

4

6

8

10

12

Iteration Number (t)

(b)

F

» 0.66 
M

8

10

12

Iteration Number (t)

14

16

18

20

14

16

18

20

Figure 3: (a) (cid:1)N (t) for H = 4, with 2% of initially classiﬁed
instances. (b) F–Measure of predictive accuracy vs iteration
step. At t = 8 (the iteration stopping point), FM (cid:25) 0:66.

local ﬁeld hi for the i–th agents as the number of its connec-
tions with known adversaries. We assume that hi-s are un-
correlated random variables drawn from a probability density
function P(h). Let f (h) = Ph0(cid:21)h P(h0) be the the fraction
of agents who are connected with at least h initially known
adversary agents. Also, let ki be the number of connections
the i-th agent has with newly classiﬁed adversaries (note that
ki excludes the links to the initially known adversaries) and
assume that ki–s are described by a probability density func-
tion P (k; t). In other words, P (k; t) is the probability that
a randomly chosen uninfected covert agent at time t is con-
nected to exactly k infected covert agents. Since the number
of infected agents changes in time, so does the distribution
P (k; t). Initially, one has P (k; t = 0) = (cid:14)k;0, where (cid:14)ij is
the Kroenecker’s symbol.1.

In the ﬁrst step of the iteration, the agents who have a local
ﬁeld larger than or equal to the threshold value, hi (cid:21) H, will
change their states to 1. Hence, the fraction of agents classi-
ﬁed as adversaries at t = 1 is n(t = 1) = f (H). Since these
new adversary agents are connected to other non-classiﬁed
agents, this will alter the local ﬁelds for non-classiﬁed agents.
Let us deﬁne a variable for each agent zi = hi + ki. Then the
distribution of zi is described by

P (z; t) =

1

1

X

X

k=0

h=0

P (k; t)P(h)(cid:14)z;k+h

1Kroenecker’s symbol is deﬁned as follows: (cid:14)ij = 1 if i = j

and (cid:14)ij = 0, i 6= j.

D
=

1

X

k=0

P (k; t)P(z (cid:0) k)

(1)

Clearly, the criterion for infection is zi (cid:21) H. Hence, the
fraction of agents that will be classiﬁed as covert at time t + 1
is

n(t + 1) =

1

X

z=H

P (z; t) =

1

X

k=0

P (k; t)f (H (cid:0) k)

(2)

Note that the probability P (k; t) of being connected to an
infected agent depends on the fraction of infected agents,
P (k; t) = P (k; n(t)) . Hence, the Equation 2 is in general a
highly non–linear map. Once the functions P (k; t) and f (h)
are speciﬁed, Equation 2 can be solved (at least numerically)
to study the dynamics of epidemic spreading in a homoge-
nous, single–population network. In particular, the ﬁnal frac-
tion of infected agents is given by its steady state n(t ! 1).
The above framework is easily generalized for the case
when there are two sub–populations in the network. We de-
note two sub–populations by C (covert) and B (benign). Let
fc(h) fb(h) be the fraction of C and B agents respectively
that are connected to at least h known adversaries. Also, let
Pcc(k; t) and Pcb(k; t) be the probability that a randomly cho-
sen C agent is connected to exactly k infected C and infected
B agents, respectively. Similarly, we deﬁne Pbb(k; t) and
Pbc(k; t) as the probability that a randomly chosen B agent
is connected to k infected B and infected C agents, respec-
tively. Then the fraction of infected agents in each population
nc(t) and nb(t) satisfy the following set of equations:

(a)

simulations
theory

5

10

Iteration number

15

20

(b)

simulations
theory

P
 
b

P
 
a

5

10

Iteration number

15

20

1

0.9

0.8

0.7

0.6

)
t
(
n

0.5

0.4

0.3

0.2

0.1

0

0

0.35

0.3

0.25

0.2

)
t
(
n

0.15

0.1

0.05

0

0

Figure 4: Analytical and simulation results for (a) n(t) and
(b) (cid:1)n(t) for a random network. The results are averaged
over 100 trials

nc(t + 1) =

nb(t + 1) =

1

1

X

X

k=0

j=0

1

1

X

X

k=0

j=0

Pcc(k; t)Pcb(j; t)fc(H (cid:0) k (cid:0) j)

Pbb(k; t), Pcb(k; t) and Pbc(k; t). Hence, one obtains from
the Equation 3

Pbb(k; t)Pbc(j; t)fb(H (cid:0) k (cid:0) j)

nc(t + 1) =

1

1

X

X

k=0

j=0

[(cid:13)ccnc(t)]k

[(cid:13)cbnb(t)]j

k!

j!

(3)
To proceed further we need to make assumptions about
the distribution functions Pcc(k; t), Pbb(k; t), Pcb(k; t) and
Pbc(k; t) i.e., probability that a randomly chosen uninfected
agent of type C (B) is connected to k infected agents of
respective type. This is particularly easy to do when the
graph is obtained by randomly establishing a link between
any two agents/nodes with a ﬁxed probability. Speciﬁcally,
let us assume that each covert agent is connected to covert
and benign agents with corresponding probabilities pcc and
pcb, while each benign agent has similarly deﬁned probabil-
ities pbb and pbc (note that pcb = pbc). Hence, each covert
agent in average is connected with (cid:13)cc = pccNc covert and
(cid:13)cb = pcbNb benign agents, and each benign agent is con-
nected with (cid:13)bb = pbbNb benign and (cid:13)bc = pbcNb benign
agents.

Consider now a randomly chosen uninfected agent of ei-
ther type, say, covert, at a certain time t, and denote it as c0.
There are Ncnc(t) infected covert agents at time t, and c0
is connected with each of them with probability pcc. Hence,
the probability Pcc(k; t) that c0 is connected with exactly k
infected covert agents at time t is given by a Poisson distri-
bution with a mean (cid:13)ccnc(t). Similar arguments hold also for

(cid:2) fc(H (cid:0) k (cid:0) j)e(cid:0)(cid:13)ccnc(t)(cid:0)(cid:13)cbnb(t)

(4)

nb(t + 1) =

1

1

X

X

k=0

j=0

[(cid:13)bbnb(t)]k

[(cid:13)bcnc(t)]j

k!

j!

(cid:2) fb(H (cid:0) k (cid:0) j)e(cid:0)(cid:13)bbnb(t)(cid:0)(cid:13)bcnc(t)

(5)

Equations 4 and 5 are a system of coupled maps that gov-
erns the evolution of fraction of infected individuals in both
sub–populations. The coupling strength depends on (cid:13)cb and
(cid:13)bc , or in other words, average number of interconnec-
tions between two sub–populations. Note that if one sets
(cid:13)cb = (cid:13)bc = 0 the dynamics of two sub–populations are
totally independent and one recovers the system Equation2
with corresponding parameters for each sub–population. To
validate the prediction of our analysis, we compared Equa-
tions 4 and 5 with experiments on randomly generated graphs.
The results are shown in Fig. 4 where we plot the fraction
of the infected nodes n(t) = nc(t) + nb(t) as well as the
difference (cid:1)n(t) = n(t + 1) (cid:0) n(t) versus iteration num-
ber for a randomly generated graph of Nc = 100 covert and
Nb = 1000 benign nodes. The parameters of the graph are
pcc = 0:2, pbb = 0:04 and pcb = 0:04. Also, we chose the

D
value of the threshold ﬁeld such that to ensure two–tier dy-
namics. The results of the simulations were averaged over
100 random realization of graphs. Clearly, the agreement be-
tween the analytical prediction given by equations 4 and 5
and the results of the simulations is quite good. In particu-
lar, these equations accurately predicts the two–tier dynamics
observed in the simulations. We also note that the graphs are
structurally very similar to the results from the Hats simulator
data in Fig. 2. This suggests that despite the the explicit or-
ganizational structure in the Hats data, its infection dynamics
is well captured by a simple random–graph analysis model.
Note however, that this agreement might deteriorate for more
complex organizational structure (e.g., large overlap between
different organizations), hence more sophisticated analytical
models might be needed.

5 Discussion and Future Work
We have presented a simple, threshold based iterative algo-
rithm for binary classiﬁcation of relational data. Our algo-
rithm can be stated in terms of epidemic spreading in net-
works with two sub–populations of nodes (data–instances)
where infected nodes correspond labelled data–instances. We
also presented a meta–heuristics that utilizes the differences
in the propagation of true and false class-labels for setting
the right threshold value in our algorithm. Speciﬁcally, we
demonstrated that if the threshold value is tuned appropri-
ately, the dynamics of the number of newly classiﬁed in-
stances will have a two–peak structure suggesting that the
infection propagation in two sub–classes is time–separated.
Consequently, we suggested that the iteration should be
stopped at the point when the second peaks starts to develop.
Our empirical tests, especially with Cora, indicate that the
two–tier dynamics is not an artifact, but is present in real
world relational data. Although we did not observe this
dynamics in all the classiﬁcation tasks in Cora, our results
nevertheless indicate that whenever the two–tier dynamics
is present, it is indeed robust, and contains useful informa-
tion that can be utilized by classiﬁcation algorithm. In ad-
dition, our experiments, as well as qualitative arguments on
epidemic spreading, suggest that the method presented in this
paper should work best when the sub–class one wants to iden-
tify is a small fraction of the whole data–set, as there is a
greater chance that the class-labels will propagate throughout
the proper sub–population ﬁrst before infecting instances of
other classes.

We also developed an analytical framework for study-
In particular,
ing the properties of iterative classiﬁcation.
we obtained a coupled of set discrete–time maps the de-
scribe the evolution infected/labelled individuals in both sub–
populations. We compared our analytical results with nu-
merical experiments on synthetic data and obtained excel-
lent agreement. We would like to mention that the assump-
tion of a random graph we used in our analysis is clearly
an over–simpliﬁcation.
Indeed, most of the real–world re-
lational structures (e.g., social networks) demonstrate small-
world phenomenon that is not captured by our random graph
model. In our future work we intend to extend our frame-
work to account for more general type of networks. Note

that in this scenario the probability of being infected will be
strongly correlated with a degree of a node (i.e., more links
will imply more chances of being infected).

6 Acknowledgements
We thank Joshua Moody for preparing the Hats data.

References
[Cohen and Morrison, 2004] P. Cohen and C. T. Morrison.
In Proceedings of the 2004 Winter

The hats simulator.
Simulation Conference, Washington, DC, 2004.

[Friedman et al., 1999] Nir Friedman, Lise Getoor, Daphne
Koller, and Avi Pfeffer. Learning probabilistic relational
models.
In Proceedings of the 16th International Joint
Conference on Artiﬁcial Intelligence (IJCAI), pages 1300–
1307, Stockholm, Sweden, 1999.

[Getoor et al., 2001] L. Getoor, E. Segal, B. Taskar, and
D. Koller. Probabilistic models of text and link structure
for hypertext classiﬁcation. In Proceedings of IJCAI–01
Workshop on Text Learning: Beyond Supervision, Seattle,
WA, 2001.

[Keogh et al., 2004] E. Keogh, S. Lonardi, and C. Ratanama-
In Pro-
hatana. Towards parameter-free data mining.
ceedings of ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, Seattle, WA,
2004.

[Kleinberg, 1999] Jon M. Kleinberg. Authoritative sources
Journal of the ACM,

in a hyperlinked environment.
46(5):604–632, 1999.

[Macskassy and Provost, 2003] S.

and
F. Provost. A simple relational classiﬁer.
In Pro-
ceedings of Workshop on Multi-Relational Data Mining in
conjunction with KDD-2003, Washington, DC, 2003.

Macskassy

[McCallum et al., 2000] Andrew McCallum, Kamal Nigam,
Jason Rennie, and Kristie Seymore. Automating the con-
struction of internet portals with machine learning. Infor-
mation Retrieval Journal, 3:127–163, 2000.
L.

Friedland,
M. Hay, B. Gallagher, A. Fast, J. Neville, and D. Jensen.
Exploiting relational structure to understand publication
patterns in. SIGKDD Explorations, 5(2):165–172, 2003.

[McGovern et al., 2003] A. McGovern,

[Neville and Jensen, 2000] J. Neville and D. Jensen. Iterative
classiﬁcation in relational data. In Proceedings of AAAI-
2000 Workshop on Learning Statistical Models from Rela-
tional Data, pages 13–20, Austin, TX, 2000.

[Slattery and Craven, 2000] Se´an Slattery and Mark Craven.
Discovering test set regularities in relational domains. In
Proceedings of ICML-2000, pages 895–902, Stanford, US,
2000.

[Taskar et al., 2004] B. Taskar, M. Wong, P. Abbeel, and
D. Koller. Link prediction in relational data. In Advances
in Neural Information Processing Systems 16. MIT Press,
Cambridge, MA, 2004.

