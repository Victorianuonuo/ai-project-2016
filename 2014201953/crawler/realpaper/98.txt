Identiﬁability of Path-Speciﬁc Effects∗

Chen Avin, Ilya Shpitser, Judea Pearl

Cognitive Systems Laboratory

Department of Computer Science

University of California, Los Angeles

Los Angeles, CA. 90095

{avin, ilyas, judea}@cs.ucla.edu

Abstract

quantities

representing

Counterfactual
path-
speciﬁc effects arise in cases where we are
interested in computing the effect of one variable
on another only along certain causal paths in the
graph (in other words by excluding a set of edges
from consideration). A recent paper [Pearl, 2001]
details a method by which such an exclusion
can be speciﬁed formally by ﬁxing the value of
the parent node of each excluded edge.
In this
paper we derive simple, graphical conditions for
experimental identiﬁability of path-speciﬁc effects,
namely,
conditions under which path-speciﬁc
effects can be estimated consistently from data
obtained from controlled experiments.

Introduction

1
Total, direct and indirect effects are important quantities in
practical causal reasoning about legal, medical, and public
policy domains, among others. The task of explicating, and
computing these quantities has been successfully addressed
in the framework of linear structural equation models (SEM),
but encountered difﬁculties in non-linear as well as non-
parametric models. See for instance [Robins and Greenland,
1992], [Galles and Pearl, 1995], [Pearl, 2001],

In the linear SEM framework, the total effect of Z on Y is
the response of Y to a unit change in the setting of Z. On
the other hand, the direct effect is the effect of Z on Y not
mediated by any other variable in the model while the indirect
effect is the effect of Z on Y excluding the direct effect.

In non-parametric models, we can deﬁne the controlled di-
rect effect as the change in the measured response of Y to a
change in Z, while all other variables in the model, hence-
forth called context variables, are held constant. Unfortu-
nately, there is no way to construct an equivalent notion of
controlled indirect effects, since it is not clear to what val-
ues other variables in the model need to be ﬁxed in order to
measure such an effect.

Recently, a novel formulation of natural [Pearl, 2001] or
pure [Robins and Greenland, 1992] effects was proposed

∗This research was partially supported by AFOSR grant
#F49620-01-1-0055, NSF grant #IIS-0097082, and ONR (MURI)
grant #N00014-00-1-0617.

which deﬁned effects in a more reﬁned way by holding vari-
ables constant not to predetermined values, but to values they
would have attained in some situation. For example, the nat-
ural direct effect of Z on Y is the sensitivity of Y to changes
in Z, while the context variables are held ﬁxed to the values
they would have attained had no change in Z taken place.
Similarly, the natural indirect effect is the sensitivity of Y to
changes the context variables would have undergone had Z
been changed, while Z is actually being ﬁxed.

Being complex counterfactual quantities, natural effects
tend to have intricate verbal descriptions. It is often easier
to explain such effects using the visual intuitions provided
by graphical causal models. Graphical causal models repre-
sent causal assumptions as graphs, with vertices representing
variables, and edges representing direct causal paths. In such
models, natural direct effect can be interpreted as the effect
along the edge Z → Y , with the effect along all other edges
’turned off.’ Similarly, the natural indirect effect can be inter-
preted as the effect along all edges except the one between Z
and Y . Using this interpretation, the suggestive next step in
the study of natural effects is to consider effects along a se-
lect subset of edges between Z and Y which are called path-
speciﬁc effects.

1.1 A Motivating Example
Consider the following example, inspired by [Robins, 1997],
A study is performed on the effects of the AZT drug on AIDS
patients. AZT is a harsh drug known to cause a variety of
complications. For the purposes of the model, we restrict
our attention to two – pneumonia and severe headaches. In
turn, pneumonia can be treated with antibiotics, and severe
headache sufferers can take painkillers. Ultimately, all the
above variables, except headache, are assumed to have a di-
rect effect on the survival chances of the patient. The graphi-
cal causal model for this situation is shown in Fig. 1.

The original question considered in this model was the to-
tal effect of AZT and antibiotics treatment on survival. How-
ever, a variety of other questions of interest can be phrased
in terms of natural effects. For instance, what is the direct
effect of AZT on survival, if AZT produced no side effects in
the patient, which is just the natural direct effect of AZT on
survival. See Fig. 2 (a). Similarly, we might be interested in
how just the side effects of AZT affect survival, independent
of the effect of AZT itself. This corresponds to the natural

H

K

A

S

P

B

Figure 1: The AZT example. A: AZT, P : pneumonia, H:
headaches, B: antibiotics, K: painkillers, S: survival

indirect effect of AZT on survival. See Fig. 2 (b).

Furthermore, certain interesting questions cannot be
phrased in terms of either direct or indirect natural effects.
For example we might be interested in the interactions be-
tween antibiotics and AZT that negatively affect survival. To
study such interactions, we might consider the effect of ad-
ministering AZT on survival in the idealized situation where
the antibiotics variable behaved as if AZT was not adminis-
tered, and compare this to the total effect of AZT on survival.
Graphically, this amounts to ’blocking’ the direct edge be-
tween antibiotics and survival or more precisely, keeping the
edge functioning at the level it would have had no AZT been
given, while letting the rest of the edges function as usual.
This is shown graphically in Fig. 3 (a). The edges which we
wish to block will be crossed out in the graph.

1.2 Outline and Discussion of Our Approach
Our goal is to study and characterize situations where path-
speciﬁc effects like the one from the previous section can be
computed uniquely from the data available to the investigator.
Our main result is a simple, necessary, graphical condition for
the identiﬁability of path-speciﬁc effects from experimental
data. Furthermore, our condition becomes sufﬁcient for mod-
els with no spurious correlations between observables, also
known as Markovian models.

The condition can be easily described in terms of blocked
and unblocked paths as follows. Let X, Y be variables in
a causal model M inducing a graph G. Then given a set of
blocked edges g, the corresponding path-speciﬁc effect of X
on Y cannot be identiﬁed if and only if there exists a node W
with an unblocked directed path from X to W , an unblocked
directed path from W to Y , and a blocked directed path from
W to Y . For instance, the effects of A on S are identiﬁable
in Fig. 2 (a), (b), and Fig. 3 (b), but not in Fig. 3 (a). There-
fore, in general we cannot study the interractions of AZT and
antibiotics in the way described above, but we can study the
interractions of AZT and painkillers. The latter case is made
tractable by an absense of blocked and unblocked paths shar-
ing edges.

Our condition also shows that all identiﬁable path-speciﬁc
effects are ’equivalent’, in a sense made precise later, to ef-
fects where only root-emanating edges are blocked. Thus
identiﬁable path-speciﬁc effects are a generalization of both
natural direct effects, where a single root-emanating edge is
unblocked, and of natural indirect effects, where a single root-
emanating edge is blocked.

A

A

H

P

H

P

K

B

K

B

S

(a)

S

(b)

Figure 2: (a) Natural direct effect (b) Natural indirect effect

A

A

H

P

H

P

K

B

K

B

S

(a)

S

(b)

Figure 3: Path speciﬁc effects

To obtain this result formally, we treat effects as probabili-
ties of statements in a certain counterfactual logic. However,
rather than manipulating these probabilities directly, we con-
vert them to subgraphs of the original causal model, and rea-
son about and perform manipulations on the subgraphs. We
then introduce simple counterfactual formulas whose prob-
abilities are not identiﬁable, and prove that certain simple
graphical conditions must be described by such formulas, and
lack of such conditions leads to subgraphs corresponding to
identiﬁable effects.

Due to space considerations, the proofs of some lemmas
have been omitted, while the proofs included generally are
missing some technical details. Our technical report contains
the complete proofs.

2 Preliminaries

This paper deals extensively with causal models and counter-
factuals. We reproduce their deﬁnitions here for complete-
ness. A full discussion can be found in [Pearl, 2000]. For
the remainder of the paper, variables will be denoted by cap-
ital letters, and their values by small letters. Similarly, sets of
variables will be denoted by bold capital letters, sets of values
by bold small letters. We will also make use of some graph
theoretic abbreviations. We will write P a(A)G, De(A)G,
and An(A)G, to mean the set of parents, descendants (in-
clusive), and ancestors (inclusive) of node A in graph G. G
will be omitted from the subscript when assumed or obvious.
If a variable is indexed, i.e. V i, we will sometimes denote the
above sets as P ai, Dei, and Ani, respectively.

2.1 Causal Models and Counterfactual Logic
Deﬁnition 1 A probabilistic causal model (PCM) is a tuple
M = hU , V , F , P (u)i, where
(i) U is a set of background or exogenous variables, which
cannot be observed or experimented on, but which can
inﬂuence the rest of the mode

(ii) V is a set {V 1, ..., V n} of observable or endogenous
variables. These variables are considered to be func-
tionally dependent on some subset of U ∪ V .

(iii) F is a set of functions {f 1, ..., f n} such that each f i is
a mapping from a subset of U ∪ V \ {V i} to V i, and
such that S F is a function from U to V .

(iv) P (u) is a joint probability distribution over the vari-

ables in U .

A causal model M induces a directed graph G, where each
variable corresponds to a vertex in G and the directed edges
are from the variables in the domain of f i (i.e P ai) to V i for
all the functions. For the remainder of this paper, we consider
causal models which induce directed acyclic graphs.

A Markovian causal model M has the property that each
exogenous variable U is in the domain of at most one func-
tion f. A causal model which does not obey this property is
called semi-Markovian. By convention, nodes corresponding
to variables in U are not shown in graphs corresponding to
Markovian models.

For the purposes of this paper, we will represent counter-
factual statements in a kind of propositional modal logic, sim-
ilar to the one used in [Halpern, 2000]. Furthermore, the dis-
tribution P (u) will induce an additional probabilistic inter-
pretation on the statements in the logic.
Deﬁnition 2 (atomic counterfactual formula) Let M be a
causal model, let X be a variable and Z be a (possibly
empty) set of variables. Then for any value x of X, and val-
ues z of Z, x is a term, and Xz(u) is a term, taken to mean
’the value X attains when Z is forced to take on values z,
and U attain values u.’

For two terms t1 and t2, an atomic counterfactual formula
has the form t1 = t2. We will abbreviate formulas of the form
Xz(u) = x as xz(u).

The ’forcing’ of the variables to z is called an intervention,
and is denoted by do(z) in [Pearl, 2000]. Counterfactual for-
mulas are constructed from atomic formulas using conjunc-
tion and negation.
Deﬁnition 3 (counterfactual formula)
(i) An atomic formula α(u) is a counterfactual formula.
(ii) If α(u) is a counterfactual formula, then so is (¬α)(u).
(iii) If α(u) and β(u) are counterfactual formulas, then so is

(α ∧ β)(u).

The satisfaction of counterfactual formulas by causal mod-
els is deﬁned in the standard way, which we reproduce from
[Halpern, 2000].
Deﬁnition 4 (entailment) A causal model M satisﬁes a
counterfactual formula α(u), written M |= α(u), if all vari-
ables appearing in α are in M and one of the following is
true

(i) α(u) ≡ t1 = t2 and for the given setting of u, the terms

t1 and t2 are equal in M.

(ii) α(u) ≡ (¬β)(u) and M 6|= β(u).
(iii) α(u) ≡ (β ∧ γ)(u) and M |= β(u) and M |= γ(u)

Thus a formula α(u) has a deﬁnite truth value in M. If the
values u are unknown, we cannot in general determine the
truth of α. However, we can easily deﬁne a natural notion of
probability of α in M as follows:

P (α|M ) = X

P (u)

(1)

{u|M |=α(u)}

We will omit the conditioning on M if the model in ques-

tion is assumed or obvious.

If we consider each value assignment u as a possible
world, then we can view P (u) as describing our degree of
belief that a particular world is true, and P (α) as our be-
lief that a particular statement is true in our causal model if
viewed as a type 2 probability structure [Halpern, 1990].
2.2 Submodels and Identiﬁability
Deﬁnition 5 (submodel) For a causal model M =
hU , V , F , P (u)i, an intervention do(z) produces a new
causal model Mz = hU , V z, F z, P (u)i, where V z is a
set of distinct copies of variables in V , and F z is obtained
by taking distinct copies of functions in F , but replacing all
copies of functions which determine the variables in Z by
constant functions setting the variables to values z.

The joint distribution P (V z) over the endogenous vari-
ables in Mz is called an interventional distribution, and is
sometimes denoted as Pz. For a given causal model M, de-
ﬁne P∗ as {Pz|Z ⊆ V , z a value assignment of Z}. In other
words, P∗ is the set of all possible interventional (or experi-
mental) distributions of M.

Intuitively, the submodel is the original causal model, min-
imally altered to render Z equal to z, while preserving the
rest of its probabilistic structure.

that

Because there is no requirement

interventions in
atomic counterfactuals in a formula α be consistent with each
other, it is in general impossible to alter the original model
using only interventions in such a way as to make the en-
tire formula true. Thus, we introduce a causal model which
encompasses the ’parallel worlds’ described by the counter-
factual formula.

Before doing so, we give a simple notion of union of sub-

models, as follows:
Deﬁnition 6 (causal model union) Let Mx, and Mz be sub-
models derived from M. Then Mx ∪ Mz is deﬁned to be Mx
if z = x, and hU , V x ∪ V z, F x ∪ F z, P (u)i, otherwise.
Deﬁnition 7 (parallel worlds model) Let M be a causal
model, α a counterfactual formula. Then the parallel worlds
model Mα is the causal model union of the submodels corre-
sponding to atomic counterfactuals of α.

We call the joint distribution P (V α) over the endogenous
variables in Mα a counterfactual distribution, and will some-
times denote it as Pα. In the language of the potential out-
comes framework [Rubin, 1974], we can view Pα as the joint
distribution over the unit-response variables mentioned in α.

The parallel worlds model is a generalization of the twin
network model, ﬁrst appearing in [Balke and Pearl, 1994], to
more than two possible worlds. It displays independence as-
sumptions between counterfactual quantities in the same way
a regular causal model displays independence assumptions
between observable quantities – by positing counterfactuals
are independent of their non-descendants given their parents.
Given a causal model M and a formula α, we are interested
in whether the corresponding counterfactual joint distribution
Pα (or its marginal distributions) can be computed uniquely
from the set of joint distributions available to the investigator.
The formal statement of this question is as follows:
Deﬁnition 8 (identiﬁability) Let M be a causal model from
a set of models M inducing the same graph G, Mα a par-
allel worlds model, and Q be a marginal distribution of the
counterfactual joint distribution Pα. Let K be a set of known
probability distributions derived from M. Then Q is K-
identiﬁable in M if it is unique and computable from K in
any M ∈ M .

It follows from the deﬁnition that if we can construct two
models in M with the same K but different Q, then Q is
not identiﬁable. An important, well-studied special case of
this problem – which we call evidential identiﬁability of in-
terventions – assumes α is an atomic counterfactual, and K
is the joint distribution over the endogenous variables in M,
or P (V ). Being able to identify an interventional marginal in
this way is being able to compute the effects of an interven-
tion without having to actually perform the intervention, and
instead relying on passive, observational data.

In this paper we are concerned with identifying probabili-
ties of counterfactuals formulas using the set P∗ of all inter-
ventional distributions of M as a given. In other words, we
are interested in computing probabilities of counterfactuals
from experimental and observational probabilities.

3 Path-Speciﬁc Effects
Our aim is to provide simple, graphical conditions for the P∗-
identiﬁability of path-speciﬁc effects. To do so, we must for-
malize such effects as counterfactual formulas, and translate
the identiﬁability conditions on the formula to conditions on
the graph.

The following is the formalization of the notion of path-
speciﬁc effect in terms of a modiﬁed causal model, as it ap-
pears in [Pearl, 2001]:
Deﬁnition 9 (path-speciﬁc effect) Let G be the causal
graph associated with model M, and let g be an edge-
subgraph of G containing the paths selected for effect analy-
sis (we will refer to g as the effect subgraph). The g-speciﬁc
effect of z on Y (relative to reference z∗) is deﬁned as the
total effect of z on Y in a modiﬁed model Mg formed as
follows. Let each parent set P Ai in G be partitioned into
two parts P Ai = {P Ai(g), P Ai(¯g)}, where P Ai(g) rep-
resents those members of P Ai that are linked to V i in g,
and P Ai(¯g) represents the complementary set. We replace
each function f i in M with a new function f i
g in Mg, deﬁned
as follows: for every set of instantiations pai(g) of P Ai(g),
g(pai(g), u) = f i(pai(g), pai(¯g)∗, u), where pai(¯g)∗ takes
f i

the value of P Ai(¯g)z∗ (u) in M. The collection of modiﬁed
functions forms a new model Mg. The g-speciﬁc effect of z
on Y , denoted SEg(z, z∗; Y, u)M is deﬁned as the total effect
(abbreviated as TE) of z on Y in the modiﬁed model:

SEg(z, z∗; Y, u)M = T E(z, z∗; Y, u)Mg

(2)

where T E(z, z∗; Y, u)Mg = Yz(u)Mg

− Yz∗(u)Mg

.

If we wish to summarize the path-speciﬁc effect over all
settings of u, we should resort to the expectation of the above
difference, or the expected path-speciﬁc effect. To identify
this effect, we need to identify P (yz) and P (yz∗) in Mg. For
our purposes we can restrict our attention to P (yz), as the
second term corresponds to the quantity P (yz∗) in the origi-
nal model M, and so is trivially P∗-identiﬁable.

In this paper we assume, without loss of generality, edges
in ¯g = G \ g are all along directed paths between Z and
Y . The next theorem states that any path speciﬁc effect, ex-
pressed as a total effect in the modiﬁed model Mg, can be
expressed as a counterfactual formula in the original model
M.

Theorem 1 Every path speciﬁc effect P (yz)Mg has a corre-
sponding counterfactual formula α in M s.t for every u,

Mg |= yz(u) ⇐⇒ M |= α(u)

Proof outline:

The proof is for causal models with ﬁ-
nite domains. Fix M, u, y, z and g. To prove the the-
orem, we need to ’unroll’ yz and remove any implicit ref-
erences to modiﬁed functions in Mg, while preserving the
truth value of the statement. Our proof will use the axiom
of composition, known to hold true for causal models un-
der consideration.
In our language, the axiom states that
for any three variables Z, Y, W , and any settings u, z, w, y,
(Wz = w ⇒ Yz,w = Yz)(u).

Fix u1. Let S = An(Y ) ∩ De(Z) Then by axiom of com-
position, yz(u1) has the same truth value as a conjunction of
atomic formulas of the form vi
pai(g), where V i ∈ S, P Ai(g)
is the set of parents of V i in Mg, and pai(g) and vi are suit-
ably chosen constants. Denote this conjunction α1.

For every term vi

pai(g),pai(¯g)∗ ∧ pai(¯g)∗

pai(g) in α1 corresponding to V i with
P Ai(g) ⊂ P Ai, replace it by vi
z∗ in the
conjunction, where pai(¯g)∗ takes the value of P Ai(¯g)z∗ (u1)
in M. Denote the result α∗
1 is in M and
1(u1). We construct a sim-
Mg |= yz(u1) ⇐⇒ M |= α∗
j for every instantiation uj in M. Let
ilar conjunction α∗
j . It’s easy to see the claim holds for α by con-
α = Wj α∗
struction.

1. Note that α∗

2

An easy corollary of the theorem is, as before,

that
P (yz)Mg = P (α)M . Note that different αi in the proof only
differ in the values they assign to variables in S. Since M is
composed of functions, the values of variables in S are ﬁxed
given u, and since P (α) = P{u|M |=Wi αi(u)} P (u) by def-
inition, we can express P (α) as a summation over the vari-
ables in S \ {Y }.

For instance, the ﬁrst term of the path-speciﬁc effect in Fig.

Z

V

Y

Z

V

Y

Z

V

W

Y

Z

V

W

Y

(a)

(b)

Figure 4: Bold edges represent directed paths (a) R1 Rule (b)
R2 Rule

2 (a) can be expressed as

P (sa)Mg2a = X

P (sk,b,p,a ∧ kh ∧ bp ∧ pa∗ ∧ ha∗)

k,b,p,h

P (sa,h,p ∧ ha∗ ∧ pa∗)

(3)

= X

h,p

which is just the direct effect. The more general case of Fig.
3 (a) can be expressed as:1

P (sa)Mg3a = X

P (sk,b,p,a ∧ kh ∧ ba∗ ∧ pa ∧ ha)

k,b,p,h

= X

b

P (sa,b ∧ ba∗ )

(4)

It looks as if the expressions in Eq.

(3) and (4) for the
two effects are very similar, moreover we know that direct
effects are always P∗-identiﬁable in Markovian models. Sur-
prisingly, the path speciﬁc effect of Fig. 3 (a) and Eq. (4) is
not P∗-identiﬁable as we will show later.

We will ﬁnd it useful to modify the effect subgraph g while
preserving the value of the path-speciﬁc effect. We do so by
means of the following two rules. Let M be a causal model
with the graph G, g an effect subgraph of G, and ¯g = G \ g.
For a node V , let in(V ) denote the set of edges incoming into
V , and out(V ) denote the set of edges outgoing from V , in
G.
R1: If there is a node V in G such that out(V ) ⊆ ¯g, then

R1(g) = (g \ out(V )) ∪ in(V ). See Fig. 4 (a).

R2: If there is an edge e ∈ ¯g, such that for all directed paths
from Z to Y which include e, there exists another edge
e0 ∈ ¯g, which occurs ’upstream’ from e, then R2(g) =
g \ {e}. See Fig. 4 (b).

Theorem 2 (Effect-Invariant Rules) If R1 is applicable the
R1(g)-speciﬁc effect is equal to the g-speciﬁc effect. If R2 is
applicable the R2(g)-speciﬁc effect is equal to the g-speciﬁc
effect.

Proof outline: The proof is by induction on graph struc-
ture, and is an easy consequence of the deﬁnition of g-speciﬁc
effect, and the R1 and R2 rules.

Intuitively, R1 ’moves’ the blocked edges closer to the
manipulated variable Z, and R2 removes redundant blocked
1Note that Eq (4) is different from Pba∗ P (sa,b ∧ ba∗ ) which is

just a marginalization over the counterfactual variable ba∗

2

Table 1: The functions f 1

R and f 2

R

Z UR R = f 1
R(z, uR) R = f 2
R(z, uR)
1
0
0
1
1
0
0
1
0
1
1
1
0
0
1
1
0
0

1
2
3
1
2
3

edges. Thus, it is not surprising these two identities cannot be
applied forever in a dag.
Lemma 1 Let M be a causal model, g an effect subgraph.
Then any sequence of applications of R1 and R2 to g will
reach a ﬁxed point g∗.

4 Problematic Counterfactual Formulas
Identiﬁcation of a distribution must precede its estimation,
as there is certainly no hope of estimating a quantity not
uniquely determined by the modeling assumptions. Further-
more, uniqueness frequently cannot be guaranteed in causal
models. For instance, when identifying interventions from
observational data, a particular graph structure, the ’bow-
arc’, has proven to be troublesome. Whenever the graph of
a causal model contains the bow-arc, certain experiments be-
come unidentiﬁable [Pearl, 2000]. Our investigation revealed
that a similarly problematic structure exists for experimental
identiﬁability, which we call the ’kite graph’, due to its shape.
The kite graph arises when we try to identity counterfactual
probabilities of the form P (rz∗ ∧ r0
Lemma 2 Let M be a causal model, let Z and R be vari-
ables such that Z is a parent of R. Then P (rz∗ ∧ r0
z) is not
P∗-identiﬁable if z∗ 6= z.

z).

Proof outline: The proof is by counter example. We let
z, and construct two causal models M 1 and
α = rz∗ ∧ r0
M 2 that agree on the interventional distribution set P∗, but
disagree on P (α).
In fact, we only need 2 variables. The
two models agree on the following: Z is the parent of R,
UZ, Z and R are binary variables, UR be a ternary variable,
fZ = UZ, and P (uZ), and P (uR) are uniform. The two
models only differ on the functions fR, which are given by
table 4. It’s easy to verify our claim holds for the two models
for any values z∗ 6= z of Z.

The next theorem shows how a particular path-speciﬁc ef-
fect leads to problematic counterfactuals from the previous
lemma.
Theorem 3 The g-speciﬁc effect of Z on Y as described in
Fig. 5 (a) is not P∗-identiﬁable.

2

Proof: We extend models M 1 and M 2 from the previous
proof with additional variables V , Y , and UY . We assume
P (uY ) is uniform, and both P (V, Y |R) and the functions
which determine V and Y are the same in both models.

Note that since all variables are discrete, the conditional
probability distributions can be represented as tables. If we
require |R| = |V | and |Y | = |V | ∗ |R|, then the conditional

Z

R

Y

V

Z

R

Y

(a)

(b)

Figure 5: (a) Problematic effect (b) The kite graph

probabilities are representable as square matrices. We ﬁx the
functions fV and fY , as well as the exogenous parents of V
and Y such that the matrices corresponding to P (V, Y |R) and
P (V |R) are matrices are invertible.

Call the extended models M 3 and M 4. Note that by con-
struction, the two models are Markovian. Since M 1 and M 2
have the same P∗, and since the two extended models agree
on all functions and distributions not in M 1 and M 2, they
must also have the same P∗.

Consider the g-speciﬁc effect shown in Fig. 5 (a). From
g in

Theorem 1 we can express the path-speciﬁc effect in M 3
terms of M 3, In particular:

P (yz)M 3

g

= X

P (yrv ∧ rz∗ ∧ vz)M 3

rv

= X

P (yrv ∧ rz∗ ∧ vr0 ∧ r0

z)M 3

r,v,r0

= X

P (yrv)M 3 P (vr0)M 3 P (rz∗ , r0

z)M 3

r,v,r0

g

The last step is licensed by the independence assumptions en-
coded in the parallel worlds model of yrv ∧rz∗ ∧vr0 ∧r0
z. The
same expression can be derived for P (yz)M 4
. Note that since
P∗ is the same for both models they have the same values
for the interventional distributions P (yrv) and P (vr0). Note
that since P (Y |R, V ) and P (V |R) are square matrices, the
summing out of P (Y |R, V ) and P (V |R) can be viewed as a
linear transf ormation. Since the matrices are invertible,
the transformations are one to one, and so if their composi-
tion. Since P (yrv) = P (y|r, v) and P (vr0) = P (v|r0), and
z) is different in the two models, we obtain
since P (rz∗ ∧ r0
that P (yz)M 3
. Since adding directed or bidi-
6= P (yz)M 4
rected edges to a graph cannot help identiﬁability, the result
also holds in semi-Markovian models.

2

g

g

5 Main Result
The main result of this section is that a simple sufﬁcient
and necessary (in Markovian models) graphical criterion ex-
ists. This condition is easily stated and can be derived from
the effect subgraph g in linear time. By contrast, the only
other methods known to us for obtaining identiﬁability re-
sults of probabilities of general counterfactual logic formulas
are proof search procedures based on results in [Galles and

Pearl, 1998], [Halpern, 2000]. Such procedures are far less
intuitive, do not have running time bounds, and cannot be
used to obtain non-identiﬁability proofs.

First let’s deﬁne this criterion:

Deﬁnition 10 (Recanting witness criterion) Let R 6= Z be
a node in G, such that there exists a directed path in g from Z
to R, a directed path from R to Y in g, and a direct path from
R to Y in G but not g. Then Z, Y , and g satisfy the recanting
witness criterion with R as a witness

The recanting witness criterion is illustrated graphically as
the ’kite pattern’ in Fig. 5 (b). The name ’recanting witness’
comes from the behavior of the variable R in the center of
the ’kite.’ This variable, in some sense, ’tries to have it both
ways.’ Along one path from R to Y , R behaves as if the
variable Z was set to one value, but along another path, R
behaves as if Z was set to another value. This ’changing of
the story’ of R is what causes the problem, and as we will
show it essentially leads to the the existence of a non P∗-
identiﬁable expression of the type discussed in section 4.

To proceed, we must make use of the following helpful
lemmas: Let g be an effect subgraph of G and g∗ the ﬁxed
point of R1 and R2. Let g∗ = G \ g∗.
Lemma 3 g∗ satisﬁes the recanting witness criterion iff g
does. Moreover, if g∗ does satisfy the criterion, then there
exists a witness R s.t out(R) ∩ g∗ 6= ∅. If g∗ does not, then
g∗ ⊆ out(Z).

Lemma 3 states that repeated applications of rules R1 and
R2 preserves the satisfaction of the recanting witness crite-
rion. Moreover, if the witness exists in the ﬁxed point g∗, then
some outgoing edge from it is blocked. If the witness does not
exist in g∗, then only root-emanating edges are blocked.
Lemma 4 Assume the g∗-speciﬁc effect of Z on Y is P∗-
identiﬁable. Let E be any set of edges in g∗. Let g0 = E ∪ g∗.
Then the g0-speciﬁc effect of Z on Y is P∗-identiﬁable.

Lemma 4 states that if a path speciﬁc effect is not identi-
ﬁed, then adding blocked directed edges ’does not help,’ in
that the effect remains unidentiﬁed. Now we can state and
prove the main results:
Theorem 4 If g satisﬁes the recanting witness criterion, then
the g-speciﬁc effect of Z on Y is not P∗-identiﬁable.
Proof: Let M be our model and assume that g satisﬁes the
recanting witness criterion. By Lemma 3 so does g∗, let R be
the witness from the lemma s.t e = R → V is in g∗. Assume
the g-speciﬁc effect is identiﬁable, By Theorem 2 so is the
g∗-speciﬁc effect. Let g0 be the path speciﬁc effect obtained
by adding all edges to g∗, but e. By Lemma 4 the g0-speciﬁc
effect is also P∗-identiﬁable. Now by composing the func-
tions in g0 we can obtain a new model M 0 which is exactly
the model of Fig. 5 (a)2 and P (yz)Mg0 = P (yz)M 0
g0 . From
Theorem 3 we know that P (yz)M 0
is not P∗-identiﬁable,
hence, neither is P (yz)Mg0 and the g0-speciﬁc effect is not
P∗-identiﬁable. Contradiction.
2 To illustrate the use of

g0

2or a similar model where we “cut” the edge R → V and not the

edge R → Y

the theorem, consider the example in Eq. (4) from Section 3.
The expression Pb P (sa,b ∧ ba∗) =

= X

P (sa,b ∧ bp0 ∧ p0

a∗)

b,p

= X

P (sa,b,p ∧ bp0 ∧ p0

a∗ ∧ pa)

(5)

b,p,p0

= X

P (sa,b,p ∧ bp0 )P (p0

a∗ ∧ pa)

b,p,p0

The ﬁrst two steps are by deﬁnition, the last step is licensed
by the parallel worlds model corresponding to the formula in
Eq. 5. The theorem shows that, as in this example, non-
identiﬁability arises because formulas of the form p0
a∗ ∧ pa
appear whenever the recanting witness criterion holds.
Theorem 5 If g does not satisfy the recanting witness crite-
rion, then the g-speciﬁc effect of Z on Y is P∗-identiﬁable in
Markovian models.
Proof: From theorem 2 we have that P (yz)Mg∗ = P (yz)Mg .
Since g does not satisfy the recanting witness criterion, by
Lemma 3 all the edges in g∗ emanate from Z. From Theorem
1 there is a formula α(g∗) corresponding to P (yz)Mg∗ that
contains only atomic counterfactuals of the form vi
pai. Since
all blocked edges emanate from Z, it can be easily observed
that for each two atomic counterfactuals in α(g∗), vi
paj ,
i 6= j. This follows, since we only introduce atomic coun-
terfactuals with do(z∗) where we cut edges. Now since in
Markovian models any two different variables are indepen-
dent if you set all their parents, all the atomic counterfactual
in α(g∗) are independent of each other which makes the ex-
pression P∗-identiﬁable.

pai , vj

For example, we stated earlier that the g speciﬁc effect of
Fig 3 (b) is identiﬁable, this is true since g does not satisfy
the recanting witness criterion. In particular the expression
for the path-speciﬁc effect is:

2

P (sa)Mg3b = X

P (sk,b,p,a ∧ kh ∧ ba ∧ pa ∧ ha∗)

k,b,p,h

P (sh,a ∧ ha∗)

(6)

P (sh,a)P (ha∗ )

= X

h

= X

h

As before, the ﬁrst two steps are by deﬁnition, and the last
step is licensed by the parallel worlds model corresponding to
the formula in Eq. 6. But now note that P (sh,a), P (ha∗ ) ∈
P∗, therefore the above expression can be computed from ex-
periments.

6 Conclusions
Our paper presented a sufﬁcient and necessary graphical con-
ditions for the experimental identiﬁability of path-speciﬁc ef-
fects, using tools from probability theory, graph theory, and
counterfactual logic. We related identiﬁable path-speciﬁc ef-
fects to direct and indirect effects by showing that all such
effects only block root-emanating edges.

While it is possible to give a sufﬁcient condition for iden-
tiﬁability of general counterfactual formulas in our language,
using induction on formula structure, this does not give a
single necessary and sufﬁcient condition for semi-Markovian
models. The search for such a condition is a good direction
for future work.

Another interesting direction is to consider special cases
of causal models where path-speciﬁc effects can be identiﬁed
even in the presence of the ’kite’ – this is true in linear mod-
els, for instance.

Finally, our result assumes causal models with ﬁnite do-
mains, and ’small’ graphs. An interesting generalization is
to consider causal models with ’large’ or inﬁnite graphs and
inﬁnite domains. Such models may require adding ﬁrst-order
features to the language.

7 Acknowledgements
The authors would like to thank Brian Gaeke and Paul
Twohey for proofreading earlier versions of this paper.

References
[Balke and Pearl, 1994] Alexander Balke and Judea Pearl.
Counterfactual probabilities: Computational methods,
bounds and applications. In Proceedings of UAI-94, pages
46–54, 1994.

[Galles and Pearl, 1995] David Galles and Judea Pearl. Test-
ing identiﬁability of causal effects. In Proceedings of UAI-
95, pages 185–195, 1995.

[Galles and Pearl, 1998] David Galles and Judea Pearl.
An axiomatic characterization of causal counterfactuals.
Foundation of Science, 3:151–182, 1998.

[Halpern, 1990] Joseph Y. Halpern. An analysis of ﬁrst-order
logics of probability. Artiﬁcial Intelligence, 46(3):311–
350, 1990.

[Halpern, 2000] Joseph Halpern. Axiomatizing causal rea-

soning. Journal of A.I. Research, pages 317–337, 2000.

[Pearl, 2000] Judea Pearl. Causality: models, reasoning, and

inference. Cambridge University Press, 2000.

[Pearl, 2001] Judea Pearl. Direct and indirect effects. In Pro-

ceedings of UAI-01, pages 411–420, 2001.

[Robins and Greenland, 1992] James M. Robins and Sander
Identiﬁability and exchangeability of direct

Greenland.
and indirect effects. Epidemiology, 3:143–155, 1992.

[Robins, 1997] James M. Robins. Causal inference from
complex longitudinal data.
In Latent Variable Modeling
and Applications to Causality, volume 120, pages 69–117,
1997.

[Rubin, 1974] D. B. Rubin. Estimating causal effects of
treatments in randomized and non-randomized studies.
Journal of Educational Psychology, 66:688–701, 1974.

