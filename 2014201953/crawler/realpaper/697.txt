Delayed  Duplicate  Detection:  Extended  Abstract 

Richard  E.  K o rf 

Computer  Science  Department 

University  of California,  Los  Angeles 

Los Angeles,  CA  90095 

korf@cs.ucla.edu 

Abstract 

Best-first  search  is 
limited  by  the  memory 
needed  to  store  nodes  in  order  to  detect  dupli(cid:173)
cates.  Disks  can  greatly  expand  the  amount  of 
storage available, but randomly accessing a disk 
is  impractical.  Rather  than  checking  newly-
generated nodes as soon as they are generated, 
we  append  them  to  a  disk  file,  then  sort  the 
file,  and  finally  scan  the  sorted  file  in  one  pass 
to  detect  and  remove  duplicate  nodes.  This 
also  speeds  up  such  searches  that  fit  entirely 
in  memory,  by  improving  cache  performance. 
We implement this idea for breadth-first search, 
performing  the  first  complete  searches  of  the 
2 x7  sliding-tile  puzzle,  and  the  18-disk,  4-peg 
Towers  of Hanoi  puzzle. 

Introduction:  The  Problem 

1 
Best-first search  algorithms,  such  as  breadth-first search 
(BFS),  Dijkstra's  algorithm  [Dijkstra,  1959],  and  A* 
[Hart,  Nilsson,  k  Raphael,  1968],  store  every  node  that 
is  generated,  in  either  the  Open  list  or  the  Closed  list. 
One  reason  for  doing  this  is  to  detect  duplicate  nodes, 
and avoid expanding a state more than once.  As a result, 
these  algorithms  are  limited  by  the  available  memory. 

In  some  problems, 

this  memory  limitation  can  be 
avoided  by  depth-first  searches  (DFS)  such  as  depth-
first  iterative-deepening  (DFID)  or  iterative-deepening-
A*  (IDA*) 
[Korf,  1985],  but  DFS  can  generate  ex(cid:173)
ponentially  more  nodes  than  BFS.  For  example,  in  a 
rectangular-grid  problem  space,  BFS  will  generate  0(r 2) 
nodes  within  a  radius  of  r,  while  DFID  will  generate 
0(3r)  nodes.  While  there  are  ways  of  detecting  some 
duplicate  nodes  in  a  DFS[Taylor  k  Korf,  1993],  they  do 
not  apply  to  all  problem  spaces. 

2  Frontier  Search 
An  algorithm  called  frontier  searc/i[Korf,  1999;  Korf  k 
Zhang,  2000]  saves  only  the  Open  list  of  nodes  at  the 
frontier  of  the  search,  and  not  the  Closed  list  of  nodes 
that  have  been  expanded,  thus  saving  some  memory. 

With  each  node,  it  stores  a  used-operator  bit for each  op-
erator,  to indicate  whether the neighboring state reached 
by  that  operator has  already  been  generated.  For exam(cid:173)
ple, the sliding-tile puzzles require four such bits for each 
state,  one  for each  direction  in  which  a tile  could  move. 
When  a parent  node  is  expanded,  only  children  that  are 
reached via unused operators are generated, and the par(cid:173)
ent node is deleted from memory.  In each child node,  the 
operator  that  generates  the  parent  is  marked  as  used. 
When  duplicate  states  are  found  in  the  Open  list,  only 
one  copy  is  kept,  and  any  operator  that  is  marked  as 
used  in  any copy is marked  as used  in the retained  copy. 
Since  the closed  list  is  not  stored,  reconstructing the so(cid:173)
lution  path  requires  additional  work.  See  [Korf,  1999; 
Korf k  Zhang,  2000]  for  two  ways  to  do  this. 

The  memory  required  by  frontier  search  is  propor(cid:173)
tional  to  the maximum  size of the  Open  list,  or the  width 
of  the  problem  space,  rather  than  the  size  of  the  space. 
For  example,  in  the  grid  space  mentioned  above,  the 
width  of  the  space  grows  only  linearly  with  the  search 
radius,  while  the  entire  space  grows  quadratically.  As 
another  example,  the  width  of  the  n-disk,  3-peg  Towers 
of  Hanoi  space  is  only  2 n  states,  while  the  entire  space 
contains  3n  states.  Frontier search  is  still  limited  by  the 
memory  required  to  store  the  Open  list,  however. 

3  Delayed  Duplicate  Detection  ( D D D) 

Hard  disks  with  hundreds  of  gigabytes  of  storage  are 
available for less than a dollar per gigabyte, which is over 
a hundred  times  cheaper  than  memory.  Because  of high 
latency,  however,  a  disk  behaves  more  like  a  sequential 
device,  such  as a magnetic-tape drive, with  large capac(cid:173)
ity  and  high  bandwidth,  but  only  if  it  is  accessed  se(cid:173)
quentially.  To quickly detect  duplicate states  in  a search 
algorithm,  however,  nodes  are  usually  stored  in  a  hash 
table,  which  is  designed  to be  accessed  randomly. 

Our  solution  to  this  problem  is  rather  than  checking 
each newly-generated node for duplicates as soon as it is 
generated, we append each node to a disk file containing 
previously generated  nodes.  At  some point  later  we  sort 
the file,  thereby bringing together nodes representing the 
same state.  Then  we scan  the sorted list of nodes in one 
pass,  merging any  duplicate  nodes. 

POSTER  PAPERS 

1539 

3.1  Breadth-First  Frontier  Search 
As  a  simple  example,  we  describe  breadth-first  frontier 
search with delayed duplicate detection.  BFS is normally 
implemented  with  a  FIFO  queue,  which  we  implement 
with two disks files, an input file and an output file.  Ini(cid:173)
tially, the input file contains the initial state.  As we read 
each  node  in  the  input  file,  we  expand  it,  and  write  its 
children  to  the  output  file,  with  no  duplicate  checking. 
When  the  input  file  is  exhausted,  we  delete  it.  At  that 
point,  the  output  file  contains  all  the  nodes  at  the  next 
depth,  including  any  duplicate  nodes.  We  then  sort  the 
nodes  in  the  output  file  by  their  state  representations, 
which  brings  together  any  duplicate  nodes  representing 
the  same  state.  Next,  we  linearly  scan  the  output  file, 
merging duplicate  nodes  and  ORing  their  used  operator 
bits,  and write one copy of each state to a new input file, 
deleting the output file when we're done.  This completes 
one level of the  breadth-first search.  The algorithm con(cid:173)
tinues  until expanding the nodes in the input file doesn't 
generate  any  more  nodes  in  the  output  file. 

3.2  Sorting  the  Disk  Files 
Algorithms  for  sorting  disk  files  are  well-known.  See 
[Garcia-Molina,  Ullman,  &  Widom,  2000],  pp.  42-48. 
The  basic  algorithm  is  to  read  as  much  of the  unsorted 
file as will  fit  into memory, sort it in memory using quick(cid:173)
sort,  for  example,  and  write  the  sorted  portion  of  the 
file  to  a  new  subfile.  Continue  until  the  entire  original 
file  has  been  read  and  written  into  a  set  of sorted  sub(cid:173)
files. Then, all the sorted subfiles are merged in one pass, 
storing the  head  of each  file  in  memory,  and  writing  the 
lowest  record  to  a  final  sorted  output  file. 

3.3  D DD  in  M e m o ry 
Surprisingly,  delayed  duplicate  detection  is  useful  even 
when  all  nodes  fit  in  memory,  resulting  in  reduced  run(cid:173)
ning  time  due  to  improved  cache  performance. 
In  the 
standard implementation of breadth-first search in mem(cid:173)
ory,  the  Open  list  is  stored  in  a  hash  table.  As  each 
new  node is  generated,  it  is  looked up  in  the  hash  table, 
which  often  results  in  a cache miss,  since the hash  func(cid:173)
tion  is  designed  to  randomly  scatter  the  nodes.  A  DDD 
implementation  doesn't  use  a  hash  table,  but  a  single 
FIFO  queue  in  memory,  reading  nodes  off  the  head  of 
the queue,  and appending them to the tail.  Once a level 
of the  search  is  completed,  the  queue  is  sorted  in  mem(cid:173)
ory using an algorithm such as quicksort, and the sorted 
queue is scanned,  merging duplicate nodes.  The  advan(cid:173)
tage  of this  approach  is  that  the  queue  is  only  accessed 
at  the head  and  tail,  or  at  two points  in  between  during 
quicksort,  and  hence most  memory references  will  reside 
in  cache,  reducing the  running  time. 

4  Experiments 
We  implemented  a  breadth-first  search  on  sliding-tile 
puzzles,  and  the  4-Peg Towers of Hanoi  problem. 

4.1  Sliding-Tile  Puzzles 
[Schofield,  1967]  published  a  complete  breadth-first 
search of the 3 x 3 Eight puzzle.  We completed a BFS for 
all  sliding-tile  puzzles  up  to  the  2 x7  Thirteen  Puzzle. 
Table  1  below  shows  the  results.  The  first  column  gives 
the  x  and  y  dimensions  of  the  puzzle,  and  the  second 
column  gives  the  number  of  moves  needed  to  reach  all 
solvable states,  starting  with  the  blank  in  a corner posi(cid:173)
tion.  This is also the worst-case optimal solution length, 
for  a goal  with  the  blank  in  a  corner.  The  third  column 
gives the  number  of solvable states,  which  is  (xy)\/2,  and 
the fourth  column  gives the  width  of the  problem  space, 
which  is  the  maximum  number  of nodes  at  any  depth. 

Size  Moves 
6 
2 x2 
2 x3 
21 
37 
2 x4 
31 
3 x3 
55 
2 x5 
2 x6 
80 
53 
3 x4 
2 x7 
108 

Total  States 
12" 
360 
20,160 
181,440 
1,814,400 
239,500,800 
239,500,800 
43,589,145,600 

Max  Width 
2 
44 
1,999 
24,047 
133,107 
13,002,649 
21,841,159 
1,862,320,864 

Table  1:  Sliding-Tile  Puzzle  Results 

The  3 x4  and  2 x6  Eleven  Puzzles  were  the  largest 
that  we  could  solve  in  memory.  We  implemented  both 
a standard  BFS  algorithm,  using  one  bit  of memory  per 
state,  and  also  breadth-first  frontier  search  with  delayed 
duplicate  detection.  The  standard  BFS  required  17.5 
minutes,  while  the  frontier  search  with  DDD  required 
only 9.6 minutes, on a 440 Megahertz Sun Ultra 10 work(cid:173)
station.  This  demonstrates  that  DDD  frontier  search  is 
useful  even  for  problems  that  fit  in  memory. 

The  2 x7  Fourteen  Puzzle  was  the  largest  we  could 
search  exhaustively  with  our  120  gigabyte  disk.  At  8 
bytes per state, this problem required about  15 gigabytes 
of disk  storage,  and  ran  for  51  hours,  13  minutes.  The 
ratio  of the  problem  size  to  the  problem  width  is  about 
23.4,  illustrating  the  advantage  of frontier  search. 
4.2  Towers  of  H a n oi 
For  the  standard  3-peg  Towers  of Hanoi  problem,  there 
is  a  simple  algorithm  that  guarantees  the  shortest  path 
between  any  pair  of states.  The  4-peg  Towers  of Hanoi 
puzzle,  known  as  Reve's  puzzle,  is  much  more  interest(cid:173)
ing.  There exists  a algorithm for finding  a solution,  and 
a conjecture  that  it  generates  optimal  solutions,  but  the 
conjecture  remains  unproven. 
[van  de  Liefvoort,  1992] 
contains a good  bibliography for this  problem.  [Szegedy, 
1999]  gives  bounds  for  the  A:-peg  version,  but  they  in(cid:173)
clude  an  unspecified  constant  in  the  exponent. 

For the  sliding-tile puzzles,  all paths  between any  pair 
of states  have  the  same  even-odd  parity,  and  the  algo(cid:173)
rithm  described  in  Section  3.1  works  correctly.  For  the 
Towers of Hanoi, however, two states can have both even 
and  odd  length  paths  between  them.  In  that  case,  fron(cid:173)
tier  search  with  delayed  duplicate  detection  can  fail  by 

1540 

POSTER PAPERS 

leaking  into  the  interior  of the  search.  One  solution  to 
this  problem is  to store  two complete levels of the search 
at  a time.  See our full  paper for the  details  [Korf,  2003]. 
Using  this  algorithm,  we  were  able  to  exhaustively 
search  all  problems  through  18  disks,  starting  with  all 
disks  on  one  peg.  Table  2  shows  the  results.  The  first 
column  gives  the  number  of  disks,  and  the  second  col(cid:173)
umn  shows  the  minimum  number  of  moves  required  to 
move  all  the  disks  from  one  peg  to  another.  The  third 
column  gives  the  total  number  of states  of the  problem, 
which is  4 n,  where n  is  the number of disks.  The fourth 
column shows the maximum width of the graph, starting 
from  a state  with  all  disks  on  one  peg.  In  all  cases,  the 
optimal  number  of  moves  equals  the  conjectured  mini(cid:173)
mal  number of moves.  The  18-disk  problem  took  almost 
6 days to run,  and at 8 bytes per state required about 30 
gigabytes  of disk  space.  Note  that  the  ratio  of the  total 
number  of  states  to  the  problem  width  for  the  18-disk 
problem  is  almost  34.5. 

r 

Max  Width 
Disks  Moves 
Total  States 
4 
1 
3 
16 
6 
3 
30 
64 
5 
72 
256 
9 
282 
1,024 
13 
17 
918 
4,096 
16,284 
2,568 
25 
9,060 
65,536 
33 
262,144 
41 
31,638 
109,890 
1,048,576 
49 
335,292 
4,194,304 
65 
1,174,230 
16,777,216 
81 
4,145,196 
67,108,864 
97 
14,368,482 
268,435,456 
113 
48,286,104 
1,073,741,824 
129 
162,989,898 
161 
4,294,967,296 
572,584,122 
193  17,179,869,184 
225  68,719,476,736  1,994,549,634 

2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 

Table  2:  4-Peg Towers  of Hanoi  Results 

5  Conclusions  and  Further  W o rk 
We  showed  that  delaying  the  detection  of  duplicate 
nodes  in  a breadth-first  search  can  effectively  make  use 
of  very  large  capacity  disk-storage  systems.  We  also 
showed  how  to  combine  this  idea  with  frontier  search. 
In  addition,  we  demonstrated  that  these  ideas  can  also 
speed up a search that  occurs entirely in memory.  Using 
these algorithms, we completed  breadth-first searches of 
sliding-tile puzzles with up to 43 billion nodes, and 4-peg 
Towers  of  Hanoi  problems  with  up  to  68  billion  nodes. 
For  the  4-peg  Towers  of Hanoi,  we  verified  a conjecture 
regarding optimal  solution  lengths  to  18  disks. 

Current  work is focussed on  implementing these tech(cid:173)
niques for more complex best-first search algorithms such 
as  Dijkstra's  algorithm  [Dijkstra,  1959]  and  A*  [Hart, 
Nilsson,  &  Raphael,  1968]. 

6  Acknowledgments 
Larry Taylor brought the 4-Peg Towers of Hanoi  problem 
to my attention,  and also used disk storage in a breadth-
first  search  to  find  duplicate  operator  strings  [Taylor  & 
Korf,  1993].  Thanks  to  Jianming  He  for  verifying  the 
Towers  of  Hanoi  results.  This  research  was  supported 
by  NSF  under  grant  No.  EIA-0113313,  by  NASA  and 
JPL  under  contract  No.  1229784,  and  by  the  State  of 
California MICRO  grant  No.  01-044. 

References 
[Dijkstra,  1959]  Dijkstra,  E.  1959.  A  note on  two prob(cid:173)
lems  in  connexion  with  graphs.  Numerische  Mathe-
matik  1:269-271. 

[Garcia-Molina,  Ullman,  &  Widom,  2000] 

Garcia-Molina,  H.;  Ullman,  J.  D.;  and  Widom,  J. 
2000.  Database  System  Implementation.  Upper  Saddle 
River,  N.J.:  Prentice-Hall. 

[Hart,  Nilsson,  &  Raphael,  1968]  Hart,  P.;  Nilsson,  N.; 
and Raphael,  B.  1968.  A formal basis for the heuristic 
determination  of  minimum  cost  paths. 
IEEE  Trans. 
Systems  Science  and  Cybernetics  SSC-4(2):100-107. 
[Korf &  Zhang,  2000]  Korf,  R.,  and  Zhang,  W.  2000. 
Divide-and-conquer  frontier  search  applied  to  opti(cid:173)
In  Proceedings  of  the  Na(cid:173)
mal  sequence  alignment. 
tional  Conference  on  Artificial 
(AAAI-
2000),  910-916. 

Intelligence 

[Korf,  1985]  Korf,  R. 

iterative-
deepening:  An  optimal  admissible  tree  search.  Ar(cid:173)
tificial 

Intelligence  27(1):97-109. 

1985. 

Depth-first 

[Korf,  1999]  Korf,  R.  1999.  Divide-and-conquer  bidi(cid:173)
In  Proceedings  of the 
rectional  search:  First  results. 
Sixteenth  International  Joint  Conference  on  Artificial 
Intelligence 

(IJCAI-99),  1184-1189. 

[Korf,  2003]  Korf, R.  2003.  Delayed duplicate detection: 
initial  results.  In  Proceedings  of  the  IJCAI-03  Work(cid:173)
shop  on  Model  Checking  and  Artificial  Intelligence. 

[Schofield,  1967]  Schofield,  P.  1967.  Complete  solution 
of  the  eight  puzzle. 
In  Meltzer,  B.,  and  Michie,  D., 
eds.,  Machine  Intelligence  3.  New  York:  American  El(cid:173)
sevier.  125-133. 

[Szegedy,  1999]  Szegedy,  M.  1999.  In  how  many  steps 
the  k  peg  version  of the  towers  of hanoi  game  can  be 
solved?  In  Proceedings  of the  16th  Annual Symposium 
on  Theoretical  Aspects  of  Computer  Science  (STACS 
'99),  LNCS  1563.  Trier,  Germany:  Springer-Vcrlag. 
[Taylor  &  Korf,  1993]  Taylor,  L.,  and  Korf,  R.  1993. 
Pruning duplicate nodes  in  depth-first  search.  In  Pro(cid:173)
ceedings  of  the  National  Conference  on  Artificial  In(cid:173)
telligence 

(AAAI-93),  756-761. 

[van  de Liefvoort,  1992]  van  de  Liefvoort,  A.  1992.  An 
iterative  algorithm  for  the  reve's  puzzle.  The  Com(cid:173)
puter  Journal  35(l):91-92. 

POSTER PAPERS 

1541 

