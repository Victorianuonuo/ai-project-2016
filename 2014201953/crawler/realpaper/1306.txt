Session  11  Robot  Implementations 

DESIGN OF A LOW COST. GENERAL PURPOSE ROBOT* 

by 

Michael  H.  Smith 

Department  of  Electrical  Engineering  and  Computer  Sciences 

University  of  California  at  Berkeley 

and 

L.  Stephen  Coles 

A r t i f i c i al 

Intelligence  Center 
Stanford  Research  Institute 

Abstract 

This  paper  reports  on  current  work  at  the  University 
of  California  at  Berkeley  whose  goal  is  the  design  and 
implementation  of  a  relatively  inexpensive,  but  versa­
t i l e,  experimental,  computer-controlled  robot  suitable 
for  use  in  either  a  research  or  educational  setting. 
The  Berkeley  robot,  dubbed  Jason,  is  nearing  comoletion 
and  hardware  tests  are  now  being  conducted. 

Jason  is  designed  so  as  to  permit  1t  to  navigate  and 

manipulate  simple  objects  in  a  real-world  environment. 
It  uses  a  variety  of  sensory-motor  and  communication 
devices;  among  these  are  an  ultrasonic  range,  motion, 
and  material  detector,  an  isolated-word  speech  recog­
nizer,  a  limited  speech  synthesizer,  six  inexpensive 
proximity  detectors,  and  two  arms  for  simple  manipula­
tion,  all  of  which  are  mounted  on  a  platform  chassis. 
The  robot  vehicle  is  remotely  controlled,  using  radio 
telemetry,  by  a  time-shared,  virtual  memory,  HP-3000 
mini-computer,  utilizing  adaptive  learning  programs. 

Jason  was  primarily  constructed  to  explore: 

(1)  how  an  inexpensive,  real-world  robot  system 

might  be  designed,  and 

(2)  what  problems  a  robot  "encounters"  and  "creates" 

while  performing  tasks  in  a  real-world  environment 
populated  by  humans. 

The  results  of  this  research  w i ll  hopefully  enable 

us  to  design  and  build  better  (more  reliable  and  safer) 
robots  at  a  modest  price  that  are  s t i ll  capable  of  per­
forming  a  variety  of  interesting  and  useful  tasks. 

Key  Words  and  Phrases 

Robots,  A r t i f i c i al  Intelligence,  Problem  Solving, 

Learning,  Real-World  Environment. 

CR Categories 

3.62  (Learning  and  Adaptive  Systems)!  3.64  (Problem 

Solving)-,  3.69  (Miscellaneous-Robots). 

♦The  research  reported  here  was  sponsored  in  part  by 
the  Electronics  Research  Laboratory  of  the  University 
of  California  at  Berkeley  under  grants  AFOSR-71-2076, 
NSF-GJ-35839  and  NSF-GO-31612.  Additional  support  was 
provided  by  the  Department  of  Electrical  Engineering 
and Computer  Sciences  and  the  Lawrence  Hall  of  Science 
of  the  University  of  California  at  Berkeley. 

I. 

Introduction 

The  f i e ld  of  robotics  is  rapidly  becoming  an  impor­
tant  topic  of  research  and  study.  This  is  due  1n  part 
to  the  possible  widespread  applications  of  robots  to 
tedious,  repetitive,  or  dangerous  tasks.  While  robots 
with  one  or  two  highly  sophisticated  sensory  devices 
have  been  extensively  investigated,  it  1s  only  recently 
that  more  research  is  being  extended  to  system  design 
and  integration  of  a  robot  having  a  relatively  large 
number  of  sensory-motor  devices. 

Current  work  at  the  University  of  California  1s 

being  carried  out  with  the  objective  of  designing  and 
building  a  comparatively  inexpensive,  but  general-
purpose  experimental  computer-controlled  robot.  The 
Berkeley  robot,  dubbed  Jason,  is  intended  to  be  capable 
of  operating  in  a  real-world  environment  populated  by 
human  beings.  For  the  sake  of  this  investigation,  the 
real-world  environment  is  taken  to  consist  of  the 
Berkeley  Campus  at  large,  especially  the  second  and 
third  floors  of  Cory  Hall,  the  engineering  building  on 
campus.  When  Jason  is  fully  operational,  it  w i ll  not 
only  be  used  for  research,  but  also  as  a  teaching  aid 
for  young  children  at  the  Lawrence  Hall  of  Science,  as 
well  as  for  public  demonstrations. 

This  paper  is  divided  into  four  sections,  The  f i r st 

section  explores  the  background  and  rationale  of  the 
project.  The  second  section  presents  a  brief  descrip­
tion  of  Jason  itself.  The  third  section  briefly 
mentions  the  need  for  safety  precautions.  Finally,  the 
last  section  summarizes  and  draws  some  conclusions 
about  the  Berkeley  robot  project. 

I I.  Background  and  Purpose 

Considerable  effort  has  already  been  directed  toward 

the  development  of  automatic  machines  for  factories, 
farming,  transportation,  and  so  forth.  Yet  such 
machines  have  been  carefully  contrived  to  deal  with 
highly  constrained  environments.  The  addition  of  just 
a  few  advanced  sensors  and  a  small  amount  of  computa­
tional  ability  might  enhance  the  versatility  of  such 
machines  man,vfold.[l]  For  example,  advanced,  general 
purpose  robots  could  carrv  out  diverse  real-world  tasks 
such  as  the  following: 
Exploration, 
(3)  Gardening, 
Guard, 
8)  Traffic  Controller, 
10)  Street  Cleaning, 
(12)  Office-building  external  window  washer. 

(2)  Teach1nq-Aid  in  Schools, 

(1)  Space  and  Underwater 

(9)  Mining  Surveilance, 

(11)  DeeD  Sea  Farming,  and 

(6)  Warehouseman, 

(7)  Inexpensive  Hospital  Aid 

(4)  Harvesting, 

(5)  Bank  Security 

334 

In  fact,  any  task  which  requires  only  "closed 

thinking",  i . e .,  a  task  constrained  by  a  specified 
goal  and  set  of  operators,  could  be  performed  by  an 
advanced  robot.  Furthermore,  several  robots,  carrying 
out  different  tasks,  could  all  be  supervised  by  the 
same  time-shared  computer  system.  These  robots,  with 
various  interchangeable  sensory-motor  devices  and 
computer  programs  for  different  tasks,  would  be  able 
to  carry  out  a  wide  variety  of  jobs  for  a  much  smaller 
cost  than  the  exnense  of  developing  special  purpose 
automation  for  each  task. 

In  the  field  of  industrial  robots,  a  careful  survey 

of  the  potential  marketinq  opportunities  has  been 
made  in  Coles  (pp.  58-74)[2]. 
tion,  Papert[3]  has  made  considerable'strides  with 
his  ''turtle"  robots. 

In  the  area  of  educa­

For  this  reason,  considerable  research  in  robots  is 

currently  being  carried  out  at  major  centers  such  as 
SRI[4],  MIT[5],  Stanford  University  [ 6 ],  and  the 
University  of  Edinburgh[7],  Sophisticated  automata 
have  been  designed  and  built  to  oper?.te  on  table-tops 
or  in  carefully  controlled  environments.  However,  when 
trying  to  perceive  and  model  the  real  world,  AI  resear­
chers  in  the  field  of  robotics  have  traditionally 
focused  their  attention  on  the  television  camera  as 
their  major  source  of  sensory  data.  Consequently,  a 
great  deal  of  effort  has  been  directed  toward  the  com­
putational  processes  needed  to  make  "sense"  out  of  the 
TV  camera  image  whenever  it  depicted  a  typically-
cluttered,  real-world  scene.  These  processes  have 
tended  to  become  increasingly  expensive,even  when  the 
environment  is  ingeniously  constrained  to  capitalize 
on  the  idiosyncrasies  of  the  TV  camera.  The  time  to 
process  a  single  complete  scene  has  taken  upwards  of 
ten  minutes  at  SRI  using  a  high-powered  computer 
f a c i l i t y.  Obviously,  a  low-cost  robot  cannot  afford 
to  adopt  this  approach. 

Our  own  research  departs  from  previous  work  1n  that 

it  attempts  to  incorporate  the  output  of  a  variety  of 
inexpensive  sensors  to  nrovide  more  efficient  percep­
tion  of  the  real  world,  when  tailored  to  simple  navi­
gation  and  manipulation  tasks.  Under  these  conditions 
such  sensors  are  not  only  computationally  cheaper,  but 
are  more  reliable,  since  different  sensory  modes  can 
mutually  reinforce  and  corroborate  one  another. 
If 
binary  sensing-decisions  can  be  made  in  real  time,  the 
possibility  for  dynamically  altering  a  precomputed 
path  during  navigation  (to  compensate  for  an  unantici­
pated  obstacle)  can  become  feasible. 

In  an  effort  to  obtain  further  insight  into  the 

problem  of  ooerating  a  real-world  robot,  our  experi­
mental  robot  project  was  begun  in  April  of  1972. 
Special  emphasis  was  placed  on  designing  a  small,  low 
cost,  but  versatile  mobile  robot  capable  of  performing 
a  wide  variety  of  tasks,  such  as  exploring  fairly  un­
cluttered  environments  and  manipulating  small  objects. 
Therefore,  Jason  has  been  provided  with  a  wide  range 
of  sensory  and  data-qathering  input  devices,  none  of 
which  1s  very  sophisticated  1n  i t s e lf  or  imposes 
severe  computational  requirements  on  the  control 
computer,  but  all  of  which  could  be  well  integrated. 
Figure  1  gives  an  overview  of  Jason  in  its  proposed 
form. 

Jason  has  the  following  sensory/motor  and  interface 

devices: 

(1)  an  ultrasonic  range  and  material  detector; 

(2)  two  simple  arms  with  clasping  grippers; 
(3)  proximity  sensors  (used  in  place  of  microswitch 

bump  detectors); 

(4)  a  30  to  40 word  speech  recognizer; 

(5)  a  limited  speech  synthesizer  ; 

(6)  optical  counters  for  measuring  wheel  distances 

traveled  by  the  vehicle; 

(7)  a  robot  chassis  powered  bv  two  1/4-horsepower 

permanent-magnetic  motors;  and, 

(8)  a  ten-watt  nower  output,  467-megahertz  radio 

communication  network. 

A  time-shared,  virtual  memory,  Hewlett  Packard  3000 

computer  with  appropriate  software  serves  as  Jason's 
control  computer.  The  HP-3000  is  located  at  the 
Lawrence  Hall  of  Science  and  controls  the  robot  vehicle 
by  means  of  radio  telemetry.  One  of  the  advantages  of 
a  time-shared  computer  1s  the  possibility  of  runninq 
several  similar  robots  (planned  for  the  near  future) 
under  the  same  executive  orogram,  so  the  Problems 
associated  with  multi-robot  cooneration  and  communica­
tion  can  be  investigated.  However,  1t  should  be 
stressed  that  neither  Jason's  robot  vehicle,  the  above 
mentioned  sensory/motor  devices,  nor  the  computer  pro­
grams  are  very  sonhisticated.  They  are  not  intended  to 
be.  Rather,  the  purpose  of  the  project  is  to  study  the 
problems  in  designing  a  simolified  and  Inexnensive  robot 
system  that  integrates  a  variety  of  sensory/motor 
devices. 

When  Jason  was  designed,  one  of  the  important  con­

straints  was  to  minimize  the  cost  of  construction. 
Throughout  this  paper  we  shall  stress  the  economical 
design  and  the  simplicity  of  the  sensory/motor  devices. 
Although  the  labor  involved  was  considerable,  the  actual 
cost  of  parts,  including  the  radio  network,  but  not  the 
computer  or  its  interface,  was  well  under  $2,000.  Yet 
Jason  cannot  be  thought  of  as  a  toy. 
It  is  capable  of 
carrying  out  a  wide  variety  of  tasks,  even  though  they 
may  be  elementary  by  human  standards. 
It  is  precisely 
this  generality  in  the  class  of  tasks  which  is  the  key 
to  the  project. 

I I I.  A  Description  of  Jason 

Jason  consists  of  three  major  subsystems: 

(A)  the 
(B)  communication  and  sensory/motor  devices, 
chassis, 
and 
(C)  software  control  nrograms.  The  robot  vehicle 
transports  Jason  through  its  environment  in  a  precise 
manner.  Reasonably  accurate  movement  is  needed  to 
avoid  either  the  ranid  accumulation  of  errors  that 
would  otherwise  lead  to  bumping  into  walls,  etc.,  or 
highly  inefficient  behavior  in  carrying  out  the  simpl­
est  of  tasks.  A  variety  of  sensory  devices  are  needed 
to  guarantee  a  rich  base  of  information  about  the  ex­
ternal  environment  so  that  reliable  decisions  can  be 
made.  The  robot  software  has  the  task  of  integrating 
the  output  of  these  sensors  so  as  to  construct  an 
accurate  model  of  the  environment  and  harmoniously 
control  the  various  sub-systems. 

A.  The  Robot  Chassis 

The  f i r st  major  subsystem  is  the  robot  chassis. 

It 
consists  of  two  segments:  the  actual  mechanical  wheel 
assembly  and  the  on-board,  electronic  logic  which  con­
trols  the  vehicle's  wheel  assembly.  The  chassis  (see 
Figure  2)  by  itself  weighs  about  125  pounds  (not  inclu­
ding  the  sensory/motor  devices). 
approximately  2  feet  by  2  feet  and  it  cost  about  $200 
for  parts,  including  electronics,  but  not  including 
labor  and  overhead. 

Its  dimensions  are 

325 

327 

The  chassis  was  designed  to  have  the  following 

mechanical  properties  and  subcomponents: 

provides  for  fall-safe  operation  in  the  event  of  a  main 
battery  power  failure. 

(1)  Each  of  the  two  six-inch  diameter,  rubber-

covered,  rear  wheels  1s  gear  driven  by  a  separate  1/4 
horsepower,  permanent-magnetic  motor. 

(2)  The  two  rear  wheel  surfaces  are  mechanically 
around  to  within  .001  of  an  inch  In  circumference  to 
insure  accuracy  in  rolling  movement. 

(3)  A  magnetic  clutch  is  utilized  to  insure  that 

both  rear  wheels  rotate  together  when  the  vehicle  is 
moving  in  a  straight-line  path. 

(4)  The  front  of  the  chassis  is  supported  by  three 
one-inch  diameter  steel  balls  in  the  shape  of  an  equi­
lateral  triangle.  This  design  f i r s t ly  eliminates 
torque  problems  otherwise  associated  with  turning,  and 
secondly,  supports  the  chassis  in  the  event  that  one 
(or  two)  ball(s)  slides  into  a  crack  1n  the  floor  or 
pavement. 

(5)  Two  five-inch  discs  with  two  rows  of  60  holes 

drilled  around  their  perimeter  are  mounted  on  the 
wheel  shafts.  When  used  with  optical  encoders,  they 
enable  the  robot  to  determine  the  distance  and  direc­
tion  of  travel  quite  precisely.  The  vehicle  has  a 
maximum  linear  accuracy  of  one-quarter  inch. 

(6)  Finally,  the  chassis  1s  of  rugged  design  with 
3/4  Inch  diameter  steel  wheel  shafts  and  a  1/2  inch 
thick  aluminum  body  plate. 

The  second  segment  of  the  chassis,  the  basic  control 

logic  (electronics)  subsystem,  is  shown  in  Figure  3. 
It  has  the  following  properties: 

(1)  The  logic  circuit  1s  designed  such  that  the 
computer  program  is  only  required  to  load  a  5-bit 
command  and  a  16-bit  location  counter  (to  indicate  the 
distance  the  vehicle  is  to  travel). 

(2)  The  logic  circuit  then  determines  (1)  the 
correct  speed  (based  on  distance  to  be  traveled), 
(ii)  direction  of  travel,  and  ( i i i)  1f  any  overshoot 
has  occurred  ( if  so,  it  is  corrected  by  the  logic 
circuit  automatically). 

(3)  The  logic  c i r c u i t,  together  with  the  clutch, 

insures  that  both  rear  wheels  rotate  together. 

(4)  If  the  robot,  for  some  reason,  cannot  move  to 
the  desired  location,  e.g.,  it  encounters  an  obstacle, 
an  interrupt  1s  generated  and  transmitted  to  the 
computer. 

(5)  The  electronics  controls  the  motor's  speed  by 
providing  pulses  to  the  motor;  this  conserves  battery 
power. 

(6)  Braking  is  done  electronically  by  placing  a 

variable  load  (amount  determines  the  rate  of  braking) 
across  the  terminals  of  each  rear  motor. 

(7)  The  maximum  distance  it  can  travel  in  a  straight 

line  without  additional  computer  commands  is  120  feet. 

(8)  Finally,  the  robot  vehicle's  motors,  control 

electronics,  and  sensory/motor  and  on-board  communica­
tion  devices  are  powered  by  an  83  amp-hour  lead-storage 
battery,  which  is  easily  recharged  as  necessary.  Other 
smaller  batteries  are  installed  on-board  for  special 
purposes.  For  example,  one  battery  provides  negative 
12  volts  to  the  speech-recognition  detector  and 

The  vehicle  has  already  been  built  and  has  proven 
satisfactory  and  reliable  1n  manual  tests.  Actual 
computer  tests  are  not  yet  possible  because  our  FCC 
approval  for  the  assianed  robot  communication  freguency 
is  s t i ll  pending  at  the  time  of  this  writing. 

B.  Communication  and  Sensery/tt)tor  Devices 

The  second  major  subsystem  for  Jason  consists  of  its 

sensory/motor  devicesand  a  2-way,  half-duplex,  radio 
communication  controller.  (See  Fioure  4).  The  communi-
cations-controllerprovides  a  central  distribution  sys­
tem  for  reception  and  transmission  for  Jason's  perpher-
ical  devices  and  the  host  computer.  The  communication 
system  consists  of:  (1)  a  standard  serial  terminal  in­
terface,  (2)  a  high-soeed  asynchronous  modem 
(up  to 
2400  baud  max.,  depends  on  radio),  (3)  two  ten-watt 
power  output, FM modulated  467  MHz  transceivers,  (4)an 
antenna  system,  (5)  a  communication  controller  on  the 
robot  vehicle,  and,  (6)  Jason's  nernherical  devices-

1.  Radio  Network.  Because  it  was  desirable  to  make 

the  controller  as  independent  as  possible  from  the 
characteristics  of  any  one  computer,  the  controller 
appears  as  a  bit  serial  asynchronous  data  terminal  to 
the  host  computer,  and  as  a  byte-serial  interface  to 
any  of  Jason's  perpherical  devices.  Thus  standard 
serial  terminal  interfaces  can  be  used;  this  allows 
easy  interfacing  to  most  time-shared  computers  with­
out  the  high  cost  of  buildina  a  highly  specialized 
interface.  Also,  either  half  duplex  (as  used  presently) 
or  f u ll  duplex  (planned  for  the  future)  transmission 
can  be  done.  Finally,  asynchronous  operation  is 
reguired  to  allow  for  transmission  interruption  by  a 
higher  priority  device. 

I n i t i a l l y,  both  the  host  computer  interface  and  the 

communications  controller  on  Jason  w i ll  be  in  the 
If  a  device  wishes  to  transmit,  it  must 
receive  mode. 
f i r st  issue  an  interrupt  reouest  to  the  controller. 
If 
no  higher  priority  device  1s  transmittina  and  the  con­
troller  is  not  receiving  data  at  the  time  (receive-Tock 
mode),  then  the  controller  w i ll  issue  an  interrupt 
acknowledge  to  the  device.  The  controller  w i ll  then 
switch  the  transceiver  to  transmit  mode,  wait  approxi­
mately  100msec  for  the  carrier  to  reach  the  transceiver 
at  the  computer  end  and  for  the  computer  software  rou­
tine  to  lock  its  ti-ansceiver  to  the  lock-receive  mode, 
queueing  any  further  transmission  requests. 

Transmission  from  Jason  to  the  computer  may  now 

begin. 
If  a  higher  priority  device  requests  to  trans­
mit,  the  current  transmission  w i ll  be  terminated  imme­
diately  and  its  interrupt  acknowledge  line  will  be  made 
false  (each  device  has  Its  own  interrupt  request  and 
interrupt  acknowledge  lines).  The  Interrupt  acknow­
ledge  for  the  higher  priority  device  w i ll  then  be  made 
true.  To  indicate  that  the  previous  transmission  was 
interrupted,  a  device-interrupted  pulse  (500nsec)  1s 
issued  to  all  devices.  Furthermore,  the  ambiguity  of 
a  device  thinking  that  it  has  been  interrupted  when  1n 
reality  it  caused  the  interrupt,  1s  avoided  by  not 
having  the  device  look  at  the  device  interrupt  control 
line  for  750nsec  after  receiving  interrupt  acknowledge. 
Finally,  each  interrupted  device  will  make  a  new  inter­
rupt  request  and  will  then  hold  the  interrupted  data  1n 
its  buffer  until  it  can  be  transmitted.  All  interrupt 
requests  are  handled  1n  an  ascending  priority  order 
until  all  Interrupts  have  been  cleared. 

If  the  transceiver  is  in  the  receive  mode  (normal 

328 

329 

330 

The  sequencer  then  tells  the  error 

default  mode  when  not  transmitting)  and  carrier  detect 
goes  true;  indicating  that  the  computer  end  has  turned 
on  Us  transmitter,  then  the  robot  vehicle's  controller 
will  go  Into  lock-receive  mode  (reception  starts  and 
interrupts  are  no  longer  acknowledged).  After  the 
controller  reaches  lock-receive  mode,  it  will  search 
the  input  data  stream  for  the  f i r st  occurance  of  a 
"control"  byte.  The  present  of  a  control  byte  w i ll 
start  the  controller's  receive  sequencer.  The  receive 
sequencer  f i r st  loads  the  control  byte  into  a  error 
detection  data  register,  then  waits  for  the  reception 
of  the  next  byte,  which  is  a  error-checking  byte.  This 
byte  is  loaded  into  the  error-detection  error-byte 
register. 
detection  logic  to  start  processing.  The  error  loaic 
will  signal  the  sequencer  when  error  checking  is 
completed.  The  tested  byte  is  now  loaded  into  the 
device  code  register  and  the  byte  count  register  if  it 
was  a  control  byte;  or  it  is  loaded  into  the  outDut 
data  bus  register  if  it  was  a  data  byte.  When  a  con-
trol  byte  is  received,  the  device  code  line,  byte 
select  lines,  and  'REC'  line  are  set  up  for  the  device 
which  is  to  receive  the  data.  The  'REC  line  plus  the 
correct  device  code  on  the  device-code  lines  is  the 
proper  indication  to  a  device  that  It  is  receiving  data; 
nete  that  only  data  can  be  passed  to  a  device  via  the 
8  bit  I/O  bus,  and  not  control  bytes. 
occurs  during  reception,  an  error  flip-flop  is  set  and 
remains  set  until  the  end  of  the  reception-sequence. 
The  error  flip-flop's  output  is  passed  to  all  devices. 
Since  the  system  will  be  i n i t i a l ly  half-dunlex,  the 
computer  cannot  be  informed  that  an  error  has  occurred 
until  the  reception  sequence  is  completed;  only  then 
may  a  special  device  transmit  the  error  condition  back 
to  the  computer. 

If  an  error 

The  error  code  used  for  error  checking  is  a  form  of 
double  error  correcting  hamming  code.  The  process 
involved  in  generating  the  error  code  is  discussed  by 
Berlekamp  in  [8,  Chap.  5].  Error  coding  generation  is 
done  in  hardware  on  the  controller  and  in  software  on 
the  computer. 
It  involves  calculating  the  polynomial 
(x  +x  +x  +x  +1)  of  the  parity  check  matrix  formed  from 
the  serial  data  input.  A  root  of  the  polynomial  is 
assumed  to  be  (x  +x+l)  and  was  used  in  developing  the 
hardware  and  software.  The  resulting  error  code  is 
then  transmitted  after  the  data.  On  reception,  the 
data  is  f i r st  passed  to  another  error-code  generator; 
the  resulting  error  code  generated  is  then  compared 
with  the  error  byte  received  after  the  data  byte. 
In 
the  present  version  of  the  system,  no  automatic  error 
correcting  1s  done  in  order  to  limit  the  i n i t i al 
expense. 

2.  Description  of  Devices.  The  sensory/motor  and 

communication  devices  utilized  by  the  robot  are 
summarized  below: 

(a)  Arms  —  Jason  will  have  two  hands  of  the  simple 

clasping  type,  each  with  three  degrees  of  freedom. 
These  have  been  roughly  designed,  but  not  yet  construc­
ted.  The  arms  are  not  intended  to  be  fast,  accurate,  or 
heavy-duty.  They  will  be  lightweight  and  will  pick  up 
lightweight  boxes,  push  buttons,and  push  or  pull  simple 
objects. 

(b)  Ultrasonic  Detector  --  a  narrow-beam,  frequency 

modulation,  echo  location  system  in  the  form  of  a 
"torch"  is  ut111zed[9].  Ultrasonic  waves  which  cover 
a  wavelength  range  of  2.5  to  5mm  are  used.  Bandwidth 
compression  (achieved  by  continuous  wave,  frequency-
modulation  transmission)  is  needed  since  the  useful 
auditory  bandwidth  1s  approximately  5  KHz  while  the 
bandwidth  of  the  Information  carrier  in  air  using 

33X 

ultrasonics  1s  about  50  KHz.  Thus,  ultrasonics  provide 
an  overall  reduction  in  Information  transmitted  of 
500,000  as  compared  with  vision.  The  ultrasonic 
"torch"  sensor  sweeps  downward  from  100kHz  to  50KHz. 
The  pitch  of  the  return  echoes,  which  are  converted  to 
audio  tones,  are  nrooortional  to  the  ranoe  of  an 
object  (each  300Hz  change  corresponding  to  about  1 
foot,  see  Figure  5).  The  ouality  (timbre)  of  the  echo 
indicates  the  type  of  surface  from  which  the  echo  was 
reflected,  hence  indicating  the  nature  of  the  object. 
Because  soft  objects  reflect  noorly  at  higher  frequen­
cies,  these  echoes  build  in  strength  as  the  sensor 
sweeps  down.  By  digitizina  the  pitch  (the  width  of 
the  echo  pulse  period)  and  the  relative  echo  strength 
(by  taking  4  to  6  samples  as  the  sensor  sweeps  down­
ward),  it  is  possible  to  determine  the  range  with  an 
accuracy  of  +10  percent  and  to  obtain  textural  infor­
mation.  Unfortunately,  the  angle  from  which  the  ultra­
sonic  beam  is  reflected  from  an  object  affects  echo 
strength,  and  thus  appears  to  change  textural  infor­
mation,  e.g.,  a  hard  object  at  an  angile  such  as  a 
slanted  wall  could  look  to  Jason  like  a  soft  object 
directly  in  front  of  the  sensor.  Semantic  information 
is  needed  to  resolve  such  ambiguities. 

Up  to  three  objects  at  different  ranoe  and  direc­
tions  within  the  field  of  view  may  be  resolved  when 
the  torch  is  held  stationary,  i . e .,  multiple  tones  or 
"chords"  are  possible  with  multiple  objects.  Dynamic 
conditions  are  more  complex.  However,  experienced 
blind  persons  using  such  a  device  are  capable  of: 

(1)  identifying  objects  such  as  the  following: 

smooth  poles,  windows,  bushes,  trees,  parking  meters, 
cars,  railings,  street  sions,  doorways,  moving  pedes­
trians,  traffic  liqhts,  mail  boxes,  rising  steps, 
grass,  plaster  walls,  etc, 

(1i)  walking  up  and  grasping  a  one-inch  diameter 

pole  from  a  distance  of  12  feet; 

(iii)  weaving  in  "slalom"  fashion  between  poles  in  a 
row  or  a  circle; 

(iv)  placing  a  group  of  poles  in  a  straight  line; 

(v)  grasping  a  pole  from  a  group  of  closely  spaced 

poles; 

(vi)  walking  past  a  pole  at  a  specified  lateral 

distance,  using  the  rate  of  change  of  distance  and 
direction  to  gage  relative  positions. 

All  these  skills  are  normally  tauoht  to  a  blind 

Derson  in  approximately  one  week  of  intensive  training 
[9].  While  it  is  not  expected  that  the  robot  will  be 
able  to  do  such  sophisticated  tasks,  we  do  suspect 
that  ultrasonics  will  be  useful  to  the  robot  since 
the  information  is  there.  Furthermore,  an  ultrasonic 
detector was  chosen  over  a  vidicon  TV  camera  as  the 
principal  sensory  modality  because  of(fi)  its  lower 
cost  (about  $200  -  $400  for  a  detector), 
(11)  the 
fact  that  a  considerably  reduced  information  process­
ing  Toad  is  imposed  on  the  computer  (as  compared  with 
a  TV  picture  whose  processing  may  take  upwards  of  ten 
minutes  on  a  high  powered  machine),  and  ( i i i)  the  fact 
that  the  ultrasonic  detector  will  probably  serve  just 
as  well  as  a  TV  camera  on  the  class  of  applications 
for  which  Jason  was  desianed.  A  detector  has  been 
loaned  to  us  from  the  Veteran's  Administration  for  use 
on  this  project  and  the  digitization  logic  is  being 
tested.  For  future  work,  simple  silicon  image  sensors 
will  offer  an  alternative  approach  to  object  detection. 

(c)  Proximity  Sensors  —  Instead  of  the  standard, 

332 

"cat-whisker"  style  mechanical  sense-switch,  bump-
detectors,  Jason  will  use  six  LED  proximity  sensors[10] 
distributed  around  the  perimeter  of  the  chassis  to 
protect  the  vehicle  against  inadvertently  bumping  into 
obstacles.  The  sensors,  loaned  to  us  by  Scientific 
Technology, 
Inc.,  are  able  to  reliably  detect  large 
barriers  or  small  objects  of  an  arbitrary  material 
within  a  range  of  up  to  eight  feet. 

The  detectors  operate  essentially  as  follows:  an 
invisible,  infra-red,  modulated  light  beam  (approxima­
tely  9000  angstroms)  is  projected  by  a  semiconductor 
gallium-arsenide  transmitter  module  with  a  fairly 
narrow beam angle.  Any  obstacle  which  intersects  the 
transmitted  beam  w i ll  reflect  light  energy  back  into 
the  receiver module  as  a  function  of  its  distance  (and 
its  color  and  texture  to  some  extent).  Thus,  if  one 
knows  the  nature  of  the  obstacle  in  advance  because  of 
semantic  information  available,  it  is  possible  to 
calibrate  the  readings  and  determine  distance  quite 
accurately.  Because  the  transmitted  light  is  modulated, 
the  detector  can  never  be  falsely  triggered  by  ambient 
light  or  heat,  or  even  bright  sunlight.  Five  of  the 
sensors  will  be  positioned  so  as  to  form  an  invisible 
curtain  of  protection  surrounding  the  vehicle,  while 
tne  last  sensor  will  be  beamed  down  at  an  angle  to 
detect  sharp  irregularities  on  the  ground  directly  in 
front  of  the  vehicle. 

(d)  Speech  Recognition  Detector  --  A  speech  recog­
nition  device  has  been  constructed  for  about  $200  in 
parts  which  can  extract  features  suitable  for  recogni-
zing  a  limited  vocabulary  of  30  to  40  carefully  chosen 
words  when  spoken  in  isolation  and  tuned  to  an  indivi­
dual  speaker.  Words  are  analyzed  by  a  bank  of  six 
f i l t e rs  (eight  in  the  future).  The  quantity  of  energy 
in  each  f i l t er  frequency  band  is  ranked  relative  to 
one  another  for  each  change  in  phoneme.  Thfs  data  is 
then  transmitted  to  the  computer  and  a  learning  program 
identifies  the  word  using  its  distinctive  features. 
This  device  must  be  tuned  to  one  person's  voice.  How­
ever,  this  is  advantageous  for  safety  reasons,  since 
properly  formulated  commands  will  not  be  accepted 
from  just  anyone. 

The  robot  w i ll  be  capable  of  recognizing  words  using 

( l)  either  a  given  word  matches  with  a 

two  methods: 
word  stored  in  memory  within  a  given  minimum  standard, 
or,  (2)  a  given  word  could  be  matched  by  sevaral  possible 
candidates',  but  the  syntactic  context  of  the  current 
sentence  restricts  the  set  of  alternatives  to  only  one 
possibility.  The  current  plan  calls  for  the  following 
thirty  words  to  be  included  in  the  recognition 
vocabulary: 

(e)  Speech  synthesizer  —  Jason  includes  a  digital 
speech  storage  and  retrieval  device  in  order  to  gener­
ate  verba!  responses  to  commands  or  to  carry  on  a 
dialog.  A  delta-modulator  with  a  clock  frequency  of 
lOKHz,  1s  utilized  to  generate  a  digital  bit-pattern 
corresponding  to  a  spoken  word  or  phoneme.  These 
digital  b it  patterns  are  stored  in  shift  registers 
on  board  the  robot  vehicle  with  about  IK  bits  required 
for  each  phoneme  (IK  shift  registers  with  a  cost  of 
about  $3.50  each (surplus) are  used  for  this  purpose)-

A  delta  demodulator,  upon  command  by  the  main  computer, 
w i ll  convert  the  string  or  strings  of  the  desired 
digital  bit-patterns  back  into  audio.  Either  strings 
of  phonemes  can  be  concatenated  to  form  words  or  whole 
words  can  be  stored  and  demodulated.  At  Dresent,  this 
device  is  operating  with  a  small  memory  of  16K  bits, 
which  w i ll  be  expanded  when  more  memory  is  obtained. 

C.  Software 

Finally,  the  third  and  one  of  the  most  d i f f i c u lt 

portions  of  the  robot  is  its  software.  The  executive 
control  programs  are  primarily  oriented  toward  simple 
problem  solving  and  adaptation  to  variations  in  the 
environment.  Figure  6  shows  a  flowchart  of  Jason's 
executive  program.  Techniques  such  as  signature  tables 
[11],  shortest  paths  [12],  strategy  learning  [13], 
and  problem  solving  methods  [14],  are  under  development. 
Once  the  mechanical  and  electronical  sub-systems  of  the 
robot  have  been  implemented,  the  bulk  of  the  research 
pursued  in  this  project  will  be  on  the  software.  A 
future  paper  will  report  on  nroaress  in  this  area  as 
soon  as  some  empirical  results  are  obtained. 

IV.  Safety  Precautions 

Once  a  robot  with  the  above  capabilities  and  func­

tions  is  operational,  a  major  problem  remaining  is  how 
to  achieve  adequate  safeguards  to  ensure  the  safety 
both  of  the  robot  itself  and  the  humans  that  may  be 
in  the  vicinity.  A  robot  that  is  simultaneously  mobile, 
fast,  powerful,  and  unpredictable  can  be  highly  danger­
ous  if  well-conceived  nrecautions  are  not  scrupulously 
observed.  Thus,  various  hardware  and  software  safety 
devices,  operational  precautions,  and  other  ground 
rules  must  be  formulated  and  implemented  before  any 
robot  should  be  released  into  the  human  world  to  carry 
out  even  the  simplest  task.  Jason  is  to  have  three 
types  of  safety  devices  and  controls:  (i)  those  built 
into  the  robot's  hardware, 
( i i)  those  built  into  the 
software,  and 
(s)  during  robot  operation.  All  of  these  are  being 
studied  and  will  be  implemented  before  Jason  is  permit­
ted  to  operate  in  a  human  environment. 

( i i i)  those  observed  by  the  experimenter 

V.  Summary  and  Conclusions 

The  Berkeley  Robot  Project  is  concerned  with  a 
relatively  unexplored  area  of  robotics  --  that  of 
designing,  implementing,  and  of  operating  an  economi­
cally  viable  and  durable  robot,  canable  of  performing 
useful  tasks  in  a  human  world.  As  mentioned  in  this 
paper,  there  remain  many  Problems  to  be  explored 
further,  such  as:safety  precautions,  planning  vs,  exe­
cution,  sensory  integration,  etc.  Such  research  is 
clearly  required  if  a  robot  is  to  be  released  into  the 
real-world  without  an  inordinate  number  of  restrictions 
and  constant  surveillance.  The  Berkeley  Project  is  in 
the  midst  of  design  and  construction.  Some  devices 
have  been  completed  and  checked  out.  Others,  such  as 
the  arms,  are  s t i ll  in  the  design  staoe. 
It  is  planned 
that  a  fully  integrated  robot  vehicle  with  elementary 
control  software  will  be  operational  in  the  near  future. 
Once  operational,  Jason  will  primarily  be  used  as  a 
test  bed  for  the  development  of  future,  real-world 
robots  with  considerably  greater  sophistication  and 
intelligence. 

334 

[11]  A.L.  Samuel,  "Some  Studies  in  Machine  Learning 

Using  the  Game  of  Checkers,  I I:  Recent  Progress," 
IBM  Systems  Journal  [Nov.  1967),  pp.  601-617. 

[12]  E.L.  Lawler,  "A  Procedure  for  Computing  the  K 

Best  Solutions  to  Discrete  Optimization  Problems 
and  Its  Application  to  the  Shortest  Path  Problem," 
Management  Science,  Vol.  18,  No.  7,  March  1972. 

[13]  M.H.  Smith,  "A  Learning  Program  which  Plays 

Partnership  Dominoes,"  Communications  of  the  ACM 
(August  1973). 

[14]  N.J.  Nilsson,  Problem  Solving  Methods  in  A r t i f i­

cial  Intelligence,  (McGraw-Hill,  New  York.  1971). 

Acknowledgments 

The  authors  wish  to  thank  various  graduate  students 

and  members  of  the  faculty  of  the  Department  of 
Electrical  Engineering)  and  Computer  Sciences  of  the 
University  of  California  at  Berkeley,  especially 
including  Professors  C.V.  Ramamoorthy,  Douglas  Maurer, 
and  Arthur  Hopkin,  and  E.E.C.S.  students  Al  Robb, 
David  Ott  and  Ken  Holt.  Messrs.  Leonard  Baldwin  and 
Wilfried  Zeilinger  of  the  Departmental  Machine  Shop 
were  responsible  for  much  of  the  construction.  Miss 
Barbara  Kerekes  did  many  of  the  final  drawings.  Also, 
students  in  EECS  290G  contributed  much  to  the  project. 

In  addition,  we  appreciate  the  help  of  various 

members  of  the  staff  of  the  A r t i f i c i al  Intelligence 
Center  and  the  Augmentation  Research  Center  at 
Stanford  Research  Institute,  especially  Dr.  William 
Rupert,  Mr.  Jerry  Gleason,  and  Mr.  Kirk  Kelley.  We 
would  like  to  acknowledge  the  computer  time,  equipment, 
and  considerable  encouragement  provided  by  the  Lawrence 
Hall  of  Science  of  the  University  of  California  at 
Berkeley.  Finally,  we  would  like  to  thank  the 
Veteran's  administration  for  the  loan  of  an  ultrasonic 
"torch",  and  Scientific  Technology,  Inc.  for  the  loan 
of  the  LED  proximity  detectors. 

335 

