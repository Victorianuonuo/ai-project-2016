Dynamics of Temporal Difference Learning

Andreas Wendemuth

Otto-von-Guericke-University, 39016 Magdeburg, Germany

Cognitive Systems Group

andreas.wendemuth@e-technik.uni-magdeburg.de

Abstract

In behavioural sciences, the problem that a sequence of stim-
uli is followed by a sequence of rewards r(t) is considered.
The subject is to learn the full sequence of rewards from the
stimuli, where the prediction is modelled by the Sutton-Barto
rule. In a sequence of n trials, this prediction rule is learned it-
eratively by temporal difference learning. We present a closed
formula of the prediction of rewards at trial time t within trial
n. From that formula, we show directly that for n → ∞ the
predictions converge to the real rewards. In this approach, a
new quality of correlation type Toeplitz matrices is proven.
We give learning rates which optimally speed up the learning
process.

We consider here a mathematical treatment of a problem in
behavioural biology. This problem has been described e.g. in
[Dayan and Abbott 2001] as learning to predict a reward. It is
Pavlovian in the sense that classical conditioning is adressed,
however reward is not immediate, but after a series of stimuli
there is a latency time, followed by a series of rewards. Us-
ing a simple linear rule, we will show that the subject is able
to predict the remaining rewards by that rule, repeating the
same stimuli-reward pattern over a series of trials. A review
of learning theory related to these problems can be found in
[Sutton and Barto 1998].

There are recent experimental biological correlates with
this mathematical model, e.g.
in the activity of primate
dopamine cells during appetitive conditioning tasks, together
with the psychological and pharmacological rationale for
studying these cells. A review was given in [Schultz 1998],
the connection to temporal difference learning can be found
in [Montague et al. 1996].

In this paper, the focus is on two mathematical issues: a) to
provide a direct constructive proof of convergence by giving
an explicit dependence of the prediction error over trials, b) to
minimize the learning time by giving a formula for optimal
setting of the learning rate. Hence, the paper contributes as
well to temporal difference learning as a purely mathematical
issue, which may be valuable also without reference to be-
havioural biology and reinforcement learning. It can also be
understood in a Dynamic Programming sense, see [Watkins
1989] and later work, e.g. [Gordon 2001] and [Szepesvari and

IJCAI-07

1107

1 Temporal Difference Learning

R(t) =

r(t + τ )

(only after stimulus onset!)

Smart 2004]. We adopt the following notation in the course
of this paper, following [Dayan and Abbott 2001]:

• Stimulus u(t)
• Future reward r(t)
• Sum of future rewards R(t)
• Weights w(k)
• Predicted reward v(t)

We want to compute, for all trials n of duration T , and for
n(t). The (ex-
any time of trial t, the predicted reward v
tended) stimulus u(t) is given at times tu,min . . . tu,max , the
(extended) reward r(t) is presented at times tr,min . . . tr,max.
Stimulus and reward do not overlap, i.e. tr,min > tu,max.

The subject is to learn the total remaining reward at time t,

(cid:4)

(cid:2)
T −t(cid:3)

τ =0

t(cid:5)

v(t) =

τ =0

(cid:6)

T −t(cid:5)

The brackets (cid:4)(cid:5) refer, in general, to stochastic values of
R(t), if not exactly the same rewards are given at each trial,
but when there are ﬂuctuations.

All previous stimuli u(t) are weighted to give a linear pre-

diction model [Sutton and Barto 1990]:

w(τ )u(t−τ )

(1)

An update rule for the Sutton-Barto-formula can easily be de-
rived from the mean square error [Dayan and Abbott 2001]:

t(cid:5)

(cid:7)2

(cid:4)R(t) − v(t)(cid:5)2

=

r(t + τ ) −

w(τ )u(t−τ )

τ =0

τ =0

(2)
using the partial derivative with respect to any weight w(α),

∂(cid:4)R(t) − v(t)(cid:5)2

(cid:6)
T −t(cid:5)

∂w(α)

τ =0

= −2

r(t + τ ) −

(cid:7)

w(τ )u(t−τ )

u(t − α)

t(cid:5)

τ =0

Updates are made in discrete steps in the direction of the neg-
ative gradient, providing the following rule:

Δw(τ ) = εδ(t)u(t − τ )

(3)

(cid:6)
T −t(cid:5)

(cid:7)

δ(t) =

τ =0

r(t + τ )

− v(t) = (cid:4)R(t)(cid:5) − v(t)

This can be written in matrix notation as follows, with E the

⎞
⎟⎟⎟⎟⎠ = (E − εG A) ×
⎞
⎟⎟⎟⎟⎠ + εG

⎜⎜⎜⎜⎜⎝

⎛

0
...
r(tr,min)
...
r(tr,max)

⎞

⎟⎟⎟⎟⎟⎠

unit matrix:⎛
⎜⎜⎜⎜⎝

v
v
...
⎛
⎜⎜⎜⎜⎝

v

n+1(tu,max)
n+1(tu,max + 1)

n+1(tr,max)
n(tu,max)
n(tu,max + 1)

v
v
...

n(tr,max)

v

×

tu,max−y(cid:5)

g(y) =

k=tu,min

where we shall now use the total time T = tr,max−tu,max+1:

u(k) u(y + k) ,

∀ y = 0...k

(8)

with any real values u(k) and u(tu,max) (cid:7)= 0, and T × T -
matrices

⎛

⎜⎜⎜⎜⎜⎜⎝
⎛
⎜⎜⎜⎜⎝

G =

A =

⎞

⎟⎟⎟⎟⎟⎟⎠ and

g0

(9)

g0

g1
...
gk

g1

g0
. . .
· · ·
. . . gk

· · ·

g1
. . .
g1

· · ·

gk

· · ·
. . .
g0

g1

0
1 −1

1

−1
. . .

. . .
1

−1
1

0
. . . gk
...
g1

⎞
⎟⎟⎟⎟⎠

where the ”0” in G refers to the full remaining upper and
lower triangle, respectively, and in A all entries except for
the two diagonals are 0. We can further write this in compact
notation (vectors have component index t):

vn+1

= (E − εG A) vn + εG r

Obviously, the total future reward R(t) is not known to the
subject at time t. We can use R(t) = r(t) + R(t + 1). In this
formulation, again R(t + 1) is not known. The subject can
approximate the value by his prediction v(t + 1). This will
provide the so-called

Temporal difference rule at time t:

Δw(τ ) = εδ(t)u(t − τ ) ,

∀τ = 0...t

δ(t) = r(t) + v(t + 1) − v(t)

(4)

The updates can be made sequentially, after each time step t,
or in parallel, sampling the weight updates for all times in a
given trial, and then updating at the end of the trial. The two
alternatives do not substantially differ in the ﬁnal result after
many trials. For computational reasons, we use the parallel
version of the update rule. Other learning schedules may be
adopted, however we use eq. (4) since this is widely accepted
in the community, following [Dayan and Abbott 2001]. Let
us denote the trial number by superscripts n.

2 Dynamics of temporal difference learning
The parallel temporal difference rule eq. (4) was obtained,
using an approximation to gradient descent. Therefore, con-
vergence is not guaranteed and shall be proven in the course
of this paper, where a compact notation will be introduced.
We proceed as follows:

• Incorporate the rule into the prediction formula, yielding

a recursive formula for all predictions v

n(t) at trial n.

• Make this a closed formula v
• Show convergence v
• Choose an optimal learning rate ε for maximally fast

n(t) → R(t) for large N .

n(t).

convergence.

n+1(t) at trial n + 1 the fol-
We obtain for the predictions v
lowing recursive formula. Summation limits explicitely state
situations where stimuli and reward phases may overlap, we
will restrict to non-overlapping cases later.

min(t,tu,max)(cid:3)
(cid:3)

k=tu,min

x=tu,min

Δw

n(t − k)u(k)

ε

min(tr,max−t+k,tu,max)

n(x + t − k)u(x)

δ

t≥tu,min

n+1

v

(t) − v

n(t)

ε

min(t,tu,max)(cid:3)
(cid:3)

k=tu,min

=

=

u(k)

min(tr,max−t,tu,max−tu,min)

y=tu,min−min(t,tu,max)

n(t + y) g(t, y)

δ

With v0 = 0 one has

(5)

vN +1

= ε

N(cid:5)

(E − εG A)n G r

where δ

n(t) = r(t) + v

n(t + 1) − v

n(t) and

min(min(t,tu,max),tu,max−y)

(cid:5)

g(t, y) =

u(k)u(y + k)

(6)

k=max(tu,min,tu,min−y)

n=0
−1

(cid:14)

= ε(εGA)
= A−1

(E − (E − εGA)
(E − εG A)

(N +1)

)Gr
(N +1) G

E − G−1

r (10)

(cid:15)

Since we are interested whether the subject will make proper
predictions after all stimuli have been given, we will restrict
our analysis to times t > tu,max. Then g(t, y) will become
independent of t, giving

min(tu,max,tu,max−y)(cid:5)

g(y) = g(t, y) =

u(k)u(y + k)

(7)

k=max(tu,min,tu,min−y)

Only if (−G A) is a Hurwitz (stability) matrix (all eigenval-
ues have negative real part), a suitable ε can be chosen such
that (E − εG A)(N +1)
will vanish with large N . A similar
approach, relying on Hurwitz matrices, was followed in
[Sutton 1988], however there the Hurwitz property was not
shown immediately on the matrix structure of eq. (9). Our
aim here is to provide an explicit proof, which will establish

IJCAI-07

1108

as an interesting result in its own right a general property of
Toeplitz matrices with correlation entries.

We will show the Hurwitz property later, and we will give
values for ε for which convergence is assured and for which it
is optimal. Continuing with the large N -behaviour, we obtain
vN +1 N→∞−→ A−1 r . This holds no matter what the stimulus!
With

⎛
⎜⎜⎜⎜⎝

A−1

=

1

1 1
1 1
. . .

1
1
. . .
1

⎞
⎟⎟⎟⎟⎠

1
1
...
1
1

we obtain

T −t(cid:5)

τ =0

∞

v

(t) =

r(t + τ ) = R(t)

hence xTGx can be written as

N(cid:5)

k(cid:5)

−

2
u(t)

2
i + 2
x

N(cid:5)

k(cid:5)

k−j(cid:5)

u(t) u(t + j) xi xi+j

i=0

t=0

i=0

j=0

t=0

Rearranging the inner sums with

k(cid:5)

k−j(cid:5)

k(cid:5)

k−t(cid:5)

=

j=0

t=0

t=0

j=0

(13)

(14)

and using vectors u of dimension (k + 1) with components
ut = u(t) leads to

N(cid:5)

k(cid:5)

N(cid:5)

xTGx = −

2
u(t)

2
i + 2
x

uT ˜X(i)u

(15)

i=0

t=0

i=0

˜X(i)

where the matrices

are (k + 1) × (k + 1) band matrices
m,m+n = xixi+n for all m and n ≥ 0, and 0

with entries
otherwise. Symmetrizing the matrix products, we can write

˜X(i)

(cid:17)

(cid:16)
N(cid:5)

(cid:17)

2

uT ˜X(i)u = uT

˜X(i)

u + uT

( ˜X(i)

)T

u

(16)
The matrix elements of the second term are, for −k ≤ n ≤ 0:

i=0

i=0

(cid:17)

N(cid:5)

( ˜X(i)

)T

=

xjxj−n =

xixi+n

(17)

i=0

m,m+n

j=0

i=0

(cid:16)
N(cid:5)

N(cid:5)

N(cid:5)

i=0

(cid:16)

N(cid:5)

where the summation limits in the last result were taken, for
convenience, larger than necessary for covering all cases of
n for which the summand is nonzero (note that n is nonposi-
tive), the extra terms being zero due to the zero padding con-
vention for the xi. As a result, the matrix elements of the
ﬁrst and the second term in eq. (16) have identical format, for
nonnegative and nonpositive n, respectively.

Making use of eq. (16) and eq. (17), and incorporating the

ﬁrst sum in eq. (15) leads to

(cid:16)
N(cid:5)

(cid:17)

xTGx = uT

i=0

ˆX(i)

u

(18)

ˆX(i)

are band matrices with entries

where the matrices
ˆX(i)

m,m+n = xixi+n for positive and negative n.
We can now write the sum of matrices in eq. (18) in a dif-
ferent way. Denote vectors ˜x(i)
of dimension (k + 1) with
(i)
m = xi+m, m = 0...k, where, as before, it is
components ˜x
understood that xj = 0 for j < 0 and j > N . Hence, these
vectors will have nonzero components only for i = −k...N .
Notice that the following covariance matrices are generated

by these vectors:(cid:18)

(cid:19)

˜x(i)

(˜x(i)

)T

= xi+m xi+n

(19)

(m,n)

Then we have for (m = 0 . . . k, n = −m . . . k − m):

(cid:16)

N(cid:5)

(cid:17)

N +m(cid:5)

˜x(i)

(˜x(i)

)T

=

xi xi+n−m

(20)

i=−k

(m,n)

i=−k+m

which is the desired result. This proves convergence in full
generality. We need to show that (−G A) is a Hurwitz ma-
trix, i.e. that all eigenvalues of that matrix have negative real
part. Further, we want to give values for ε which provide
maximum speed of convergence.

3 Proof of convergence
In previous approaches in the literature, temporal difference
(TD) learning was extended to TD(λ) learning where the pa-
rameter λ refers to an exponential weighting with recency.
Learning and convergence issues were considered e.g.
in
[Dayan 1992] and [Dayan and Sejnowski 1994]. In the TD(λ)
framework, what we consider here is TD(0)-learning where
in contrast to the mentioned literature we concentrate on a di-
rect proof of convergence by establishing a general property
of Toeplitz matrices with correlation entries.

The proof proceeds as follows: we will show ﬁrst that G
is positive deﬁnite. Then, we will show that all eigenvalues
of (G A) have positive real part. Hence, we will have estab-
lished the Hurwitz property required for convergence.

In order to see that G is positive deﬁnite, we consider any
nonzero real vector x and show that xTGx is always positive.
We ﬁrst extract from G the diagonal matrix GD and the upper
triangular matrix G+. Then we have

xTGx = xTGDx + xTG+x + xTGT
+x
+x)T
= xTGDx + xTG+x + (xTGT
= xTGDx + 2 xTG+x

N(cid:5)

k(cid:5)

N(cid:5)

=

2
i + 2
g(0) x

xi

g(j) xi+j (11)

i=0

i=0

j=1

where in order to keep summation limits easy it is understood
that xi = 0 for i < 0 and i > N (”zero padding”). There are
2k+1 Toeplitz bands, k being the number of stimuli. Shifting
the time index in eq. (8) from tu,min to 0, g(j) arises from the
k stimuli for u(k) (cid:7)= 0, u(t) real as

k−|j|(cid:5)

g(j) =

t=0

u(t) u(t + |j|) ,

|j| = 0 . . . k , ∀ t

(12)

IJCAI-07

1109

Let y be any eigenvector of (G A) and λ be the corre-
sponding eigenvalue. Since (G A) is real, y and λ are ei-
ther both real or both complex. In the complex case, there
exists a further eigenvector y∗
and corresponding eigenvalue
∗
λ

denotes complex conjugated and transposed.

, where ()∗
Let us denote z = A y and write

z∗Gz = y∗A∗GAy = λy∗A∗y

Also, with G real and symmetric, we have G = G∗

∗
z∗Gz = (z∗Gz)

= λ

∗y∗Ay

The summation of eqns. 26 and 27 gives

and

(26)

(27)

2z∗Gz = y∗

∗A + λA∗

[λ

] y

(28)
With G real, symmetric and positive deﬁnite, we have for any
complex z that z∗Gz is real and positive. This can be used as
follows.

Case 1: y and λ are both real.

Then we have, with real A, from eq. (28) immediately

0 < Re(2z∗Gz) = λyT

hence

AT + A

y

sign(Re(λ)) = sign(λ) = sign(yT
Case 2: y and λ are both complex.

AT + A

(cid:21)

(29)

y)

(30)

Let us write y = v + iw and λ = g + ih. Then from eq. (28),
with real A, we obtain

(cid:20)

(cid:20)

0 < Re(2z∗Gz) = g vT

+g wT

AT + A

AT − A

AT − A

v

0 = Im(2z∗Gz) = h vT

+h wT

AT + A

(cid:22)

(cid:20)

Combining eqns. 31 and 32 gives
AT + A

0 < g(g

+ h

vT

)

2

2

v + wT

AT + A

w

(cid:22)

(cid:20)

(cid:21)

vT

v + wT

AT + A

AT + A

from which follows with sign(Re(λ)) = sign(g):
sign(Re(λ)) = sign

w
(34)
The results for both cases, eqns. 30 and 34, allow the
following sufﬁcient condition:
Let G be a real, symmetric and positive deﬁnite matrix,
and A be a real square matrix. If the matrix
is
positive deﬁnite, then the real parts of the eigenvalues of
(G A) are positive.

AT + A

(cid:21)

(cid:20)

Let us now turn our attention to the speciﬁc matrix A given

in eq. (9). We have

(cid:21)
(cid:21)

AT + A
w − 2 h wT
AT + A
w + 2 g wT

(cid:20)
(cid:20)
(cid:21)

v

(cid:21)
(cid:20)
(cid:21)
(cid:20)
(cid:20)

v

(cid:21)
(cid:21)
(cid:21)

(31)

v

(32)

(cid:23)

(cid:21)

(33)

(cid:23)

(cid:21)

(cid:20)

AT + A =

−1

2
−1 2
. . .

−1
. . .
. . .
−1 2

−1

−1 2

⎞
⎟⎟⎟⎟⎠

(35)

(cid:20)
(cid:20)

⎛
⎜⎜⎜⎜⎝

N(cid:5)

i=−k

N(cid:5)

and (cid:16)

N(cid:5)

(cid:17)

˜x(i)

(˜x(i)

)T

N +m(cid:5)

=

xi xi+n

(21)

i=−k

(m,m+n)

i=−k+m

which establishes that

˜x(i)

(˜x(i)

)T =

N(cid:5)

i=0

ˆX(i)

(22)

Then we can rewrite eq. (18), using eq. (22):

N(cid:5)

xTGx =

uT˜x(i)

(˜x(i)

)T u =

|uT˜x(i)|2

(23)

i=−k

i=−k

This sum is certainly nonnegative. We will now show that it
cannot become zero.

The proof is by contradiction. Suppose the sum is zero.
Then all individual terms must be zero. Start with the ﬁrst
term. We have from the deﬁnition

uT˜x(−k)

=

ujx−k+j = ukx0

(24)

j=0

This becomes zero, since uk (cid:7)= 0 (eq. (12)), only for x0 = 0.
Now proceed with the second term:

k(cid:5)

uT˜x(−k+1)

=

ujx−k+1+j = uk−1x0 + ukx1 = ukx1

j=0

(25)
where the previous result x0 = 0 was used. This becomes
zero, since uk (cid:7)= 0 (eq. (12)), only for x1 = 0. Continuing in
this vein, after N steps, we end with the product

k(cid:5)

k(cid:5)

uT˜x(−k+N)

=

ujx−k+N +j

j=0

= u0xN −k + . . . + uk−1xN −1 + ukxN = ukxN

where all the previous results were used. Hence xN = 0,
which in total means that x = 0. This is a contradiction,
since x must be a nonzero vector.

With this result, we have established that xTGx > 0,

hence we have established:

Symmetric Toeplitz matrices of the structure of G after
eq. (9), with correlation entries gj after eq. (12), are positive
deﬁnite.

We now turn our attention to showing that all eigenvalues
of (G A) have positive real part. We will look at any real
A and any G which is real, symmetric and positive deﬁnite.
(We will not require the stronger condition that the structure
of G is after eq. (9), and we say nothing about the entries gj.)
Under these premises, the proof will ﬁrst give a sufﬁcient
condition for the sign of the real part of the eigenvalues of
(G A). Then we will show that this sign is indeed positive
for the A at hand.

It can be shown that the matrix Q = AT + A is positive def-
inite, by using the previous result of this paper: matrices of
the structure of G are positive deﬁnite. Noting that Q has the
structure of G, using eq. (12) with k = 1 and u = (1,-1), im-
mediately gives the desired result. This completes our proof
that (−G A) is a Hurwitz matrix.

IJCAI-07

1110

4 Learning rate ε for fast convergence
The convergence behaviour of the temporal difference rule is
known from eq. (10). For large number of trials, convergence
speed will be dominated by the eigenvalue of (E − εG A)
with the largest modulus, for which convergence speed is
slowest. We have for the eigenvalues (ev):
ev(E − εG A) = 1 − ε ev(G A) = 1 − ε (g + i h) (36)
where the same notation for the eigenvalues of G A as in the
previous section, λ = g + i h, was used.

Hence, the ﬁrst task to do is to compute the eigenvalues of
G A which are only dependent on the given stimuli u(k) and
on the total time T . Note that G A deﬁnes the special struc-
ture of an unsymmetric Toeplitz matrix with 2k + 2 bands.
It is well known that a closed solution for the eigenvalues of
Toeplitz matrices exists only for not more than three bands,
they are given for symmetric and asymmetric cases e.g. in
[Beam and Warming 1993]. Hence only for k = 0 can a
closed solution been given, which we do in sec. 5. For k > 0
numerical values must be obtained, special methods for the
solution, and for the asymptotic structure of the eigenvalues
for large T , are given in [Beam and Warming 1993].

The square modulus m of the eigenvalues is given by
m(ε) = | ev(E − εG A) |2

2
= (1 − ε g)

+ ε

h

2

2

(37)

We will ﬁrst give a choice for ε for which convergence is
always assured and which also serves as a good rough value
for setting ε without much computational effort.

Note ﬁrst that m(ε = 0) = 1 for all eigenvalues. Fur-
ther, since (− G A) is Hurwitz, g > 0 for all eigenvalues,
and for small ε > 0, m(ε) < 1 for all eigenvalues due to
eq. (37). Lastly, for large ε, m(ε) will increase again beyond
all bounds for all eigenvalues, since m(ε) ∝ ε
for large ε
and all eigenvalues.

2

After this sketch of the general behaviour of m(ε), it is
clear that for each eigenvalue k there is a ε(k) (cid:7)= 0 for which
m(ε(k)) = 1 and m(ε(k)) is rising with ε(k). Computing
these values from eq. (37) for eigenvalues λk = gk + ihk
gives

ε(k) =

g

2 gk
2
k + h

2
k

(38)

Hence, m(ε) < 1 for 0 < ε < mink ε(k), and a good choice
˜ε for convergent behaviour is therefore the mean value of the
bounds,

˜ε = mink

gk

2
k + h

2
k

g

(39)

Note again that whenever hk (cid:7)= 0, there is an additional
eigenvalue gk − i hk for which the minimum in eq. (39) is
identical and needs not be computed.

We now turn to ﬁnding the optimal value ε

vergence. This is given by

∗

for fastest con-

∗

ε

= argminε maxk m(ε(k))

(40)

This optimization problem has no closed solution. However,
a simple line search algorithm can be given to ﬁnd the solu-
tion in ﬁnitely many (less than T ) steps.

The general idea is to start at ε = 0 and increase ε un-
. In all of this process, we select a k and go

til we reach ε

∗

along curves m(ε(k)), ensuring the condition that our chosen
k satisﬁes maxk m(ε(k)).

At ε = 0, all m(ε(k)) = 1 and decreasing with ε. The
for
∗ = argmink gk, which ensures that the condition
. Our current

slope is given by −2gk < 0. We start by choosing the k
which k
maxk m(ε(k)) is satisﬁed by our choice of k
position is εc = 0. Then we apply the following procedure:

∗

∗

[START]

Continuing on curve k

∗

, we would reach the minimum for
∗
k∗ =

gk∗

ε

(41)

2
k∗ + h

2
k∗

g

if everywhere between our current position εc and the pro-
∗
k∗ the maximum condition maxk m(ε(k)) is
posed position ε
. In order to check this, we compute the inter-
satisﬁed for k
sections of our curve under inspection k
to all other curves
k.

∗

∗

After eq. (37), these intersections are given at values εk

according to

2
(1 − εk gk)

+ ε

2
k h

2
2
k = (1 − εk gk∗ )

+ ε

2
k h

2
k∗

or

εk = 2

gk − gk∗
2
2
k − h
k∗ + h

2
k − g

g

2
k∗

(42)

(43)

Now we inspect the intersection which is closest to our
current position of εc, i.e. for which ˆk = argmink{ εk,
εk > εc}.

∗
k∗ , then ε

∗
k∗ after eq. (41) is indeed the solution

If εˆk > ε

(free minimum).

[STOP]

Else, there is an intersection prior to reaching ε

∗
k∗ . If the
curve that is intersecting is rising at ε(ˆk), this means that
we are done, since we actually have reached the condition
of eq. (40). The solution is

(cid:24)

(cid:25)

ε(ˆk) = mink

ε(k) = 2

gk − gk∗
2
2
k − h
k∗ + h

2
k − g

g

2
k∗

, ε(k) > εc

(44)

(bounded minimum).

[STOP]

Else, if the curve that is intersecting is falling at ε(ˆk), we
must continue on that new curve which now satisﬁes the max-
imum condition in eq. (40). To this end, we set εc = ε(ˆk) and
∗ = ˆk and continue (change in falling curves with maximum
k
modulus).

[GO TO START]

Fig. 1 illustrates the behaviour with free minimum, ﬁg. 2
with bounded minimum. Both ﬁgures have a change in falling
curves with maximum modulus.

This algorithm terminates after ﬁnitely many steps, either
or at an intersection of a
at the minimum of the curve k
It is clear that one of the two
falling with a rising curve.
possibilities exist since all curves eventually rise with large ε.

∗

5 One stimulus
We look at the special case where only one stimulus u is
present, hence k = 0. Then, eq. (10) takes a particularly
simple form, where (E − A) is the unit shift matrix:

AvN +1

= r −

N
j

(1 − ε u

2

)N −j

2

ε u

(E − A)

r

(cid:27)

(cid:26)

T(cid:5)

j=0

(cid:20)

(cid:21)j

(45)

IJCAI-07

1111

(1 − ε)2 + 4 ε2
(1 − 1.3 ε)2 + 40 ε2
(1 − 3 ε)2 + 120 ε2

tors of algebraic multiplicity 1 . . . T .

6 Conclusion

We have presented a closed formula of the prediction of re-
wards at trial time t within trial n and shown its convergence,
where two general formulae for Toeplitz matrices and eigen-
values of products of matrices were derived and utilized. We
have given learning rates which optimally speed up the learn-
ing process.

References
[Beam and Warming 1993] Beam, R and Warming, R
(1993). The Asymptotic Spectra of Banded Toeplitz and
Quasi-Toeplitz Matrices. SIAM Jour. Scientiﬁc Comput-
ing, 14 (4), 971–1006.

[Dayan and Abbott 2001] Dayan, P and Abbott, LF (2001).

Theoretical Neuroscience. Cambridge, MA: MIT Press.

[Dayan and Sejnowski 1994] Dayan, P and Sejnowski, TJ
(1994). TD(λ) converges with probability 1. Machine
Learning, 14, 295-301.

[Dayan 1992] Dayan, P (1992). The convergence of TD(λ)

for general λ. Machine Learning, 8, 341-362.

[Gordon 2001] Gordon, GJ (2001) Reinforcement

learn-
ing with function approximation converges to a region.
Neural Information Processing Systems, pages 1040-1046
(NIPS’01).

[Montague et al. 1996] Montague, PR, Dayan, P and Se-
jnowski, TJ (1996) A framework for mesencephalic
dopamine systems based on predictive Hebbian learning.
Journal of Neuroscience, 16, 1936-1947.

[Schultz 1998] Schultz, W (1998) Predictive reward signal
of dopamine neurons. Journal of Neurophysiology, 80,
1–27.

[Sutton and Barto 1998] Sutton, RS and Barto, AG (1998)

Reinforcement Learning. Cambridge, MA: MIT Press.

[Sutton and Barto 1990] Sutton, RS and Barto, AG: Time-
derivative models of Pavlovian reinforcement. In M.
Gabriel and J. Moore, editors: Learning and Computa-
tional Neuroscience: Foundations of Adaptive Networks,
pages 497–537. MIT Press, 1990.

[Sutton 1988] Sutton, RS (1988). Learning to predict by the
method of temporal differences. Machine Learning, 3,
9–44.

[Szepesvari and Smart 2004] Szepesvari, C and Smart, WD
(2004) Convergent value function approximation methods.
International Conference on Machine Learning (ICML04).

[Watkins 1989] Watkins, CJCH (1989) Learning from De-
layed Rewards. PhD thesis, Kings College, Cambridge,
England.

1

0.98

)
ε
(
m

0.96

0.94

0.92

0

0.01

0.02

ε

0.03

0.04

∗

∗

Figure 1: Free minimum: starting at ε = 0, the solid curve
). At the circle, another falling
has maximum modulus (k
curve (dashed) is intersecting and takes the maximum role of
. The global minimum of that curve (diamond) is as well
k
the total minimum after eq. (40), with m = 0.959. The next
intersection with the rising (dotted) curve (square) is of no
importance since it occurs at a higher ε. The vertical line indi-
cates the approximate value ˜ε after eq. (39) with non-optimal
m(˜ε) = 0.962.

1

0.98

)
ε
(
m

0.96

0.94

0.92

0

(1 − ε)2 + 4 ε2
(1 − 1.3 ε)2 + 40 ε2
(1 − 2.5 ε)2 + 130 ε2

0.01

0.02

ε

0.03

0.04

∗

Figure 2: Bounded minimum: As in ﬁg. 1, starting at ε = 0,
ﬁrst the solid curve and then the dashed curve have maximum
). The next intersection (square) occurs with the
modulus (k
rising (dotted) curve, hence this intersection is the total mini-
mum after eq. (40), with m = 0.961. The global minimum of
the dashed curve (diamond) is of no importance since it oc-
curs at a higher ε. The vertical line indicates the approximate
value ˜ε after eq. (39) with non-optimal m(˜ε) = 0.966.

After eq. (38), any 0 < ε < 2u

will ensure convergence
with exponential error decay over time, except for the case
2 = 1. In this
when choosing the optimal learning rate ε u
case we obtain for N ≤ T :
= A−1

E − (E − A)N

vN +1

(cid:29)

r

−2

(cid:28)

(46)

and for N > T we have vN +1 = A−1r. Hence, after ﬁnitely
many (T ) steps, convergence is reached when choosing the
optimal learning rate. This is due to the fact that (G A) has
only one degenerate eigenvalue, and T generalized eigenvec-

IJCAI-07

1112

