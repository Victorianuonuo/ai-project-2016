Combining Learning and Word Sense Disambiguation

for Intelligent User Proﬁling

∗

Giovanni Semeraro, Marco Degemmis, Pasquale Lops, Pierpaolo Basile

Department of Informatics

University of Bari, Italy

{semeraro, degemmis, lops, basilepp}@di.uniba.it

Abstract

Understanding user interests from text documents
can provide support to personalized information
recommendation services. Typically, these services
automatically infer the user proﬁle, a structured
model of the user interests, from documents that
were already deemed relevant by the user. Tradi-
tional keyword-based approaches are unable to cap-
ture the semantics of the user interests. This work
proposes the integration of linguistic knowledge in
the process of learning semantic user proﬁles that
capture concepts concerning user interests. The
proposed strategy consists of two steps. The ﬁrst
one is based on a word sense disambiguation tech-
nique that exploits the lexical database WordNet to
select, among all the possible meanings (senses) of
a polysemous word, the correct one. In the second
step, a na¨ıve Bayes approach learns semantic sense-
based user proﬁles as binary text classiﬁers (user-
likes and user-dislikes) from disambiguated docu-
ments. Experiments have been conducted to com-
pare the performance obtained by keyword-based
proﬁles to that obtained by sense-based proﬁles.
Both the classiﬁcation accuracy and the effective-
ness of the ranking imposed by the two different
kinds of proﬁle on the documents to be recom-
mended have been considered. The main outcome
is that the classiﬁcation accuracy is increased with
no improvement on the ranking. The conclusion
is that the integration of linguistic knowledge in
the learning process improves the classiﬁcation of
those documents whose classiﬁcation score is close
to the likes / dislikes threshold (the items for which
the classiﬁcation is highly uncertain).

1 Introduction

Personalized systems adapt their behavior to individual users
by learning their preferences during the interaction in order
to construct a user proﬁle, that can be later exploited in the

∗This research was partially funded by the European Commis-
sion under the 6th Framework Programme IST Integrated Project
VIKEF, Priority 2.3.1.7 Semantic-based Knowledge Systems.

search process. Traditional keyword-based approaches are
primarily driven by a string-matching operation: If a string,
or some morphological variant, is found in both the proﬁle
and the document, a match occurs and the document is con-
sidered relevant. String matching suffers from problems of
polysemy, the presence of multiple meanings for one word,
and synonymy, multiple words having the same meaning. The
result is that, due to synonymy, relevant information can be
missed if the proﬁle does not contain the exact keywords in
the documents, while, due to polysemy, wrong documents
could be deemed relevant. These problems call for alternative
methods to learn more accurate proﬁles that capture concepts
expressing user interests from relevant documents. These se-
mantic proﬁles should contain references to concepts deﬁned
in lexicons or ontologies. This paper describes an approach
in which user proﬁles are obtained by machine learning tech-
niques integrated with a word sense disambiguation (WSD)
strategy based on the WordNet lexical database [Miller, 1990;
Fellbaum, 1998]. The paper is organized as follows: After a
brief discussion about the main works related to our research,
in Section 3 the WSD strategy proposed to represent docu-
ments by using WordNet is described. Section 4 presents the
na¨ıve Bayes text categorization method we adopted to build
WordNet-based user proﬁles. This method is implemented
by the content-based proﬁling system ITem Recommender
(ITR). An experimental sessions has been carried out in order
to evaluate the proposed approach in a movie recommending
scenario. The main results are presented in Section 5. Con-
clusions and future work are discussed in Section 6.

2 Related Work
Our research was mainly inspired by the following works.
Syskill & Webert [Pazzani and Billsus, 1997] learns user pro-
ﬁles as Bayesian classiﬁers able to recommend web pages,
but it represents documents using keywords. LIBRA [Mooney
and Roy, 2000] adopts a Bayesian classiﬁer to produce
content-based book recommendations by exploiting product
descriptions obtained from the web pages of the Amazon on-
line digital store. Documents are represented by using key-
words and are subdivided into slots, each one corresponding
to a speciﬁc section of the document. Like Syskill & Webert,
the main limitation of this work is that keywords are used
to represent documents. Conversely, SiteIF [Magnini and
Strapparava, 2001] exploits a sense-based document repre-

IJCAI-07

2856

sentation to build a user proﬁle as a semantic network whose
nodes represent senses of the words in documents requested
by the user. The semantic network is built by assigning each
node with a score that is inversely proportional to its fre-
quency over all the corpus. Thus, the score is higher for
less frequent senses, and this prevents very common mean-
ings from becoming too prevailing in the user model. In our
approach, a probability distribution of the senses, found in
the corpus of the documents rated by the user, is learned.
OntoSeek [Guarino et al., 1999] is a system designed for
content-based information retrieval from online yellow pages
and product catalogs, which explored the role of linguistic
ontologies in knowledge-retrieval systems. That approach
has shown that structured content representations, coupled
with linguistic ontologies, can increase both recall and pre-
cision of content-based retrieval systems. By taking into ac-
count the lessons learned by the aforementioned works, ITR
has been conceived as a text classiﬁer able: 1) To deal with
a sense-based document representation obtained by exploit-
ing a linguistic ontology; 2) To learn a Bayesian proﬁle from
documents subdivided into slots. The strategy we devise in
order to shift from a keyword-based document representa-
tion to a sense-based one, is to integrate lexical knowledge
in the indexing step of training documents. Several meth-
ods have been proposed to accomplish this task. Scott and
Matwin [1998] included WordNet information at the feature
level by expanding each word in the training set with all its
synonyms in WordNet in order to avoid a WSD process. This
approach has shown a decrease of effectiveness in the ob-
tained classiﬁer, mostly due to the word ambiguity problem.
Therefore, it suggests that some kind of disambiguation is
required. Bloedhorn and Hotho [2004] experiment with var-
ious settings for mapping words to senses: No WSD, most
frequent sense as provided by WordNet, WSD based on con-
text. They found positive results on the Reuters 251781, the
OHSUMED2 and the FAODOC3 corpora. None of the pre-
vious approaches for embedding WSD in classiﬁcation has
taken into account the fact that WordNet is a hierarchical the-
saurus. A distinctive feature of our work is the adoption of
a similarity measure that takes into account the hierarchical
structure of WordNet.

3 Using WordNet to Represent Documents
We consider the problem of learning user proﬁles as a binary
text categorization task: Each document has to be classiﬁed as
interesting or not with respect to the user preferences. The set
of categories is C = {c+, c−}, where c+ is the positive class
(user-likes) and c− the negative one (user-dislikes). There
are several ways in which content can be represented in order
to be used as a basis for the learning component and there
exists a variety of machine learning methods that could be
exploited for inferring user proﬁles. We propose a strategy
to learn sense-based proﬁles that consists of two steps. This
section describes the ﬁrst one, that is, a WSD technique that
exploits the word senses in WordNet to represent documents.

1http://about.reuters.com/researchandstandards/corpus/
2http://www.ltg.ed.ac.uk/disp/resources/
3http://www4.fao.org/faobib/index.html

In the second step, described in Section 4, a na¨ıve Bayes
approach learns sense-based user proﬁles as binary text clas-
siﬁers (user-likes and user-dislikes) from disambiguated doc-
uments. A thorough experimental evaluation of that idea in
the context of a hybrid (content-based / collaborative) rec-
ommender system has been carried out in [Degemmis et al.,
2007].

3.1 The JIGSAW Algorithm for Word Sense

Disambiguation

Textual documents cannot be directly interpreted by learning
algorithms. An indexing procedure that maps a document
di into a compact representation of its content must be ap-
plied. A typical choice for document indexing is the classi-
cal bag-of-words (BOW) approach, where each document is
represented as a feature vector counting the number of occur-
rences of different words as features [Sebastiani, 2002]. We
extend the BOW model to a model in which each document
is represented by the senses corresponding to the words in its
content and their respective occurrences. This sense-based
document representation is exploited by the learning algo-
rithm to build semantic user proﬁles. Here, “sense” is used
as a synonym of “meaning”. Any implementation of sense-
based document indexing must solve the problem that, while
words occur in a document, meanings do not, since they are
often hidden in the context. Therefore, a procedure is needed
for assigning senses to words. This task, known as word sense
disambiguation, consists in determining which of the senses
of an ambiguous word is invoked in a particular use of that
word [Manning and Sch¨utze, 1999].

The goal of a WSD algorithm is to associate a word wi oc-
curring in a document d with its appropriate meaning or sense
s, by exploiting the context C in which wi is found, com-
monly deﬁned as a set of words that precede and follow wi.
The sense s is selected from a predeﬁned set of possibilities,
usually known as sense inventory. In the proposed algorithm,
the sense inventory is obtained from WordNet (version 1.7.1).
WordNet was designed to establish connections between four
types of Parts of Speech (POS): Noun, verb, adjective, and
adverb. The basic building block for WordNet is the SYNSET
(SYNonym SET), which represents a speciﬁc meaning of a
word. The speciﬁc meaning of one word under one type
of POS is called a sense. Synsets are equivalent to senses,
which are structures containing sets of words with synony-
mous meanings. Each synset has a gloss, a short textual de-
scription that deﬁnes the concept represented by the synset.
For example, the words night, nighttime and dark constitute
a single synset that has the following gloss: “the time after
sunset and before sunrise while it is dark outside”. Synsets
are connected through a series of relations: Antonymy (oppo-
sites), hyponymy/hypernymy (IS-A), meronymy (PART-OF),
etc. JIGSAW is a WSD algorithm based on the idea of com-
bining three different strategies to disambiguate nouns, verbs,
adjectives and adverbs. The motivation behind our approach
is that the effectiveness of the WSD algorithms is strongly
inﬂuenced by the POS tag of the target word. An adaptation
of Lesk dictionary-based WSD algorithm has been used to
disambiguate adjectives and adverbs [Banerjee and Pedersen,
2002], an adaptation of the Resnik algorithm has been used to

IJCAI-07

2857

disambiguate nouns [Resnik, 1995], while the algorithm we
developed for disambiguating verbs exploits the nouns in the
context of the verb as well as the nouns both in the glosses
and in the phrases that WordNet utilizes to describe the us-
age of the verb. The algorithm disambiguates only words
which belong to at least one synset. JIGSAW takes as in-
put a document d = {w1, w2, . . . , wh} and will output a
list of WordNet synsets X = {s1, s2, . . . , sk} (k ≤ h) in
which each element si is obtained by disambiguating the tar-
get word wi based on the information obtained from WordNet
about a few immediately surrounding words. We deﬁne the
context C of the target word to be a window of n words to
the left and another n words to the right, for a total of 2n
surrounding words. The algorithm is based on three different
procedures for nouns, verbs, adverbs and adjectives, called
JIGSAWnouns, JIGSAWverbs, JIGSAWothers, respec-
tively. The POS tag of each word is computed by the HMM-
based tagger ACOPOST t34. JIGSAW proceeds in several
iterations by using the disambiguation results of the previ-
ous iteration to reduce the complexity of the next one. First,
JIGSAW performs the JIGSAWnouns procedure. Then,
verbs are disambiguated by JIGSAWverbs by exploiting the
words already disambiguated by JIGSAWnouns. Finally,
the JIGSAWothers procedure is executed. More details for
each one of the above mentioned procedures follow.

JIGSAWnouns
The algorithm assigns to wi the most appropriate synset sih
among the sense inventory Wi for wi. It computes the sim-
ilarity between each sik in the sense inventory and the con-
text for wi. The method differs from the original algorithm
by Resnik [1995] in the use of the similarity measure. We
adopted the Leacock-Chodorow measure [1998], which is
based on the length of the path between concepts in an IS-
A hierarchy. The idea behind this measure is that similar-
ity between synsets a and b is inversely proportional to their
distance in the WordNet IS-A hierarchy. The distance is
computed by counting the number of nodes in the shortest
path joining a with b (by passing through their most spe-
ciﬁc subsumer). The similarity function is: SinSim(a, b) =
− log(Np/2D), where Np is the number of nodes in the
shortest path p from a to b, and D is the maximum depth
of the taxonomy (D = 16, in WordNet 1.7.1). The proce-
dure starts by deﬁning the context C of wi as the set of words
having the same POS tag and found in the same sentence as
wi. Next, the algorithm identiﬁes both the sense inventory
for wi and the sense inventory Wj, for each word wj in C.
The sense inventory T for the whole context C is given by
the union of all Wj. JIGSAWnouns measures the similar-
ity between each candidate sense sik ∈ Wi and each sense
sh ∈ T . The sense assigned to wi is the one with the highest
similarity score.

JIGSAWverbs
Before describing the JIGSAWverbs procedure, the descrip-
tion of a synset must be deﬁned. It is the string obtained by
concatenating the gloss and the sentences that WordNet uses
to explain the usage of a word. For example, the gloss for

the synset corresponding to the sense n.2 of the verb look
({look, appear, seem}) is “give a certain impression or have
a certain outward aspect”, while some examples of usage of
the verb are: “She seems to be sleeping”; “This appears to
be a very difﬁcult problem”. The description of the synset
is “give a certain impression or have a certain outward as-
pect She seems to be sleeping This appears to be a very dif-
ﬁcult problem”. First, the JIGSAWverbs includes in the
context C for the target verb wi all the nouns in the win-
dow of 2n words surrounding wi. For each candidate synset
sik of wi, the algorithm computes nouns(i, k), that is the
set of nouns in the description for sik. In the above exam-
ple, nouns(look, 2)={impression, aspect, problem}. Then,
for each wj in C and each synset sik, the following value is
computed:

maxjk = maxwl∈nouns(i,k) {SinSim(wj ,wl)}

(1)

In other words, maxjk is the highest similarity value for wj,
with respect to the nouns related to the k-th sense for wi.
Finally, a score for each sik is computed:

(cid:2)

ϕ(i, k) = R(k) ·

wj ∈C G(posj) · maxjk

(cid:2)

hG(posh)

(2)

where R(k) is the ranking of sik (synsets in WordNet are
ranked according to their frequency of usage) and G(posj ) is
a gaussian factor related to the position of wj with respect to
wi in the original text that gives a higher weight to words near
the target word. The synset assigned to wi is the one with the
highest ϕ value.

JIGSAWothers

This procedure is based on the WSD algorithm proposed
in [Banerjee and Pedersen, 2002]. The idea is to compare
the glosses of each candidate sense for the target word to
the glosses of all the words in its context. Let Wi be the
sense inventory for the target word wi. For each sik ∈
Wi, JIGSAWothers computes the string targetGlossik that
contains the words in the gloss of sik. Then, the proce-
dure computes the string contextGlossi, which contains the
words in the glosses of all the synsets corresponding to each
word in the context for wi. Finally, the procedure computes
the overlap between contextGlossi and targetGlossik, and
assigns the synset with the highest overlap score to wi. This
score is computed by counting the words that occur both in
targetGlossik and in contextGlossi. The JIGSAW algo-
rithm was evaluated according to the parameters of the Sen-
seval initiative5, that provides a forum where the WSD sys-
tems are assessed against disambiguated datasets. In order to
measure the capability of disambiguating a complete text, the
“All Words Task” for English was chosen. JIGSAW reaches
the fourth position in that task, by achieving precision and re-
call equal to 50%. This result assures that our WSD algorithm
can be conﬁgured to have high precision, and thus would add
very little noise in the training set. Due to space limitations,
the details of the experiments are not reported.

4http://acopost.sourceforge.net/

5http://www.senseval.org.

IJCAI-07

2858

3.2 Keyword-based and Synset-based Document

Representation

The WSD procedure described in the previous section is
adopted to obtain a synset-based vector space representation
that we called bag-of-synsets (BOS). In this model, a synset
vector instead of a word vector represents a document. An-
other key feature of the approach is that each document is
represented by a set of M slots, where each slot is a textual
ﬁeld corresponding to a speciﬁc feature of the document, in
an attempt to take also into account the document structure.
According to the BOS model, the text in each slot is repre-
sented by counting separately the occurrences of a synset in
the slots in which it occurs. More formally, assume that we
have a collection of N documents. Let m be the index of the
slot, for n = 1, 2, . . . , N , the n-th document dn is reduced to
M bags of synsets, one for each slot:

nDnm

n1, tm

n2, . . . , tm

(cid:6), m=1, 2, . . . , M

dm
n = (cid:5)tm
where tm
nk is the k-th synset in slot sm of document dn and
Dnm is the total number of synsets appearing in the m-th slot
of document dn. For all n, k and m, tm
nk ∈ Vm, which is
the vocabulary for the slot sm (the set of all different synsets
found in slot sm). Document dn is ﬁnally represented in the
vector space by M synset-frequency vectors:

f m
n = (cid:5)wm

n1, wm

n2, . . . , wm

nDnm

(cid:6)

where wm
nk is the weight of the synset tk in the slot sm of doc-
ument dn, and can be computed in different ways: It can be
simply the number of times synset tk appears in slot sm, as
we used in our experiments, or a more complex TF-IDF score.
Our hypothesis is that the proposed document representation
helps to obtain proﬁles able to recommend documents seman-
tically closer to the user interests. The difference with respect
to keyword-based proﬁles is that synset unique identiﬁers re-
place words.

4 A Na¨ıve Bayes Method for User Proﬁling
ITem Recommender (ITR) uses a Na¨ıve Bayes text catego-
rization algorithm to build proﬁles as binary classiﬁers (user-
likes vs user-dislikes). The induced probabilistic model esti-
mates the a posteriori probability, P (cj|di), of document di
belonging to class cj as follows:
(cid:3)

P (cj|di) = P (cj)

P (tk|cj)N (di,tk)

(3)

w∈di

where N (di, tk) is the number of times token tk occurs in
document di. In ITR, each document is encoded as a vec-
tor of BOS in the synset-based representation, or as a vector
of BOW in the keyword-based representation, one BOS (or
BOW) for each slot. Therefore, equation (3) becomes:

P (cj|di) =

P (cj)
P (di)

|S|(cid:3)

|bim|(cid:3)

m=1

k=1

P (tk|cj, sm)nkim

(4)

BOW-represented documents, tokens tk in bim are words, and
the induced categorization model relies on word frequencies.
Conversely, when training is performed on BOS-represented
documents, tokens are synsets, and the induced model relies
on synset frequencies. To calculate (4), the system has to esti-
mate P (cj) and P (tk|cj, sm) in the training phase. The doc-
uments used to train the system are rated on a discrete scale
from 1 to MAX, where MAX is the maximum rating that can
be assigned to a document. According to an idea proposed
in [Mooney and Roy, 2000], each training document di is la-
beled with two scores, a “user-likes” score wi
+ and a “user-
dislikes” score wi

−, obtained from the original rating r:

wi

+ =

r − 1

M AX − 1

;

wi

− = 1 − wi
+

(5)

The scores in (5) are exploited for weighting the occur-
rences of tokens in the documents and to estimate their prob-
abilities from the training set T R. The prior probabilities of
the classes are computed according to the following equation:

|T R|(cid:2)

wi

j + 1

i=1
|T R| + 2

ˆP (cj) =

(6)

smoothing [1991]

Witten-Bell
is adopted to compute
P (tk|cj, sm), by taking into account that documents are
structured into slots and that token occurrences are weighted
using scores in equation (5):

⎧⎪⎪⎨
⎪⎪⎩

ˆP (tk|cj, sm) =

N (tk,cj ,sm)
P
+

N (ti,cj ,sm)

i

Vcj

if N (tk, cj, sm) (cid:7)= 0

Vcj

+

P

i

Vcj
N (ti,cj ,sm)

1

V −Vcj

otherwise

(7)
where N (tk, cj, sm) is the count of the weighted occurrences
of token tk in the slot sm in the training data for class cj,
Vcj is the total number of unique tokens in class cj, and
V is the total number of unique tokens across all classes.
N (tk, cj, sm) is computed as follows:
|T R|(cid:8)

N (tk, cj, sm) =

i=1

wi

jnkim

(8)

In (8), nkim is the number of occurrences of token tk in slot
sm of document di. The sum of all N (tk, cj, sm) in the de-
nominator of equation (7) denotes the total weighted length
of the slot sm in class cj. In other words, ˆP (tk|cj, sm) is es-
timated as the ratio between the weighted occurrences of tk
in slot sm of class cj and the total weighted length of the slot.
The ﬁnal outcome of the learning process is a probabilistic
model used to classify a new document in the class c+ or c−.
This model is the user proﬁle, which includes those tokens
that turn out to be most indicative of the user preferences,
according to the value of the conditional probabilities in (7).

where S= {s1, s2, . . . , s|S|} is the set of slots, bim is the BOS
or the BOW in the slot sm of di, nkim is the number of oc-
currences of token tk in bim. When the system is trained on

5 Experimental Evaluation
The goal of the experiments was to compare the performance
of synset-based user proﬁles to that of keyword-based pro-

IJCAI-07

2859

ﬁles. Experiments were carried out on a content-based ex-
tension of the EachMovie dataset6, a collection of 1, 628 tex-
tual descriptions of movies rated by 72, 916 users on a 6-point
scale (1−6). The content information for each movie was col-
lected from the Internet Movie Database7 by using a crawler
that gathered the Title, the Director, the Genre, that is the cat-
egory of the movie, the Keywords, the Summary and the Cast.
Movies are subdivided into different genres: Action, Anima-
tion, Classic, Art Foreign, Comedy, Drama, Family, Horror,
Romance, Thriller. For each genre or category, a set of 100
users was randomly selected among users that rated n items,
30 ≤ n ≤ 100 in that movie category (only for genre ‘Anima-
tion’, the number of users that rated n movies was 33, due to
the low number of movies in that genre). In this way, for each
category, a dataset of at least 3, 000 triples (user, movie, rat-
ing) was obtained (at least 990 for ‘Animation’). Table 1 sum-
marizes the data used for the experiments.

Id
1
2
3
4
5
6
7
8
9
10

Genre
Action

Animation
Art Foreign

Classic
Comedy
Drama
Family
Horror

Romance
Thriller

Number ratings % POS % NEG

4,474
1,103
4,246
5,026
4,714
4,880
3,808
3,631
3,707
3,709
39,298

72
57
76
92
63
76
64
60
73
72
72

28
43
24
8
37
24
36
40
27
28
28

Table 1: 10 ‘Genre’ datasets obtained from EachMovie

Tokenization, stopword elimination and stemming have
been applied to index the documents according to the BOW
model. The content of slots title, director and cast was only
tokenized because the elimination of the stopwords produced
some unexpected results. For example, slots containing ex-
clusively stopwords, such as “It” or “E.T.”, became empty.
Moreover, it does not make sense to apply stemming and
stopword elimination on proper names. Documents have
been processed by the JIGSAW algorithm and indexed ac-
cording to the BOS model, obtaining a 38% feature reduction.
This is mainly due to the fact that synonym words are repre-
sented by the same synset. Keyword-based proﬁles were in-
ferred by learning from BOW-represented documents, whilst
synset-based proﬁles were obtained from BOS-represented
documents. As ITR is conceived as a text classiﬁer, its ef-
fectiveness is evaluated by the well-known classiﬁcation ac-
curacy measures precision and recall [Sebastiani, 2002]. Also
used is F1 measure, a combination of precision and recall. We
adopted the Normalized Distance-based Performance Mea-
sure (NDPM) [Yao, 1995] to measure the distance between
the ranking imposed on documents by the user ratings and
the ranking predicted by ITR, that ranks documents accord-

6EachMovie

dataset

no
the GroupLens

see

load,
sion named MovieLens,
http://www.cs.umn.edu/Research/GroupLens/

home

longer

available

down-
new ver-
originally based on this dataset:

page

for

for

a

7IMDb, http://www.imdb.com

Id
1
2
3
4
5
6
7
8
9
10

Precision
BOS
BOW
0.70
0.74
0.57
0.51
0.86
0.76
0.93
0.92
0.67
0.56
0.75
0.78
0.73
0.58
0.72
0.53
0.77
0.70
0.75
0.71
0.67
0.75

Recall

F1

NDPM

BOW
0.83
0.62
0.84
0.99
0.66
0.89
0.67
0.65
0.83
0.86
0.78

BOS
0.89
0.70
0.96
0.99
0.80
0.92
0.83
0.89
0.91
0.91
0.88

BOW
0.76
0.54
0.79
0.96
0.59
0.81
0.71
0.58
0.75
0.77
0.73

BOS
0.80
0.61
0.91
0.96
0.72
0.84
0.79
0.79
0.83
0.81
0.81

BOW
0.45
0.41
0.45
0.48
0.46
0.46
0.42
0.41
0.49
0.48
0.45

BOS
0.45
0.39
0.45
0.48
0.46
0.45
0.42
0.43
0.49
0.48
0.45

Table 2: Performance of ITR on 10 different datasets

ing to the a-posteriori probability of the class likes. Values
range from 0 (agreement) to 1 (disagreement). The adop-
tion of both classiﬁcation accuracy and rank accuracy metrics
gives us the possibility of evaluating both whether the sys-
tem is able to recommend relevant documents and how these
documents are ranked. In all the experiments, a movie de-
scription di is considered relevant by a user if the rating is
greater or equal to 4, while ITR considers a description rele-
vant if P (c+|di) > 0.5, computed as in equation (4). We ex-
ecuted one run of the experiment for each user in the dataset.
Each run consisted in: 1) Selecting the documents and the
corresponding ratings given by the user; 2) Splitting the se-
lected data into a training set Tr and a test set Ts; 3) Using
Tr for learning the corresponding user proﬁle; 4) Evaluating
the predictive accuracy of the induced proﬁle on Ts, using
the aforementioned measures. The methodology adopted for
obtaining Tr and Ts was the 5-fold cross validation. Table 2
shows the results reported over all 10 genres by ITR.

A signiﬁcant improvement of BOS over BOW both in pre-
cision (+8%) and recall (+10%) can be noticed. The BOS
model outperforms the BOW model speciﬁcally on datasets
5 (+11% of precision, +14% of recall), 7 (+15% of precision,
+16% of recall), 8 (+19% of precision, +24% of recall). Only
on dataset 4 no improvement can be observed, probably be-
cause precision and recall are already very high. It could be
noticed from the NDPM values that the relevant / not rele-
vant classiﬁcation accuracy is increased without improving
the ranking. This result can be explained by the example in
Table 3, in which each column reports the ratings or scores of
the items and the corresponding positions in the ranking.

Let Ru be the ranking imposed by the user u on a set of
10 items, RA the ranking computed by A, and RB the rank-
ing computed by method B (ratings ranging between 1 and 6
- classiﬁcation scores ranging between 0 and 1). An item is
considered relevant if the rating r > 3 (symmetrically, if the
ranking score s ≥ 0.5). Method A has a better classiﬁcation
accuracy compared to method B (Recall=4/5, Precision=4/5
vs. Recall=3/5, Precision=3/4). NDPM is almost the same
for both methods because the two rankings RA and RB are
very similar. The difference is that I4 is ranked above I6 in
RA, whilst I6 is ranked above I4 in RB. The general conclu-
sion is that method A (BOS model) has improved the clas-
siﬁcation of items whose score (and ratings) are close to the
relevant / not relevant threshold (items for which the classi-

IJCAI-07

2860

Item

I1
I2
I3
I4
I5
I6
I7
I8
I9
I10

Ru
6 (1)
5 (2)
5 (3)
4 (4)
4 (5)
3 (6)
3 (7)
2 (8)
1 (9)
1 (10)

RA

RB

0.65 (2)
0.62 (3)
0.75 (1)
0.60 (4)
0.43 (6)
0.55 (5)
0.40 (7)
0.30 (8)
0.25 (9)
0.20 (10)

0.65 (2)
0.60 (3)
0.70 (1)
0.45 (5)
0.42 (6)
0.55 (4)
0.40 (7)
0.30 (8)
0.25 (9)
0.20 (10)

Table 3: Example of situation in which classiﬁcation accu-
racy is increased without improving ranking

ﬁcation is highly uncertain). A Wilcoxon signed ranked test
(p < 0.05) has been performed to validate the results. Each
genre dataset has been considered as a single trial for the test.
Results conﬁrmed that there is a statistically signiﬁcant differ-
ence in favor of the BOS model compared to the BOW model
as regards precision, recall and F1-measure. Conversely, the
two models are equivalent in deﬁning the ranking of the pre-
ferred movies according to the score for the class “likes”.

6 Conclusions and Future Work

We presented a system that exploits a Bayesian learning
method to induce semantic user proﬁles from documents rep-
resented by WordNet synsets suggested by the WSD algo-
rithm JIGSAW. Our hypothesis is that, replacing words with
synsets in the indexing phase, produces a more effective doc-
ument representation, which can help learning algorithms to
infer more accurate user proﬁles. Our approach has been eval-
uated in a movie recommending scenario. Results showed
that the integration of the WordNet linguistic knowledge in
the learning process improves the classiﬁcation of those doc-
uments for which the classiﬁcation is highly uncertain. As a
future work, we plan to exploit not only the WordNet hier-
archy, but also domain ontologies in order to realize a more
powerful document indexing.

References

[Banerjee and Pedersen, 2002] S. Banerjee and T. Pedersen.
An Adapted Lesk Algorithm for Word Sense Disambigua-
tion using WordNet.
In CICLing ’02: Proceedings of
the Third International Conference on Computational Lin-
guistics and Intelligent Text Processing, pages 136–145,
London, UK, 2002. Springer-Verlag.

[Bloedhorn and Hotho, 2004] S. Bloedhorn and A. Hotho.
Boosting for text classiﬁcation with semantic features. In
Proceedings of 10th ACM SIGKDD International Confer-
ence on Knowledge Discovery and Data Mining, Mining
for and from the Semantic Web Workshop, pages 70–87,
2004.

[Degemmis et al., 2007] M. Degemmis, P. Lops, and G. Se-
meraro. A Content-Collaborative Recommender that Ex-
ploits WordNet-based User Proﬁles for Neighborhood For-
mation. User Modeling and User-Adapted Interaction:

The Journal of Personalization Research, 2007. Forthcom-
ing.

[Fellbaum, 1998] C. Fellbaum. WordNet: An Electronic Lex-

ical Database. MIT Press, 1998.

[Guarino et al., 1999] N. Guarino, C. Masolo, and G. Vetere.
Content-Based Access to the Web. IEEE Intelligent Sys-
tems, 14(3):70–80, 1999.

[Leacock and Chodorow, 1998] C.

and
M. Chodorow. Combining Local Context and WordNet
Similarity for Word Sense Identiﬁcation. In C. Fellbaum,
editor, WordNet: An Electronic Lexical Database, pages
266–283. MIT Press, 1998.

Leacock

[Magnini and Strapparava, 2001] B. Magnini and C. Strap-
Improving User Modelling with Content-based
parava.
In Proceedings of the Eighth International
Techniques.
Conference on User Modeling, pages 74–83. Springer,
2001.

[Manning and Sch¨utze, 1999] C. Manning and H. Sch¨utze.
Foundations of Statistical Natural Language Processing,
chapter 7: Word Sense Disambiguation, pages 229–264.
MIT Press, Cambridge, US, 1999.

[Miller, 1990] G. Miller. WordNet: An On-Line Lexical
International Journal of Lexicography, 3(4),

Database.
1990.

[Mooney and Roy, 2000] R. J. Mooney and L. Roy. Content-
Based Book Recommending Using Learning for Text Cat-
egorization. In Proceedings of the Fifth ACM Conference
on Digital Libraries, pages 195–204, San Antonio, US,
2000. ACM Press, New York, US.

[Pazzani and Billsus, 1997] M. Pazzani and D. Billsus.
Learning and Revising User Proﬁles: The Identiﬁcation of
Interesting Web Sites. Machine Learning, 27(3):313–331,
1997.

[Resnik, 1995] P. Resnik. Disambiguating Noun Groupings
with respect to WordNet Senses.
In Proceedings of the
Third Workshop on Very Large Corpora, pages 54–68. As-
sociation for Computational Linguistics, 1995.

[Scott and Matwin, 1998] S. Scott and S. Matwin. Text Clas-
siﬁcation Using WordNet Hypernyms.
In S. Harabagiu,
editor, Use of WordNet in Natural Language Processing
Systems: Proceedings of the Conference, pages 38–44. As-
sociation for Computational Linguistics, Somerset, New
Jersey, 1998.

[Sebastiani, 2002] F. Sebastiani. Machine Learning in Au-
tomated Text Categorization. ACM Computing Surveys,
34(1), 2002.

[Witten and Bell, 1991] I.H. Witten and T.C. Bell. The Zero-
frequency Problem: Estimating the Probabilities of Novel
Events in Adaptive Text Compression. IEEE Transactions
on Information Theory, 37(4), 1991.

[Yao, 1995] Y. Y. Yao. Measuring Retrieval Effectiveness
Based on User Preference of Documents. Journal of the
American Society for Information Science, 46(2):133–145,
1995.

IJCAI-07

2861

