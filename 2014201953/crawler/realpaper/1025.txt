Automatic Synthesis of New Behaviors from a Library of Available Behaviors

Giuseppe De Giacomo

Sebastian Sardina

Dipartimento di Informatica e Sistemistica

Department of Computer Science

Universit`a di Roma “La Sapienza”

Roma, Italy

RMIT University

Melbourne, Australia

degiacomo@dis.uniroma1.it

ssardina@cs.rmit.edu.au

Abstract

We consider the problem of synthesizing a fully
controllable target behavior from a set of available
partially controllable behaviors that are to execute
within a shared partially predictable, but fully ob-
servable, environment. Behaviors are represented
with a sort of nondeterministic transition systems,
whose transitions are conditioned on the current
state of the environment, also represented as a non-
deterministic ﬁnite transition system. On the other
hand, the target behavior is assumed to be fully
deterministic and stands for the behavior that the
system as a whole needs to guarantee. We for-
mally deﬁne the problem within an abstract frame-
work, characterize its computational complexity,
and propose a solution by appealing to satisﬁability
in Propositional Dynamic Logic, which is indeed
optimal with respect to computational complexity.
We claim that this problem, while novel to the
best of our knowledge, can be instantiated to mul-
tiple speciﬁc settings in different contexts and can
thus be linked to different research areas of AI, in-
cluding agent-oriented programming and cognitive
robotics, control, multi-agent coordination, plan in-
tegration, and automatic web-service composition.

1 Introduction
Imagine an intelligent system built from a variety of different
components or devices operating (that is, performing actions)
on the same shared environment. For example, consider the
case of a blocks world scenario in which different kind or ver-
sions of robotic arms can move, paint, clean, dispose blocks,
and so on. Next, imagine that the central system possesses
some information about the logic of these components or
devices—e.g., a particular arm type can paint or clean a block
after picking it up, but another type of arm is only capable of
painting blocks. However, the knowledge about these devices
is partial in that their internal logic may potentially expose
nondeterministic features. For instance, the system may have
no information regarding the use of paint in a painting arm,
and thus, it is always unable to predict whether the arm will
run out of paint after a painting action. If it does, then the arm
cannot be used to paint again until it is recharged. Nonethe-
less, the central system has full observability on the state of

the devices in question: after the arm is used to paint a block,
the central system will come to know whether such arm ran
out of paint or not (maybe via a sensor light). Finally, the cen-
tral system is also (partially) knowledgeable about the shared
environment, in which all the components ought to execute.
As with the devices, the system possesses a nondeterminis-
tic model of the real environment and has full observability
on it too. The question then is: can the central system (al-
ways) guarantee a speciﬁc deterministic overall behavior by
(partially) controlling the available devices or components in
a step-by-step manner, that is, by instructing them on which
action to execute next and observing, afterwards, the outcome
in the device used as well as in the environment?

It is not hard to see that the above setting can be recast
in a variety of forms. In the context of agent-oriented pro-
gramming [6; 4], an intelligent agent may control the exe-
cution of a set of predeﬁned nondeterministic agent plans in
order to realize a desired deterministic plan-intention, which
in turn, may have been obtained via planning [13; 8]. Simi-
larly, when it comes to plan coordination [9], one can think
of coordinating or merging approximate models of multiple
agents’ plans into a global fully deterministic multi-agent
plan. Also, in the context of web-service composition [12; 1;
3],1 existing web services may be composed on the Internet
so as to implement a new complex web service. In all these
cases, the challenge is to automatically synthesize a fully con-
trollable module from a set of partially controllable existing
modules executing in a partially predictable environment.

Under this setting, the technical contributions of this paper
are threefold. First, we formally deﬁne the problem within an
abstract framework. Second, we devise a formal technique to
perform automatic synthesis of the fully controllable module.
We show that the technique proposed is sound, complete, and
terminating. Lastly, we characterize the computational com-
plexity of the problem and show that the proposed technique
is optimal with respect to computational complexity.

2 The setting
Let us start by deﬁning the synthesis problem [15] that is the
subject of our research. To that end, we develop an abstract
framework based on (sort of) ﬁnite state transition systems.

1In particular, [3] can be seen as a simpler variant of the setting

studied here, with no environment and deterministic behaviors.

IJCAI07

1866

Environment We assume to have a shared observable en-
vironment, which provides an abstract account of the observ-
able effect and preconditions of actions. In giving such an
account, we take into consideration that, in general, we have
incomplete information about the actual effects and precondi-
tions of actions. Thus, we allow the observable environment
to be nondeterministic in general. In that way, the incomplete
information on the actual world shows up as nondeterminism
in our formalization.

Formally, an environment E = (A, E, e0, δE ) is character-

ized by the following ﬁve entities:

• A is a ﬁnite set of shared actions;
• E is a ﬁnite set of possible environment states;
• e0 ∈ E is the initial state of the environment;
• δE ⊆ E × A × E is the transition relation among states:
(cid:2)) holds when action a performed in state e may

δE (e, a, e
lead the environment to a successor state e

.

(cid:2)

Note that our notion of the environment shares a lot of sim-
ilarities with the so-called “transition system” in action lan-
guages [5]. Indeed, one can think of using that kind of for-
malism to compactly represent the environment in our setting.

Behavior A behavior is essentially a program for an agent
or the logic of some available device or component. Such a
program however leaves the selection of the action to perform
next to the agent itself. More precisely, at each step the pro-
gram presents to the agent a choice of available actions; the
agent selects one of them; the action is executed; and so on.

Obviously, behaviors are not intended to be executed on
their own, but they are executed in the environment (cf.
above). Hence, we equip them with the ability of testing con-
ditions (i.e., guards) on the environment when needed.

Formally, a behavior B = (S, s0, G, δB, F ) over an envi-

ronment E, is a characterized by the following entities:

• S is a ﬁnite set of behavior states;
• s0 ∈ S is the single initial state of the behavior;
• G is a set of guards, which are boolean functions g :
E → {true, false}, where E is the set of the environ-
ment states of E;

• δB ⊆ S × G × A × S is the behavior transition relation,
where A is the set of actions of E—we call the G × A
components of such tuples, the label of the transition;

• ﬁnally, F ⊆ S is the set of ﬁnal states of the behavior,
that is, the states in which the behavior may stop execut-
ing, but does not necessarily have to.

Observe that, in general, behaviors are nondeterministic in
the sense that they may allow more than one transition with
the same action a and compatible guards evaluating to the
same truth value.2 As a result, the central system, when mak-
ing its choice of which action to execute next, cannot be cer-
tain of which choices it will have later on, since that depends
on what transition is actually executed. In other words, non-
deterministic behaviors are only partially controllable.

We say that a behavior B = (S, s0, G, δB, F ), over the en-
vironment E, is deterministic if there is no environment state e
of E for which there exist two distinct transitions (s, g1, a, s1)
and (s, g2, a, s2) in δB such that g1(e) = g2(e). Notice that
given a state in a deterministic behavior and a legal action
in that state, we always know exactly which is the next state
of the behavior. In other words, deterministic behaviors are
fully controllable through the selection of the action to per-
form next, while this is not the case for nondeterministic ones.

Runs and traces Given a behavior B = (S, s0, G, δ, F )
and an environment E = (A, E, e0, δE), we deﬁne the
runs of B on E as, possibly inﬁnite, alternating sequences
2 · · · , where
of
0 = e0, and for every i we have that
0 = s0 and e
s
i+1
(s
, e

the following form:

i+1(s

1)a

0)a

1(s

i)a

(s

, e

, e

0

1

i

, e
• there exists a transition (e
• there exists a transition (s
i

i+1) is such that:
i+1

, a
, g

i+1

i

that g

i+1(ei) = true.

i+1) ∈ δE ; and
i+1

i+1) ∈ δB, such

, s

, e
, a

that is,

it is of the form

Moreover if the run is ﬁnite,
(s
(cid:2)), then s

1 · · · a

0)a

(cid:2)(s

, e

0

(cid:2)

(cid:2) ∈ F .

0

2

1

, e

, a

0)a

1) · (g
, a
1)a
, e

, e
Apart from runs, we are also interested in traces gener-
ated by the behavior. A trace is a sequence of pairs (g, a),
where g ∈ G is a guard of B and a ∈ A is an action, of the
2) · · · such that there exists a run
form t = (g
1
1(s
i(ei−1) = true
(s
(cid:2)) is ﬁnite, then
for all i. If the trace t = (g
(cid:2)) with s
(cid:2) ∈ F .
there exists a ﬁnite run (s
, e
The traces of the deterministic behaviors are of particular
interest: any initial fragment of a trace leads to a single state
in the behavior. In a sense, the deterministic behavior itself
can be seen as a speciﬁcation of a set of traces.

2 · · · , as above, where g
, a
(cid:2)
, e

1) · · · (g
1
(cid:2)
, a
0)a
1 · · · a
(cid:2)(s

0

The system A system S = (B1, . . . , Bn, E) is formed by
an observable environment E and n predeﬁned nondeter-
ministic behaviors Bi, called the available behaviors. A
system conﬁguration is a tuple (s1, . . . , sn, e) denoting a
snapshot of the system: behavior Bi is in state si and the
environment E is in state e. We assume that the system has a
speciﬁc component, called the scheduler, that is able to acti-
vate, stop, and resume the behaviors at each point in time.

The problem The problem we are interested in is the fol-
lowing: given a system S = (B1, . . . , Bn, E) and a determin-
istic behavior, called the target behavior B0 over E, synthe-
size a program for the scheduler such that the target behavior
is realized by suitably scheduling the available behaviors.

In order to make this precise, we need to clarify which are
the basic capabilities of the scheduler. The scheduler has the
ability of activating-resuming one3 of the many available be-
haviors by instructing it to execute an action among those that
are possible in its current state (taking into account the envi-
ronment). Also, the scheduler has the ability of keeping track
(at runtime) of the current state of each available behavior.

2Note that this kind of nondeterminism is of a devilish nature, so
as to capture the idea that through the choice of actions alone one
cannot fully control the behavior.

3For simplicity, we assume that the scheduler activates/resumes
only one behavior at each step, though our approach can be extended
to the case where more available services are activated at each step.

IJCAI07

1867

Technically, such a capability is called full observability on
the states of the available behaviors. Although other choices
are possible [1], full observability is the natural choice in this
context, since the available behaviors are already suitable ab-
stractions for the actual behaviors, and hence there is no rea-
son to make its states partially unobservable: if details have
to be hidden, this can be done directly within the abstract be-
havior exposed, possibly making use of nondeterminism.

Let

We are now ready to formally deﬁne our synthesis
the system be S = (B1, . . . , Bn, E),
problem.
where E = (A, E, e0, δE ) is the environment and Bi =
(Si, si0, Gi, δi, Fi) are the available behaviors. Let the tar-
get behavior be B0 = (S0, s00, δ0, F0).

A system history is an alternating sequence of system con-
1 ·
(cid:2))

ﬁgurations and actions of the form h = (s
(cid:2)) · a
(s
such that the following constraints hold:

0) · a
(cid:2)
(cid:2)
1, . . . , s
n, e

0
0
1, . . . , s
n, e
(cid:2) · (s

1
1
1, . . . , s
n, e

1) · · · (s

(cid:2)−1
n , e

, . . . , s

(cid:2)−1
1

• s

0
i = si0 for i ∈ {1, . . . , n}, that is, each behavior starts
in its initial state;
0 = e0, that is, the environment starts in its initial state;
• e
• at each step 0 ≤ k ≤ (cid:3), there exists an i ∈ {1, . . . , n}
such that (s
) ∈ δi and for all j (cid:6)= i,
k+1
k
j = s
s
j , that is, at each step in the history, only one of
the behaviors, namely Bi, has made a (legal) transition
(according to its transition relation δi), while the other
ones have remained still;

k+1
i

k+1
i

k
i , g

k+1

, a

, s

• at each step 0 ≤ k ≤ (cid:3), we have that (e

k+1) ∈
δE , that is, the environment has also made a legal transi-
tion according to its transition relation.

k+1

, a

, e

k

A scheduler program is a function P : H × A →
{1, . . . , n, u} that, given a history h ∈ H (where H is the set
of all system histories as deﬁned above) and an action a ∈ A
to perform, returns the behavior (actually the behavior index)
that is scheduled to perform the action. Observe that such a
function may also return a special value u, for “undeﬁned.”
This is a technical convenience to make P a total function re-
turning values even for histories that are not of interest, or for
actions that no behavior can perform after a given history.

Next, we deﬁne when a scheduler program is a composi-
tion that realizes the target behavior—a solution to the prob-
lem. First, we point out that, because the target behavior is
a deterministic transition system, its behavior is completely
characterized by the set of its traces, that is, by the set of in-
ﬁnite sequences of actions that are faithful to its transitions,
and of ﬁnite sequences that in addition lead to a ﬁnal state.

1) · (g

So, given a trace t = (g

2) · · · of the target be-
havior, we say that a scheduler program P realizes the trace
t iff for all (cid:3) and for all system histories h ∈ H(cid:2)
is deﬁned below) such that g
vironment state e
H(cid:2)+1
inductively deﬁned as follows:

h) = true in the last en-
(cid:2)+1) (cid:6)= u and
t,P is

t,P is nonempty, where the set of system histories H(cid:2)

h of h, we have that P (h, a

t,P (H(cid:2)

(cid:2)+1(e

, a

, a

t,P

1

2

(cid:2)

(cid:2)

• H0
• H(cid:2)+1

t,P = {(s10, . . . , sn0, e0)};
t,P is the set of (cid:3) + 1-length system histories of the

form h · a

(cid:2)+1 · (s

(cid:2)+1
1

, . . . , s

(cid:2)+1
n , e

(cid:2)+1) such that:

• h ∈ H(cid:2)

t,P , where (s
conﬁguration in h;

(cid:2)
(cid:2)
1, . . . , s
n, e

(cid:2)) is the last system

• a

• (s

(cid:2)+1

is an action such that P (h, a

(cid:2)+1)=i, with i(cid:6)=
at
u, that is, the scheduler states that action a
system history h should be executed in behavior Bi;
(cid:2)) = true, that is,
behavior Bi may evolve from its current state s
(cid:2)
i to
(cid:2)
(cid:2)
state s
i w.r.t. the (current) environment state e
;
(cid:2)+1
, a

(cid:2)+1) ∈ δE , that is, the environment may

(cid:2)
i) ∈ δi with g(e

(cid:2)
i , g, a

(cid:2)+1

(cid:2)+1

, s

, e

(cid:2)

• s

evolve from its current state e
(cid:2)+1
i = s
behavior Bi is allowed to perform a step.

(cid:2)+1
j = s

(cid:2)
i and s

to state e

j, for j (cid:6)= i, that is, only
(cid:2)

;

(cid:2)

(cid:2)+1

• (e

Moreover, as before, if a trace is ﬁnite and ends after
m actions, and all along all its guards are satisﬁed, we
have that all histories in Hm
t,P end with all behaviors in a
ﬁnal state. Finally, we say that a scheduler program P
realizes the target behavior B0 if it realizes all its traces.4

In order to understand the above deﬁnitions, let us observe
that, intuitively, the scheduler program realizes a trace if, as
long as the guards in the trace are satisﬁed, it can choose at
every step an available behavior to perform the requested ac-
tion. If at a certain point a guard in the trace is not satisﬁed in
the current environment state, then we may consider the trace
ﬁnished (even if it is not in a ﬁnal state). As before, however,
because the available behaviors nondeterministically choose
what transition to actually perform when executing an action,
the scheduler program must be such that the scheduler will
always be able to continue with the execution of the next ac-
tion no matter how both the activated behavior and the envi-
ronment evolve after each step. Finally, the last requirement
makes sure that all available behaviors are left in a ﬁnal state
when a ﬁnite trace reaches its end with all guards satisﬁed.

Observe that, in general, a scheduler program could require
inﬁnite states. However, we will show later that if a scheduler
that realizes the target behavior does exist, then there exists
one with a ﬁnite number states. Note also that the scheduler
has to observe the states of the available behaviors in order
to decide which behavior to select next (for a given action
requested by the target behavior). This makes these scheduler
programs akin to an advanced form of conditional plans [16].

3 An example

We now come back to our original blocks world example in
order to illustrate the abstract framework developed in the
previous section. The complete scenario is depicted in Figure
1. The aim of the whole system is to paint existing blocks.
Blocks can be processed by cleaning and painting them. Be-
fore processing a block, though, it is necessary to prepare it,
for example, by moving it to a special processing location.
Furthermore, only after a block has been disposed, can an-
other block be prepared for processing. Finally, cleaning and
painting may, sometimes, require resources, namely, water
and paint, respectively: we assume there are two tanks, for
water and paint, respectively, and that both are recharged si-
multaneously by pressing a recharging button.

4Recall that because the target behavior is deterministic, it can

be seen as a speciﬁcation of a, possibly inﬁnite, set of traces.

IJCAI07

1868

Arm A

dispose

paint clean

Arm B

a2

b1

b2

b3

e2 : clean

a1

recharge

dispose

Environment E

e1

dispose

prepare

recharge

recharge

e4

prepare

dispose

e2

e3

clean

b4

t2

clean

prepare

paint

prepare

recharge

Target T

paint
clean

t1

recharge

prepare

paint

clean

paint
clean

t5

dispose

paint

t4

t3

Figure 1: A painting blocks world scenario.

Now, the desired target behavior T that we want to achieve
is as follows. First, a block is prepared for processing. Then,
the block in question can either be painted right away or
painted after being cleaned—some (dirty) blocks may need
to be washed before being painted. Note that the decision of
whether a block needs to be cleaned lays outside of our frame-
work. After a block has been painted, it is disposed. Finally,
the recharging button is pushed. See that this target behavior
is “conservative,” in that it always recharges the tanks after a
block has been processed.

One can think of the above target behavior as the arm that
one would like to have. However, such arm does not exist
in reality. Instead, there are only two different arms available.
The ﬁrst arm A, a cleaning-disposing arm, is able to clean and
dispose blocks. The second arm B is capable of preparing,
cleaning, and painting blocks. Both arms are able to press the
recharge button to reﬁll the tanks.

So, the system is composed of the environment E and the
two arms A and B shown in Figure 1. Let us now note a few
interesting points. First, the environment E provides the (gen-
eral) preconditions of actions in the domain (e.g., dispose
can only be executed after a prepare action). The environ-
ment also includes some information about the water tank:
in e1 and e2, the water tank is not empty; and in e3 and e4,
the water tank is indeed empty. Notice that it is still conceiv-
able to clean a block in state e3, by some method that does
not rely on water. However, because arm A does use water
to clean blocks, it can only do it when the environment is in
fact in state e2. Second, we observe that whereas only the
second arm can prepare a block, only the ﬁrst arm can dis-
pose a block. Lastly, the most interesting remark comes from
arm B’s internal logic, for which the system only has partial
information. After painting a block, arm B may evolve non-
deterministically to two different states: b1 or b3. Intuitively,
the arm evolves to state b3 as soon as the paint tank becomes
empty; otherwise the arm evolves to state b1. Once the arm
runs out of paint, it can only clean blocks until the tanks are
eventually recharged. Notice also that, unlike arm A, arm B
does not require the environment to be in state e2 to clean a
block, as its cleaning mechanism does not rely on water.

We aim to automatically synthesize a scheduler program
so as to realize the target behavior (T ) by making use of the
available behaviors (arms A and B) and considering the en-
vironment (E). See the next section.

4 The synthesis technique

We are now ready to investigate how to check for the exis-
tence of a scheduler program that realizes the target behavior,
and even more, how to actually compute it. We start with
some preliminary considerations on the computational com-
plexity that we should expect. The result by Muscholl and
Walukiewicz in [14], which can be easily rephrased in our
framework, gives us an EXPTIME lowerbound.

More precisely, let us call empty environment any envi-
ronment of the form E = (A, E, eo, δE ), where E = {eo}
(i.e., the (observable) environment has a single state), and
δE = {(e0, a, e0) | a ∈ A}, (i.e., there are no preconditions
on actions, nor actions have any effect on the environment).
Also, let us call deterministic guardless behavior any behav-
ior of the form B = (S, s0, {gtrue}, δB, F ), where gtrue is
the constant function returning always true, and δB is func-
tional, i.e., for each state s ∈ S and action a ∈ A, there is at
(cid:2)) ∈ δB. Then, Muscholl
most one state s
and Walukiewicz’s result can be stated as follows.

such that (s, a, s

(cid:2)

Theorem 4.1 (Muscholl & Walukiewicz 2005) Checking
the existence of a scheduler program that realizes a target
deterministic guardless behavior in a system consisting of
an empty environment and a set of available deterministic
guardless behaviors is EXPTIME-hard.5

Hence, checking the existence of a scheduler program in
our general framework is at least exponential time. Next, we
show that the problem is actually EXPTIME-complete, by
resorting to a reduction to satisﬁability in Propositional Dy-
namic Logic (PDL). Moreover, such a reduction can be ex-
ploited to generate the actual scheduler program which will
be ﬁnite. In doing this, we extend the approach in [3], origi-
nally developed in the context of service composition to deal
with empty environments and deterministic guardless behav-
iors. Dealing with a non-trivial environment, and especially
dealing with the nondeterminism of the available behaviors,
requires solving same subtle points that reﬂects the sophisti-
cated notion of scheduler program that is needed for that.

4.1 Propositional Dynamic Logic
Propositional Dynamic Logic (PDL) is a modal logic specif-
ically developed for reasoning about computer programs [7].
Syntactically, PDL formulas are built from a set P of atomic
propositions and a set Σ of atomic actions:

(cid:2)
φ −→ P | ¬φ | φ1 ∧ φ2 | φ1 ∨ φ2 | φ → φ

r −→ a | r1 ∪ r2 | r1; r2 | r

(cid:9)r(cid:10)φ | [r]φ | true | false,
∗ | φ?,

|

where P is an atomic proposition in P, r is a regular ex-
pression over the set of actions in Σ, and a is an atomic ac-
tion in Σ. That is, PDL formulas are composed from atomic
propositions by applying arbitrary propositional connectives,
and modal operators (cid:9)r(cid:10)φ and [r]φ. Formula (cid:9)r(cid:10)φ means that
there exists an execution of r (i.e., a sequence of actions con-
forming to the regular expression r) reaching a state where φ

5In fact, Muscholl and Walukiewicz show EXPTIME-hardness
in the setting of service composition studied in [2; 3], where all
available services are deterministic [14].

IJCAI07

1869

holds; and formula [r]φ is intended to mean that all terminat-
ing executions of r reach a state where φ holds.

A PDL formula φ is satisﬁable if there exists a model for
φ—an interpretation where φ is true. Checking satisﬁability
of a PDL formula is EXPTIME-complete [7].

PDL enjoys two properties that are of particular interest
for us [7]. The ﬁrst is the tree model property, which says
that every model of a formula can be unwound to a, possi-
bly inﬁnite, tree-shaped model (considering domain elements
as nodes and partial functions interpreting actions as edges).
The second is the small model property, which says that every
satisﬁable formula admits a ﬁnite model whose size (in par-
ticular the number of domain elements) is at most exponential
in the size of the formula itself.

4.2 Reduction to PDL
Let S=(B1, . . . , Bn, E) be a system, where E = (A, E, e0, δE )
is the environment and Bi = (Si, si0, Gi, δi, Fi) are the avail-
able behaviors over E, and let B0 = (S0, s00, δ0, F0) be the
target behavior (over E as well). Then, we build a PDL for-
mula Φ to check for satisﬁability as follows.

As actions in Φ, we have the actions A in E. As atomic

propositions, we have:6

• one atomic proposition e for each state e of E, which

intuitively denotes that E is in state e;

• one atomic proposition s for each state s of Bi, for i ∈

{0, 1, . . . , n}, denoting that Bi is in state s;

• atomic propositions Fi, for i ∈ {0, 1, . . . n}, denoting

that Bi is in a ﬁnal state;

• atomic propositions execia, for i ∈ {1, . . . n} and a ∈
A, denoting that a will be executed next by behavior Bi;
• one atomic proposition undef denoting that we reached

a situation where the scheduler can be left undeﬁned.

Let us now build the formula Φ. For representing the tran-
sitions of the target behavior B0, we construct a formula φ0
as the conjunction of (for each s of B0 and e of E):

(cid:2)

• s∧e → (cid:9)a(cid:10)true∧[a]s

, for each transition (s, g, a, s

(cid:2)) ∈
δ0 such that g(e) = true, encoding that the target be-
havior can do an a-transition, whose guard g is satisﬁed,
by going from state s to state s

(cid:2)
• s ∧ e → [a]undef , for each a such that for no g and s
(cid:2)) ∈ δ0 with g(e) = true. This takes
we have (s, g, a, s
into account that the target behavior cannot perform an
a-transition.

;

(cid:2)

For representing the transitions of each available behavior

Bi, we construct a formula φi as the conjunction of:

• the formula

s∧e∧execia→

(cid:2)

((cid:9)a(cid:10)(s

(cid:2)∧e

(cid:2)))∧[a](

(cid:3)

(s

(cid:2)∧e

(cid:2))),

(s(cid:2),e(cid:2))∈Δ

(s(cid:2) ,e(cid:2))∈Δ

where Δ = {(s
true, (e, a, e

(cid:2)) | (s, g, a, s

(cid:2)) ∈ δi, g(e) =
(cid:2)) ∈ δE }, for each environment state e,

, e

(cid:2)

6In this paper, we are not concerned with compact representa-
tions of the states of the environment E and the behaviors Bi. How-
ever, we observe that if states are succinctly represented (e.g., in
binary format) then, in general, we can exploit such a representation
in Φ to get a corresponding compact formula as well.

each s of Bi, and each a ∈ A. These assertions encode
that if the current environment state is e and the available
behavior Bi is in state s and is selected for the execution
of an action a (i.e., execia is true), then for each possible
a-transition of Bi with its guard true in e and of E, we
have a possible a-successor in the models of Φ;

(cid:2)

, we have that (s, g, a, s

• s ∧ e ∧ execia → [a]false, for each environment state
e of E, and each state s of Bi such that for no g, s
, and
(cid:2)) ∈ δi with g(e) = true and
(cid:2)
e
(cid:2)) ∈ δE . This states that if the current environment
(e, a, e
state is e and Bi, whose current state is s, is selected for
the execution of a, but a cannot be executed by Bi in e,
then there is no a-successor in the models of Φ;

• s ∧ ¬execia → [a]s, for each state s of Bi and each
action a. This assertion encodes that if behavior Bi is
in state s and is not selected for the execution of a, then
if a is performed (by some other available behavior), Bi
does not change state.

In addition, we have the formula φadd, of general con-

straints, obtained as the conjunction of:

(cid:2)

• s → ¬s

(cid:2)
, for all pairs of states s, s

of Bi, and for
i ∈ {0, 1, , . . . , n}, stating that propositions represent-
ing different states of Bi are disjoint;

• Fi ↔

s∈Fi s, for i ∈ {0, 1, , . . . , n}, highlighting the

(cid:4)

ﬁnal states of Bi;

(cid:4)

• undef → [a]undef , for each action a ∈ Σ, stating
that once a situation is reached where undef holds, then
undef holds also in all successor situations;

• ¬undef ∧ (cid:9)a(cid:10)true →

i∈{1,...,n} execia, for each a ∈
A, denoting that, unless undef is true, if a is performed,
then at least one of the available behaviors must be se-
lected for the execution of a;

• execia → ¬execja for each i, j ∈ {1, . . . , n}, i (cid:6)= j,
and each a ∈ A, stating that only one available behavior
is selected for the execution of a;

(cid:5)

i∈{1,...,n} Fi, stating that when the target behav-

• F0 →

ior is in a ﬁnal state, so are all the available behaviors.

Finally, we deﬁne Φ as

Init ∧ [u](φ0 ∧

(cid:2)

i∈{1,...,n}

φi ∧ φadd),

(cid:6)

a∈Σ a)∗
(cid:5)

where Init stands for e0 ∧s00 ∧s01 ∧· · ·∧s0n, and represents
the initial state of the environment E and of all behaviors Bi
(including the target), and u = (
, which acts as the
master modality [7], is used to force φ0∧
i∈{1,...,n} φi∧φadd
to be true in every point of the model. Note that u is the only
complex program that appears in the PDL formula Φ. We can
now state our main result.
Theorem 4.2 The PDL formula Φ, constructed as above, is
satisﬁable iff there exists a scheduler program for the system
S = (B1, . . . , Bn, E) that realizes the target behavior B0.

Proof (sketch).

“If ”: PDL has the tree-model property.
Hence, if Φ is satisﬁable then it has a model that is tree
shaped. Each node in this tree can be put in correspondence
with a history, and from the truth value assignment of the

IJCAI07

1870

Scheduler

b1 : (A, recharge)

s1

s5

(B, prepare)

s2
b3 : (B, recharge)

(A, clean)

s3

(B, paint)

(B, paint)

(A, dispose)

s4

b1 :
Figure 2: The painting blocks scheduler program.
(A, recharge) means that arm B is in state b1 and action
recharged is performed by arm A.

propositions execia in the node one can reconstruct the sched-
uler program. “Only if ”: if a scheduler program that realizes
B0 exists, one can use it to build a tree model of Φ.

Observe that the size of Φ is polynomially with respect
to E, B1, . . . , Bn and B0. Hence, from the EXPTIME-
completeness of satisﬁability in PDL and Theorem 4.1, we
get the following result:

Theorem 4.3 Checking the existence of a scheduler program
that realizes a target behavior B0 relative to a system S =
(B1, . . . , Bn, E) is EXPTIME-complete.

Finally, by the ﬁnite-model property of PDL (i.e., if a for-
mula is satisﬁable, it is satisﬁable in a model that is at most
exponential in the size of the formula), we get a systematic
procedure for synthesizing the composition:

Theorem 4.4 If there exists a scheduler program that real-
izes a target behavior B0 relative to a system (B1, . . . , Bn, E),
then there exists one that requires a ﬁnite number of states.
Moreover such a ﬁnite state program can be extracted from a
ﬁnite model of Φ.

To end, let us return to our example of Section 3. The
corresponding PDDL formula Φblocks
, obtained as explained
above, has a a ﬁnite model from which we can extract the
scheduler program depicted in Figure 2 (after having pro-
jected out irrelevant propositions and applied minimization
techniques to reduce the number of states). Such scheduler
realizes the target behavior T by appealing to the two avail-
able arms A and B. As one can observe, even in this simplis-
tic scenario, the existence of a scheduler and its correspond-
ing program is far from trivial. For instance, it is critical to
make the correct decision on which machine must recharge
the tanks at every step—such a choice would depend on how
arm B evolves after painting a block. Also, the scheduler
must be able to terminate both arms in their corresponding
ﬁnal states whenever the target behavior is its ﬁnal state t1.

5 Conclusion

In this paper, we have looked at automatic synthesis of a fully
controllable module from a set of partially controllable exist-
ing modules that execute in a partially predictable environ-
ment. The kind of problem that we dealt with is clearly a
form of reactive process synthesis [15; 10]. Standard tech-
niques for such problems are based on automata on inﬁnite
trees, which however relay on critical steps, such as Safra’s
construction for complementation, that have resisted efﬁcient
implementation for a long time [11]. Instead, we based our

synthesis on a reduction to satisﬁability in PDL [7] with a
limited use of the reﬂexive-transitive-closure operator. Such
kind of PDL satisﬁability shares the same algorithms that are
behind the success of the description logic-based reasoning
systems used for OWL,7 such as FaCT, Racer, and Pellet.8
Hence, its applicability in our context appears to be quite
promising from a practical point of view.

Acknowledgments The authors would like to thank Daniela Be-
rardi, Diego Calvanese, Rick Hull, Massimo Mecella, and Maur-
izio Lenzerini for discussion and insights on the issues treated in
this paper. The ﬁrst author was partially supported by the the Eu-
ropean FET basic research project FP6-7603 Thinking Ontologies
(TONES). The second author was supported by the Australian Re-
search Council and Agent Oriented Software (grant LP0560702).

References
[1] D. Berardi, D. Calvanese, G. De Giacomo, R. Hull, and
M. Mecella. Automatic composition of transition-based se-
mantic web services with messaging. In Proc. of VLDB, 2005.
[2] D. Berardi, D. Calvanese, G. De Giacomo, M. Lenzerini, and
M. Mecella. Automatic composition of e-Services that export
their behavior. In Proc. of ICSOC, pages 43–58, 2003.

[3] D. Berardi, D. Calvanese, G. De Giacomo, M. Lenzerini, and
M. Mecella. Automatic service composition based on be-
havioural descriptions. International Journal of Cooperative
Information Systems, 14(4):333–376, 2005.

[4]

J. R. Firby. Adaptive Execution in Complex Dynamic Domains.
PhD thesis, Yale University, 1989.

[5] M. Gelfond and V. Lifschitz. Action languages. Electronic

Transactions of AI (ETAI), 2:193–210, 1998.

[6] M. P. Georgeff and A. L. Lansky. Reactive reasoning and plan-

ning. In Proc. of AAAI, pages 677–682, 1987.

[7] D. Harel, D. Kozen, and J. Tiuryn. Dynamic Logic. The MIT

Press, 2000.

[8] L. P. Kaelbling, M. L. Littman, and A. R. Cassandra. Planning
and acting in partially observable stochastic domains. Artiﬁcial
Intelligence Journal, 101:99–134, 1998.

[9] M. J. Katz and J. S. Rosenschein. The generation and exe-
cution of plans for multiple agents. Computers and Artiﬁcial
Intelligence, 12(1):5–35, 1993.

[10] O. Kupferman and M. Y. Vardi. Synthesis with incomplete

information. In Proc. of ICTL, 1997.

[11] O. Kupferman and M. Y. Vardi. Safraless decision procedures.

In Proc. of FOCS, pages 531–542, 2005.

[12] S. McIlraith and T. C. Son. Adapting Golog for programming

the semantic web. In Proc. of KR, pages 482–493, 2002.

[13] N. Meuleau, L. Peshkin, K.-E. Kim, and L. P. Kaelbling.
Learning ﬁnite-state controllers for partially observable envi-
ronments. In Proc. of UAI, pages 427–436, 1999.

[14] A. Muscholl and I. Walukiewicz. A lower bound on web ser-

vices composition. Submitted, 2005.

[15] A. Pnueli and R. Rosner. On the synthesis of a reactive module.

In Proc. of POPL, pages 179–190, 1989.

[16] J. Rintanen. Complexity of planning with partial observability.

In Proc. of ICAPS, pages 345–354, 2004.

7www.omg.org/uml/
8www.cs.man.ac.uk/∼sattler/reasoners.html

IJCAI07

1871

