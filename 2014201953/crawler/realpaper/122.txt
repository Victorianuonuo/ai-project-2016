Minimal and Absent Information in Contexts

Floris Roelofsen1 and Luciano Seraﬁni2

1 Institute for Logic, Language, and Computation, Amsterdam

2 Instituto per la Ricerca Scientiﬁca e Tecnologica, Trento

Abstract

Multi-context systems (MCS) represent contextual
information ﬂow. We show that the semantics of
an MCS is completely determined by the informa-
tion that is obtained when simulating the MCS, in
such a way that a minimal amount of information is
deduced at each step of the simulation.
In MCS, the acquisition of new information is
based on the presence of other information only.
We give a generalized account to model situations
in which information can be obtained as a result of
the absence of other information as well.

Introduction

1
Based on motivational papers by McCarthy [1987] and
Giunchiglia [1993] several formalizations of contextual in-
formation and inter-contextual information ﬂow have been
proposed. Most notable are the propositional logic of context
developed by McCarthy, Buvaˇc and Mason [1993; 1998], and
the multi-context systems devised by Giunchiglia and Ser-
aﬁni [1994], which later have been associated with the lo-
cal model semantics introduced by Giunchiglia and Ghidini
[2001]. Seraﬁni and Bouquet [2004] have argued from a tech-
nical point of view that multi-context systems constitute the
most general formal framework. This conclusion is supported
by a more conceptual argument of Benerecetti et.al. [2000].
A multi-context system describes the information available
in a number of contexts (i.e., to a number of people / agents
/ databases, etc.) and speciﬁes the information ﬂow between
those contexts. The local model semantics deﬁnes a system
to entail a piece of information, if and only if that piece of in-
formation is acquired, independently of how the information
ﬂow described by the system is accomplished.

Our ﬁrst contribution is based on the observation that the
local model semantics of a multi-context system is com-
pletely determined by the information that is obtained when
simulating the information ﬂow speciﬁed by the system, in
such a way that a minimal amount of information is deduced
at each step of the simulation. We deﬁne an operator which
suitably implements such a simulation, and thus determines
the information entailed by the system. This operator consti-
tutes a ﬁrst constructive account of the local model semantics.

Our second contribution is based on the observation that in
multi-context systems, new information is derived based on
the presence of other information only. However, in many
natural situations (concrete examples will be given below),
new information is obtained due to a lack of other informa-
tion. We propose a generalized framework so as to account
for such situations. Non-monotonic reasoning techniques are
applied to formulate a suitable semantics for this framework.
We proceed, in section 2, with a brief review of multi-
context system syntax and local model semantics. Minimal-
ity is discussed in section 3, and the generalized framework
is presented in section 4. We conclude, in section 5, with a
concise recapitulation of our main observations and results.1

2 Preliminaries

Figure 1: a magic box.

A simple illustration of the main intuitions underlying the
multi-context system framework is provided by the situation
depicted in ﬁgure 1. Two agents, Mr.1 and Mr.2, are looking
at a box from different angles. The box is called magic, be-
cause neither Mr.1 nor Mr.2 can make out its depth. As some
sections of the box are out of sight, both agents have partial
information about the box. To express this information, Mr.1
only uses proposition letters l (there is a ball on the left) and
r (there is a ball on the right), while Mr.2 also uses a third
proposition letter c (there is a ball in the center).
In general, we consider a set of contexts I, and a language
Li for each context i ∈ I. We assume I and {Li}i∈I to be
ﬁxed, unless speciﬁed otherwise. Moreover, for the purpose
of this paper we assume each Li to be built over a ﬁnite set of
proposition letters, using standard propositional connectives.
To state that the information expressed by a formula ϕ ∈
Li is established in context i we use so-called labeled formu-
las of the form i : ϕ (if no ambiguity arises, we simply refer

1See http://home.student.uva.nl/f.roelofsen/

for all proofs that are omitted or merely sketched here.

Mr.1Mr.2to labeled formulas as formulas, and we even use capital let-
ters F , G, and H to denote labeled formulas, if the context
label is irrelevant). A rule r is an expression of the form:

F ← G1 ∧ . . . ∧ Gn

(1)
where F and all G’s are labeled formulas; F is called the con-
sequence of r and is denoted by cons(r); all G’s are called
premises of r and together make up the set prem(r). Rules
without premises are called facts. Rules with at least one pre-
miss are called bridge rules. A multi-context system (system
hereafter) is a ﬁnite set of rules. A fact describes informa-
tion that is established in a certain context, independently of
which information is obtained in other contexts. A bridge
rule speciﬁes which information is obtained in one context, if
other pieces of information are acquired in different contexts.
Thus a system can be thought of as a speciﬁcation of contex-
tual information and an inter-contextual information ﬂow.
Example 1 The situation in ﬁgure 1 can be modeled by the
following system:

1 : ¬r
2 : l
1 : l ∨ r
2 : l ∨ c ∨ r ← 1 : l ∨ r

←
←
← 2 : l ∨ c ∨ r

Mr.1 knows that there is no ball on the right, Mr.2 knows that
there is a ball on the left, and if any agent gets to know that
there is a ball in the box, then he will inform the other agent.
A classical interpretation m of language Li is called a local
model of context i. A set of local models is called a local
information state.
Intuitively, every local model in a local
information state represents a “possible state of affairs”. If a
local information state contains exactly one local model, then
it represents complete information. If it contains more than
one local model, then it represents partial information: more
than one state of affairs is considered possible. A distributed
information state is a set of local information states, one for
each context. In conformity with the literature, we will refer
to distributed information states as chains.
Example 2 The situation in ﬁgure 1, in which Mr.1 knows
that there is no ball on the right but does not know whether
there is a ball on the left, is represented by a chain whose ﬁrst
component [ {l,¬r} ,{¬l,¬r} ] contains two local models.
As such, the chain reﬂects Mr.1’s uncertainty about the left
section of the box.
A chain c satisﬁes a labeled formula i : ϕ (denoted c |=
i : ϕ) iff all local models in its ith component classically
satisfy ϕ. A rule r is applicable with respect to a chain c iff
c satisﬁes every premiss of r. Notice that facts are applicable
with respect to any chain. A chain c complies with a rule r,
iff, whenever r is applicable with respect to c, then c satisﬁes
r’s consequence. We call c a solution chain of a system S iff
it complies with every rule in S. A formula F is true in S
(denoted S |= F ) iff every solution chain of S satisﬁes F .

Let C denote the set of all chains. Notice that, as each Li is
assumed to be built over a ﬁnite set of proposition letters, C is
assumed to be ﬁnite. Let c⊥ denote the chain containing ev-
ery local model of every context (notice that c⊥ does not sat-
isfy any non-tautological expression); let c> denote the chain

containing no local models at all (notice that c> satisﬁes any
expression). If C is a set of chains, then the component-wise
union of C is the chain, whose ith component consists of all
local models that are in the ith component of some chain in
C. If c and c0 are chains, then c \ c0 denotes the chain, whose
ith component consists of all local models that are in ci but
not in c0
i. Finally, we sometimes say that a local model m
is (not) in c, when we actually mean that m is (not) in some
(any) component ci of c.

3 Minimality
We order chains according to the amount of information they
convey. Intuitively, the more local models a chain component
contains, the more possibilities it permits, so the less infor-
mative it is. Formally, we say that c is less informative than
c0 (c (cid:22) c0), if for every i we have ci ⊇ c0
i. If, moreover, for at
least one i we have ci ⊃ c0
i, then we say that c is strictly less
informative than c0 (c ≺ c0).
Lemma 1 Let c and c0 be two chains, such that c (cid:22) c0. Then
any formula that is satisﬁed by c is also satisﬁed by c0.

We call c minimal among a set of chains C, iff c is in C
and no other chain c0 in C is strictly less informative than c.
In particular, we call c a minimal solution chain of a system
S, if it is minimal among the set of all solution chains of S.
Theorem 1 Every system S has a unique minimal solution
chain cS.
Proof. Let CS be the set of all solution chains of S. CS 6= ∅
as c> ∈ CS for any S. Let cS be the component-wise union
of all chains in CS. Then cS ∈ CS and cS (cid:22) c for any
c ∈ CS. So cS is the unique minimal solution chain of S. (cid:3)

Theorem 2 The semantics of a system S is completely deter-
mined by its unique minimal solution chain cS:

S |= F ⇔ cS |= F

Proof. F is true in S iff F is satisﬁed by all solution chains
of S iff F is satisﬁed by the component-wise union cS of all
(cid:3)
solution chains of S.

Theorem (1) and (2) are extremely useful, because they
establish that, to answer queries about a system S, it is no
longer necessary to compute all solution chains of S; we only
need to consider the system’s minimal solution chain cS.

3.1 Computing the Minimal Solution Chain
The minimal solution chain of S can be characterized as the
(cid:22)-least ﬁxpoint of an operator TS, which, intuitively, simu-
lates the information ﬂow speciﬁed by S. Let S∗(c) denote
the set of rules in S, which are applicable w.r.t. c. Then we
deﬁne:

TS(c) = c \ {m | ∃r ∈ S∗(c) : m 2 cons(r)}

(2)

For every rule r in S that is applicable w.r.t. c, TS re-
moves from c all local models that do not satisfy cons(r).

Intuitively, this corresponds to augmenting c with the infor-
mation expressed by cons(r). In this sense, TS simulates the
information ﬂow described by S. As TS(c) is obtained from c
only by removing local models from it, TS(c) is always more
informative than c.
As (C,(cid:22)) forms a complete lattice, and TS is monotone
and continuous w.r.t. (cid:22), [Tarski, 1955] yields:
Theorem 3 TS has a (cid:22)-least ﬁxpoint, which is obtained af-
ter a ﬁnite number of consecutive applications of TS to c⊥.
Lemma 2 Let c be a chain and let S be a system. Then c is a
ﬁxpoint of TS if and only if c is a solution chain of S.
Theorem 4 Let S be a system. Then the minimal solution
chain cS of S coincides with the (cid:22)-least ﬁxpoint of TS.

From theorems 3 and 4 we conclude that the minimal solu-
tion chain cS of a system S is obtained after a ﬁnite number
of applications of TS to the least informative chain c⊥. But
we can even prove a slightly stronger result:
Theorem 5 Let S be a system and let |S| denote the number
of bridge rules in S. Then the minimal solution chain cS of S
is obtained after at most |S| + 1 applications of TS to c⊥.

In fact, a slightly more involved, but essentially equiva-
lent procedure was introduced for rather different reasons by
Roelofsen et.al. [2004]. This procedure was shown to have
worst-case time complexity O(|S|2 × 2M ), where M is the
maximum number of propositional variables in either one of
the contexts involved in S.

Example 3 Consider the system from example 1. Applying
TS to c⊥ establishes the facts given by the ﬁrst two rules of
the system. But then Mr.2 knows that there is a ball in the box,
so the next application of TS simulates the information ﬂow
speciﬁed by the third rule of the system: Mr.2 informs Mr.1 of
the presence of the ball. The resulting chain is left unaltered
by any further application of TS, and therefore constitutes the
minimal solution chain of S. The fact that this chain satisﬁes
the formula 1 : l reﬂects, as desired, that Mr.1 has come to
know that there is a ball in the left section of the box.

4 Absent Information
Rules of the form (1) only allow us to model a rather restricted
kind of information ﬂow, namely one in which new informa-
tion is established based on the presence of other information
only. There are many natural situations in which information
is obtained as a result of the absence of other information.
Such situations cannot be modeled by the present formalism.
Example 4 (Coordination) Let d1, d2 be two meteorologi-
cal databases that collect their respective data from sensors
located in different parts of the country. At the end of the
day each database produces a weather forecast based on its
own data but also on the information obtained by the other
database. For example, d1 predicts rain, if that follows from
its own data and if, moreover, d2 does not maintain that it
won’t rain:

1 : r ← 1 : r ∧ not 2 : ¬r

Example 5 (Integration) Let d1 and d2 be as in example 4
and let d3 be a third database, which integrates the informa-
tion obtained in d1 and d2, respectively. Any piece of infor-
mation that is established by d1 and not refuted by d2 (or vice
versa) is included in d3:

3 : ϕ ← 1 : ϕ ∧ not 2 : ¬ϕ
3 : ϕ ← 2 : ϕ ∧ not 1 : ¬ϕ

Example 6 (Trust) Let d1, d2, and d3 be as in example 5.
It would be natural for d3 to regard d1 as more trustworthy
than d2 (or vice versa). In this case any piece of information
that is established in d1 is automatically included in d3, but
information obtained in d2 is only included in d3 if it is not
refuted by d1:

3 : ϕ ← 1 : ϕ
3 : ϕ ← 2 : ϕ ∧ not 1 : ¬ϕ

To model these situations we need rules r of the form:
F ← G1 ∧ . . . ∧ Gm ∧ not H1 ∧ . . . ∧ not Hn

(3)

where F , all G’s, and all H’s are labeled formulas. As before,
F is called the consequence of r (cons(r)). G1, . . . , Gm are
called positive premises of r and together constitute the set
prem+(r). H1, . . . , Hn are called negative premises of r and
make up the set prem−(r). A rule does not necessarily have
any premises (m, n ≥ 0). In analogy with commonplace ter-
minology in deductive database and logic programming the-
ory, we call such rules normal rules, and ﬁnite sets of them
normal multi-context systems (normal systems for short). If a
rule only has positive premises, we call it a positive rule. Note
that a system, which consists of positive rules only conforms
with the original deﬁnition of multi-context systems. From
now on we call such systems positive systems.

Our aim is to generalize the result obtained section 3, i.e. to
deﬁne the semantics of a normal system S in terms of a single
canonical chain cS of S, such that, whenever S is a positive
system, cS coincides with the minimal solution chain of S.

A ﬁrst naive attempt would be to say that a chain c complies
with a normal rule r iff it satisﬁes r’s consequence, whenever
it satisﬁes every positive premise of r and does not satisfy
any negative premise of r. The (minimal) solution chains
of a normal system can then be deﬁned as for positive sys-
tems. However, as the following example shows, a normal
system does not generally have a unique minimal solution
chain, and worse, its minimal solution chains do not gener-
ally correspond with its intended meaning.
Example 7 Let a system S be given by the following rule:

1 : p ← not 2 : q
Then S has two minimal solution chains:

(cid:26)(cid:20) {p} (cid:21)
(cid:26)(cid:20) {p}
(cid:21)

{¬p}

1

cp =

cq =

(cid:20) {q}
(cid:21)
(cid:20) {q} (cid:21)

{¬q}

2

(cid:27)
(cid:27)

1

2

Intuitively, S provides no ground for deriving q in context 2.
Thus, p should be derived in context 1, and every “proper”
canonical chain of S should satisfy 1 : p. As cq fails to do
so, it should be rejected as such. But how, then, should the
canonical chain of a normal system be characterized?

Extensive research efforts have been involved with an anal-
ogous question in the setting of logic programming, when, in
the late 80’s / early 90’s, a proper semantics for normal logic
programs was sought. In motivating our characterization of
canonical chains for normal multi-context systems, we will
recall some important intuitions and adapt some crucial deﬁ-
nitions that have resulted from these efforts.

A ﬁrst desired property of canonical chains, introduced in
[1988] and
the setting of logic programming by Apt et.al.
Bidoit and Froidevaux [1991], is termed supportedness. In-
tuitively, a chain c is a supported solution chain of a normal
system S iff, whenever c satisﬁes a formula F , then S pro-
vides an explanation for why this is so.
Deﬁnition 1 We call a chain c a supported solution chain of
a normal system S iff, whenever c satisﬁes a formula F , then
S contains a set R of rules, such that:

(cid:26) ∀G ∈ prem+(r) : c |= G

∀H ∈ prem−(r) : c 2 H

• ∀r ∈ R :

• S

r∈R cons(r) |= F

Example 8 In example 7, as desired, cp is a supported so-
lution chain of S, while cq is not. But both cp and cq are
supported solution chains of the following extension S0 of S:

1 : p ← not 2 : q
2 : q ← 2 : q

Intuitively, cp should be accepted as a canonical chain of S0,
but cq should be rejected as such, because the explanation
provided by S0 for the fact that cq satisﬁes 2 : q is circular,
i.e., it relies on the very fact that cq satisﬁes 2 : q. So, in
general, the concept of supportedness does not satisfactorily
characterize the canonical chain of a normal system.

The notion of well-supportedness, ﬁrst introduced for logic
programs by Fages [1991], reﬁnes the notion of supported-
ness to avoid the counter-intuitive result obtained in example
8. Intuitively, a chain c is a well-supported solution chain of
a normal system S iff, whenever c satisﬁes a formula F , then
S provides a non-circular explanation for why this is so.

Fages also proved this notion to be equivalent to the notion
of stability, which had been deﬁned somewhat earlier by Gel-
fond and Lifschitz [1988]. The results obtained in section 3
pave the way for a straightforward adaptation of the notion of
stability to our present setting.
Deﬁnition 2 Let c be a chain and S a normal system. Deﬁne:

S0(c) = {r ∈ S | ∀H ∈ prem−(r) : c 2 H}
S00(c) = pos(S0(c))

where pos(S0(c)) is obtained from S0(c) by removing all neg-
ative premises from its rules. Then, c is a stable solution chain
of S, iff it is the unique minimal solution chain of S00(c).

Intuitively, a solution chain c of a system S is stable iff,
whenever the information represented by c is assumed, then

the information ﬂow speciﬁed by S reproduces exactly c.
Namely, if c is assumed to contain valid information, then any
rule in S, one of whose negative premises is satisﬁed by c, is
certainly not applicable w.r.t. c. Negative premises which are
not satisﬁed by c can be removed from the remaining rules,
because they do certainly not inhibit those rules from being
applicable w.r.t. c. Thus, c is stable iff it corresponds exactly
to the meaning of S00(c), i.e., by Theorem 2, to its minimal
solution chain.
Example 9 In example 8, as desired, cp is a stable solution
chain of S0, while cq is not.

For many systems, stability suitably characterizes a unique
canonical chain. There are still some special cases, however,
in which it fails to do so. We give some typical examples.
Example 10 Both cp and cq from example 7 are stable solu-
tion chains of the system given by the following rules:

1 : p ← not 2 : q
2 : q ← not 1 : p

Example 11 The following system does not have any stable
solution chains.

1 : p ← not 1 : p

In both cases we think it is most reasonable to conclude that
no information is derived at all, i.e. to regard c⊥ as the proper
canonical chain.
Example 12 The following system does not have any stable
solution chains either.

1 : p ← not 1 : p
1 : t ← not 2 : q
2 : r ← 1 : t

Example 12 illustrates that, even if the rest of the system is
unproblematic, one single rule (in this case the ﬁrst one) can
cause the system not to have any stable solution chain at all.
In this case, t and r should be derived in context 1 and 2, resp.
The well-founded semantics, ﬁrst proposed for logic pro-
grams by van Gelder et.al. [1991] avoids the problems en-
countered in the above examples. The well-founded model
of a program is deﬁned as the least ﬁxpoint of an operator,
which, given an interpretation, determines the atoms that are
necessarily true and those that are necessarily not true with
respect to the program and the interpretation. It assigns true
to the former set of atoms, and f alse to the latter. As a result,
more atoms may become necessarily true or necessarily not
true. Corresponding truth values are assigned until a ﬁxpoint
is reached. All atoms that have not been assigned a deﬁnite
truth value, are interpreted as unknown.

Our approach shares an important intuition with the well-
founded semantics for logic programs, namely, that while
constructing the canonical chain of a system, it is not only
important to accumulate the information that can certainly be
derived from the system, but also to keep track of information
that can certainly not be derived from the system.

But the two approaches are also fundamentally different.
The well-founded semantics constructs a 3-valued interpre-
tation I, which is minimal with respect to a truth order v
(i.e. I v I0 iff I makes less atoms true and more atoms false
than I0), whereas we seek a chain which is minimal with re-
spect to an information order (cid:22) (i.e. c (cid:22) c0 iff c makes less
expressions either true or false than c0). This particularly re-
sults in a different treatment of expressions that are found not
to be true. To regard these expressions as false, as the well-
founded semantics does, would be to introduce redundant in-
formation. Instead, in our setting, such expressions should
simply be recorded as not being derivable.

4.1 Constructing the Canonical Chain
The canonical chain of a normal system S, henceforward de-
noted by cS, is constructed by an iterative transformation of
a datastructure hc, ai, where:

• c is the “canonical chain under construction”. Initially,
c = c⊥. Every transformation of c removes from it those
local models that are found not to be in cS. So at any
phase of the construction of cS, c contains those local
models that are possibly in cS, and as such represents
the information that is necessarily conveyed by cS.
• a is the “anti-chain”. Initially, c = c>. Every transfor-
mation of a adds to it those local models that are found
to be in cS. So at any phase of the construction of cS,
a contains those local models that are necessarily in cS,
and as such represents the information that is possibly
conveyed by cS.

Observation 1 By construction, we have c (cid:22) cS (cid:22) a.
Therefore, by lemma 1, for any formula F :
c |= F ⇒ cS |= F
a 2 F ⇒ cS 2 F

(cid:3)
We call a chain-anti-chain pair hc, ai less evolved than an-
other such pair hc0, a0i (denoted as hc, ai ≤ hc0, a0i) iff c is
less informative than c0 and a is more informative than a0. If,
moreover, c is strictly less informative than c0 or a is strictly
more informative than a0, then we say that hc, ai is strictly
less evolved than hc0, a0i. We call hc, ai minimal among a set
CA of chain-anti-chain pairs, iff hc, ai ∈ CA and no other
chain-anti-chain pair hc0, a0i in CA is strictly less evolved
than hc, ai. Notice that, if hc, ai is minimal among CA, then
c is minimal among {c | hc, ai ∈ CA}.
Given a certain chain-anti-chain pair hc, ai, the intended
transformation ΨS ﬁrst determines which rules in S will (not)
be applicable w.r.t. cS, and then reﬁnes hc, ai accordingly.
The canonical chain cS of S will be characterized as the ﬁrst
component of the ≤-least ﬁxpoint of ΨS.
We ﬁrst specify how ΨS determines which rules will (not)
be applicable w.r.t. cS. Let hc, ai and a rule r in S be given.
If r has a positive premise G, which is satisﬁed by c, then
G will also be satisﬁed by cS. On the other hand, if r has
a negative premiss H, which is not satisﬁed by a, then H
will not be satisﬁed by cS either. So if all positive premises

of r are satisﬁed by c and all negative premises of r are not
satisﬁed by a, then r will be applicable with respect to cS:

S+(c, a) =

∀G ∈ prem+(r) : c |= G
∀H ∈ prem−(r) : a 2 H

and

r ∈ S

r ∈ S





If r has a positive premise G, which is not satisﬁed by a,
then G will not be satisﬁed by cS either. If r has a negative
premise H, which is satisﬁed by c, then H will be satisﬁed
by cS as well. In both cases r will certainly not be applicable
with respect to cS:

S−(c, a) =

∃G ∈ prem+(r) : a 2 G
∃H ∈ prem−(r) : c |= H

or

For convenience, we write:

S∼(c, a) = S \ S−(c, a)

Think of S∼(c, a) as the set of rules that are possibly applica-
ble with respect to cS, and notice that S+(c, a) ⊆ S∼(c, a),
whenever c (cid:22) a, and that S+(c, a) = S∼(c, a), if c = a.
Lemma 3 If S is a normal system and hc, ai and hc0, a0i are
two chain-anti-chain pairs s.t. hc, ai ≤ hc0, a0i, then we have:
1. S+(c, a) ⊆ S+(c0, a0)
2. S−(c, a) ⊆ S−(c0, a0)
3. S∼(c, a) ⊇ S∼(c0, a0)

Proof. Suppose that hc, ai ≤ hc0, a0i. Then, by deﬁnition,
c (cid:22) c0 and a0 (cid:22) a. Let r be a rule in S. For the ﬁrst statement,
suppose that r ∈ S+(c, a). Then c satisﬁes all of r’s positive
premises, and a does not satisfy any of r’s negative premises.
By lemma 1, the same goes for c0 and a0, respectively, which
implies that r ∈ S+(c0, a0). The second statement is proven
analogously; the third follows directly from the second. (cid:3)
Next, we specify how ΨS reﬁnes hc, ai, based on S+(c, a)
and S∼(c, a). Every local model m ∈ ci that does not satisfy
the consequence of a rule in S+(c, a) should certainly not be
in cS and is therefore removed from c. On the other hand,
every local model m ∈ ci that satisﬁes the consequences of
every rule in S∼(c, a) should certainly be in cS (S provides
no ground for removing it) and is therefore added to a.

ΨS(hc, ai) = hΨc

S(hc, ai), Ψa

S(hc, ai)i

where:

S(hc, ai) = c \(cid:8)m | ∃r ∈ S+(c, a) : m 2 cons(r)(cid:9)

Ψc
S(hc, ai) = a ∪ {m | ∀r ∈ S∼(c, a) : m |= cons(r)}
Ψa
As (C × C,≤) forms a complete lattice, and ΨS is mono-

tone and continuous w.r.t. ≤, [Tarski, 1955] yields:
Theorem 6 ΨS has a ≤-least ﬁxpoint, which is obtained af-
ter ﬁnitely many iterations of ΨS, starting with hc⊥, c>i.

Deﬁnition 3 Let S be a normal system, and let hcS, aSi be
the ≤-least ﬁxpoint of ΨS. We deﬁne cS to be the canonical
chain of S, and we deﬁne the semantics of S to be completely
determined by cS. That is, for every formula F :

S |= F ≡ cS |= F

(cid:3)

A bound on the number of iterations needed by ΨS to
reach its ≤-least ﬁxpoint can be formulated in terms of the
number of bridge rules in S.
Theorem 7 Let |S| denote the number of bridge rules of a
normal system S. Then, starting with hc⊥, c>i, ΨS will reach
its ≤-least ﬁxpoint after at most |S| + 1 iterations.

The semantics for normal systems deﬁned above properly

generalizes the local model semantics for positive systems.

Theorem 8 The canonical chain of a positive system S coin-
cides with its minimal solution chain.

If S is positive, then for every pair hc, ai, S+(hc, ai)
Proof.
S(hc, ai) does not depend on a. As
and S∗(c) coincide, so Ψc
a consequence, cS is the (cid:22)-least ﬁxpoint of TS iff, for some
anti-chain aS, hcS, aSi is the ≤-least ﬁxpoint of ΨS.
(cid:3)

The canonical chain of a system S, and other ﬁxpoints of
ΨS, are intimately related to the stable solution chains of S.
Theorem 9 Let S be a normal system, let hcS, aSi be the
≤-least ﬁxpoint of ΨS, and let cstable be any stable solution
chain of S. Then cS (cid:22) cstable (cid:22) aS.
Theorem 10 Let S be a normal system and let hcS, aSi be
the ≤-least ﬁxpoint of ΨS. If cS and aS coincide, then cS is
the unique stable solution chain of S.

Finally, we remark that, in our view, all the examples pre-
sented above are suitably dealt with by the present analysis.
We treat one of them explicitly.

Example 13 Let S be the system from example 12. Then:

(cid:26)(cid:20) {p, t}

{¬p, t}

(cid:21)

1

(cid:20) {q, r}

{¬q, r}

(cid:21)

(cid:27)

2

cS =

As desired, no information is derived about p and q, while t
and r are indeed established in context 1 and 2, respectively.

5 Conclusions
We showed that the semantics of a multi-context system is
completely determined by its least informative solution chain.
We provided a way to compute this chain, and thus gave a ﬁrst
constructive account of the local model semantics.

We presented a generalized framework in which new in-
formation can be derived based on the absence of other infor-
mation. We applied non-monotonic reasoning techniques to
establish a suitable semantics for this framework.

References
[Apt et al., 1988] K. R. Apt, H. A. Blair, and A. Walker. To-

wards a theory of declarative knowledge. 1988.

[Benerecetti et al., 2000] M. Benerecetti, P. Bouquet, and
C. Ghidini. Contextual reasoning distilled.
Journal
of Experimental and Theoretical Artiﬁcial Intelligence,
12(3):279–305, 2000.

[Bidoit and Froidevaux, 1991] N. Bidoit and C. Froidevaux.
General logical databases and programs: Default logic se-
mantics and stratiﬁcation. Information and Computation,
91:15–54, 1991.

[Fages, 1991] F. Fages. A new ﬁxpoint semantics for gen-
eral logic programs compared with the wellfounded and
the stable model semantics. New Generation Computing,
9(4), 1991.

[Gelfond and Lifschitz, 1988] M. Gelfond and V. Lifschitz.
The stable model semantics for logic programming. In In-
ternational Conference on Logic Programming (ICLP 88),
pages 1070–1080, 1988.

[Ghidini and Giunchiglia, 2001] C.

F. Giunchiglia.
tual reasoning = locality + compatibility.
Intelligence, 127(2):221–259, 2001.

and
Local models semantics, or contex-
Artiﬁcial

Ghidini

[Giunchiglia and Seraﬁni, 1994] F. Giunchiglia and L. Ser-
aﬁni. Multilanguage hierarchical logics, or: how we can
do without modal logics. Artiﬁcial Intelligence, 65(1):29–
70, 1994.

[Giunchiglia, 1993] F. Giunchiglia. Contextual reasoning.

Epistemologia, XVI:345–364, 1993.

[McCarthy and Buvaˇc, 1998] J. McCarthy and S. Buvaˇc.
Formalizing context (expanded notes). In Computing Nat-
ural Language, volume 81 of CSLI Lecture Notes, pages
13–50. 1998.

[McCarthy, 1987] J. McCarthy. Generality in artiﬁcial in-
telligence. Communications of ACM, 30(12):1030–1035,
1987.

[McCarthy, 1993] J. McCarthy. Notes on formalizing con-
text. In International Joint Conference on Artiﬁcial Intel-
ligence (IJCAI 93), pages 555–560, 1993.

[Roelofsen et al., 2004] F. Roelofsen, L. Seraﬁni,

and
A. Cimatti. Many hands make light work: Localized sat-
isﬁability for multi-context systems.
In European Con-
ference on Artiﬁcial Intelligence (ECAI 04), pages 58–62,
2004.

[Seraﬁni and Bouquet, 2004] L. Seraﬁni and P. Bouquet.
Comparing formal theories of context in AI. Artiﬁcial In-
telligence, 155:41–67, 2004.

[Tarski, 1955] A. Tarski. A lattice-theoretical ﬁxpoint theo-
rem and its applications. Paciﬁc Journal of Mathematics,
5:285–309, 1955.

[van Gelder et al., 1991] A. van Gelder, K. Ross, and J. S.
Schlipf. The well-founded semantics for general logic pro-
grams. Journal of the ACM, 38(3):620–650, 1991.

