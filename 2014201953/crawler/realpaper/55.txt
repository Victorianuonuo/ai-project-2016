Counting Solutions of CSPs: A Structural Approach∗

Gilles Pesant

ILOG, 1681 route des Dolines, 06560 Valbonne, France

pesant@crt.umontreal.ca

Abstract

Determining the number of solutions of a CSP has
several applications in AI, in statistical physics, and
in guiding backtrack search heuristics. It is a #P-
complete problem for which some exact and ap-
proximate algorithms have been designed. Suc-
cessful CSP models often use high-arity, global con-
straints to capture the structure of a problem. This
paper exploits such structure and derives polytime
evaluations of the number of solutions of individ-
ual constraints. These may be combined to approx-
imate the total number of solutions or used to guide
search heuristics. We give algorithms for several
of the main families of constraints and discuss the
possible uses of such solution counts.

1 Introduction
Many important combinatorial problems in Artiﬁcial Intelli-
gence (AI), Operations Research and other disciplines can be
cast as Constraint Satisfaction Problems (CSP). One is usually
interested in ﬁnding a solution to a CSP if it exists (the com-
binatorial existence problem) and much scientiﬁc literature
has been devoted to this subject in the past few decades. An-
other important question, though not as thoroughly studied,
is how many solutions there are (the combinatorial enumera-
tion problem). Our ability to answer this question has several
applications in AI (e.g. [Orponen, 1990],[Roth, 1996],[Dar-
wiche, 2001]), in statistical physics (e.g. [Burton and Steif,
1994], [Lebowitz and Gallavotti, 1971]), or more recently in
guiding backtrack search heuristics to ﬁnd solutions to CSPs
[Horsch and Havens, 2000][Kask et al., 2004][Refalo, 2004].
In this latter context, an estimation of the number of solutions
is sought repeatedly as search progresses. The best strategy
to keep the overall runtime low may be to trade accuracy for
speed while computing these approximations.

The model of a CSP is centered on the constraints, which
give it its structure. This paper proposes to exploit this in-
herent structure to derive polytime approximations to the so-
lution count of a CSP by combining solution counts of com-
ponent constraints. At the level of the individual constraint,

∗Research conducted while the author was on sabbatical leave

from ´Ecole Polytechnique de Montr´eal.

consistency algorithms act on the domains of the variables in
its scope (i.e. on which the constraint is deﬁned) to ﬁlter out
values which do not belong to any solution of this constraint,
thus avoiding some useless search. For many families of con-
straints, all such values can be removed in polynomial time
even though globally the problem is N P-hard. The only vis-
ible effect of the consistency algorithms is on the domains,
projecting the set of solutions on each of the variables. But
a constraint’s consistency algorithm often maintains informa-
tion which may be exploited to evaluate the number of valid
tuples. We intend to show that a little additional work is often
sufﬁcient to provide close or even exact solution counts for a
constraint, given the existing consistency algorithm.

The global counting problem for CSPs (denoted #CSP) is
#P-complete even if we restrict ourselves to binary con-
straints and is thus very likely intractable. Recent theoret-
ical work [Bulatov and Dalmau, 2003] characterizes some
tractable classes of CSPs for this problem but these are quite
restrictive, especially for practical problems. The counting
problem for Boolean CSPs (#SAT) is the best studied subclass
(see e.g. [Birnbaum and Lozinskii, 1999]).

For binary CSPs, exponential time exact algorithms have
been described (e.g. [Angelsmark and Jonsson, 2003]). For
backtrack search, [Kask et al., 2004] adapts Iterative Join-
Graph Propagation to approximate the number of solutions
extending a partial solution and uses its results in a value-
ordering heuristic to solve CSPs, choosing the value whose as-
signment to the current variable gives the largest approximate
solution count. An implementation optimized for binary con-
straints performs well compared to other popular strategies.
[Refalo, 2004] proposes a generic variable-ordering heuris-
tic based on the impact the assignment of a variable has on
the reduction of the remaining search space, computed as the
Cartesian product of the domains of the variables. It reports
promising results on multi-knapsack, magic square, and Latin
square completion benchmarks for (not necessarily binary)
CSPs. The value- and variable-ordering heuristics described
above rely on an approximation of the solution count. Both
can beneﬁt from an improvement in the quality and/or efﬁ-
cient computation of this approximation.

In the rest of the paper, Section 2 revisits several families of
constraints to evaluate the effort necessary to provide solution
counts, Section 3 explores possible uses for them, Section 4
gives some examples, and Section 5 discusses future work.

2 Looking at Constraints
This section proceeds through a short list of usual constraints
(for their origin, see e.g.[R´egin, 2004]) and examines how
solution counts may be derived. We assume throughout that
the constraints are domain consistent, unless stated otherwise.
Given a variable x, we denote its domain of possible values
as D(x), the smallest and largest value in D(x) as xmin and
xmax respectively, and the number of values in D(x) as dx.
We use #γ to mean the number of solutions for constraint γ.

2.1 Binary Constraints
Many arc consistency algorithms have been developed for
binary constraints of the form γ(x, y). Among them, AC-4
[Mohr and Henderson, 1986] maintains a support counter for
each value in D(x) and D(y). The total solution count is then
simply the sum of those counters over the domain of one of
the variables:

#γ(x, y) = X
v∈D(x)

sc(x, v)

(1)

where sc(x, v) stands for the support counter of value v in the
domain of variable x. However, other consistency algorithms
only compute support witnesses as needed and hence would
not have support counters available.

2.2 Arithmetic Binary Constraints
Typically, support counters are not maintained by the con-
sistency algorithm for arithmetic binary constraints but one
rather relies on the semantics of the constraint. Take for ex-
ample x < y: knowing xmin and ymax is sufﬁcient to remove
all the inconsistent values. To compute the number of valid
couples we can simply enumerate them, which done naively
would require Ω(dx · dy) time. Provided the domains are
maintained in sorted order, a reasonable assumption, that enu-
meration can be done in Θ(dx + dy) time by using a running
pointer in each domain as described in Algorithm 1.

function lt card(x, y)
let tx and ty be tables containing the values of the
domains of x and y, respectively, in increasing order;
p := 1; q := 1 c := 0;
while q ≤ dy do

while p ≤ dx and tx[p] < ty[q] do

p := p + 1;

c := c + p − 1;
q := q + 1;

return c;

Algorithm 1: Computing the number of solutions to x < y.

#(x < y) = lt card(x, y)

(2)

For each value v in D(y), it ﬁnds out of the number of sup-
ports sc(y, v) from D(x) and adds them up in c. We can make
the algorithm incremental by storing sc(y, v) for each v in
D(y) and q(w), the smallest q such that w < ty[q], for each
w in D(x): if v is removed from D(y), the total number of
solutions decreases by sc(y, v); if w is removed from D(x),

the total number of solutions decreases by dy − q(w) + 1 and
sc(y, v) is decremented by one for q(w) ≤ v ≤ dy.

Sometimes the domains of variables involved in such con-
straints are maintained as intervals. This simpliﬁes the com-
putation, for which we derive a closed form:

#(x < y) =

ymax−xmin

ymax−xmax−1

X

i −

i=ymin−xmin

X

i=1

i

= ymax · (xmax + 1) − xmin · dy

− 1

2 · (x2

max + xmax + y2

min − ymin) (3)
Clearly, what preceded equally applies to constraints
x ≤ y, x > y, and x ≥ y, with small adjustments. Counting
solutions for equality and disequality constraints is compar-
atively straightforward (remember that domain consistency
has been achieved):

#(x = y) = dx
#(x 6= y) = dx · dy − |D(x) ∩ D(y)|

(4)
(5)
With an appropriate representation of the intersection of
D(x) and D(y), an incremental version of the count for
x 6= y requires constant time.

In some applications such as temporal reasoning, constants
are present in the binary constraints (e.g. x < y + t for some
constant t). The previous algorithms and formulas are easily
adapted to handle such constraints.
2.3 Linear Constraints
Many constraint models feature linear constraints of the form
Pn
i=1 aixi ◦ b where ◦ stands for one of the usual relational
operators and the ai’s and b are integers. Bound consistency
is typically enforced, which is a fast but rather weak form
of reasoning for these constraints. Working from domains
ﬁltered in this way is likely to yield very poor approximations
of the number of solutions.
Example 1 Constraint 3x1 +2x2 −x3 −2x4 = 0 with bound
consistent domains D(xi) = {0, 1, 2}, 1 ≤ i ≤ 4 admits
only seven solutions even though the size of the Cartesian
product is 81. Since the value of any one variable is totally
determined by the combination of values taken by the others,
the upper bound can be lowered to 27 but this is still high.

These constraints are actually well studied under the name
of linear Diophantine equations and inequations. In particu-
lar, [Ajili and Contejean, 1995] offers an algorithm adapted
to constraint programming that produces a ﬁnite description
of the set of solutions of a system of linear Diophantine equa-
tions and inequations over N

When the constraints are of the form b′ ≤ Pn

i=1 aixi ≤ b
with the ai’s and xi’s belonging to N, we get knapsack con-
straints for which [Trick, 2003] adapts a pseudo-polynomial
dynamic programming algorithm. It builds an acyclic graph
Ghaii,hxii,b,b′ of size O(nb) in time O(nbd) (where d =
max{dxi}) whose paths from the initial node to a goal node
correspond to solutions. It is pointed out that enumerating
solutions amounts to enumerating paths through a depth-ﬁrst
search, in time linear in the size of the graph.

#(b′ ≤

n

X

i=1

aixi ≤ b)=|{paths traversing Ghaii,hxii,b,b′ }|

(6)

Interestingly, the approach could be generalized so as to lift
the nonnegativity restriction on the coefﬁcients and variables
at the expense of a larger graph of size O(nr) where r repre-
sents the magnitude of the range of Pn
i=1 aixi over the ﬁnite
domains.

2.4 Element Constraints
The ability to index an array with a ﬁnite-domain variable,
commonly known as an element constraint, is often present
in practical models. Given variables x and i and array of val-
ues a, element(i, a, x) constrains x to be equal to the ith
element of a (x = a[i]). Note that this is not an arbitrary
relation between two variables but rather a functional rela-
tionship. As a relation, it could potentially number dx · di
solutions, corresponding to the Cartesian product of the vari-
ables. As a functional relationship, there are exactly as many
tuples as there are consistent values for i:

#element(i, a, x) = di

(7)

This exact count improves on the product of the domain

sizes by a factor dx.

2.5 Regular Language Membership Constraints
Given a sequence of variables X = hx1, x2, . . . , xni and
a deterministic ﬁnite automaton A, regular(X, A) con-
strains any sequence of values taken by the variables of X
to belong to the regular language recognized by A [Pesant,
2004]. The consistency algorithm for this constraint builds a
directed acyclic graph GX,A whose structure is very similar
to the one used by [Trick, 2003] for knapsack constraints, as
reported in Section 2.3. Here as well, each path corresponds
to a solution of the constraint and counting them represents
no complexity overhead with respect to the consistency algo-
rithm.

#regular(X, A) = |{paths traversing GX,A}|

(8)

2.6 Among Constraints
Under constraint among(c, X, V ), variable c corresponds to
the number of variables from set X taking their value from
set V [Beldiceanu and Contejean, 1994]. Let R = {x ∈ X :
D(x) ⊆ V }, the subset of variables required to take a value
from V , and P = {x ∈ X \ R : D(x) ∩ V 6= ∅}, the subset
of variables possibly taking a value from V . Those two sets
are usually maintained by the consistency algorithm since the
relationship |R| ≤ c ≤ |R| + |P | is useful to ﬁlter the domain
of c.

Deﬁne νS as the number of variables from set S taking
their value from V . To derive the number of solutions, we
ﬁrst make the following observations:

1. νR = |R|, a constant, so that in any solution to the con-
straint the value taken by x ∈ R can be replaced by any
other in its domain and it remains a solution.

2. νX\(R∪P ) = 0, a constant, so that in any solution to
the constraint the value taken by x ∈ X \ (R ∪ P ) can
be replaced by any other in its domain and it remains a
solution.

3. Any assignment of the variables of P such that νP =
c − |R| of them take a value in V can be extended into
Qx∈X\P dx complete solutions.

4. There are such assignments for every value of νP from
cmin − |R| to cmax − |R| and for every subset S of P
identifying the νP variables in question. How many as-
signments, given S? Each variable y ∈ S has |D(y)∩V |
possible values and each variable z ∈ P \ S has |D(z) \
V | possible values, totaling #a(S) = Qy∈S |D(y) ∩
V | · Qz∈P \S |D(z) \ V | assignments.

Putting it all together gives:

cmax

#among(c, X, V ) = Y
x∈X\P

dx ·

X

k=cmin

#a(S)

(9)

X

S⊆P

|S|=k−|R|

In the worst case, the number of S sets to consider is ex-
ponential in the number of variables. It may be preferable
sometimes to compute faster approximations. We can re-
place every #a(S) by some constant lower or upper bound.
Let tin be a table in which the sizes of D(x) ∩ V for ev-
ery x ∈ P appear in increasing order. Similarly, let tout
be a table in which the sizes of D(x) \ V for every x ∈
P appear in increasing order. We deﬁne a lower bound
ℓ(a(k)) = Qk−|R|
and an upper bound
u(a(k)) = Qk−|R|
Then

tin[i] · Q|P |−k+|R|
tin[|P |−i+1]·Q|P |−k+|R|

tout[|P |−i+1].

tout[i]

i=1

i=1

i=1

i=1

#among(c, X, V ) ≥ Y
x∈X\P

dx ·

k−|R|) · ℓ(a(k))
( |P |

(10)

cmax

X

k=cmin

cmax

k=cmin

#among(c, X, V ) ≤ Y
x∈X\P

dx ·

X

k−|R|) · u(a(k)) (11)
( |P |

Note that if the variables in P have identical domains then
the lower and upper bounds coincide and we obtain the exact
count.
Example 2 Consider among(c, {x1, x2, x3, x4, x5}, {1, 2})
with D(c) = {3, 4}, D(x1) = {1, 3, 4}, D(x2) =
{1, 2}, D(x3) = {3, 4}, D(x4) = {2}, and D(x5) =
{1, 2, 3}. We obtain R = {x2, x4}, P = {x1, x5}, and
#among(c, {x1, x2, x3, x4, x5}, {1, 2}) = dx2 · dx3 · dx4 ·
(|D(x1) ∩ {1, 2}| · |D(x5) \ {1, 2}| + |D(x5) ∩ {1, 2}| ·
|D(x1) \ {1, 2}| + |D(x1) ∩ {1, 2}| · |D(x5) ∩ {1, 2}|) =
2 · 2 · 1 · (1 · 1 + 2 · 2 + 1 · 2) = 28, by (9). Using (10),(11)
we get 16 ≤ #among(c, {x1, x2, x3, x4, x5}, {1, 2}) ≤ 40.
In comparison, the size of the Cartesian product is 72.

2.7 Mutual Exclusion and Global Cardinality

Constraints

Besides among, other constraints are concerned with the
number of repetitions of values. Constraint alldiff(X)
forces the variables of set X to take different values.
Constraint gcc(Y, V, X),
for a sequence of variables
Y = hy1, y2, . . . , ymi and a sequence of values V =
hv1, v2, . . . , vmi, makes each yi equal to the number of times

a variable of X takes value vi. It is a generalization of the
former.

Already for the alldiff constraint, the counting prob-
lem includes as a special case the number of perfect match-
ings in a bipartite graph, itself equivalent to the N P-hard
problem of computing the permanent of the adjacency ma-
trix representation of the graph. So currently we do not
know of an efﬁcient way to compute #alldiff(X) or
#gcc(Y, V, X) exactly. A polytime randomized approxima-
tion algorithm for the permanent was recently proposed in
[Jerrum et al., 2004] but its time complexity, in Ω(n10), re-
mains prohibitive. Therefore even getting a reasonable ap-
proximate ﬁgure is challenging. We nevertheless propose
some bounds.
Upper Bound
If D(x) ⊆ D(y) for some variables x, y ∈ X then regard-
less of the value v taken by x we know that at most dy − 1
possibilities remain for y since v ∈ D(y). We generalize this
simple observation by considering D = {D(x) : x ∈ X},
the distinct domains of X. For each D ∈ D, deﬁne ED =
{x ∈ X : D(x) = D}, the set of variables with domain D,
and SD = {x ∈ X : D(x) ⊂ D}, the set of variables whose
domain is properly contained in D. Then

#alldiff(X) ≤ Y
D∈D

|ED|
Y

(|D| − |SD| − i + 1)

(12)

i=1

Computing it requires taking the product of n terms, each of
which can be computed easily in O(nm) time and probably
much faster with an appropriate data structure maintaining
the ED and SD sets. This upper bound is interesting be-
cause for the special case where all domains are equal, say
{v1, v2, . . . , vm}, it simpliﬁes to the exact solution count,

n

Y

i=1

(m − i + 1) = m!/(m − n)!

Lower Bound
As hinted before, the consistency algorithm for alldiff
computes a maximum matching in a bipartite graph.
It is
known that every maximum matching of a graph can be ob-
tained from a given maximum matching by successive trans-
formations through even-length alternating paths starting at
an unmatched vertex or through alternating cycles.1 Each
transformation reverses the status of the edges on the path or
cycle in question: if it belonged to the matching it no longer
does, and vice versa. The result is necessarily a matching
of the same size. Finding every maximum matching in this
way (or any other) would be too costly, as we established be-
fore, but ﬁnding those that are just one transformation away
is fast and provides a lower bound on the number of max-
imum matchings, or equivalently on the solution count of
alldiff.

By not applying transformations in succession, we also
avoid having to check whether two matchings obtained by
distinct sequences of transformations are in fact identical,

1An alternating path or cycle alternates between edges belonging

to a given matching and those not belonging to it.

which could happen. However, successive transformations
from distinct connected components is safe: each resulting
matching is distinct. We may therefore take the product of
the number of maximum (sub)matchings in each connected
component of the bipartite graph. Identifying the connected
components C takes time linear in the size of the graph. Enu-
merating all the appropriate cycles and paths of each con-
nected component can be done in O(nm2) time. Let their
number be νg for each connected component g ∈ C. Then

#alldiff(X) ≥ Y
g∈C

(νg + 1)

(13)

For the gcc constraint, we may be able to adapt the ideas
which gave rise to the previous lower bound. The consis-
tency algorithm for this constraint is usually based on net-
work ﬂows. Given a network and a ﬂow through it, a resid-
ual graph can be deﬁned and the circuits in this graph lead
to equivalent ﬂows. Another idea is to decompose the con-
straint into among constraints on singleton sets of values and
use (9)-(11).

3 Using Solution Counts of Constraints
This section examines the possible uses of solution counts of
constraints.

3.1 Approximate the Solution Count of a CSP
They can be used to approximate the number of solutions to
a CSP. Given a model for a CSP, consider its variables as
a set S and its constraints as a collection C of subsets of S
deﬁned by the scope of each constraint. Add to C a singleton
for every variable in S. A set partition of S is a subset of C
whose elements are pairwise disjoint and whose union equals
S (see Section 4 for some examples). To each element of
the partition corresponds a constraint (or a variable in case
of a singleton) for which an upper bound on the number of
solutions can be computed (or taken as the cardinality of the
domain in case of a singleton). The product of these upper
bounds gives an upper bound on the total number of solutions.
In general there are several such partitions possible and we
can ﬁnd the smallest product over them. If it is used in the
course of a computation as variables become ﬁxed and can be
excluded from the partition, new possible partitions emerge
and may improve the solution count.

3.2 Guide Search Heuristics
As we saw in the introduction, these counts are also useful
to develop robust search heuristics. They may allow a ﬁner
evaluation of impact in the generic search heuristic of [Re-
falo, 2004] since their approximation of the size of the search
space is no worse than the Cartesian product of the domains.
Value-ordering heuristics such as [Kask et al., 2004] are also
good candidates. Other search heuristics following the ﬁrst-
fail principle (detect failure as early as possible) and centered
on constraints can be guided by a count of the number of so-
lutions left for each constraint. We might focus the search
on the constraint currently having the smallest number of so-
lutions, recognizing that failure necessarily occurs through a
constraint admitting no more solutions (see Section 4).

3.3 Evaluate Projection Tightness
We can also compute the ratio of the (approximate) solution
count of a constraint to the size of the Cartesian product of
the appropriate domains, in a way measuring the tightness
of the projection of the constraint onto the individual vari-
ables. A low ratio stresses the poor quality of the infor-
mation propagated to the other constraints (i.e.
the ﬁltered
domains) and identiﬁes constraints whose consistency algo-
rithm may be improved. Tightness can also serve as another
search heuristic, focusing on the constraint currently exhibit-
ing the worst tightness (i.e. the smallest ratio). An ideal ratio
of one corresponds to a constraint perfectly captured by the
current domains of its variables.

4 Some Examples
The purpose of this section is to illustrate solution counts and
their possible uses through a few simple models, easier to
analyse.

4.1 Map Coloring
Consider the well-known map coloring problem for six Euro-
pean countries: Belgium, Denmark, France, Germany, Lux-
embourg, and the Netherlands. Any two countries sharing a
border cannot be of the same color. To each country we asso-
ciate a variable (named after its ﬁrst letter) that represents its
color. Constraints

f 6= b, f 6= ℓ, f 6= g, ℓ 6= g, ℓ 6= b, b 6= n, g 6= n, g 6= d, g 6= b

model the problem. If we allow ﬁve colors, there are 1440 le-
gal colorings. The cardinality of the Cartesian product of the
domains of the variables initially overestimates that number
to be 15625 (56). A set partition such as {f 6= ℓ, b 6= n, g 6=
d} provides a slightly better estimate, using (5):

(dx · dy − |D(x) ∩ D(y)|)3 = (5 · 5 − 5)3 = 8000.

Noticing that four of these countries are all pairwise adjacent,
an alternate model is

alldiff({b, f, g, ℓ}), b 6= n, g 6= n, g 6= d

yielding a still better upper bound on the solution
count, 5! · 52 = 3000, using (12) with set partition
{alldiff({b, f, g, ℓ}), n, d}. We see here that the solution
counts of the constraints in a CSP model, particularly those
of high arity, can quickly provide good approximations of
the number of solutions of CSPs. The projection tightness
of b 6= n, g 6= n, and g 6= d is 20/25 = 0.8; that of
alldiff({b, f, g, ℓ}) is 5!/54 = 0.192. This could be taken
as an indication that search should focus on the latter.

Let us now analyse the effect of coloring one of the coun-
tries red. Regardless of the country we choose, the number of
legal colorings will decrease ﬁve fold to 288 since colors are
interchangeable. The true impact of ﬁxing a variable, mea-
sured as 1 minus the ratio of the remaining search space after
and before ([Refalo, 2004]), is thus 0.8. Table 4.1 reports af-
ter each country is colored red the cardinality of the Cartesian
product of the domains (column 2), the upper bound on the
solution count from each of the two set partitions (columns

domains

1st partition

var
ℓ
f
b
g
n
d
avg

solns
1600
1600
1280
1024
2000
2500
–

impact
.898
.898
.918
.934
.872
.840
.893

solns
1024
1024
768
576
1280
1600
–

impact
.872
.872
.904
.928
.840
.800
.869

2nd partition
impact
solns
600
.800
.800
600
.840
480
.872
384
.880
360
480
.840
.839
–

Table 1: Comparing different approximations of the number
of solutions of a small map coloring problem.

4 and 6), and their corresponding impacts (columns 3, 5, and
7).

Again we note a signiﬁcant improvement in the approxi-
mation of the number of solutions over the Cartesian prod-
uct, particularly from the second set partition based on the
model using an alldiff constraint. The latter also provides
a closer approximation of the true impact: the average com-
puted impact is less than 5% away whereas it is more than
11% away for the average computed impact using Cartesian
products.

4.2 Rostering
Consider next a simple rostering problem: a number of daily
jobs must be carried out by employees while respecting some
labor regulations. Let E be the set of employees, D the days
of the planning horizon, and J the set of possible jobs, in-
cluding a day off. Deﬁne variables jde ∈ J (d ∈ D, e ∈ E)
to represent the job carried out by employee e on day d. To
ensure that every job is performed on any given day, we can
state the following constraints:

gcc(h1, 1, . . . , 1i, J \ {day off}, (jde)e∈E)
Some jobs are considered more demanding than others and
we wish to balance the workload among employees. We in-
troduce variables wde representing the workload of employee
e on day d and link them to the main variables in the follow-
ing way:

d ∈ D. (14)

element(jde, (ℓj)j∈J , wde)

d ∈ D, e ∈ E (15)

where ℓj corresponds to the load of job j. We then add con-
straints enforcing a maximum workload k:

Pd∈D wde ≤ k

e ∈ E.

(16)

Finally work patterns may be imposed on individual rosters:

regular((jde)d∈D, A)
with the appropriate automaton A.

e ∈ E

(17)

To approximate the number of solutions, there are a few
possibilities for a set partition of the variables (jde)d∈D,e∈E
and (wde)d∈D,e∈E: constraints (14)(16) are one, constraints
(17)(16) are another, and so are constraints (15). In deciding
which one to use, its size (the number of parts), the qual-
ity of the bounds, and the projection tightness of each con-
straint may help. Partition (15) has size |D| · |E| compared
to |D| + |E| and 2 · |E| for the other two: a smaller size

means larger parts and probably a better overall approxima-
tion since each solution count has a more global view. We
presented exact counts for every constraint used here except
(14), making partition (14)(16) less attractive. A set partition
that includes constraints with low tightness (which is difﬁcult
to assess here without precise numbers) is more likely to do
signiﬁcantly better than the size of the Cartesian product of
the individual domains, which can be considered a baseline.

5 Discussion
This paper argued that looking at the number of solutions of
individual constraints in CSPs is interesting and useful. It can
approximate the number of solutions as a whole or help guide
search heuristics. Efﬁcient ways of counting solutions were
given for several families of constraints. The concepts of set
partition over the variables and of projection tightness were
deﬁned in order to combine solution counts and measure the
efﬁcacy of consistency algorithms, respectively.

But this is a ﬁrst step and many questions remain. Some
of the main families of constraints have been investigated but
others were left out: for example, those useful in schedul-
ing or packing problems such as cumulative and diffn,
or those for routing problems such as cycle. How close
can we get to the solution count for them and at what com-
putational cost? For the simplest constraints that we investi-
gated, we mentioned how the algorithms computing solution
counts could be made incremental. This is an important issue
to achieve efﬁciency when such counts are computed repeat-
edly as in backtrack search. What can be done for the other
constraints? The whole question of the usefulness of such
an approach hasn’t been settled either. The answer is likely
to come, at least in part, from empirical evidence. Compu-
tational experiments will need to be run on larger and more
realistic models.

Acknowledgements
Philippe Refalo’s work on impact-based search sparked the
idea for this paper. I thank Jean-Charles R´egin for discus-
sions and the anonymous referees for their constructive com-
ments. This work was partially supported by the Canadian
Natural Sciences and Engineering Research Council under
grant OGP0218028.

References
[Ajili and Contejean, 1995] F. Ajili and E. Contejean. Com-
plete Solving of Linear Diophantine Equations and In-
equations without Adding Variables.
In Proc. CP’05,
pages 1–17. Springer-Verlag LNCS 976, 1995.

[Angelsmark and Jonsson, 2003] O. Angelsmark and P. Jon-
Improved Algorithms for Counting Solutions in
sson.
Constraint Satisfaction Problems. In Proc. CP’03, pages
81–95. Springer-Verlag LNCS 2833, 2003.

[Beldiceanu and Contejean, 1994] N.

and
Introducing Global Constraints in CHIP.
E. Contejean.
Mathematical and Computer Modelling, 20:97–123,
1994.

Beldiceanu

[Birnbaum and Lozinskii, 1999] E. Birnbaum and E. L.
Lozinskii. The Good Old Davis-Putnam Procedure Helps
Counting Models. Journal of Artiﬁcial Intelligence Re-
search, 10:457–477, 1999.

[Bulatov and Dalmau, 2003] A.A. Bulatov and V. Dalmau.
Towards a Dichotomy Theorem for the Counting Con-
straint Satisfaction Problem.
In Proc. FOCS’03, pages
562–573. IEEE Computer Society, 2003.

[Burton and Steif, 1994] R. Burton and J. Steif. Nonunique-
ness of Measures of Maximal Entropy for Subshifts of
Finite Type. Ergodic Theory and Dynamical Systems,
14:213–236, 1994.

[Darwiche, 2001] A. Darwiche. On the Tractable Counting
of Theory Models and its Applications to Truth Main-
tenance and Belief Revision.
Journal of Applied Non-
Classical Logic, 11:11–34, 2001.

[Horsch and Havens, 2000] M. Horsch and B. Havens. Prob-
abilistic Arc Consistency: A Connection Between Con-
straint Reasoning and Probabilistic Reasoning.
In UAI-
2000, pages 282–290, 2000.

[Jerrum et al., 2004] M. Jerrum, A. Sinclair, and E. Vigoda.
A polynomial-Time Approximation Algorithm for the Per-
manent of a Matrix with Non-Negative Entries. Journal of
the ACM, 51:671–697, 2004.

[Kask et al., 2004] K. Kask, R. Dechter, and V. Gogate.
Counting-Based Look-Ahead Schemes for Constraint Sat-
isfaction. In Proc. CP’04, pages 317–331. Springer-Verlag
LNCS 3258, 2004.

[Lebowitz and Gallavotti, 1971] J.

and
G. Gallavotti.
Phase Transitions in Binary Lattice
Gases. Journal of Mathematical Physics, 12:1129–1133,
1971.

Lebowitz

[Mohr and Henderson, 1986] R. Mohr and T.C. Henderson.
Arc and Path Consistency Revisited. Artiﬁcial Intelli-
gence, 28:225–233, 1986.

[Orponen, 1990] P. Orponen. Dempster’s Rule of Combi-
nation is #-Complete. Artiﬁcial Intelligence, 44:245–253,
1990.

[Pesant, 2004] G. Pesant. A Regular Language Membership
Constraint for Finite Sequences of Variables.
In Proc.
CP’04, pages 482–495. Springer-Verlag LNCS 3258,
2004.

[Refalo, 2004] P. Refalo. Impact-Based Search Strategies for
Constraint Programming. In Proc. CP’04, pages 557–571.
Springer-Verlag LNCS 3258, 2004.

[R´egin, 2004] J.-C. R´egin. Global Constraints and Filtering
Algorithms. In M. Milano, editor, Constraint and Integer
Programming: Toward a Uniﬁed Methodology. Kluwer,
2004.

[Roth, 1996] D. Roth. On the Hardness of Approximate Rea-

soning. Artiﬁcial Intelligence, 82:273–302, 1996.

[Trick, 2003] M.A. Trick. A Dynamic Programming Ap-
proach for Consistency and Propagation for Knapsack
Constraints. Annals of Operations Research, 118:73–84,
2003.

