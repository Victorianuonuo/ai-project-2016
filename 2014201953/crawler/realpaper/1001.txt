Database-Text Alignment via Structured Multilabel Classiﬁcation

Benjamin Snyder and Regina Barzilay

Computer Science and Artiﬁcial Intelligence Laboratory

Massachusetts Institute of Technology

{bsnyder,regina}@csail.mit.edu

Abstract

This paper addresses the task of aligning a database
with a corresponding text. The goal is to link in-
dividual database entries with sentences that ver-
balize the same information. By providing explicit
semantics-to-text links, these alignments can aid
the training of natural language generation and in-
formation extraction systems. Beyond these prag-
matic beneﬁts, the alignment problem is appeal-
ing from a modeling perspective: the mappings be-
tween database entries and text sentences exhibit
rich structural dependencies, unique to this task.
Thus, the key challenge is to make use of as many
global dependencies as possible without sacriﬁc-
ing tractability. To this end, we cast text-database
alignment as a structured multilabel classiﬁcation
task where each sentence is labeled with a subset of
matching database entries. In contrast to existing
multilabel classiﬁers, our approach operates over
arbitrary global features of inputs and proposed la-
bels. We compare our model with a baseline clas-
siﬁer that makes locally optimal decisions. Our re-
sults show that the proposed model yields a 15%
relative reduction in error, and compares favorably
with human performance.

1 Introduction
Uncovering the mapping between text and its underlying se-
mantic representation lies at the core of natural language
processing. For instance, the goal of information extraction
is to structurally represent the semantic content of a given
text. Natural language generation, on the other hand, seeks
to create such texts from structured, non-linguistic represen-
tations. Training both information extraction and natural lan-
guage generation systems generally requires annotated data
that speciﬁes the mapping between structured representations
and corresponding fragments of text. Creating these map-
pings by hand is prohibitively expensive.

An alternative source of data for learning text-to-semantics
mappings are parallel collections of databases and their cor-
responding texts. Such parallel collections are abundant and
are readily available in multiple domains, including terror-
ism, sports, ﬁnance, and weather. However, text-database

pairs cannot be used directly for system training without more
reﬁned alignment of their components. Such an alignment
should explicitly link database entries to the sentences that
verbalize their content.

In this paper, we investigate a supervised learning approach
to aligning database entries and sentences. For example, con-
sider a database containing statistics on an American football
game and the corresponding newspaper summary. Figure 1
shows an excerpt from such a database and several summary
sentences along with the target alignment.

Text-database alignment differs in several important re-
spects from word alignment in machine translation. First, the
databases and texts are not exactly parallel: many database
entries may not be verbalized in a text, and conversely, some
sentences may contain information not found in a database.
Second, the number of items to be aligned is greater than the
number of words in translated sentences. A typical database
may contain hundreds of entries compared to an average of
25 words in a newspaper sentence. Finally, the database and
text units to be aligned exhibit rich internal structure and
complex interdependencies. Thus, the database schema pro-
vides a key for mining semantic relations between entries and
corresponding sentences. For instance, in Figure 1 we can
see that the three entries aligned to the ﬁnal sentence bear a
strong relationship to one another: the interception leads to a
drive which culminates in a touchdown run. This relationship
and many others like it can be determined by examining the
database structure.

One possible approach is to formulate semantics-to-text
alignment as simple binary classiﬁcation of sentence-entry
pairs. By considering the content overlap between a database
entry and a sentence, the classiﬁer determines whether they
are aligned. This approach, however, fails to capture depen-
dencies between local alignment decisions such as the one we
just saw. Local alignments could also lead to overmatching
when a sentence contains a single anchor that locally matches
multiple database entries. For instance, the ﬁnal sentence in
Figure 1 contains the name “Brown” and the number “2.” Be-
sides matching an entry in the play-by-play table, these an-
chors also match the second entry in the fumbles table.1 By
making independent decisions for each of these entries, a lo-

1In American Football, a “fumble” occurs when a ball has been

dropped and may be recovered by either team.

IJCAI-07

1713

Research has focused on developing local ranking models
aiming to minimize the number of incorrect labels predicted
above correct ones, often ignoring threshold selection or
treating it as a secondary concern [Elisseeff and Weston,
2001; Crammer and Singer, 2002; McDonald et al., 2005;
Schapire and Singer, 1999].

Our approach shares the initial local ranking step with tra-
ditional multilabel classiﬁers. However, in a task with struc-
tured labels, where the set of correct labels exhibit compati-
bility properties, it is insufﬁcient to choose a cutoff by merely
looking at the local ranking scores. Therefore, we treat rank-
ing as a mere pruning step and learn to make intelligent
threshold selections based on ranking scores as well as re-
lations between entries. By considering collective properties
of various label sets, we can mitigate ranking errors.

Ghamrawi and McCallum [2005] propose an approach to
multilabel classiﬁcation using Conditional Random Fields.
Their approach models co-occurrence dependencies between
pairs of class labels and individual input features. Our ap-
proach, on the other hand, learns weights for features deﬁned
jointly on the input and sets of (structured) labels. Also, our
global feature function is not constrained to examining pairs
of labels, but instead operates over arbitrary label sets.

Alignment The problem of word alignment of parallel
bilingual corpora has been extensively studied in machine
translation. While most of the research focuses on un-
supervised models [Brown et al., 1993], recently a num-
ber of supervised discriminative approaches have been pro-
posed [Taskar et al., 2005; Lacoste-Julien et al., 2006].
Taskar et al. [2005] cast alignment as a graph matching prob-
lem and solve it in an optimization framework. Their model
ﬁnds the global alignment which maximizes word-pair align-
ment scores, subject to a hard fertility constraint. Recently,
they have reformulated the optimization problem to instead
apply soft constraints on alignment fertility as well as con-
trol for other properties speciﬁc to word alignment [Lacoste-
Julien et al., 2006].

Our model differs in that it can consider arbitrary features
of the alignment decisions. For instance, depending on the
structural properties of the aligned objects, we often wish to
encourage, rather than penalize, additional alignments.

3 Problem Formulation
In an alignment problem each input consists of a set of x vari-
ables L and a set of y variables R. For each input (L, R) there
is a target alignment consisting of edges between individual
x and individual y variables: A ⊆ L × R. Note that an in-
dividual x or y variable may occur many times in such an
alignment.

In a structured alignment problem, rather than taking on
categorical or numerical values, each x variable encodes an
element from a set of permissible structures X , and each y
value similarly represents a structure from Y. For example,
in our case the x variables are sentences in a text, and the
y variables encode entries in a relational database. Thus, an
input (L, R) represents a text-database pair for a particular
NFL football game, and the target alignment A is the set of
all sentence-entry pairs referring to the same fact or event.

Figure 1: Sample target alignment between the NFL database
and summary text.

cal classiﬁer may erroneously align them both to the same
sentence.

To capture global features of alignments, we cast our prob-
lem as a structured multilabel classiﬁcation task. In the mul-
tilabel framework, each instance can be assigned any subset
of the labels. In our case, we treat the sentences as instances
and label them with the subset of database entries that match
in content. By jointly considering a sentence with an entire
set of candidate entries, our method ensures the global coher-
ence of the aligned set. Moreover, we guide the alignment
towards sets of entries with favorable structural properties.
This task is accomplished by using a model that operates over
arbitrary global features of the sentence and proposed entry
set. However, the number of potential entry sets per sen-
tence is exponential, and therefore this feature space cannot
be searched exhaustively. To focus on promising label sets,
we ﬁrst rank all the database entries based on their individual
match to the input sentence. We then only consider entry sets
formed by choosing a cut-off in this ranking. Our model then
selects among the remaining sets by examining their global
alignment features. Although the target entry set may not be
among these candidates, we train our model to choose the set
closest to the target in Hamming distance.

We evaluate our algorithm on a corpus of manually aligned
text-database pairs in the sports domain. To assess the con-
tribution of our global model, we compare our method with
a local classiﬁer which treats every sentence-entry pair in-
dependently. Our method achieves a 15% relative reduction
in error over this baseline, demonstrating the contribution of
global features in our task.

2 Related Work
Multilabel classiﬁcation A typical multilabel classiﬁer has
two stages: ﬁrst, the labels of each input are ranked by a
local scoring function. Then, a regression model predicts
a threshold as a function of the label ranking scores. Fi-
nally, all the labels above the predicted threshold are returned.

IJCAI-07

1714

Given a set of inputs and their true alignments, our goal
is to learn a mapping from inputs to alignments which mini-
mizes the errors in the predicted alignments.

4 Modeling Assumptions
Unfortunately, for a particular input (L, R) with |L| = m
and |R| = n, there are 2mn possible alignments. For in-
stance, in our scenario, where (L, R) is a text-database pair
with around 50 sentences and 330 database entries, it is in-
feasible to search through this entire space. However, if some
local decisions in the alignments are assumed to be indepen-
dent of others, we can learn a model which makes optimal
partial alignment decisions and then combines them into a
full alignment. Next we describe several degrees of indepen-
dence between local alignment decisions that might occur.

Full Independence In the case of full independence, the
likelihood of any pair (x, y) ∈ L × R being aligned is inde-
pendent of the alignment of any pair (x(cid:2), y (cid:2)) ∈ L × R when
either x (cid:4)= x(cid:2) or y (cid:4)= y (cid:2). Assuming this complete indepen-
dence, we can train a local binary classiﬁer using the m × n
(x, y) pairs from each of our inputs.

Partial Independence A weaker, asymmetric indepen-
dence might occur in one of two ways. Consider any two
pairs (x, y) ∈ L × R and (x(cid:2), y (cid:2)) ∈ L × R. If the alignment
decisions for these pairs are independent only if x (cid:4)= x(cid:2) then
we say that the alignments are left-side partially independent.
If, on the other hand, the alignment decisions are independent
only if y (cid:4)= y (cid:2), then the alignments are right-side partially in-
dependent.

To illustrate these ideas, consider their application to our
task of text-database alignment. Left-side partial indepen-
dence would occur if the set of entries verbalized in a sentence
is independent of those chosen for any other sentence. But at
the same time, the entries to be verbalized in a particular sen-
tence are chosen jointly and dependently – if, for example, a
sentence mentioning a score is more likely now to mention a
play which led to the score. We could thus train a model to
choose the optimal aligned set of entries individually for each
sentence.

5 Algorithm

To strike an appropriate balance between tractability and
model richness, we base our text-database alignment method
on a partial independence assumption. In particular, we as-
sume that alignment decisions for each sentence are indepen-
dent of other alignment decisions. At the same time, we allow
dependencies within the set of database entries aligned to a
sentence. Following the terminology introduced in Section 4,
this model makes a left-side partial independence assump-
tion. We believe that this is a natural choice for this task be-
cause a typical sentence conveys several facts that are seman-
tically related in a meaningful way. When these facts are rep-
resented in a database, we can capture their inter-relations by
examining the structural links of the corresponding database
entries.

As a result of this independence assumption, we can train
a model to make optimal alignment decisions separately for

each sentence. In other words, each sentence is an indepen-
dent instance that must be labeled with a subset of database
entries. In essence, by treating entries as structured labels of
sentences, we reformulate alignment as a structured multil-
abel classiﬁcation task. The key advantage of our approach
lies in its ability to consider arbitrary global features of each
sentence and its proposed label set. However, since we can-
not possibly examine every subset of labels, we need to intel-
ligently prune the decision space. This pruning is driven by
local alignments: for each sentence, all the database entries
are ranked by their individual alignment likelihood. We then
only consider sets of entries consistent with the ranking. That
is, for every predicted label, the labels ranked above it must be
predicted as well. Now that the number of considered candi-
dates is linear in the number of entries, we can train a model
to choose the one with optimal global characteristics. The
latter stage of this approach is similar in spirit to global parse
reranking [Collins and Koo, 2005]. However, our approach
constrains the decision space through local ranking of labels
rather than an n-best list produced by a generative model.

Below we formally describe the training and decoding pro-

cedures for text-database alignment.

5.1 Model Structure
The model takes as an input a set of sentences L with |L| = m
and a set of database entries R with |R| = n. Each sentence-
entry pair (x, y) ∈ L × R is represented as a local feature
vector Φx,y(x, y). Each component of this vector is a bi-
nary feature. For instance, the ith component of this vector
may indicate whether the sentence and entry contain the same
number:

(Φx,y(x, y))i =

1 if x and y contain the same number
0 otherwise

(cid:2)

(cid:2)

In addition, our model captures dependencies among mul-
tiple entries aligned to the same sentence. We represent a
sentence x ∈ L paired with a set of candidate entries Y ⊆ R
with the global feature vector Φx(x, Y ). The components
here are also binary features. For example, the ith may indi-
cate whether all the entries in Y match the same name in the
sentence:

(Φx(x, Y ))i =

1 ∀y ∈ Y contain the same name
0 otherwise

Our model predicts alignments in two basic steps.

Step One The goal of this step is to prune the decision space
by inducing a ranking of database entries for each sen-
tence x ∈ L. To do so, for each each entry y ∈ R, the
model maps the feature vector Φx,y(x, y) to a real num-
ber. This mapping can take the form of a linear model,

Φx,y(x, y) · α1

where α1 is the local parameter vector.
We then order the entries in R: y1, y2, y3, . . . , yn such
that Φx,y(x, yi) · α1 ≥ Φx,y(x, yi+1) · α1, ∀i.

IJCAI-07

1715

Step Two Given a particular

ranking of

entries
for each i ∈ 0, 1, ..., n, we deﬁne
y1, y2, . . . , yn,
the set of i initial elements Yi = {y1, . . . , yi}. The goal
of this step is to choose a cut-off i∗ and return Yi∗ as
the aligned set of entries. To do so, our model computes
a score for each i ∈ 0, 1, . . . , n based on the global
feature vector Φx(x, Yi)

Φx(x, Yi) · α2

where α2 is the global parameter vector. The ﬁnal output
of the model is Yi∗ , for i∗ = arg maxi Φx(x, Yi) · α2.

5.2 Training the Model
We are given a training corpus with text-database pairs (L, R)
and alignments A ⊆ L × R.

Training for Step One For the label ranking model
Φx,y(x, y) · α1, the scores returned by a classiﬁer or
ranking model may be used. Standard training tech-
niques can be applied to learn this model. In fact, we
employed an SVM classiﬁer with a quadratic kernel as
it yielded the best results for our task.

Training for Step Two The global model Φx(x, Yi) · α2
is trained using the label ranking returned by the local
model. For each sentence x ∈ L it considers all en-
try sets Y0, ..., Yn formed by varying the cut-off point of
the initial ranking. However, the true alignment may not
be among these sets: the ranking may have incorrectly
placed an unaligned entry above an aligned entry, in ef-
fect pruning away the true target. Therefore, to identify
a new target alignment set Yi∗ , we need to identify the
closest remaining entry set.
As our similarity metric between two sets A and B, we
use the Hamming distance H(A, B) (deﬁned as the car-
dinality of the symmetric difference of A and B). For
each input (L, R), and each sentence x ∈ L, we identify
the cut-off in the ranking which produces the entry set
closest in Hamming distance to the true label set T :

i∗ = arg min

i

H(Yi, T )

This process of identifying a training target for the
global model is illustrated in Table 1.
Once all the training targets in the corpus have been
identiﬁed through this procedure,
linear
model is learned using a variant of the Perceptron
algorithm [Collins and Duffy, 2002]. This algorithm
encourages a setting of the parameter vector α2 that
will assign the highest score to the global feature vector
associated with the optimal cut-off i∗.

the global

α2 ← 0
For each (L, R) and each sentence x ∈ L:

imax ← arg maxi Φx(x, Yi) · α2
if imax (cid:4)= i∗, set:

α2 ← α2 + Φx(x, Yi∗ )
α2 ← α2 − Φx(x, Yimax )

← Φx(x, {})

H = 2
y1 ← Φx(x, {y1})
H = 3
y2 ← Φx(x, {y1, y2})
H = 2
y3 ← ∗ Φx(x, {y1, y2, y3})
H = 1
y4 ← Φx(x, {y1, y2, y3, y4}) H = 2

-
+
+
-

Table 1: To select the training target for the global model, we
select the cut-off i∗ which minimizes the Hamming distance
H to the true label set. “+” and “-” indicate whether a label is
in the true label set or not. In this example, i∗ = 3, since the
set {y1, y2, y3} has the minimum Hamming distance.

6 Features

In this section we describe local and global features used by
our model.

Local Features

We assume that a high overlap in names and numbers in-
creases the likelihood that a given sentence-entry pair is
aligned. Thus, our local alignment is driven by anchor-based
matching. A feature vector generated for each sentence-entry
pair captures various statistics about name and number over-
lap. To further reﬁne the matching process, these features
also represent the unigrams and bigrams surrounding each
matched name and number. In addition, the feature vector
includes the type of database entry as certain entry types (i.e.,
scoring summary) are more commonly verbalized in text.
Close to 60,000 local features are generated. See Table 2 for
a list of local feature templates.

Global Features

Our global model jointly considers a sentence with an entire
set of candidate entries, seeking alignments with favorable
structural properties. We select global features that express
these properties, thereby allowing our model to correct local
decisions. Two simple global features that we used are the
number of aligned entries and the Hamming distance between
aligned entries and the set predicted by a local model. We can
group the remaining global features into three classes based
on the type of dependency they capture:

• Co-occurrence of entry types A simple analysis of the
aligned corpus reveals that certain entry types tend to
be aligned together to the same sentence. For instance,
entries from the play-by-play table are often verbalized
together with entries from the scoring-summary table.
To model this property, we introduce features for each
commonly occurring set of entry types. These features
parallel the label-pair co-occurrences modeled in Gham-
rawi and McCallum [2005], but are not limited to pairs.
• Local match overlap A common error of local align-
ments is overmatching. A number that appears once
in a sentence may be erroneously matched to multiple
database entries during local alignment. For instance,
consider the example in Figure 2: the number 4 in the
sentence causes an overmatch with two database entries
that contain this number. By examining the entire set

IJCAI-07

1716

NAME MATCH=(name category in entry) LEX=(bigrams)
NUM MATCH=(num category in entry) LEX=(bigrams)
ENTRY TYPE=(entry type)
COUNT NUM MATCHES=(count of num matches)
COUNT NAME MATCHES=(count of name matches)
%NUMS=(percent of nums in entry matched)
%NAMES=(percent of names in entry matched)

Table 2: Local feature templates. Text enclosed by brackets
is replaced as appropriate. Also, various backoffs are used,
such as using unigrams or no lexicalization at all in the ﬁrst
two features.

COUNT=(number of entries in set)
DIFF=(hamming distance to local prediction)
ENTRY TYPES=(combination of entry types)
PLAYS ALONE=(plays w/o corresponding scores)
SCORES ALONE=(scores w/o corresponding plays)
PAIRS=(corresponding play/score pairs)
MATCHED DRIVE=(drive with its plays or score)
UNMATCHED DRIVE=(drive with other plays or scores)
MATCHED1 ENTRIES=(# entries matched by num)
MATCHED2 ENTRIES=(# entries matched by name)
SHARE1 ENTRIES=(# entries sharing nums)
SHARE2 ENTRIES=(# entries sharing name)
UNMATCHED1 ENTRIES=(# entries unmatched by num)
UNMATCHED2 ENTRIES=(# entries unmatched by name)
MATCHED NUMS=(# of matched nums in sentence)
SHARED NUMS=(# of shared nums in sentence)
MATCHED NAMES=(# of matched names in sentence)
SHARED NAMES=(# of shared names in sentence)

Table 3: Global feature templates.

of proposed entries simultaneously, we can separately
count the entries that match distinct sentence anchors as
well as those that share anchors. The latter number indi-
cates the degree of overmatching and our model should
learn to discourage such erroneous alignments.

• Domain-speciﬁc semantic constraints Besides these
generic global features, we further reﬁne the alignments
using the database semantics deﬁned by its schema. We
can express a semantic relation between entries by ana-
lyzing their structural links in the database. For exam-
ple, when summarizing the result of a drive, any play
that occurred during the drive is likely to be mentioned
as well. While the type co-occurrence feature described
above would capture the correlation between these two
entry types, it would fail to distinguish this case from
semantically unrelated drives and plays. We engineered
several domain-speciﬁc features of this variety.

Overall, 247 global features were generated. See Table 3

for a complete list of the global feature templates.

SVM baseline
Multilabel Global
Threshold Oracle
Multilabel Regression
Graph Matching

F-measure

Precision
Recall
84.33% 70.67%
76.90%
87.26% 74.48% 80.31%
89.75%
94.13% 85.76%
70.21%
77.65% 64.08%
73.36% 64.47%
68.63%

Table 4: 10-fold cross validation results for the baseline, our
global multilabel model, an oracle, and two other approaches.

7 Evaluation Setup
Corpus For our evaluation, we used the NFL football corpus
previously used by Barzilay and Lapata [2005]. This corpus
contains text-database pairs for 466 football games played
over the 2003 and 2004 seasons. The database contains a
wealth of statistics describing the performance of individual
players and their teams. It includes a scoring summary and
a play-by-play summary giving details of the most important
events in the game together with temporal (i.e., time remain-
ing) and positional (i.e., location in the ﬁeld) information.
This information is organized into several table types includ-
ing aggregate statistics, scoring summary, team comparison,
drivechart, and playbyplay. Each game is typically repre-
sented by 330 database entries. The accompanying texts are
written by Associated Press journalists and typically contain
50 sentences.

Annotation In order to train and evaluate our model, we
had a human annotator explicitly mark the linked sentence-
entry pairs for a set of 78 games. We also conducted a human
interannotator agreement study on a smaller set of 10 games.
We compute a Kappa statistic over the chance of agreement
for both positive and negative alignment decisions. We found
high agreement between annotators, yielding a Kappa score
of 0.73.

On average, 24 sentence-entry pairs (out of 330 × 50) are
aligned per game. These alignments include about 6% of all
database entries and about 28% of all sentences. Most aligned
sentences are aligned to more than one database entry.

Training and Testing Regime From 78 manually anno-
tated texts, we obtain about 1,250,000 entry-sentence pairs,
from which 1,900 represent positive alignments. Given the
relatively low number of positive examples, we opted to use
10-way cross validation for training and testing our algo-
rithm. We compute precision and recall using aligned pairs
as positive examples and unaligned pairs as negative exam-
ples.

8 Results
The results of the evaluation are shown in Table 4. We ﬁrst
compare our global model to a local classiﬁer. This base-
line model makes independent alignment decisions for each
sentence-entry pair and is implemented using an SVM classi-
ﬁer with a quadratic kernel. The local features used are those
described in Section 6. Our method achieves a 3.4% absolute
reduction in error which corresponds to a 15% relative re-
duction in error. The global model predicts a different align-
ment for 239 out of 3,732 sentences in the corpus. Of these
changes, 170 are improvements over the local model, while in

IJCAI-07

1717

tion. In contrast to existing multilabel classiﬁers, our method
operates over arbitrary global features of inputs and proposed
labels. Our empirical results show that this model yields su-
perior performance without sacriﬁcing tractability.

Acknowledgments

The authors acknowledge the support of the National Science Foun-
dation (Barzilay; CAREER grant IIS-0448168 and grant IIS-
0415865). Thanks to Eli Barzilay, Michael Collins, Pawan Desh-
pande, Yoong Keok Lee, Igor Malioutov, and the anonymous re-
viewers for helpful comments and suggestions. Any opinions, ﬁnd-
ings, and conclusions or recommendations expressed above are
those of the authors and do not necessarily reﬂect the views of the
NSF.

References
[Barzilay and Lapata, 2005] Regina Barzilay and Mirella
Lapata. Collective content selection for concept-to-text
generation. In Proceedings of HLT/EMNLP, pages 331–
338, Vancouver, 2005.

[Brown et al., 1993] Peter F. Brown, Stephen Della Pietra,
Vincent Della Pietra, and Robert Mercer. The mathematics
of statistical machine translation: Parameter estimation.
Computational Linguistics, 19(2):263–311, 1993.

[Collins and Duffy, 2002] Michael Collins and Nigel Duffy.
New ranking algorithms for parsing and tagging: Kernels
over discrete structures, and the voted perceptron. In Pro-
ceedings of the ACL, 2002.

[Collins and Koo, 2005] Michael Collins and Terry Koo.
Discriminative reranking for natural language parsing.
Computational Linguistics, 31(1):25–69, 2005.

[Crammer and Singer, 2002] Koby Crammer and Yoram
Singer. A new family of online algorithms for category
ranking. In Proceedings of SIGIR, pages 151–158, 2002.
[Elisseeff and Weston, 2001] Andre Elisseeff and Jason We-
ston. A kernel method for multi-labelled classiﬁcation. In
Proceeding of NIPS, pages 681–687, 2001.

[Ghamrawi and McCallum, 2005] Nadia Ghamrawi and An-
drew McCallum. Collective multi-label classiﬁcation. In
Proceedings of CIKM, pages 195–200, 2005.

[Lacoste-Julien et al., 2006] Simon Lacoste-Julien, Ben
Taskar, Dan Klein, and Michael Jordan. Word alignment
via quadratic assignment. In Proceedings of HLT/NAACL,
2006.

[McDonald et al., 2005] Ryan McDonald, Koby Crammer,
and Fernando Pereira. Flexible text segmentation with
structured multilabel classiﬁcation.
In Proceedings of
HLT/EMNLP, pages 987–994, 2005.

[Schapire and Singer, 1999] Robert E. Schapire and Yoram
Singer. Improved boosting using conﬁdence-rated predic-
tions. Machine Learning, 37(3):297–336, 1999.

[Taskar et al., 2005] Ben Taskar, Simon Lacoste-Julien, and
Dan Klein. A discriminative matching. approach to word
alignment. In Proceedings of HLT/EMNLP, pages 73–80,
2005.

Figure 2: The top three ranked entries for the given sen-
tence. The local model erroneously aligns the top two due
to the matched “4”, but the global model corrects this over-
matching.

the other 69 cases the accuracy goes down. By a sign test, this
difference is statistically signiﬁcant at the level of p < 0.01.
Figure 2 shows an example where global features correct the
erroneous decisions of the local alignment.

We also present the performance obtained when an oracle
chooses the optimal cut-off of the possibly ﬂawed local la-
bel ranking. The performance of the oracle compared to our
global model indicates that we can further improve alignment
by either reﬁning our search of the global space or by consid-
ering more powerful global features.

We also compare our model against a standard multilabel
classiﬁer [Elisseeff and Weston, 2001]. Like our model, this
method ﬁrst ranks the labels by their local scores, but then
applies regression on these scores to determine an optimal
threshold. This approach fails to outperform the SVM base-
line.

Finally, we compare against the global alignment model of
Taskar et al. [2005]. This model was developed for the task
of word alignment, and attempts to maximize the local scores
of the aligned word pairs subject to a fertility constraint. The
best results we have obtained for this model are lower than the
quadratic kernel SVM baseline. We used fertility constraints
that allowed database entries to match up to three times and
sentences to match up to ﬁve times. While we attempted to
ﬁnd the best settings for these and other parameter values, we
cannot guarantee that the values selected are fully optimal,
as our application is quite different from the model’s original
setting.

9 Conclusions

This paper introduces a novel algorithm for aligning database
entries to the sentences that verbalize their content. We cast
text-database alignment as structured multilabel classiﬁca-

IJCAI-07

1718

