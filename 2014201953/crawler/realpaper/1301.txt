MECHANISM  OF  DEDUCTION 
A  QUESTION  ANSWERING  SYSTEM 
W I TH  N A T U R AL  LANGUAGE 
INPUT 

IN 

Makoto  Nagao  and  Jun-ichi  T s u j ii 
Kyoto  U n i v e r s i t y,  Dept.  Elec.  Eng. 
Kyoto,  Japan 

ABSTRACT 

We  have  constructed  a  deductive  question  answer(cid:173)

ing  system  which  accepts  natural  language  input  in 
Japanese. 
The  semantic  trees  of  aseertional  input 
sentences  are  stored  in  a  semantic  network  and  i n t e r(cid:173)
relationships  — c o n d i t i o n a l,  i m p l i c a t i o n a l,  and  so 
f o r t h—  are  established  among  them. 
A  matching  r o u t(cid:173)
ine  looks  for  the  semantic  trees  which  have  some  r e l a(cid:173)
tions  to  a  query,  and  returns  the  mismatch  information 
(difference) 
routine  produces  sub-goals  to  diminish  t h is  difference. 
This  process 
takes  place  recursively  u n t il  the  d i f f e r(cid:173)
ence  is  completely  resolved  (success),  or  there  is  no 
other  p o s s i b i l i ty  of  matching  in  the  semantic  network 
( f a i l u r e ). 
Standard  problem  solving  techniques  are 
As  the  result  the  system  is 
used  in  t h is  process. 
very  powerful  in  handling  deductive  responses. 
In 
t h is  paper  only  the  part  of  the  l o g i c al  deduction  is 
explained  in  d e t a i l. 

to  a  deduction  r o u t i n e. 

The  deduction 

DESCRIPTIVE  TERNS:  question  answering,  deduction, 
natural  language,  semantic  network,  problem  solving. 

I 

INTRODUCTION 

There  are  a  few  deductive  question  answering  systems 
using  natural  language,  almost  a ll  of  which  use  l o g i c al 
expressions,  especially  the 
culus  expression,  as  an  intermediate  language. 
ever  systems  which  use  formal  logics  have  problems: 
(1)  Syntactic  and  semantic  analyses  of  natural  language 
input  are  necessary  to  transform  the  input  to  l o g i(cid:173)
cal  expression  without  ambiguity. 

f i r st  order  predicate  c a l(cid:173)
How(cid:173)

(2)  The  axiom  set  must  be  clearly  defined  and  must  not 

be  contradictory. 

(5)  Predicates  and  variables  must  be  fixed  beforehand. 

This  is  a  problem  for  the  system's  expansion. 
Also  t h is  prevents  mixing  the 
f i r st  and  higher 
order  predicate  calculus  systems. 

(4)  Deduction  using  the  resolution  principle 

is  cumber(cid:173)
Usually  question  answering  does  not  require 

some. 
a  deep  deductive  process. 

(5)  Good  q u a l i ty  of  natural  language  output  is  very  . 

hard  to  obtain  from  a  l o g i c al  expression. 

To  avoid  the  above  problems  we  have  used  a  kind  of 

Session  10  Natural  Language:  Systems 

semantic  representation  of  natural 
as  an  intermediate  expression. 
following  characteristic 
(1)  The  question  answering  system  is  a  composite  of  sub(cid:173)
systems  for  language  analysis,  deduction,  and  lang(cid:173)
uage  generation. 

language  sentences 

pur  systern  has  the 

features. 

(2)  The  parsed  trees  of  sentences  are  permitted  to  have 
Ambiguities  are  resolved  in  the 

some  ambiguities. 
process  of  l o g i c al  deduction, 

(3)  During  the  question  answering  process, 

the  deduction 

a b i l i ty  is  increased  and  the  area  which  the  system 
can  deal  with  is  also  expanded. 
a b i l i ty  of  a  system  depends  on  how  many  theorems 
the  system  can  use,  and  on  how  e f f i c i e n t ly  it  can 
deal  with  them.  We  have  constructed  a  system  in 
which  the  available  theorems  increase  during  the 
question  answering  process. 

The  deduction 

(4)  Facts  can  play  the  role  of  theorems.  We  think  the 
d i s t i n c t i on  between  facts  and  theorems  is  not  clear 
enough. 
one  time  and  as  a  fact  at  another  time. 
example, 

A  statement  can  be  used  as  a  theorem  at 

For 

A  human  is  an  i n t e l l i g e nt  animal, 

plays  the  role  of  a  theorem  to  answer 

Is  Smith  i n t e l l i g e nt  ? 

because  Smith  is  an  instance  of  a  variable 
On  the  contrary  it  plays  the  role  of  a  fact  to  the 
question 

'human'. 

Is  a  man  an  animal  ? 

'a  human' 
'man'. 

is  treated  as  an  instance  of  a 

because 
variable 
In  our  system  the  assertions  given  by  a  user,  which 
correspond  to  facts  in  usual  systems,  can  play  the 
role  of  theorems. 
a  higher  concept  term  to  be  a  variable 
concept  term. 
There  is  no  d i s t i n c t i on  between 
them,  and  both  facts  and  theorems  have  the  same 
structures  in  the  data  base. 
This  is  the  most 
s i g n i f i c a nt  character  of  the  system  we  have  develop(cid:173)
ed. 

This  is  accomplished  by  allowing 

to  i ts  lower 

(5)  In  order  to  deal  with  a  large  data  base, 

the  system 

has  a  well  organized  data  structure  and  relevant 
information  to  a  question  is  accessed  by  a  t e c h n i(cid:173)
que  of  indexing  and  r e t r i e v a l, 

(6)  The  deduction  process  is  similar  to  that  of  humans. 

It  allows  introducing  many  heuristics  i n to  the 
deduction  process. 

In  t h is  paper  the  d e t a i ls  of  deduction  subsystem  alone 
are  explained. 
published  elsewhere  in  the  near 

The  other  two  subsystems  w i ll  be 

future, 

II  SYSTEM  ORGANIZATION 

A  block  diagram  of  our  system  is  shown  in  F i g.  1. 

The  internal  data  base  of  the  system  is  divided  i n to 
two  parts: 
( 1;  semantic  representations  (semantic 

trees)  of  input 

sentences. 

2S5 

(2)  network  (mutual  connection)  of  ( 1 ). 
The  mutual  connection  consists  of  i n t e r r e l a t i o n s h i ps 
such  as  c o n d i t i o n a l,  i m p l i c a t i o n a l,  and  so  f o r t h. 
input  sentence 
is  read  i n to 
and  is  not  in  the  network  y e t. 
lates  in  a  very  natural  way  in  the  question  answering 
process. 
An  inverted  f i le  of  keywords  makes  it  easy 
to  extract  information  relevant  to  the  question. 

An 
t r e e,  and  it 
the  semantic  network  if  it  is  an  assertion 
Thus  knowledge  accumu-

is  analyzed  i n to  a  semantic 

The  parsing  routine  performs  syntactic  and  seman(cid:173)
t ic  analyses  of  an  input  query  sentence,  and  produces 
the  parse  t r e e. 
accepts  the 
which  contains  sentences  already  accepted. 

tree  and  r e l a t es  it  to  the  semantic  network 

A  network  administration  routine 

To  accomplish  a  deduction,  there  are  two  main 

parts: 
the  execution  routine  and  the  deduction  r o u t i n e. 
The  execution  r o u t i n e,  which  plays  the  central  role  in 
the  deduction  process,  searches  through  the  network  for 
sentences  relevant  to  the  current  goal  and  matches  them 
one  by  one  against  i t. 
The  deduction  routine  manages 
the  global  information  in  the  problem  solving  process 
such  as  goal-subgoal  relationships,  variable  bindings 
( f or  example 
•Smith'),  and  so  f o r t h. 
execution  routine  to  determine  which  sentence  must  be 
v e r i f i ed 

This  routine  also  directs  the 

is  bound  to  the  word 

the  word 

f i r s t. 

'man' 

IIl  KNOWLEDGE  STRUCTURE 

3.1  Semantic  Trees. 

We  have  applied  a  kind  of  dependency  analysis  to 
the  input  Japanese  sentences. 
A  noun  modified  by  an 
adjective  is  transformed  i n to  a  kernel  sentence  having 
another  kernel  sentence  related  to  the  noun. 
sentence 

The 

KINBEN MA WITO WA SEIKO SURU 
(  A  d i l i g e nt  man  w i ll  succeed.) 

is  divided  i n to  two  sentences  l i ke 

HITO WA SEIKO SURU 
(  A  man  w i ll  Bucceed.) 

and 

HITO WA KINBEN DA 
(  A  man  is  d i l i g e n t .) 

The  parsed  tree  stfueture  of  t h is  sentence  is  shown  in 
Fig. 2. 

Some  sentences  in  Japanese  have  two  possible  sub(cid:173)
that  i s,  one  which  contains  the  reference 

j e ct  phrases, 
p a r t i c le  'GA'  and  the  other  which  contains  'WA*.  We 
consider  the  r e l a t i o n al  phrase  w i th  the  p a r t i c le 
i n d i c a t i ng  what  the  sentence  t a l ks  about; 
with 
predicate  in  the  sentence. 

the  phrase 
is  the  subject  phrase  corresponding  to  the 

'GA' 

'WA'  as 

ZO  WA HANA  GA  NAGAI 
(  Elephant  has  a  long  nose.) 

is  a  t y p i c al  example. 
I ts  l i t e r al 
"  As  for  elephant  the  nose  is  l o n g ." 
ture  of  it 

is  shown  in  F i g,  3. 

t r a n s l a t i on  is 

The  tree  s t r u c(cid:173)

the 

Sentences  connected  by  AND  or  OK  are  represented  in 
tree  structure  as  shown  in  F i g.  4. 
A  sentence  which  contains  upper  concept  terms 

replaceable  by  t h e ir  lower  concept 
terms  is  considered 
as  a  theorem  available  to  prove  a  statement  which  has 
the  lower  concept  terms  in  i t. 
So  upper-lower  concept 
r e l a t i o n s h ip  among  words  plays  an  important  role  in  our 
system. 
meaning  A  is  a  lower  concept  of  B,  and  B  is  an  upper 
concept  of  A,  has  a  special  structure 
to  express  the 
"  NINGEN  WA  KASHIKOI  DOBUTSU  DA" 
r e l a t i o n s h ip  c l e a r l y. 
(  A  man  is  an  i n t e l l i g e nt  animal.)  is  parsed  as  shown  in 
F i g.  5. 

The  input  sentence  in  the  form  of  "  A  WA  B  DA" 

Properties  of  sentences  are  attached  to  the  top 

node  of  the  parsed  tree  s t r u c t u r e. 
treated  are  p o t e n t i a l,  a c t i v e,  passive,  subjenctive, 
tense,  and  so  f o r t h. 
ed  as  true,  so  that  a  sign  T  is  given  to  the  property 
part  of  the  parsed  t r e e. 
property  part  indicate 
i v e l y. 

The  signs  F  and  U  in  the 

false  and  undetermined  respect(cid:173)

The  assertion  sentence  is  regard(cid:173)

The  properties  we 

3.2  Semantic  Network. 

The  network  is  constructed  in  the 
In  the  case  of  an  assertion  sentence  S„, 
1'. 
ed  in  the 

form  shown  in  F i g.  6a. 

following  way. 

it  is  s t o r(cid:173)

(1) 

286 

{1)  Branches  in  the  network  and  trees  are  b i - d i r e c t i o n(cid:173)

for 

al 
search  in  the  deduction  process. 

transformation  and 

f l e x i b le 

f or  e f f i c i e nt 

(2)  Words  are  not  stored  in  nodes  of  the  parsed  trees 
but  by  a  pointer  to  the  l e x i c al  entry  of  the  word 
( F i g.  7 ). 

( 3)  The 

l e x i c al  e n t ry  of  a  w o r d,  c a l l ed  NLIST,  c o n t a i ns 

n ot  o n ly 
a l so  a 
of 
NLIST 

l e x i c al 

l i st  of  sentences 

i n f o r m a t i on  about 
( p o i n t e rs 

the  w o r d,  b ut 
the  e n t r i es 
to 

the  sentences 

in  SLIST)  which  c o n t a i ns 

t he  w o r d. 

is  a  k i nd  of 

f i le  of  keywords. 

CO  The  node  of 

the  network 

i n d i c a t ed  by  a  p o i n t er 

t a b l e,  c a l l ed  SLIST,  which  c o n t a i ns  i n f o r m a(cid:173)

i n v e r t ed 
is 

from  a 
t i on  about 
whether 
d e t e r m i n ed 

the  sentence 

the  s e n t e n c e. 
is 
( U ),  and  so 

(5)  D i f f e r e nt  nodes 

in 

The 

i n f o r m a t i on  of 

t r ue 
f o r th 

( P ),  or  u n(cid:173)
in 
l i s t. 
the  network  correspond 

( T ), 
f a l se 
is  s t o r ed 

t h is 
to  d i f(cid:173)

f e r e nt  s e n t e n c e s. 
a  sentence  can  be  r e t r i e v ed 
the  n e t w o r k. 

As  a  r e s u l t, 

i n f o r m a t i on  about 
in 

from  a  s i n g le  node 

IV  EXECUTION  ROUTINE 

' t he 

T h is 

is  r e a l i z ed  by 

t h is  s t u dy 
"the 

the  d e d u c t i on  r o u t i n e. 

law  of  s u b s t i t u t i o n'  and 

in 
the  use  of 
i m p l i c a t i o n .' 

Among  many  i n t e l l e c t u al  a b i l i t i es  of  humans,  we 
the  d e d u c t i on  a b i l i ty 
implemented 

have 
baaed  on 
law  of 
r o u t i ne  and 
r o u t i ne 
t r i es 
a n o t h er  one, 
l o w er  c o n c e p t s. 
over 
duces  subgoals  and 
t e l ls 
sentence  must  be  v e r i f i ed 
searches 
are  e q u i v a l e nt 
t i on  r o u t i n e. 
s e a r c h,  m a t c h i n g,  and  r e s o l v i ng  d i f f e r e n c e s. 

The  e x e c u t i on 
to  match  a  sentence  s t r u c t u re  a g a i n st 
r e g a r d i ng  an  upper  concept  as  a  v a r i a b le 
The  d e d u c t i on  r o u t i ne  p r o(cid:173)
the  e x e c u t i on  r o u t i ne  which 
f i r s t. 
f or 

the  network 
the  g o al  sentence  g i v en  by 

the  sentences  which 

t h r o u gh 
to 

It  c o n s i s ts  of 

i ts 

the  deduc(cid:173)

t h r ee  main  p a r t s:  keyword 

The  e x e c u t i on  r o u t i ne 

the  e x e c u t i on 

4.1  Keyword  S e a r c h. 

The  system  has  an  i n v e r t ed 

f i le  of  words  c a l l ed 

By  u s i ng 

t h is 

f i l e, 

the  e x e c u t i on  r o u t i ne 

t a k es 

the  sentences  which  c o n t a in  words 

in 

the  g o al  s e n t(cid:173)

These  s e l e c t ed  sentences  a re  presumed  to  be 
to 

the  c u r r e nt  s e n t e n c e. 

NLIST. 
out 
e n c e. 
r e l e v a nt 

(2)  In  the  case  of  a  negation  sentence,  schematically 
form 
w r i t t en  as 
ae  F i g.  6a,  but  the  property  part  is  w r i t t en  as  F. 

it  is  stored  in  the  same 

'not  S2 

(3)  If  a  sentence  is  - If  s1, 

in  the 

form  shown  in  F i g.  6b. 

then  S 

. ', 

it  is  stored 

(4)  If  a  sentence 

is 

'Because  S1,  S2. 

it 

is  stored 

in  the 

form  shown  in  F i g.  6c. 

(5)  If  the  sentences  S1  and  S2  in  <1)--(4)  are 

found  in 

they  are  not  stored  newly, 
the  semantic  network, 
but  the  stored  ones  are  used. 
For  example  the 
following  sentences  are  stored  in  the  network  as 
shown  in  F i g.  6d. 

Because  S1,  S2. 
then  S3. 
If  S1, 

In  t h is  case  because  S1  is  asserted  as  t r u e,  S3  is  also 
t r u e. 

5 

The  network  and  parsed  trees  have  the 

i n t e r n al  constructions. 

following 

287 

4.2  Hatching  Method 

The  matching  algorithm  is  constructed  so  that  two 

parsed  trees  which  are  d i f f e r e nt  in  the  sequence  of 
branches  <Fig.  8)  w i ll  be  matched  successfully  by  the 
branch  labels  on  the  parsed  trees.  Matching  between 
two  parsed  trees  f a i ls  for  various  reasons. 
causes  of  mismatch,  named  differences,  are  c l a s s i f i ed 
i n to  the 
(1)  N-difference:  The  words  which  are  attached  to  the 
corresponding  node  are  d i f f e r e nt  in  the  two  sent(cid:173)
ences. 
F i g.  9a  shows  an  example,  where  the  d i f(cid:173)
ference  is  expressed  as  (N  (*C  * D ) ). 
pointer  to  the  node  C. 

following  four  classes. 

The 

(2)  S1-differenee:  One  structure  ( f i r st  argument)  has 

extra  branches  which  the  other  does  not  have. 
F i g.  9b  shows  an  example  of  t h is  category,  abbre(cid:173)
viated  as  CS1  ((*R4)  - B ) ),  which  shows  the  branch 
R4 is  the  extra  one. 

*C  shows  the 

(3)  S2-difference:  One  structure  (second  argument)  has 

extra  branches. 
difference  is  shown  by  (s2  (*C  (*R5))). 

F i g.  9c  is  an  example  and  t h is 

(4)  SO-difference:  Both  structures  have  extra  branches. 

An  example  is  shown  is  F i g.  9d. 
The  matching  subroutine 
t r i es 

argument  against  i ts  second  one. 
succeeds, 
the  subroutine  returns 
uction  r o u t i n e. 

If  not, 

it  returns 

to  match  i ts 
If  the  matching 

f i r st 

'success' 

to  the  ded(cid:173)

the  differences. 

(N  CC  'D)) 

(S1  ((•R4) 

'B)) 

286 

F i g.  11  is  an  example. 
the 
two  structures,  S-structure  and  T-structure,  are  equi(cid:173)
valent  and  the  difference  is  resolved. 

If  the  matching  succeeds, 

V  DEDUCTION  ROUTINE 

The  deduction  routine  controls  the  whole  of  the 
This  routine  has  a  global  know(cid:173)
This  knowledge  contains  the 

deduction  process. 
ledge  of  the  process. 
goal-subgoal  organization,  variable  binding  and  so  f o r t h, 
The  deduction  routine 
sentence  must  be  v e r i f i ed  and  which  sentence, 
f i r st  t r i al 

t e l ls  the  execution  routine  which 

f a i l s,  has  to  be  v e r i f i ed  next. 

if  the 

5.1  Goal  Organization 

The  deduction  method  in  our  system  takes  a  ques(cid:173)

t r i al 

f a i l s, 

the  deduction  routine  searches 

the  sentences  stored  in  the  network. 

t i on  Q  as  a  .goal  and  t r i es  to  v e r i fy  it  by  means  of 
matching  it  with 
If  the 
through  the  network  for  such  sentences  as  P-*Q. 
Those  sentences  P's, 
to  accomplish  the  previous  goal. 
In  the  same  manner 
sub-subgoals  are  produced  to  accomplish  the  subgoals. 
As  the  process  advances,  many  goals  are  produced  h i e r(cid:173)
a r c h i c a l l y. 
remember  the  h i e r a r c h i c a l ly  organized  relationships 
among  goals. 

An  AND-OR  tree  structure  is  used  to 

if  any,  are  considered  as  subgoals 

Subgoals  are  created  in  various  cases. 

(1)  If  a  goal  sentence  G  can  not  be  determined  to  be 
true  or  f a l s e,  subgoals  are  created  by  means  of 
searching  through  the  network  for  the  sentences 
which  are  antecedents  of  G. 

(2)  In  the  same  case  of  (1), 

the  negations  of  conseque(cid:173)

nces  of  G  are  taken  as  subgoals. 
proved  to  be  true, 
be  f a l s e. 

the  sentence  G  is  determined  to 

If  they  are 

(3)  If  the  matching  between  two  parsed  trees  is  i n(cid:173)

complete,  subgoals  to  diminish  the  mismatches  are 
created. 
In  addition  to 

these  cases,  subgoals  are  also 

produced  when  a  goal  is  divided  i n to  several  subgoals. 
For  example  'KARE  WA  KINBEN  DE  SHOJIKI  DA'  (He  is 
d i l i g e nt  and  honest)  is  divided  i n to  'KARE  WA  KINBEN 
DA'  (He  is  d i l i g e n t ),  and  'KARE  WA  SHOJIKI  DA'  (He  is 
honest). 

The  goals  are  t r i ed  one  by  one,  and  when  there 
the  deduction  process  stops  with  a 

remains  no  goal, 
f a i l u re  message. 
A  goal  which  has  several  subgoals 
w i ll  succeed  or  not,  depending  upon  whether  the  sub-
goals  w i ll  succeed  or  not. 
A  goal  keeps  some  i n f o r(cid:173)
the  information 
mation 
of  whether  it  is  an  AND-type  or  an  OR-type. 
Depth  of 
goal  shows  the  depth  between  the  top-goal  (that  i s,  a 
question  given  by  a  user)  and  the  present  goal. 
The 
top-goal  is  0  and  the  depth  of  the  immed(cid:173)
depth  of  the 
iate  subgoal 
is  1. 

For  example 

for  i t s e l f. 

it  has 

The  indicators  such  as 

The  deduction  routine  chooses  a  goal, 

the  depth 
of  which  is  the  smallest  of  a l l,  and  t e l ls  the  execu(cid:173)
tion  routine  to  v e r i fy  i t. 
KOTEI  (positive  assertion),  HITEI  (negative  assertion), 
MATCH  (to  be  matched)  and  so  f o r th  show  the  effects  of 
the  goals'  r e s u l ts  to  be  transferred  to  t h e ir  previous 
goals. 
the  sentence  corresponding  to  i ts  previous  goal  is 
proved  to  be  true  ( f a l s e ). 
produced  in  order  to  resolve  the  mismatch  between  two 
parsed  trees  have  the  indicator  MATCH. 

KOTEI  (HITEI)  shows  that  if  t h is  goal  succeeds, 

The  subgoals  which  are 

5.2  Variable  Binding. 

To  use  the  law  of  s u b s t i t u t i on  is  one  of  most 

important  a b i l i t i es  in  t h is  system. 
out  by  considering  an  upper  concept  as  a  variable  over 
i ts  lower  concepts. 
it  is  a  lower  concept  of  another  word,  and  as  a  v a r i(cid:173)
able  when  it  is  an  upper  concept  of  another  word. 
We  do  not  introduce  unary  predicates  such  as'human(x)', 

A  word  behaves  as  a  constant  when 

This  is  carried 

289 

' a n l m a l ( x ) ',  which  are  usually  used  in  the  predicate 
calculus  system  in  order  to  r e s t r i ct  the  range  of  v a r i(cid:173)
ables. 

We  regard  a ll  words  as  variables  which  have  t h e ir 

own  domains  of  values.  We  i l l u s t r a te  t h is  by  the 
following  example. 
(1)  HITO  GA  KENKO  NARA-BA  HITO  WA  SEIKO  SURU 
the  man  w i ll  succeed.) 

( If  a  man  is  healthy, 

(Q)  Smith  WA  SEIKO  SURU  KA  ? 

(Will  Smith  succeed  ?) 

f i r s t. 

The  system  searches  through  the  network  to  find  out  the 
sentence  (1)  which  is  expected  to  answer  the  given  ques(cid:173)
The  matching  between  the  consequent  part  of  (1) 
t i o n. 
and  the  question  f a i ls  at 
The  cause  of  mismatch 
is  N  difference  between  'Smith*  and  'HITO  (man)'. 
routine  is  called  to  find  out  that  HITO  is  an  upper 
concept  of  Smith,  which  is  proved  by  the  information 
'Smith  is  a  man.' 
in  the  network. 
Thus  a  subgoal,  the 
antecedent  of  (1), 
in  which  HITO  is  replaced  by  Smith  is 
produced, 
that  i s, 
'Is  Smith  healthy  ? '. 
As  the  deduc(cid:173)
t i on  process  proceeds,  several  such  bind  conditions  are 
produced. 
deration  the  related  bind  conditions  produced  during  the 
former  process. 

Each  goal  must  be  t r i ed  taking  i n to  consi(cid:173)

N 

The  deduction  routine  has  a  stack  to  remember  these 

This  stack  is  i l l u s t r a t ed  in  F i g,  10. 

conditions. 
Each  goal  has  a  pointer  to  t h is  stack  and  the  routine 
can  retrieve 
If  a  goal 
during  the  t r i al  of  the  goal  is  abandoned. 
other  hand  if  a  goal  succeeds, 
ed  for  use  in  the  succeeding  process. 

then  the  bind  condition  generated 
On  the 

the  corresponding  bind  condition  of  a  goal. 

i ts  condition  is  memoriz(cid:173)

f a i l s, 

VI  COMPARISON  WITH  THE  SYSTEMS  USING  PREDICATE  CALCULUS 

formulas. 

In  those  systems 

formula,  store  it 

Those  systems  which  use  predicate  calculus  translate 
input  i n to  a  predicate  calculus 

the 
in  the  data  base,  and  use  a  universal  method  of  deduct(cid:173)
ion  such  as  the  resolution  method. 
common  subexpressions  appearing  in  d i f f e r e nt  sentences 
are  stored  as  many  times  as  they  appear  in  d i f f e r e nt 
l o g i c al 
system  the  same  subexpressions  are  stored  only  once  and 
t h e ir  r e l a t i o ns  to  the  other  parts  of  sentences  are 
stored  by  l i n k s. 
u t i l i z ed  in  the  deduction  process. 
system  deals  with  a  great  amount  of  data  and  only  a 
r e l a t i v e ly  small  portion  of  the  data  has  a  direct  r e l a t(cid:173)
ion  to  the  given  question, 
the  quick  access  to  these  r e(cid:173)
lated  expressions  is  very  important 
process. 

So  these  i n t e r r e l a t i o n s h i ps  can  be 

This  is  not  e f f i c i e n t. 

Especially  when  the 

in  the  deduction 

In  our 

Which  sentences  or  formulas  are  available  for  the 

current  problem  needs  to  be  recognized  e a s i l y,  and  to  do 
t h i s,  a  well  organized  data  base  is  necessary. 
tempting  to  t ry  to  incorporate  the  use  of  property  l i s ts 
to  speed  up  r e s o l u t i o n. 
useful  for  each  object  symbol  c  to  have  access  to  a 
chained  l i st  of  a ll  l i t e r a ls  or  clauses  where  c  occurs. 

For  example  one  may  find  it 

It  is 

A  d i f f i c u lt  but  more  important  problem  is  to 

It  is  desirable 

recognize  how  a  meaningful  unit  is  related  to  another 
u n i t. 
to  contain 
information  about  the  i n t e r r e l a t i o n s h i ps  among  the 
meaningful  u n i t s. 
In  our  system  the  deduction  procedure 
can  retrieve  from  a  node  those  sentences  which  have  some 

for  the  data  base 

290 

