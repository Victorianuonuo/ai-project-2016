Variable Resolution Particle Filter 

Vandi Verma, Sebastian Thrun and Reid Simmons 

Carnegie Mellon University 

5000 Forbes Ave. Pittsbugh PA 15217 

{vandi, thrun, reids}@cs.cmu.edu 

Abstract 

Particle filters are used extensively for tracking the state 
of non-linear dynamic systems.  This paper presents a 
new  particle  filter  that  maintains  samples  in  the  state 
space  at dynamically  varying  resolution  for computa(cid:173)
tional efficiency. Resolution within siatespace varies by 
region, depending on the belief that the true state lies 
within each region. Where belief is strong, resolution is 
fine. Where belief is low, resolution is coarse, abstract(cid:173)
ing multiple similar states together. The resolution of the 
statespace is dynamically updated as the belief changes. 
The proposed algorithm makes an explicit bias-variance 
tradeoff to select between maintaining samples in a bi(cid:173)
ased generalization of a region of state space versus in 
a high variance specialization at fine resolution.  Sam(cid:173)
ples are maintained at a coarser resolution when the bias 
introduced by the generalization to a coarse resolution is 
outweighed by the gain in terms of reduction in variance, 
and at a finer resolution when it is not. Maintaining sam(cid:173)
ples  in  abstraction prevents potential  hypotheses from 
being  eliminated  prematurely  for  lack  of  a  sufficient 
number of particles. Empirical results show that our vari(cid:173)
able resolution particle filter requires significantly lower 
computation for performance comparable to a classical 
particle filter. 

Bayesian posterior in the limit as the number of samples go to 
infinity. For real-time state estimation it is impractical to have 
an infinitely large number of particles. With a small number 
of particles, the variance of the particle based estimate can be 
high, particularly when there are a large number of possible 
state transitions. 

This paper presents a new particle filter, the variable res(cid:173)
olution particle filter (VRPF), for tracking large state spaces 
efficiently with low computation.  The basic idea is to rep(cid:173)
resent a set of states1 rather than a single state with a single 
particle and thus increase the number of states (or hypothe(cid:173)
ses) that may be tracked with the same number of particles. 
This makes it possible to track a larger number of states for 
the same computation, but results in a loss of information that 
differentiates between the states that are lumped together and 
tracked in abstraction. We formalize this tradeoff in terms of 
bias and variance.  Tracking in abstraction at a coarser res(cid:173)
olution introduces a bias over tracking at a finer resolution, 
but it reduces the variance of the estimator given a limited 
number of samples. By dynamically varying the resolution in 
different parts of the state space to minimize the bias-variance 
error, a finite set of samples are used in a highly efficient man(cid:173)
ner. Initial experimental results support our analysis and show 
that the bias is more than compensated for by the reduction 
in variance from not eliminating potential hypotheses prema(cid:173)
turely for lack of a sufficient number of particles. 

Introduction 

1 
A  number of problems  in  Al  and  robotics  require  estima(cid:173)
tion of the state of a system as it changes over time from a 
sequence of measurements of the system that provide noisy 
(partial) information about the state. Particle filters have been 
extensively used for Bayesian state estimation  in nonlinear 
systems with noisy measurements  [Isard and Blake,  1998; 
Fox et al., 1999; Doucet et al, 2001 ]. The Bayesian approach 
to dynamic state estimation computes a posterior probability 
distribution over the states based on the sequence of measure(cid:173)
ments.  Probabilistic models of the change in state over time 
(state transition model) and relationship between the mea(cid:173)
surements and the state capture the noise inherent in these 
domains.  Computing the full posterior in real time is often 
intractable.  Particle filters approximate the posterior distri(cid:173)
bution over the states with a set of particles drawn from the 
posterior.  The particle approximation converges to the true 

2  Bayesian Filtering 
We denote the multivariate state at time t as Xt and measure(cid:173)
ments or observations as Ot.  As is commonly the case, we 
concentrate on the discrete time, first order Markov formu(cid:173)
lation of the dynamic state estimation problem.  Hence, the 
state at time t is a sufficient statistic of the history of mea(cid:173)
surements,  i.e.  p(Xt\Xo:t-i)  =  p(Xt\Xt-\)  and  the  obser(cid:173)
vations depend only on the current state, i.e.  p(Ot\Xo.t)  = 
p(Ot\Xt).  In the Bayesian framework, the posterior distribu(cid:173)
tion  at time  t%  p{X^t\0\:t),  includes  all  the  available  infor(cid:173)
mation upto time t and provides the optimal solution to the 
state estimation problem.  In this paper we are interested in 
estimating recursively in time a marginal of this distribution, 
the filtering distribution, p(Xt\Oi:t), as the measurements be-

'or regions of a continuous state space 

976 

PROBABILISTIC  INFERENCE 

come available. Based on the Markovian assumption, the re(cid:173)
cursive filter is derived as follows: 

This process is known as Bayesian filtering, optimal filter(cid:173)
ing or stochastic  filtering  and may be characterized by three 
(2) an ob(cid:173)
distributions: (1) a transition model 
and, (3) an initial prior distribu(cid:173)
servation model 
tion, 
In a number of applications, the state space is 
too large to compute the posterior in a reasonable time. Par(cid:173)
ticle filters are a popular method for computing tractable ap(cid:173)
proximations to this posterior. 

2.1  Classical Particle Filter 
A Particle  filter  (PF) [Metropolis and Ulam,  1949; Gordon 
et al.%  1993; Kanazawa ex a/.,  1995] is a Monte Carlo ap(cid:173)
proximation of the posterior in a Bayes  filter.  PFs are non-
parametric and can represent arbitrary distributions. PFs ap(cid:173)
proximate the posterior with a set of N fully instantiated state 
samples or particles, 

as follows: 

(2) 

as 

denotes the Dirac delta function. It can be shown 
where 
that 
the approximation in (2) approaches the true 
posterior density [Doucet and Crisan,  2002].  In general  it 
instead, sam(cid:173)
is difficult to draw samples from, 
ples are drawn from a more tractable distribution, 
called 
the proposal or importance distribution.  Each particle is as(cid:173)
signed a weight, 
to account for the fact that the sam(cid:173)
ples were drawn from a different distribution [Rubin,  1988; 
Rubinstein,  1981].  There  are  a  large number of possible 
choices for the proposal distribution, the only condition be(cid:173)
ing that its support must include that of the posterior.  The 
common practice is to sample from the transition probability, 
in which case the importance weight is equal to 
the likelihood, 
The experiments in this paper were 
performed using this proposal distribution. The PF algorithm 
is: 

3  Variable Resolution Particle Filter 

A well known problem with particle filters is that a large num(cid:173)
ber of particles are often needed to obtain a reasonable ap(cid:173)
proximation of the posterior distribution.  For real-time state 
estimation  maintaining such a large number of particles  is 
typically not practical.  However, the variance of the particle 
based estimate can be high with a limited number of samples, 
particularly when the process is not very stochastic and parts 
of the state space transition to other parts with very low, or 
zero, probability.  Consider the problem of diagnosing loco(cid:173)
motion faults on a robot.  The probability of a stalled motor 
is low and wheels on the same side generate similar observa(cid:173)
tions.  Motors on any of the wheels may stall at any time.  A 
particle filter that produces an estimate with a high variance 
is likely to result in identifying some arbitrary wheel fault on 
the same side, rather than identifying the correct fault. 

The variable resolution particle filter introduces the notion 
of an abstract particle, in which particles may represent in(cid:173)
dividual states or sets of states.  With this method a single 
abstract particle simultaneously tracks multiple states. A lim(cid:173)
ited number of samples are therefore sufficient for represent(cid:173)
ing large state spaces.  A bias-variance tradeoff is made to 
dynamically refine and abstract states to change the resolu(cid:173)
tion, thereby abstracting a set of states and generalizing the 
samples or specializing the samples in the state into the indi(cid:173)
vidual states that it represents.  As a result reasonable poste(cid:173)
rior estimates can be obtained with a relatively small number 
of samples. In the example above, with the VRPF the wheel 
faults on the same side of the rover would be aggregated to(cid:173)
gether into an abstract fault. Given a fault, the abstract state 
representing the side on which the fault occurs would have 
high likelihood. The samples in this state would be assigned a 
high importance weight. This would result in multiple copies 
of these samples on resampling proportional to weight. Once 
there are sufficient particles to populate all the refined states 
represented by the abstract state, the resolution of the state 
would be changed to the states representing the individual 
wheel faults. At this stage, the correct hypothesis is likely to 
be included in this particle based approximation at the level 
of the individual states and hence the correct fault is likely to 
be detected. 

For the variable resolution particle  filter  we need:  (1) A 
variable resolution state space model that defines the relation(cid:173)
ship between states at different resolutions, (2) an algorithm 
for state estimation given a fixed resolution of the state space, 
(3) a basis for evaluating resolutions of the state space model, 
and (4) and algorithm for dynamically altering the resolution 
of the state space. 

PROBABILISTIC  INFERENCE 

977 

3.1  Variable resolution state space model 

We could use a directed acyclic graph (DAG) to represent the 
variable resolution state space model, which would consider 
every possible combination of the (abstract)states to aggre(cid:173)
gate or split.  But this would make our state space exponen(cid:173)
tially large.  We must therefore constrain the possible com(cid:173)
binations of states that we consider.  There are a number of 
ways to do this.  For the experiments in this paper we use 
a multi-layered hierarchy where each physical (non-abstract) 
state only exists along a single branch.  Sets of states with 
similar state transition and observation models are aggregated 
together at each level in the hierarchy. In addition to the phys(cid:173)
the variable resolution model, M consists 
ical state set 
of a set of abstract states 
that represent sets of states and 
or other abstract states. 

(3) 

Figure 1 (a) shows an arbitrary Markov model and figure 1 (b) 
shows an arbitrary variable resolution model for 1(a). Figure 
1(c) shows the model in 1(b) at a different resolution. 

quence of measurement 

We denote the measurement at time  as 

and the se(cid:173)
From the dynamics, 
probabilities  we com(cid:173)
pute the stationary distribution (Markov chain invariant distri(cid:173)
bution) of the physical states 

and  measurement 

as 

[Behrends, 20001. 

3.2  Belief state estimation at a fixed resolution 

This section describes the algorithm for estimating a distri(cid:173)
bution over the state space, given a fixed resolution for each 
state, where different states may be at different fixed resolu(cid:173)
tions. For each particle in a physical state, a sample is drawn 
from the predictive model for that state 
It is then 
assigned a weight proportional to the likelihood of the mea(cid:173)
surement given the prediction, 
For each particle in 
an abstract state, 
that  it 
represents in abstraction is selected proportional to the prob(cid:173)
ability of the physical state under the stationary distribution, 
The predictive and measurement models for this phys(cid:173)
ical state are then used to obtain a weighted posterior sample. 
The particles are then resampled proportional to their weight. 
Based on the number of resulting particles in each physical 
state a Bayes estimate with a Dirichlet(l) prior is obtained as 
follows: 

one of the physical states, 

(4) 

represents the number of samples in the physi(cid:173)
represents the total number of particles 

where, 
cal state  and 
in the particle filter. The distribution over an abstract state 
at time 

is estimated as: 

(5) 

3.3  Bias-variance tradeoff 
The loss /, from a particle based a p p r o x i m a t i o n of 
the true distribution 

where, 

(6) 
is the bias  a n d is  the variance. 
The posterior belief state estimate from tracking states at 
the resolution of physical states introduces no bias.  But the 
variance of this estimate can  be high,  specially with small 
sample sizes. An approximation of the sample variance at the 
resolution of the physical states may be computed as follows: 

(7) 

The loss of an abstract state 
sum of the loss of the physical states 

is computed as the weighted 

, as follows2: 

(8) 

The generalization  to abstract states  biases the distribution 
over the physical states to the stationary distribution. In other 
words, the abstract state has no information about the relative 
posterior likelihood, given the data, of the states that it repre(cid:173)
sents in abstraction. Instead it uses the stationary distribution 
to project its posterior into the physical layer. The projection 
of the posterior distribution 
to 
the resolution of the physical layer 
is computed as 
follows: 

of abstract state 

(9) 

where, 

As a consequence of the algorithm for computing the pos(cid:173)
terior distribution over abstract states described in section 3.2, 
an unbiased posterior over physical states 
is available at no 
extra computation, as shown in equation (4). The bias 
introduced by representing the set of physical states 
in abstraction as 

is approximated as follows: 

(10) 

It is the weighed sum of the squared difference between the 
, computed at the resolution of the 
unbiased posterior 
physical states and the biased posterior 
computed at 
the resolution of abstract state 

An  approximation of the  variance of abstract state  Sj  is 
computed as a weighted sum of the projection to the physical 
states as follows: 

The relative importance/cost of the physical states may also be 

included in the weight 

(11) 

978 

PROBABILISTIC  INFERENCE 

(a) Example 

(b)  Variable  resolution 
model 

(c) S2 at a finer resolution 

Figure 1: (a)Arbitrary Markov model (b) Arbitrary variable resolution model corresponding to the Markov model in (a). Circles that enclose 
other circles represent abstract states. S2 and S3 and S6 are abstract states. States S2, S4 and S5 form one abstraction hierarchy, and states 
S3, S6, S7, S8 and S9 form another abstraction hierarchy. The states at the highest level of abstraction are Sl, S2 and S3, (c) The model in 
(b) with states S4 and 55 at a finer resolution. 

The loss from tracking a set of states 
tion of the physical states is thus: 

at the resolu(cid:173)

(12) 

The loss from tracking the same set of states in abstraction as 

is: 

(13) 
There is a gain in terms of reduction in variance from gener(cid:173)
alizing and tracking in abstraction, but it results in an increase 
in bias.  Here, a tradeoff between bias and variance refers to 
the process of accepting a certain increase in one term for a 
larger reduction in the other and hence in the total error. 

3.4  Dynamically varying resolution 
The  variable  resolution  particle  filter  uses  a  bias-variance 
tradeoff to make a decision to vary the resolution of the state 
space.  A decision to abstract to the coarser resolution of ab(cid:173)
is made if the state space is currently at the 
stract state 
resolution of states 
and the combination of bias and vari(cid:173)
ance in abstract state 
is less than the combination of bias 
an variance of all its children 5,, as shown below: 

On the other hand if the state space is currently at the reso(cid:173)
lution of abstract state 
and the reverse of equation (14) is 
true, then a decision to refine to the finer resolution of states 
is made.  The resolution of a state is left unaltered if its 
bias-variance combination is less than its parent and its chil(cid:173)
dren.  To avoid hysteresis, all abstraction decisions are con(cid:173)
sidered before any refinement decisions. 

Each time a new measurement is obtained the distribution 
of particles over the state space is updated.  Since this alters 
the bias and variance tradeoff, the states explicitly represented 
at the current resolution of the state space are each evaluated 
for gain from abstraction or refinement.  Any change in the 
current resolution of the state space is recursively evaluated 
for further change in the same direction. 

4  Experimental results 
The problem domain for our experiments involves diagnos(cid:173)
ing locomotion faults in a physics based simulation of a six 
wheel rover. Figure 2(a) shows a snapshot of the rover in the 
Darwin2K [Leger, 2000] simulator. 

The experiment is formulated in terms of estimating dis(cid:173)
crete fault and operational modes of the robot from contin(cid:173)
uous control inputs and noisy sensor readings.  The discrete 
represents the particular fault or operational mode. 
state, 
The continuous variables, 
provide noisy measurements of 
the change in rover position and orientation. The particle set 
Pt therefore consists of TV particles, where each particle 
is a hypothesis about the current state of the system. In other 
words, there are a number of discrete fault and operational 
states that a particle may transition to based on the transition 
model.  Each discrete fault state has a different observation 
and predictive model for the continuous dynamics. The prob(cid:173)
ability of a state is determined by the density of samples in 
that state. 

The Markov model representing the discrete state transi(cid:173)
tions consists of 7 states. As shown in figure 2(c) the normal 
driving (ND) state may transition back to the normal driv(cid:173)
ing state or to any one of six  fault states:  right front (RF), 
right middle (RM), right rear (RR), left front (LF), left mid(cid:173)
dle (LM) and left rear (LR) wheel stuck. Each of these faults 
cause a change in the rover dynamics, but the faults on each 
side (right and left), have similar dynamics. 

Given that the three wheels on each side of the rover have 
similar dynamics, we constructed a hierarchy that clusters the 
fault states on each side together. Figure 2(d) shows this hier(cid:173)
archical model, where the abstract states right side fault (RS), 
and left side fault (LS) represent sets of states 
respectively. The highest level of abstrac(cid:173)
and 
tion therefore consists of nodes 
Figure 2(e) 
shows how the state space in figure 2(d) would be refined if 
the bias in the abstract state RS given the number of parti(cid:173)
cles outweighs the reduction in variance over the specialized 
states RF, RM and RR at a finer resolution. 

When particle filtering is performed with the variable reso(cid:173)
lution particle filter, the particles are initialized at the highest 

PROBABILISTIC  INFERENCE 

979 

Figure 2: (a) Snapshot from the dynamic simulation of the six wheel rocker bogie rover in the simulator, (b) An example showing the normal 
trajectory (ND) and the change in the same trajectory with a fault at each wheel, (c) Original discrete state transition model. The discrete 
states are: Normal driving (ND), right and left, front, middle and rear wheel faulty (RF, RM, RR, LF, LM, LR) (d) Abstract discrete slate 
transition model. The states, RF, RM and RR have been aggregated into the Right Side wheel faulty states and similarly LF, LM and LR into 
Left Side wheel faulty states (RS and LS). (e) State space model where RS has been refined. All states have self transitions that have been 
excluded for clarity. 

level in the abstraction hierarchy,i.e. in the abstract states ND, 
RS and LS. Say a RF fault occurs, this is likely to result in a 
high likelihood of samples in RS. These samples will mul(cid:173)
tiply which may then result in the bias in RS exceeding the 
reduction in variance in RS over RF, RM and RR thus favor(cid:173)
ing tracking at the finer resolution.  Additional observations 
should then assign a high likelihood to RF. 

The  model  is  based  on  the  real-world  and  is  not  very 
stochastic. It does not allow transitions from most fault states 
to other fault states. For example, the RF fault does not tran(cid:173)
sition to the RM fault.  This does not exclude transitions to 
multiple fault states and if the model included multiple faults, 
it could still transition to a "RF and RM" fault, which is dif(cid:173)
ferent from a RM fault.  Hence,  if there are no samples in 
the actual fault state, samples that end up in fault states with 
dynamics that are similar to the actual fault state may end up 
being identified as the fault state. The hierarchical approach 
tracks the state at an abstract level and does not commit to 
identifying any particular specialized fault state until there is 
sufficient evidence.  Hence it is  more likely to identify the 
correct fault state. 

Figure 3(a) shows a comparison of the error from moni(cid:173)
toring the state using a classical particle filter that tracks the 
full state space, and the VRPF that varies the resolution of 
the state space.  The X  axis shows the number of particles 
used, the Y axis shows the KL divergence from an approxi(cid:173)
mation of the true posterior computed using a large number of 
samples. 1000 samples were used to compute an approxima(cid:173)
tion to the true distribution. The KL divergence is computed 
over the entire length of the data sequence and is averaged 
over multiple runs over the same data set 3.  The data set in(cid:173)
cluded normal operation and each of the six faults.  Figure 
3(a) demonstrates that the performance of the VRPF is su-

3The results are an average over 50 to 5 runs with repetitions 

decreasing as the sample size was increased. 

of the state space 

980 

PROBABILISTIC  INFERENCE 

perior to that of the classical filter for small sample sizes.  In 
addition figure 3(b) shows the Kl-divergence along the Y axis 
and wall clock time along the X axis. Both filters were coded 
in matlab and share as many functions as possible. 
5  Discussion and Future Work 
This paper presents a novel approach for state abstraction in 
particle filters that allows efficient tracking of large discrete, 
continuous or hybrid state spaces.  The advantage of this ap(cid:173)
proach is that it makes efficient use of the available computa(cid:173)
tion by selecting the resolution of the state space based on an 
explicit bias-variance tradeoff.  It performs no worse than a 
classical particle filter with an infinite number of particles 4. 
But with limited particles we show that its performance is 
considerably superior. The VRPF does not prematurely elim(cid:173)
inate potential hypotheses for lack of a sufficient number of 
particles. It maintains particles in abstraction until there are a 
sufficient number of particles to provide a low variance esti(cid:173)
mate at a lower resolution. 

The VRPF generalizes from current samples to unsampled 
regions of the state space. Regions of the state space that had 
no samples at time t may acquire samples at time 
1 on 
abstraction. This provides additional robustness to noise that 
may have resulted in eliminating a likely hypothesis. [Koller 
and Fratkina, 1998] addresses this by using the time  sam(cid:173)
ples as input to a density estimation algorithm that learns a 
distribution over the states at time t. Samples at time 
are 
then generated using this generalized distribution. [Ng et al, 
2002] uses a factored representation to allow a similar mix(cid:173)
ing of particles.  The VRPF uses a bias-variance tradeoff to 
generalize more selectively and efficiently. 

We have presented the variable resolution particle filter for 
a discrete state space.  We plan to extend it to a continuous 
4There is a minor overhead in terms of evaluating the resolution 

(a) 

(b) 

Figure 3: Comparison of the KL divergence from the true distribution for the classical particle filter and the VRPF, against (a) number of 
particles used, (b) wall clock time. 

state space where regions of state space, rather than sets of 
states are maintained at different resolutions.  A density tree 
may be used for efficiently learning the variable resolution 
state space model  with abstract states composed of finitely 
many sub-regions. 

The  VRPF makes  efficient  use  of available  computation 
and  can  provide significantly  improved posterior estimates 
given a small  number of samples.  However,  it should not 
be expected to solve all problems associated with particle im(cid:173)
poverishment. For example, it assumes that different regions 
of the state space are important at different times.  We have 
generally found this to be the case, but the VRPF does not im(cid:173)
prove performance if it is not.  Another situation is when the 
transition and observation models of all the states are highly 
dissimilar and there is no possibility for state aggregation. 

6  Acknowledgments 
We would like to thank Geoff Gordon, Tom Minka and the 
anonymous reviewers. 

References 
iBehrends, 20001  E.  Behrends. 

Introduction  to  Markov 
Chains with Special Emphasis on Rapid Mixing. Vieweg 
Verlag, 2000. 

[Doucet and Crisan, 20021  A. Doucet and D. Crisan.  A sur(cid:173)
vey of convergence results on particle  filtering  for practi(cid:173)
tioners. IEEE Trans. Signal Processing, 2002. 

[Doucet et al, 20011  A. Doucet, N. de Freitas, and N.J. Gor(cid:173)

don, editors. Sequential Monte Carlo Methods in Practice. 
Springer-Verlag, 2001. 

[Fox et al, 19991 D. Fox, W. Burgard, and S. Thrun. Markov 
localization for mobile robots in dynamic environments. In 
Journal of Artificial Intelligence, volume 11, pages 391-
427, 1999. 

[Gordon et al., 19931 N.J. Gordon, D.J Salmond, and A.F.M 
Smith. Novel approach to nonliner/non gaussian bayesian 
state estimation, volume 140 of ZEE Proceedings-F, pages 
107-113,1993. 

[Isard and Blake, 19981  M.  Isard and A.  Blake.  Conden(cid:173)
sation:  conditional density propagation for visual track(cid:173)
ing. International Journal of Computer Vision, 29(1 ):5-
28, 1998. 

[KanazawaeT a/., 19951  K.  Kanazawa,  D.  Koller,  and 
S. Russell.  Stochastic simulation algorithms for dynamic 
probabilistic networks, pages 346-351, 1995. 

[Koller and Fratkina, 1998]  D. Koller and R. Fratkina.  Us(cid:173)
ing learning for approximation in stochastic processes.  In 
ICML, 1998. 

iLeger, 20001 PC. Legcr.  Dan\'in2K: An Evolutionary Ap(cid:173)
proach to Automated Design for Robotics. Kluwcr Aca(cid:173)
demic Publishers, 2000. 

[Metropolis and Ulam,  1949]  N.  Metropolis  and  S.  Ulam. 
The monte carlo method,  volume 44 of Journal of the 
American Statistical Association, 1949. 

[Ng et al, 2002]  B. Ng, L. Peshkin, and A. Pfeffer. Factored 

particles for scalable monitoring. In UAI, 2002. 

[Rubin, 19881 D. B. Rubin. Using the SIR algorithm to sim(cid:173)
ulate posterior distributions.  Oxford University Press, 
1988. 

[Rubinstein,  1981]  R. Y. Rubinstein.  Simulation and Monte 

Carlo method. In John Wiley and Sons, 1981. 

PROBABILISTIC  INFERENCE 

981 

