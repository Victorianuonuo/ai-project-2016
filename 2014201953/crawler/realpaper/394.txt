444 

Session No.  10 Computer  Understanding I (Communication) 

FINDING  THE CONCEPTUAL  CONTENT AND  INTENTION 

IN  AN  UTTERANCE  IN  NATURAL  LANGUAGE 

CONVERSATION* 
Roger  C.  Schank 

Computer  Science  Department 

and 

Committee  on  Linguistics 

Stanford  University 

Stanford,  California,  U.S.A. 

Abstract 

The  conceptual  dependency  analyzer  described 
in  the  f i r st  IJCAI  (8)  has  been  modified  so  as  to 
function  more  conceptually  with  less  reliance  on 
syntactic  rules. 
In  order  to  have  an  analyzer  be 
conceptually  driven, 
it  is  necessary  for  the  sys­
tem  to  know  what  it  is  looking  for.  That  i s,  it 
must  make  predictions  as  to  what  can  follow  con­
ceptually  at  any  point  in  the  analysis.  This 
paper  discusses  the  extension  of  conceptual  pre­
diction  to  include  predictions  based  on  context 
and  the  structure  of  the  memory  model  that  oper­
ates  with  the  analyzer.  Such  predictions  make 
use  of  relations  between  conceptual  actions  and 
the  implications  of  those  actions.  This  enables 
the  conceptual  analyzer  to  discover  not  only  the 
conceptual  content  of  an  utterance  but  also  the 
intention  of  that  utterance  in  context.  We  are 
concerned  with  the  extraction  of  the  conceptual 
content  both  explicit  and  implicit  in  an  utterance 
in  order  to  analyze  effectively  in  an  interactive 
conversational  situation. 

I.  Levels  of  Expectation 

The  primary  emphasis  that  has  been  given  to 

the  study  of  the  sentence  by  linguists  and  com­
putational  linguists  has  brought  about  some  pecu­
liar  ways  of  studying  natural  language.  Clearly 
people  do  not  understand  nor  generate  sentences 
It  has  been  in  fashion  among  l i n­
in  isolation. 
guists  who  like  to  attack  other  linguists' 
ideas 
of  grammaticality,  to  refute  a  statement  of  un-
grammaticality  by  finding  a  situation  in  which 
the  supposed  ungrammatical  sentence  makes  sense. 
Lakoff  (6)  has  recently  noted  the  need  for  using 
presupposition  -  sentence  pairs  before  one  can 
discuss  grammaticality. 
It  has  long  been  our  as­
sertion  that,  while  it  seems  reasonable  that  l i n­
guists  who  are  studying  grammaticality  should  take 
context  into  account, 
i t s e lf  seems  a  bit  misguided  (see  Schank  (11)). 
What  would  seem  to  be  more  reasonable  Is  to  re­
alize  that  people  talk  in  order  to  communicate 

the  study  of  grammaticality 

*This  research  is  supported  by  Grant  PHS  MH  06645-09 
from  the  National  Institute  of  Mental  Health,  and 
(in  part)  by  the  Advanced  Research  Projects  Agency 
of  the  Office  of  the  Secretary  of  Defense  (SD-183). 

something  and  it  is  the  discovery  of  what  this 
something  is  that  is  the  proper  domain  of  study 
for  researchers  interested  in  natural  language. 
This  point-of-view  necessitates  looking  at  lan­
guage  analytically  rather  than  from  the  genera­
tive  view  of  transformational  grammar. 
kind  of  viewpoint  that  eliminates  notions  that 
semantics  consists  of  selectional  restrictions 
which  t e ll  you  what  cannot  be  said.  Clearly  if 
something  was  said  it  must  be  dealt  with  regard­
less  of  i ts  grammaticality. 

It  is  this 

But  even  if  we  recognize  that  the  analytic 

study  of  language  might  yield  some  f r u i t f ul 
results,  the  possibility  of  falling  into  some  of 
the  traps  left  lying  around  by  generative  gram­
marians  is  extant.  Of  these  traps,  by  far  the 
most  troublesome  is  the  notion  that  the  sentence 
is  the  core  of  the  problem.  Theories  that  are 
sentence-based  simply  miss  the  essence  of  the 
problem,  namely  that  something  is  attempting  to 
be  communicated  by  the  speaker  and  it  can  be  as­
certained  by  taking  the  entire  situation  in  which 
it  was  uttered  into  account.  Here  we  mean  not 
only  the  linguistic  context,  but  the  physical, 
mental,  emotional,  and  social  contexts  as  well. 
Now  this  is  not  to  say  that  we  must  disregard  a ll 
work  that  has  been  done  on  sentence  analysis  up 
u n t il  now.  On  the  contrary,  many  of  the  tech­
niques  used  there  have  their  analogues  on  other 
levels  of  analysis.  But  just  as  it  was  important 
to  realize  that  it  simply  made  no  sense  to  analyze 
a  sentence  so  as  to  detect  a ll  four  or  f i f ty  pos­
sible  syntactic  arrangements  for  it  (as  the  Kuno-
Oettinger  parser  did  for  example  (5)), 
likewise 
one  does  not  wish  to  find  more  than  one  concep­
tual  analysis  of  a  sentence  if  the  prevailing 
context  clearly  eliminates  a ll  but  one  of  the 
choices. 

One  element  which  humans  rely  heavily  on 
during  the  understanding  process  is  that  of  ex­
pectation.  At  the  sentence-level,  we  can  predict 
at  any  point  in  an  analysis  what  type  of  syntactic 
element  is  most  likely  to  follow.  Thus,  if  we 
have  just  seen  a  noun  the  likelihood  that  a  verb 
w i ll  appear  next  is  good  assuming  one  has  not  a l­
ready  appeared.  By  the  same  token,  an  auxiliary 
or  adverb  is  likely  to  appear  but  with  a  different 
probability.  Some  elements  are  much  less  likely 
to  appear  (an  adjective  for  example)  and  some 
likely  to  appear  depending  on  some  of  the  seman­
tic  information  contained  within  the  noun.  At 
any  rate,  guesses  can  be  made  based  on  what  one 
might  expect  w i ll  occur.  Guesses  of  this  kind 
perform  three  major  functions.  First  they  point 
the  way  in  searching  a  data  base  for  an  item. 
Second,  they  allow  for  disambiguation.  On  the 
sentential  level,  this  means  being  able  to  choose 
between  alternative  senses  of  a  word  that  are 
based  on  syntactic  category.  Third,  they  enable 
one  to  predict  occurrences  of  information  related 
to  items  that  have  already  been  discovered.  This 
is  important  in  establishing  dependency  informa­
tion. 

Session No.  10 Computer  Understanding I (Communication) 

445 

At  the  conceptual  level  expectations  work  in 
roughly  the  same  way.  That  i s,  we  can  guess  the 
type  of  conceptual  information  that  is  needed  to 
make  an  unfinished  sentence  sensible. 
If  we  for­
malize  these  expectations  we  can  enable  a  machine 
to  know  what  it  is  looking  for  when  it  searches 
through  a  sentence  attempting  to  find  the  concep­
tual  structure  underlying  i t.  We  can  use  this 
information  for  searching  the  data  base,  disam­
biguating,  and  creating  dependencies. 

There  are  predictions  that  can  be  made,  how­
ever,  that  are  based  on  criteria  other  than  that 
directly  derivable  from  the  stratified  linguistic 
system  that  comprises  conceptual  dependency  theory 
(9).  Consider  the  following  situation  and  con­
versation: 

John  meets  his  friend  Fred  on 

the  street.  Fred  is  holding  a  knife. 
John  is  angry  because  his  wife  Mary 
has  yelled  at  him. 

Fred:  Hi. 
John:  What  are  you  doing  with  that 

knife? 

John: 

Fred:  Thought  I'd  teach  the  kids  to 

play  mumblypeg. 
I  could  use  a  knife  right  now. 
(agitated  tone) 

Fred:  What's  the  matter? 
John:  Damn  Mary,  always  on  my  back. 

Fred: 

She'll  be  sorry. 
I  don't  think  a  knife  w i ll 
help  you. 

John:  You're  just  on  her  side. 

I 

think  I  ought  to 

Now  what  can  Fred  expect  that  he  w i ll  hear 
next?  There  are  at  least  six  distinct  types  of 
information  with  which  we  can  answer  this  ques­
tion.  Sententially,  Fred  expects  a  verb.  Con­
ceptually, 
there  is  a  conceptual  representation 
of  what  John  has  just  said  which  requires  a  com­
plete  actor-action-object  construction  (which  we 
call  a  conceptualization)  in  order  to  be  complete. 
Thus,  conceptually  a  conceptualization  is  expected. 
But  we  can  also  make  predictions  based  on  context. 
According  to  the  context,  there  are  only  a  certain 
set  of  concepts  which  w i ll  f it  into  the  needed 
conceptualization  such  that  the  conceptualization 
makes  sense  in  context.  We  most  certainly  would 
be  surprised  if  the  next  piece  of  information 
would  be  'I  think  I  ought  to  have  fish  for  din­
ner'. 
at  any  point  in  any  analysis  which  allows  us  to 
be  surprised,  shocked  or  whatever  other  emotional 
attribute  by  a  piece  of  information.  You  are  not 
able  to  be  surprised  if  you  don't  anticipate  and 
it  is  therefore  necessary  for  a  system  such  as 
this  to  anticipate. 

It  is  knowing  what  we  do  and  do  not  expect 

What  we  anticipate  here  are  the  following 

four  types  of  statements  based  on  their  contextual 
likelihood: 
(1)  hurt  someone,  (2)  end  relation­
ship  with  somebody,  (3)  go  to  someplace,  and  (4) 

emote. 

'hurt' 

These  are  classes  of  actions.  We  don't  know 
'go'  or  'emote'  w i ll 

which  sentential  form 
take  but  we  can  estimate  the  likelihood  of  the 
class  on  the  basis  of  the  conceptual  category  and 
the  prevailing  semantic  categories  that  have  been 
used  in  context.  All  of  these  above  actions  are 
predicted  on  the  strength  of  their  likely  conse­
quences.  That  i s,  a  desired  consequence  is  known 
(John  feel  better)  and  the  above  actions  would 
each  lead  to  John's  feeling  better,  but  each  in 
a  different  way.  This  w i ll  be  explained  at  length 
later  on. 

A  fourth  type  of  expectation  or  prediction 
is  conversational.  That  i s,  people  talk  for  a 
reason,  usually  to  communicate  something  or  to 
gain  some  desired  effect  in  the  hearer.  Here, 
it  is  either  to  arouse  sympathy  or  to  inform  about 
something  he  is  about  to  do.  But  the  use  of  ought 
implies  he  might  not  do  this,  so  that  his  probable 
reason  in  making  this  statement  has  to  do  with  the 
effect  which  it  w i ll  create  on  the  hearer.  Thus 
we  can  predict  what  kind  of  effect  is  intended  to 
be  made  by  the  speaker  and  then  expect  certain 
types  of  utterances. 

A  f i f th  kind  of  expectation  information  has 

to  do  with  a  world  view  of  the  situation  based  on 
his  own  individual  memory  model.  Thus,  if  he  knows 
John  to  be  a  convicted  murderer  his  expectation 
of  John's  completion  of  this  sentence  ought  to  be 
different  from  his  expectation  if  John  were  an 
avowed  pacifist. 

A  sixth  type  of  expectation  is  based  on  a 
memory-structure  that  is  common  to  the  cultural 
norm  rather  than  the  particular  language  or  par­
ticular  individual.  The  results  of  this  kind  of 
expectation  have  to  do  with  the  options  that  Fred 
can  take  as  a  result  of  the  expected  input  from 
John.  That  i s,  the  conversation  is  heading  to­
wards  death  (this  idea  w i ll  be  explained  below) 
and  Fred's  expectation  of  this  can  avert  the 
situation  by  appropriate  action,  either  physical 
informative  conversational  or  emotional  conver­
sational. 
appropriate  action  and  his  expectation  is  based 
on  the  ' l i fe → death'  memory  structure  explained 
below. 

It  is  his  expectation  that  decides  the 

Basically  then,  we  must  recognize  that  any 

complete  processing  system  for  a  natural  language 
utterance  takes  place  within  a  context  that  is 
extremely  complex  because  there  are  humans  in  the 
conversation . 
Each  has  a  complex  memory  to  be­
gin  with  and  is  now  in  a  new  complex  situation. 
Part  of  this  problem  is  being  able  to  anticipate. 
Therefore,  getting  a  machine  to  be  able  to  make 
predictions  is  an  important  part  of  the  language 
understanding  problem. 

We  have  dealt  elsewhere  with  sentential  and 
conceptual  predictions  that  aid  a  computer  anal­
ysis,  so  these  w i ll  be  only  briefly  discussed  in 

446 

Understanding 

In  the  remaining  sections  we 
the  next  section. 
w i ll  be  primarily  concerned  with  discovering  the 
intention  of  an  utterance  in  a  given  situation, 
once  the  conceptual  content  has  been  ascertained. 

I I.  Conceptual  Dependency  Analysis 

Before  we  can  begin  to  make  predictions  based 

on  the  last  four  expectation  types,  it  is  neces­
sary  to  have  a  conceptual  representation  of  each 
input  utterance.  That  i s,  we  must  have  analyzed 
what  was  said  before  we  can  know  what  the  inten­
tion  of  a  given  utterance  was. 

Conceptual  networks  have  been  developed  (see 
(9),  (10))  that  are  intended  to  represent  the  con­
ceptual  content  of  a  natural  language  utterance. 
We  require  of  these  conceptual  networks  that  there 
be  only  one  such  network  for  any  number  of  natu­
ral  language  utterances  that  have  the  same  meaning. 
Thus,  the  f i r st  task  in  natural  language  analysis 
is  to  get  the  input  utterances  into  some  repre­
sentation  of  the  meaning  of  that  utterance. 

The  conceptual  representation  schema  pre­

sented  here  makes  the  following  assumptions  and 
notation: 

(1)  Underlying  natural  language  sentences 
there  are  abstract  conceptualizations. 

(2)  A  conceptualization  is  either  an 

actor-action  complex  (denoted  by  «») ; 
or  an  attribute  statement  (denoted  b y) 

(3)  Actions  have  labeled  dependents  denoting, 

object  (→),  recipient  («B),  direction 
(D),  or  instrument  (J). 

(4)  Conceptualizations  can  relate  to  other 

conceptualizations  by  nesting  as  i n­
struments  or  objects,  or  by  causation 
(denoted  by 

). 

(5)  Conceptualizations  are  modified  as  to 

t(transition); 

tense  by:  p(past);  f(future);  c(con­
ditional); 
ts/ tf( t r a n s i-
tion  starting  or  finishing);  k(continu­
/(nega­
ant) ;  A(timeless);Ǿ(present); 
tive);  ?(interrogative),  written  over  the 
• 

(6)  A  concept  within  a  conceptualization 

can  be  modified  by  vertical  arrows 
denoting  attribution  (t)  and  relation 
to  another  concept 

(7)  Conceptualizations  can  be  modified  by 

times  (t)  or  by  locations  (ft). 

To  see  what  the  analysis  of  an  actual  sentence 

is  like  we  can  consider  the  simple  sentence  'The 
man  took  the  book.'.  Using  the  above  notation 
we  might  analyze  this  as: 
. book 
But,  in  attempting  to  uncover  the  actual  concep­
tualization  underlying  a  sentence,  we  must  recog­
nize  that  conceptually  a  sentence  is  often  more 

man  » take 

In  fact,  a  dialogue 

than  i ts  component  parts. 
is  usually  based  on  the  information  that  is  left 
out  of  the  various  conceptualizations.  For  ex­
ample,  in  this  sentence,  we  know  that  there  was 
a  time  and  location  of  this  conceptualization 
and  furthermore  that  the  book  was  taken  from 
'someone'  or  'someplace'  and  i s,  as  far  as  we 
know,  now  in  the  possession  of  the  actor.  Thus, 
conceptually,  there  exists  here  a  two-pronged 
recipient  case,  dependent  on  the  conceptual  verb 
(ACT)  through  the  object.  We  use  this  recipient 
case  to  denote  the  transition  in  possession  of 
the  object.  Thus  we  have  the  following  network: 

In  this  instance  the  recipient  and  the  actor  are 
the  same.  We  can  posit  an  underlying  ACT  here 
that  is  more  abstract  than  'take'  but  denotes 
the  transition  that  is  taking  place,  which  we 
call 
' t r a n s . '.  This  abstraction  allows  us  to 
recognize  paraphrases  at  the  conceptual  level 
without  losing  syntactic  information.  We  can 
define  the  English  word  'take'  as  the  instance 
when  Z  =  Y  in  the  following  network: 

'Receive 
'Give'  Is  the  realized  verb  when  Z  =  X. 
represents  the  same  diagram  as  'give'.  Similarly 
other  'trans'  verbs,  for  example, 
'steal1,  have  conceptual  realizates  where  other 
aspects  of  the  network  are  defined  in  some  man­
ner.  Thus  the  following  network,  with  a  concep­
tualization  as  instrument,  can  be  sententially 
realized  with  'send'. 

'send'  and 

Each  ACT  (such  as  'trans')  belongs  to  an  ACT 

category  that  requires  certain  conceptual  cases 
(or  ACT  dependents). 
'Trans',  for  example,  must 
have  an  object,  instrument,  and  recipient  concep­
tually  even  if  none  were  explicitly  stated  in  the 
original  sentence.  Conceptual  analysis  by  comput 
utilizes  a  verb  dictionary  which  locates  the  ap­
propriate  sense  of  a  verb  by  use  of  contiguous 
semantic  information  and  then  proceeds  to  rewrite 
the  verb  into  a  conceptual  construction.  This 
conceptual  construction  is  a  dependency  network 
consisting  of  the  underlying  primitive  action 
(e.g.  'trans', 
'go')  and  the  conceptual  case 
dependents  that  are  required  by  this  action. 

Session No.  10 Computer  Understanding I (Communication) 

447 

Thus,  we  can  set  up  a  network  that  has  blank  spaces 
in  it  with  very  definite  requirements  for  what 
w i ll  f i ll  them.  The  system  can  then  know  what  it 
doesn't  know  and  needs  to  find  out.  This  predic­
tive  capability  is  very  important  in  an  analysis 
system  that  can  function  in  a  dialogue  situation. 
Furthermore,  semantic  predictions  enable  the  sys­
tem  to  function  without  f i r st  doing  a  syntactic 
analysis.  Syntax  is  called  into  play  only  as  a 
searching  mechanism  for  already  known  semantic 
information. 

Conceptual  Dependency  uses  four  conceptual 

cases,  objective,  recipient,  instrumental  and 
directive.  These  cases,  while  not  being  too  dis­
parate  from  Fillmore's  (3)  ideas  on  syntactic 
cases,  have  their  justification  on  conceptual 
grounds.  We  note  that  there  is  a  difference  be­
tween  a  conceptual  instrument  and  the  instrument 
as  it  functions  syntactically.  To  better  explain 
this  it  is  necessary  to  digress  for  a  moment  to 
discuss  a  certain  class  of  English  verbs  which  we 
call 

'pseudo-state'. 

that  'grew'  and  not 

An  example  of  a  pseudo-state  verb  is  'grow'. 
When  we  say  'John  grew  plants',  we  usually  mean 
that  it  was  the  'plants' 
'John'.  But  'John'  was  an  actor.  However,  the 
action  that  John  did,  which  we  call  'growing', 
was  complex  and  probably  consisted  of  weeding, 
hoeing,  adding  f e r t i l i z e r,  watering  and  so  on. 
What  we  are  really  saying  is  that  his  action 
'doing'  (not  'he')  caused  the  plants  to  'grow'. 
The  two  conceptualizations  are  related  causally 
(  ||  )  with  the  direction  of  the  arrow  denoting 
the  governor  and  dependent  conceptualizations. 
Thus,  the  above  sentence  is  realized  as: 

Now  we  can  see  that  the  sentential  instrument 

in  the  following  sentence 

of  ' f e r t i l i z e r' 
grew  the  trees  with  f e r t i l i z e r' 
the  instrument  of  one  of  the  'do's'  associated 
with  the  verb  'grow',  and  not  the  ACT  'grow'.  (In 
fact  'grow'  belongs  to  the  class  of  intransitive 
ACTs  (IACT)  which  cannot  take  any  conceptual  case.) 
The  most  likely  analysis  of  this  sentence  then,  i s: 

'John 
is  conceptually 

Of  importance  here  is  the  fact  that  the  instrument 
is  dependent  on  'do'  and  not  'grow'  (nor  on  'cause'). 
However,  the  verb  'grow'  can  take  an  instrument  of 
' f e r t i l i z e r '.  This  is  an  important  distinction 
which  is  used  by  the  parser. 

The  conceptual  analysis  technique  that  is 
referred  to  here,  while  reliant  on  syntactic  i n­
formation,  does  not  f i r st  do  a  syntactic  analysis. 
It  is  interesting  to  see  how  sentences  that  are 
similar  syntactically  are  dealt  with. 

Consider  the  sentence 

'John's  can  of  beans  was  edible'  but 

'John's  love  of  Mary 
was  beautiful'.  This  has  the  same  surface  struc 
ture  as 
they  have  different  underlying  conceptual  struc­
tures.  We  consider  that  'love'  is  an  ACT  no  mat 
ter  how  it  is  realized  and  thus  the  NP  in  the 
f i r st  sentence  is  graphed: 

The  graph  of  the  active  sentence  is  then 

Here  we  have  an  abstract 
noun  that  is  realized  as  an  ACT. 
In  the  latter 
sentence  we  have  the  abstract  adjective  'edible' 
and  this  too  is  an  ACT  conceptually.  Thus  the 
conceptual  realization  of  this  sentence  i s: 

actor. 
second  sentence, 
dictionary  as 

In  order  to  find  these  analyses  in  the 
'edible'  is  discovered  in  the 

'One'  is  a  dummy 

means  that  this  conceptualization  is  conditionally 
true  (denoted  by  c)  and  the  potential  object  is 
of  the  semantic  class  'food'.  Syntactic  rules 
indicate  where  to  look  for  this  'food'. 
In  this 
sentence, 
'can'  is  examined  f i r s t,  and  put  aside 
in  lieu  of  a  better  candidate  for  'food'.  Since 
'beans' 
f i t s,  it  is  used  and  semantic  relations 
determine  the  dependencies  involved. 

'love' 

In  the 

f i r st  example, 

is  the  under­
lying  action  (ACT).  A  conceptualization  is  set 
up  with  'love'  as  the  ACT  and  the  syntactics  are 
used  to  determine  the  correct  placement  of  the 
conceptual  nominals  (PP's).  A  predication  about 
this  conceptualization  (is  beautiful)  is  found 
and  is  placed  in  the  network. 

The  primary  task  of  the  conceptual  analyzer, 
then,  is  to  discover  the  underlying  action  present 
in  a  sentence,  if  there  is  one,  then  to  go  through 
i ts  experience  to  find  out  what  kinds  of  syntactic 
combinations  it  is  likely  to  find.  That  i s,  we 
want  to  know  what  to  expect  next  at  any  point  in 
the  parse.  These  expectations  are  discovered  on 
the  basis  of  the  syntactic  and  conceptual  cate­
gories  associated  with  a  given  verb. 

The  analyzer  must  then  be  able  to  choose  be­
tween  the  set  of  senses  assigned  to  a  given  verb 
by  the  dictionary.  This  it  does  by  the  use  of 
what  we  might  choose  to  call  'semantic'information, 
or 

'selectional  restrictions'. 

448 

Session No.  10 Computer  Understanding I (Communication) 

The  primary  problem  in  conceptual  analysis 
is  finding  the  verb.  To  do  this  we  make  use  of 
low  level  syntactic  information,  such  as  inflec­
tion  and  agreement  rules  and  certain  simple  syn­
tactic  rules.  This  process  has  i ts  parallel  on 
the  conceptual  level  in  the  heuristics  that  the 
parser  employs  to  discover  where  to  go  in  the  con­
ceptual  network  whenever  it  has  become  confused. 
These  heuristics  are  then  low  level  conceptual 
rules.  That  i s,  they  operate  on  language-specific 
information  that  serve  as  commands  to  the  concep­
tual  apparatus. 

Thus  the  parsing  process  consists  of  searching 

for  a  central  element  at  each  level  (the  verb  sen-
tentially,  and  the  actor-action  combination  con­
ceptually,  given  that  these  exist);  then  using  the 
expectation  information  provided  as  a  guide  to 
putting  together  the  pieces  of  the  puzzle.  To  see 
how  predictions  work  in  actual  conceptual  analysis 
we  can  consider  parsing 
flying  to  New  York.'  A  parse  of  this  sentence 
that  was  conceptually  motivated  would  have  to  at­
tempt  to  attach  ' f l y'  to  'Grand  Canyon1  since  we 
can  observe  that  most  English  speakers  find  this 
sentence  to  be  amusing,  implying  that  they  have 
tried  just  that. 

'I  saw  the  Grand  Canyon 

'I' 

We  begin  by  looking  for  ACTOR  =  ACT  combina­

in  the  network  and  look  for 

tions.  We  place 
an  ACT  that  can  have  a  semantic  connection  to  ' I '. 
'See'  satisfies  this  requirement  and  we  create  a 
two-way  dependency  between  them.  Upon  encountering 
'Grand  Canyon',  we  look  for  the  nearest  concept 
that  w i ll  form  an  acceptable  dependency  with  i t. 
The  nearest  concept  is  the  ACT  'see'  which  is  a 
'flying' 
semantically  acceptable  connection.  Next, 
is  input  and  we  have  an  ACT  the  nearest  concept  to 
which  is  'Grand  Canyon'.  We  then  try  to  connect 
them.  However,  this  choice  is  disallowed  upon 
consulting  the  verb-ACT  dictionary  (which  we  do 
each  time  we  find  a  verb). 

(Here  vio  denotes  a  verb  that  takes  a  sentential 
indirect  object  and  vt  is  a  transitive  verb.  The 
'subject'  and  'object'  refer  to  sentential  expec 
tations,  some  of  which  are  category  names.) 

Upon  entering  the  dictionary  we  look  for 
'location'  as  a  possible  subject  of  a  vio  entry 
for  ' f l y '.  We  do  not  find  i t,  however,  and  thus 

must  go  back  to  the  network  and  try  again. 

We  are  now  faced  with  the  problem  of  what  to 

Its  only  possible  governor  ac­

do  with  our  ACT. 
cording  to  the  pertnissable  dependencies  is  ' I '. 
In  order  to  attach  the  ACT  to  I  we  employ  an  En­
glish  heuristic  which  states, 
' if  you  cross  back 
over  the  =  you  have  created  a  time  T  phrase,  the 

«=» 

actor  of  which  is  the  previous  actor'.  We  now 
re-enter  the  dictionary  entry  for  ' f l y'  and  dis­
cover  that  ' i'  is  an  animal  and  thus  f i ts  under 
the  second  conceptual  realizate  for  ' f l y '.  We 
place  this  realizate  in  the  network.  When  we  en­
counter  the  'to  N1  construction  we  recognize  a 

(In  a  dialogue  program we might  well  discover  that 
this  was  not  the  intended  network  at  a l l,  and  the 
speaker  believed  that  'Grand  Canyon1  had  'flown'. 
We  could  then  correct  our  error.  However,  we 
certainly  would  not  want  to  assume  that  he  had 
intended  the  latter  interpretation.) 

The  important  point  here  is  that  the  system 

analyzes  this  sentence  in  the  same  way  as  a  human 
does  insofar  as  we  can  t e l l.  That  i s,  we  could 
predict  a  chuckle  on  the  part  of  the  speaker  based 
upon  an  attempt  to  attach  two  concepts  that  ac­
cording  to  experience  could  not  be  attached. 
other  words,  we  try  to  make  the  'Grand  Canyon  f l y' 
but  we  cannot. 

In 

What  is  occurring  here  is  that  we  are  making 
use  of  a  stratified  linguistic  system  in  order  to 
make  predictions.  This  system  has  a  sentential 
and  a  conceptual  level.  Each  level  has  i ts  own 
rules  for  permissable  constructions  (syntax)  and 
acceptable  particular  choices  within  a  given  con­
struction  (semantics). 
In  the  analysis  operation 
the  sentential  syntax  allows  'Grand  Canyon  flying' 
as  do  the  conceptual  dependency  rules  (or  concep­
tual  syntax).  But  the  conceptual  semantics  dis­
allows  the  proposed  combination  and  forces  the 
parser  to  try  another  dependency  instead. 
case,  the  prediction  of  the  syntax  has  fooled  us 
but  the  conceptual  predictions  have  corrected  the 
matter.  The  conceptual  predictions  can  direct  the 
analysis  once  an  ACT  is  found. 
In  this  case,  when 
'go' 
known  that  a  directive  case  w i ll  occur  conceptu­
ally.  The  incoming  prepositional  phrase  Is  placed 
in  i ts  proper  slot  by  the  parser  since  it 
what  it  is  looking  for  at  this  point. 

is  discovered  to  be  the  underlying  ACT  it  is 

In  this 

'knows' 

Session No.  10 Computer  Understanding I (Communication) 

449 

I I I.  Associations 

A  program  is  running  that  w i ll  do  what  has 
been  stated  so  far  for  a  testing  vocabulary  of 
about  250  verbs  and  for  a  f a i r ly  large  range  of 
sentence-types. 

But  understanding  natural  language  is  more 

than  recognizing  the  conceptual  content  of  a  given 
sentence.  One  problem  that  needs  to  be  handled  is 
that  of  extracting  the  presupposed  information  im­
p l i c it  in  an  utterance. 

Consider  the  sentence  'I  like  books'.  The 
is  not  an  allowable 

analysis  'I  =  like  £  books' 
construction  conceptually  because  the  ACT  (action) 
' l i k e'  is  of  two  possible  conceptual  types,  each 
with  i ts  own  semantic  restriction.  As  what  we 
call  EACT  (emotion  ACT), 
' l i k e'  allows  conceptual 
objects  as  shown  above  by  ' O books'  but  requires 
that  these  objects  be  of  the  class  'animal1.  The 
other  sense  of  ' l i k e'  is  conceptually  an  SACT 
(state  ACT)  which  requires  an  entire  conceptual­
ization  as  object.  A  conceptualization  must  have 
an  ACTOR  and  an  ACTION  at  the  least  and  we  are 
thus  faced  with  the  problem  of  uncovering  these 
in  the  analysis  of  the  above  sentence.  We  have 
then: 
We  know  that  'books'  is  part 

of  this  conceptualization  and  by  the  heuristics 
of  the  conceptual  dependency  system  we  know  that 
'I' 
is  as  well.  The  problem  is  what  arrangement 
and  what  ACT  is  correct. 

The  ACT  'read'  is  listed  in  our  system  as 

requiring  a  'human'  subject  and  an  object  that  is 
chosen  from  the  set  of  objects  that  have  been  made 
by  men  for  exactly  the  purpose  of  'reading'  them. 
That  i s,  while  we  could  l i st  a ll  possible  such 
objects  (books,  newspapers,  etc.)  or  categorize 
them  in  some  a r t i f i c i al  hierarchical  structure, 
conceptually  the  object  of  'reading' 
Is  'that 
which  is  read'.  Specifically  this  class  could 
Include  anything  with  printing  on  it  or  whatever. 
The  point  here  is  that  we  can  call  the  potential 
object  a  member  of  the  class  'read-PP  (where  PP  is 
the  abbreviation  for  conceptual  nominals).  Then, 
in  any  listing  of  the  elements  of  the  world,  their 
semantic  category  is  the  place  that  they  l it  in 
our  ACT-based  model. 
'read-PPO'  denotes  that  it  is 
read-PPo;'  where 
the  conceptual  object  of  the  ACT  'read'.  Then  our 
.  The  only 
I «=>> like 
diagram  becomes: 

'Book'  then,  i s: 

'book:  N; 

thing  missing  is  the  actor,  which  is  ' I'  due  to  a 
heuristic  which  governs  these  situations. 

read  ♦- book 

There  are  conceptual  representations  for  many 
objects  which  can  be  made  in  the  same  way  as  was 
done  for  'book'.  For  example,  consider  ' k n i f e '. 
'Knife'  is  an  instance  of  'cut-PPj',  this  means 
that  it  serves  as  the  object  in  the  instrumental 
conceptualization  in  conceptualizations  involving 
' c u t ';  and  'banana'  is  an  Instance  of  'eat-PP0o'. 

There  is  a  second,  more  complex,  type  of  rec-

ognition  of  implicit  information  that  is  a  part 
of  understanding.  For  example,  the^  sentence  'I 
fear  bears1  is  directly  related  to  the  harm  that 
a  bear  might  do.  That  i s,  a  correct  analysis 
might  be: 

.  Here  again,  this 

fear 

I  • 

action  ('fear'  is  related  to  a  conceptualization 
rather  than  one  particular  concept.) 
(In  other 
words,  you  'fear'  consequences  not  properties.) 
What  would  seem reasonable  here  is  that  'fear' 
and  'hurt'  are  directly  relatable.  Now  it  is 
possible  to  think  of  this  relationship  (fear-hurt) 
as  some  relatable  grouping of  ACTIONS.  But  this 
is  not  the  case.  Conceptually,  'hurt'  is  a men­
tal  ^tate attribute  and  not  an ACT.  Mental  state 
attributes  (denoted  2PA)  are nearly  always  ex­
pressed  in English  as  transitive verbs.  The  ob­
ject  sententially  is  often  the  subject  of  the  at­
tributive  statement,  when ZPA's  are used  in a 
sentence  (e.g.  'x hurt  y1  means  'y  is  hurt'.) 
This means  that  certain ACT's  like  fear  should 
have  consequent  2PA's  that  they  are  related  to. 
We can carry this one step further.  The reason 
that  'hurt'  is  'feared'  is  because  of  another  con­
sequence, namely  'death'.  Now this may seem a 
little  melodramatic,  but  it  does  in  fact  seem  to 
be  the  case.  In other words,  a  lot  of  'hurt'  leads 
to  'death'.  Now  'death*  is  conceptually  the  IACT-
'die'.  So we have here a relationship from SACT 
(fear)  to  2PA  (hurt)  to  IACT  (die). 
there  is  one  element missing  here,  namely  the  'do' 
associated  with  'bear'.  This  'do'  may be  'claw', 
'eat'  or  some  other  physical  action  that  takes 
instrumental  case  (PACT) .  So what we have is 
the  set of relations  SACT -  PACT -  ZPA -  IACT 
(see  Weber  (13)  for detailed  explanation  of  these 
terms).  This  relation  of  conceptualization  types 
always holds  for  any ACT. 

In  fact, 

The main  point  here  is  analogous  to  that  made 
in  the  previous  section:  Whenever  certain  concepts 
are  encountered  other  concepts  are  actually  present 
in the underlying conceptualization and must be 
ascertained before  a reasonable  claim of  under­
standing can be made. 

The relationship beLween SACT -  [variable 

ACT]  -  ZPA  -  IACT  essentially  states  that  people 
do  and  say  things  [or  reasons  or desired eliects. 
Thus, actions have their consequences in new men­
tal  states  for  a  doer  or  receiver  of  this  action 
and  these  lead  to new  actual  states. 
talk  of  actual  states  it  will  be  necessary  to 
explain  the  notion  of  variant  levels  within  a 
conceptual base.  Celce and  Schwarcz  (1)  and 
Tesler  (12)  discuss  the  notion  that  certain  con­
cepts have both mental  and physical  realities. 
For  example,  you read a  'mental book'  but  l i ft a 
'physical book'.  This dichotomy can be broadened 
to  include  levels  of  a  social,  emotional  and  spir­
itual  nature  as  well  according  to Tesler.  Actions, 
for example,  can be  seen to have different but 

In order  to 

450 

Session No.  10 Computer  Understanding I (Communication) 

related  meanings  on  each  level.  Consider  'go'. 
Physically  .'go'  means  to  go  from  one  place  to 
another.  This  has  i ts  analogue  socially  in  two 
ways.  On  the  one  hand,  you  can  go  to  a  'social 
place'  e.g.  a  convention.  On  the  other  you  can 
go  to  a  place  within  society  i.e.  social  climbing 
('He  went  upwards  socially  after  his  election'.). 
One  can  'go1  emotionally  ('After  his  death,  I 
went  to  a  state  of  depression1.).  Mentally  we 
have, 
And  spiritually  we  have  the  common  'You  w i ll  go 
to  heaven.' 

'My  thoughts  went  to  the  days  in  Tangiers.' 

The  reason  for  this  apparent  digression  is 
that  certain  ACT's  relate  to  certain  ZPA's  and 
IACT's  according  to  the  variant  level  of  the  ACT. 
Thus,  the  statement  'I  was  afraid  that  the  bear 
would  claw  me'  is  a  statement  of  physical  dimension 
where  the  notion  that  'physical  clawing  leads  to 
physical  hurt  leads  to  physical  death'  holds.  Now 
the  fear  of  death  that  is  implied  here  does  not 
indicate  that  the  object  is  necessarily  aware  of 
his  fear  of  death. 

This  same  kind  of  ACT  -  ZPA  -  IACT  statement 

can  be  said  to  exist  on  each  variant  level.  Con­
sider  the  statement  'We  are  going  to  take  away  a ll 
your  p o l i t i c al  power  in  this  state'.  The  'take' 
that  is  being  used  here  is  hardly  the  physical 
'take'  (take 

)  used  in  'He  took  my  toy'.  Rather 

i s,  when  something  is  taken  from  one,  the  conse­
quence  is  that  the  'taker' 
is  richer  in  some  way 
and  the  'taken'  is  poorer  in  some  way.  This  is 
the  ZPA  of  attribute  in  this  case.  The  last  con­
sequence  of  'death'  holds  as  well  in  this  case, 
but  here  it  is  'death 
the 

'.  That  is  to  say, 

SOC 

end  result  of  such  an  action  as  stated  above  is 
that  after  his  p o l i t i c al  power  is  taken  away,  he 
can  be  said  to  have  'died'  p o l i t i c a l l y.  The  end 
result  is 

'die 

'. 
SOC 

What  we  are  saying  then  is  that  it  is  pos­

sible  to  get  a  great  deal  more  information  out  of 
one  ACT  then  is  readily  obvious.  On  the  most  ap­
parent  level,  the  notion  of  expected  objects  and 
subjects  and  other  conceptual  case  dependents  can 
be  predicted.  But  more  significantly,  we  can  also 
make  simple  implications  as  a  result  of  the  posi­
tion  of  the  ACT  in  question  with  respect  to  i ts 
relation  to  other  conceptual  consequences.  That 
i s,  we  can  know  the  way  in  which  an  ACT  relates  to 
' l i v i n g'  or  'dying'  on  a  certain  level  and  the 
range  of  human  mental  reactions  on  these  levels  to 
such  an  ACT. 

Consider  the  following  PACT's:  a)  eat,  drink, 

love,  fight,  h i t;  b)  h i t,  cut,  attack, 
The  ACT's  in  l i st  (a)  are  positive  with  respect 

PHYS 

it  is  a  social  'take'  (take 

SOC 
'take'  leads  to  'impoverishment 

physical 

'take' 

leads  to  impoverishment 

).  Now  this  social 

'  just  as  a 

SOC 

'.  That 

PHYS 

to  the  subject.  Those  in  l i st  (b)  are  negative 
with  respect  to  the  object. 

When  we  say  that  an  ACT  is  positive  with 
respect  to  the  object,  we  mean  that  the  subject 
performs  this  ACT  with  the  intention  of  having  a 
good  result  occur  on  the  particular  level  with 
which  we  are  dealing. 

By  the  same  token,  if  an  ACT  is  negative 
with  respect  to  the  object,  we  can  assume  that 
this  ACT's  consequent  effect  on  the  object  is  bad 
for  the  object  and  tends  to  hurt  him  on  the  same 
level  as  the  type  of  ACT  with  which  we  are  dealing. 
That 

'rob'  is  social  and  leads  to  'hurt 

' ). 
SOC 
Statements  of  this  kind  are  assumed  to  have 

i s, 

ordinary  circumstances  prevailing.  While  it  is 
possible  to  envision  circumstances  under  which 
the  supposed  implications  of  an  ACT  do  not  hold, 
for  the  purpose  of  making  predictions  we  assume 
the  most  likely  situation.  Often,  the  likely  im­
plications  were  implicitly  part  of  a  given  utter­
ance.  The  problem  here  is  to  undo  the  basically 
telegraphic  nature  of  natural  language  utterances, 
and  the  possibility  that  we  can  make  errors  in  so 
doing  should  not  surprise  us. 

IV. 

Intentions 

The  relationship  of  conceptualization  types 
and  the  consistency  of  variant  levels  with  these 
types  can  provide  the  basis  of  a  schema  for  dis­
covering  the  intention  of  an  utterance. 

Consider  a  sequence  such  as  this:  Q:  Do  you 

it  is  unreasonable  to  claim  that  the 

In  a  model  of  natural  language  under­

want  a  piece  of  chocolate?  A:  I  just  had  an  ice 
cream  cone. 
standing, 
system  has  understood  the  utterance  unless  it  is  * 
capable  of  producing  for  (A)  not  only  a  conceptual 
diagram  of  the  information  just  stated,  but  also 
something  like  the  answer  'no  I  don't  want  a  piece 
of  chocolate'.  That  is  what  a  human  could  under­
stand  in  the  above  situation  and  it  is  incumbant 
upon  any  so-called  understanding  model  to  under­
stand  the  same. 
before  computers  came  on  the  scene,  in  his  defi­
nition  of  meaning  (4): 
'The  meaning  of  any  sen­
tence  is  what  the  speaker  intends  to  be  understood 
from  it  by  the  listener.') 

(This  was  noted  by  Gardiner, 

We  can  actually  do  this  as  follows:  The 

conceptual  dependency  analysis  of  (Q)  is: 

model  that  we  have  been  discussing  would  be  char­
ged  with  taking  the  conceptual  representation  of 
the  input  and  drawing  the  necessary  implications 
that  can  be  said  to  be  understood  implicitly.  In 
this  case,  chocolate  is  discovered  in  the  dic­
tionary  to  be  an  'eat:PP  '.  The  association  be­
tween  'want'  (SACT)  and  'eat'  (PACT)  f i ts  into 

Session No.  10 Computer Understanding I (Communication) 

451 

the  SACT  -  ACT  -  ZPA  -  TACT  paradigm  on  the  phys­
ical  level  because  of  the  definition  of  'eat'  and 
yields  the  implications  that  the  ZPA  'satiate1  is 
caused  by  the  connection  with  respect  to  the  sub­
ject  of  'want1.  This  gives  us: 

We  can  now  reconsider  the  levels  of  expec­
In 

tation  with  which  we  were  concerned  earlier. 
the  conversation  between  'John'  and  'Fred'  we 
noted  that  the  context  predicts  what  kinds  of 
conceptualizations  are  likely  to  be  asserted.  We 
said  that  what  was  likely  was  that  John  would  say 

Now  it  is  also  true  that  people  eat  for  reasons 
other  than  satiation,  particularly  for  pleasure. 
So  the  causal  connection 

is 

also  a  consequence  of  the  'eat'  conceptualization 
But  this  is  not  necessary  here. 

words  that  would  be  used  here  are  not  at  issue, 
but  only  their  conceptual  content.  Now,  the 
question  i s,  how  do  we  get  a  machine  to  make 
these  predictions? 

The  problem  is  one  of  derivation.  That  i s, 
where  would  this  information  come  from?  Consider 
the  statement  made  by  John  previous  to  the  one 
under  discussion  ( 'I  could  use  a  knife  right  now'). 
This  is  represented  as: 

Now  we  are  ready  to  analyze  the  answer  (A). 
The  conceptual  diagram  associated  with  the  input 
i s: 

icecream.  This  diagram  is 

eat 

1 

cone 

obtained  by  treating  'have'  as  a  dummy  ACT  and 
finding  the  ACT  associated  with  'ice  cream',again 
'eat'  to  put  in  i ts  place.  Here  again, 
plies  the  causal  for  satiation  and  we  have: 

'eat'  im­

Now  we  can  compare  the  question  and  the  answer. 
The  question  can  be  matched  with  the  answer  by 
looking  at: 

the  answer.  Since  'you'  and  ' I'  represent  the 
same  token  in  memory,  the  answer  to  a  question 
about  desired  transition  (t)  lias  been  answered 
with  a  statement  of  completed  transition  ( t f ).  In 
other  words,  we  can  assume  that  we  have,  'do  you 
want  to  be  satiated?',  -  'l  have  just  been  sati­
ated'.  Thus  we  have  the  simple  implied  negative. 
The  point  here  is  that  the  implications  that 
are  to  be  found  in  this  memory  model  are  part  and 
parcel  of  the  understanding  process  and  in  fact 
make  l i t t le  sense  without  them.  We  can  expect 
that  a  natural  language  analysis  system  must  be 
continually  making  these  associative  implications 
in  order  to  be  able  to  use  them  when  they  are 
needed.  What  we  are  doing  is  attempting  to  un­
cover  the  reasons  that  a  given  sentence  was  said. 
In  order  to  correctly  respond  to  an  utterance  it 
is  necessary  to  have  understood  why  that  utter­
ance  was  said. 

Here  the  f i r st  causal  implication  comes  from  the 
SACT  -  ACT  -  fiPA  -  IACT  paradigm,  or,  in  this 
case  -  'want  -  ACT  -  ZPA  -  l i v e '.  Now,  we  can 
say  that  we  have  a  conceptualization  in  the  short-
term  memory  that  w i ll  affect  the  context.  That 
Is, 

John  »  want 

John 

t 
«* 

o 
cut  *- 

T 
•-  knife 

In  order  to  make  accurate  use  of  this  information, 
it  is  necessary  to  have  at  the  system's  disposal 
a  belief  that  could  be  characterized  as  part  of 
the  world  view  expectation.  This  belief  is  of 
the  general  order: 

this  rule  explains  that  if  one  is  angry 
That  i s, 
at  someone  that  means  that  one  doesn't  want  to 
interact  with  that  person.  We  also  need  a  rule 
that  says: 

In  other  words,  if  one  is  hurt  one  wants  to  retal­
iate.  Now  oi  course,  this  rule  is  not  always 
true  for  every  individual.  We  would  like  to  note 

452 

Session No.  10 Computer  Understanding I (Communication) 

the  conditionality  of  this  rule  by  placing  a  'c' 
over  'one2  =  want'  and  then  using  the  rule  if  it 
is  the  case  that  in  our  memory  of  the  individual 
to  whom  we  are  talking  we  have  some  information 
about  previous  actions  of  a  'cause  to  die'nature. 
That  i s,  if  we  know  that  John  already  killed  for 
some  reason,  we  might  guess  that  John  w i ll  retal­
iate  again.  On  the  other  hand  we  might  have  the 
information  that  John  frequently  talks  about 
harming  people,  but  doesn't  do  i t. 

Now  the  question  i s,  who  f i ts  the  following  para 
digm? 

Since,  John  has  said  that  Mary  angered  him,  she-
f i ts  the  paradigm  by  definition  of 
Since,  Fred  has  just  convinced  John  that: 

'angered'. 

we  can  say  that  'Fred'  and  'Mary'  are  in  the  same 
situation  in  the  paradigm.  This  is  done  by  yet 
another  belief  that  says: 

That  i s,  if  one  sides 

with  one's  enemy  then  one  is  angry  at  the  enemy's 
compatriot  also.  Thus  we  can  say  that  John  is 
likely  to  say  that  he  w i ll  k i ll  either  Fred  or 
Mary.  Also,  we  can  say  that  the  context  of  the 
knife  aside,  he  is  likely  to  say  that  he  doesn't 
want  to  interact  with  either  Fred  or  Mary. 

The  important  point  here  is  that  it  is  pos­
sible  to  make  contextual  predictions  as  to  the 
content  of  expected  conceptualizations,  but  that 
this  process  of  prediction  is  based  on  primitive 
beliefs  that  include  generalized  rules  for  oper­
ating  in  the  world,  and  idiosyncratic  beliefs 
about  the  behavior  of  an  individual  in  the  world 
based  upon  one's  view  of  people  and  the  particu­
lar  person  under  discussion. 

Although  it  may  seem  so,  the  number  of  the 
primitive  beliefs  necessary  to  handle  tasks  such 
as  this  is  not  large.  Colby  (2)  and  Morris  (7) 
have  estimated  the  core  beliefs  of  a  human  as 
under  50. 

V.  Conclusion 

It  is  a  nice 

it  destroys  the 

In  order  to  achieve 
I  claim  that  it  is  not  possible  to 

In  order  to  enable  computers  to  use  natural 
language  it  may  be  a  good  idea  to  understand  how 
it  is  that  people  do  these  things  that  we  would 
like  our  machines  to  do. 
this  goal, 
separate  language  from  the  rest  of  the  i n t e l l i­
gence  mechanisms  of  the  human  mind.  Language 
simply  does  not  work  in  isolation. 
idea  that  one  should  in  principle  be  able  to  fully 
describe  and  characterize  language  by  i t s e lf  as 
most  linguists  are  trying  to  do,  but  in  fact  it 
is  as  absurd  an  idea  as  trying  to  understand  the 
workings  of  the  human  mind  by  cutting  off  a  man's 
head  and  taking  a  look  inside.  No  doubt  It  is 
possible  to  find  out  some  things  that  way,  but 
the  separation  is  a r t i f i c i a l, 
very  process  that  we  would  be  trying  to  investi­
gate-.  So  it  is  with  language.  The  ability  oi 
linguists  to  Ignore  this  while  trying  to  sepa­
rate  language  into  neat  formal  rules  has  caused 
an  unbelievable  number  of  unrealistic  studies  to 
take  place  under  the  banner  of  linguistics.  People 
neither  randomly  generate  sentences  nor  do  they 
attempt  to  assign  syntactic  markers  to  input  dis­
course. 
It  is  certainly  true  that  humans  may  per­
form  some  of  the  subtasks  that  are  needed  in  order 
to  have  a  formal  model  do  these  things,  but  the 
overriding  question  is  one  of  purpose.  Since  we 
are  trying  to  enable  computers  to  communicate  with 
people  we  must  deal  with  problems  of  communication 

Session No.  10 Computer  Understanding I (Communication) 

453 

Certain  pairs  of  people  find  it  harder  to  commu­
nicate  than  other  pairs.  This  is  indicative  of 
a  lack  of  certain  common  memory  structures  and 
inference  relations.  We  cannot  understand  some­
body  whose  i n i t i al  assumptions  and  cultural  back­
ground  are  radically  different  from  our  own,  even 
if  we  share  a  common  language.  That  i s,  under­
standing  language  is  a  misnomer  or  at  least  is 
only  a  small  part  of  the  problem.  Understanding 
what  one  has  heard  is  a  complex  process  that  ne­
cessitates  connecting  words  with  certain  concep­
tual  constructions  that  exist  in  one's  memory. 
The  entire  linguistic  process  uses  the  output  of 
such  understanding  and  interpreting  mechanisms 
in  order  to  produce  reasonable  replies  (verbal  or 
not).  What  constitutes  a  reasonable  reply  is  an 
intrinsic  part  of  the  linguistic  process,  but  yet 
is  s t i ll  a  conceptual  process  and  is  therefore  1 
suppose  out  of  the  domain  of  modern  linguistics. 
Yet  it  is  unreasonable  for  it  to  remain  in  that 
scientific  no-man's-land.  A  computer  model  must 
respond  as  well  as  understand.  Of  course,  its 
response  must  be  connected  to  a  powerful  res­
ponding  mechanism  that  is  in  fact  the  point  of 
the  entire  computer  program,  that  i s,  why  the 
program  was  written  in  the  f i r st  place.  These 
then  are  the  problems  of  computer  understanding 
of  natural  language. 

Now,  why  should  it  be  necessary  to  make  a ll 

these  different  predictions  that  have  been  out­
lined  here?  The  answer  is  that  in  a  complete 
automatic  linguistic  system  the  responses  that 
are  generated  w i ll  be  dependent  on  the  corrobo­
ration  of  the  predicted  input  as  compared  to  the 
actual  input  and  the  memory  structure.  That  i s, 
we  respond  differently  to  different  people  saying 
the  same  things,  and  differently  to  the  same  peo­
ple  saying  the  same  things  in  different  contexts. 
These  contexts  include,  physical,  conversational 
and  time  contexts. 
fn  other  words,  no  person  is 
really  the  same  at  any  given  point  in  time  as  he 
was  at  some  other  time  with  respect  to  the  viewer's 
own  memory  model  of  that  person.  So,  1n  some 
sense,  the  context  is  always  different  and  the 
responses  should  always  be  potentially  different 
according  to  the  time  of  the  conversation. 
It  is 
precisely  the  predictive  ability  that  permits  this 
difference  in  response.  And, 
response  is  caused  by  the  difference  in  analysis. 
That  i s,  in  order  to  effectively  analyze  a  given 
linguistic  input, 
it  is  necessary  to  make  predic­
tions  as  to  what  that  input  might  look  l i k e,  com­
pare  the  actual  input  to  the  expected  input  and 
coordinate  both  with  the  memory  model.  Under­
standing  i s,  therefore,  a  complicated  process 
which  cannot  be  reasonably  isolated  into  linguis­
tic  and  memory  components  but  must  be  a  combined 
effort  of  both. 

the  difference  in 

The  remaining  question  i s,  w i ll  the  sugges­

tions  made  here  for  understanding  natural  language 
actually  work?  The  answer  is  that  we  can't  really 
know  that  until  we  are  through.  The  structures 
that  must  be  built  are  large  and  the  number  of 
beliefs  and  implication  rules  arc  also  large.  But 

the  basic  elements  of  the  process  should  be  not 
much  larger  than  has  been  described  here. 

It  should  in  principle,  be  possible  to  use 
the  suggestions  made  here  for  a  beginning  to  at­
tempt  to  truly  understand  input  utterances.  We 
are  beginning  to  extend  our  conceptual  analyzer 
to  incorporate  these  ideas. 

REFERENCES 

1.  Celce,  M.  and  Schwarcz,  R. 

"A  Note  on  Two 

Basic  Semantic  Distinctions",  System 
Development  Corporation,  Santa  Monica, 
California,  April  1969. 

2.  Colby,  K.,  Tesler,  L.,  and  Enea,  II. 

"Experi­

ments  with  a  Search  Algorithm  for  the 
Data  Base  of  a  Human  Belief  Structure", 
in  Proceedings  of  the  International  Joint 
Conlerence  on  AI.  Walker  and  Norton  (eds.) 
Washington,  D.C.,  May  1969. 

3.  Fillmore,  C. 

"The  Case  for  Case",  in  Bach 

and  Harms  (eds.),  Universals  in  Linguistic 
Theory,  Holt,  Rinehart  and  Winston,  New 
York,  1968. 

A.  Gardiner,  A. 

"The  Definition  ol  the  Word  and 

the  Sentence",  British  Journal  of  Psychol­
ogy,  V12,  1922. 

5.  Kuno,  S.,  and  Oettinger,  A. 

"Multiple  Path 
Syntactic  Analyzer",  in  Information  Pro­
cessing  1962,  North  Holland,  Amsterdam, 
1963. 

6.  Lakoff,  G.  "Presuppositions  and  Relative 

in  Automatic  Translation 

Grammaticality", 
and  Mathematical  Linguistics,  NSF-24, 
Harvard  Computation  Center,  Cambridge, 
Massachusetts,  1970. 

7.  Morris,  C.  Signification  and  Signjficance, 

MIT  Press,  Cambridge,  Massachusetts,  1964. 

8. 

9. 

10. 

Schank,  R.,  and  Tesler,  1,. 

"A  Conceptual 

Parser  for  Natural  Language",  in  Pro­
ceedings  of  the  International  Joint  Con­
ference  on  AI.  Walker  and  Norton  (eds.), 
Washington,  D.C.,  May  1969. 

Schank,  R. 

"A  Conceptual  Dependency  Repre­

sentation  for  a  Computer-Oriented  Semantics 
Stanford  A . I.  Memo  83,  Computer  Science 
Department,  Stanford  University,  Stanford, 
California,  March  1969. 

Schank,  R.,  Tesler,  L.,  and  Wrber,  S.  "Spinoza 

I I:  Conceptual  Case-Based  Natural  Language 
Analysis",  Stanford  A.I  Memo  109,  Computer 
Science  Department,  Stanford  University, 
Stanford,  California, 

lanuary  1970. 

11.  Schank,  R. 

"Semantics  in  Conceptual  Analysis", 

Stanford  A . I.  Memo  122,  Computer  Science 

Session No.  10 Computer  Understanding I (Communication) 

Drpartment,  Stanford  University,  Stanford 
California,  May  1970. 

12.  Tesler,  L. 

"New  Approaches  to  Conceptual 

Dependency  Analysis",  in  (10). 

13.  Weber,  S. 

(10). 

"Conceptual  ACT  Categories",  in 

