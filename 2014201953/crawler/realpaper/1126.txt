Using a Hierarchical Bayesian Model to Handle High Cardinality Attributes

with Relevant Interactions in a Classiﬁcation Problem ∗

Jorge Jambeiro Filho

Secretaria da Receita Federal

Jacques Wainer

Instituto de Computac¸ ˜ao

Alfndega do Aeroporto de Viracopos

Universidade Estadual de Campinas

Rodovia Santos Dummont, Km 66

Caixa Postal 6176

Campinas-SP, Brazil, CEP 13055-900

Campinas - SP, Brazil, CEP 13083-970

jorge.ﬁlho@jambeiro.com.br

wainer@ic.unicamp.br

Abstract

We employed a multilevel hierarchical Bayesian
model in the task of exploiting relevant interactions
among high cardinality attributes in a classiﬁcation
problem without overﬁtting. With this model, we
calculate posterior class probabilities for a pattern
W combining the observations of W in the train-
ing set with prior class probabilities that are ob-
tained recursively from the observations of patterns
that are strictly more generic than W . The model
achieved performance improvements over standard
Bayesian network methods like Naive Bayes and
Tree Augmented Naive Bayes, over Bayesian Net-
works where traditional conditional probability ta-
bles were substituted by Noisy-or gates, Default Ta-
bles, Decision Trees and Decision Graphs, and over
Bayesian Networks constructed after a cardinality
reduction preprocessing phase using the Agglom-
erative Information Bottleneck method.

1 Introduction

In most countries, imported goods must be declared by the
importer to belong to one of large set of classes (customs
codes). It is important that each good is correctly classiﬁed,
because each of the customs codes mean not only different
customs duties but also different administrative, sanitary, and
safety requirements. The goal of this project is to develop
a tool that, considering four attributes: declared custom code
(DCC), importer (IMP), country of production (CP) and entry
point in the receiving country (EPR), will estimate, for each
new example, the probability that it involves a misclassiﬁca-
tion. Such estimates will be used latter by a larger system that
allocates human resources for different types of anti-fraud op-
erations.

Our data set has 47826 examples of correct classiﬁcation
(which we will call negative examples) and 590 examples of
misclassiﬁcation (positive examples). In this dataset, the ﬁrst
attribute has 3826 distinct values, the second, 1991 values,
the third, 101 values, and the fourth 52 values.

∗

This work is part of the HARPIA project and is supported by

Brazil’s Federal Revenue

With only 1.2% of positive examples, dataset is imbal-
anced what is usually handled with different resampling
strategies [Chawla et al., 2002]. However, resampling re-
quires retraining the classiﬁers for each different assignment
of costs for false positives and false negatives. In our con-
text, such costs are not known in advance (priorities changes
acording to other anti-fraud demands) and they may vary
from example to example (not all false negatives cost the
same). Thus we cannot train the classiﬁers for all possible
cost assignments in advance.

On the other hand, if we can produce reliable probability
estimates directly from the original dataset the work of the
human resource allocation system becomes much easier. It
can, for example, at any time, deﬁne a selection rate SR that
matches the available human resources for the speciﬁc task
of detecting wrong customs codes considering all other anti-
fraud demands at the moment. The examples to be veriﬁed
will naturally be the SR examples that are most likely to
involve a misclassiﬁcation. The allocation system may also
combine the probability estimates with costs that may vary
from to example to example without any retraining. It be-
comes also unnecessary that customs administration discuss
their cost criteria with us. Thus we decided to concentrate on
Bayesian techniques and not to use resampling or any other
technique that requires retraining when costs change.

Domain specialists claim that there are combinations of at-
tributes values (some involving all of them) that make the
probability of an instance being positive signiﬁcantly higher
then it could be expected looking at each value separately.
They call such combinations critical patterns. To beneﬁt
from critical patterns we would like to use a Bayesian Net-
work (BN)[Pearl, 1988] where all attribute nodes are parents
of the class node. We call such structure the Direct BN Struc-
ture.

In a BN, considering that xji is a possible value for node
Xj and πjk is a complete combination of values for Πj, the
set of parents of node Xj, the vector, θjk, such that θjki =
P (xji|πjk), contained in the CPT of a node Xj, is assessed
from the frequencies of the values of Xj among the training
instances where Πj = πjk. The distributions of Xj given any
two different combinations of values for the parents of Xj are
assumed to be independent and a Dirichlet prior probability
distribution for θjk is usually adopted. Applying Bayes rule

IJCAI-07

2504

and integrating over all possible values for θjk it is found that:

E(θjki) = P (xji|πjk) = Njki + αjki
Njk + αjk
(cid:2)

(1)

where Njki is the number of simultaneous observations of
xji and πjk in the training set, Njk =
∀i Njki, αjki is the
value of one of the parameters of the Dirichlet prior probabil-
ity distribution and αjk =
∀i αjki, the equivalent sample
size of the prior probability distribution.

(cid:2)

The Dirichlet prior probability distribution is usually as-

sumed to be noninformative, what yields to:

P (xji|πjk) = Njki + λ
Njk + λMj

(2)

where all parameters of Dirichlet distribution are equal to a
small smoothing constant λ, and Mj is the number of possible
values for node Xj. We call this Direct Estimation (DE).

In the Direct BN Structure the node whose CPT is to be
estimated is the class node and all other attribute nodes are
its parents. The Conditional Probability Table (CPT) of the
class node in such a structure contains more than 40 × 109
parameters. It is clear that for rarely seen combinations of
attributes the choice of the structure in the Direct BN Struc-
ture and equation 2 tends to produce unreliable probabilities
whose calculation is dominated by the noninformative prior
probability distribution. This suggests that using the Direct
BN Structure and traditional CPTs we will have overﬁtting
problems.

Instead of the Direct BN Structure, we can choose a net-
work structure that does not lead to too large tables. This
can be achieved limiting the number of parents for a network
node. Naive Bayes [Duda and Hart, 1973] is an extreme ex-
ample where the maximum number of parents is limited to
one (the class node is the only parent of any other node). Tree
augmented Naive Bayes (TAN) [Friedman et al., 1997] adds
a tree to the structure of Naives Bayes connecting the non-
class attributes, and thus limits the maximum number of par-
ent nodes to two. However, limiting the maximum number of
parents also limits our ability to capture interactions among
attributes and beneﬁt from critical patterns. Thus, we would
prefer not to do it.

Since the high cardinality of our attributes is creating trou-
ble, it is a reasonable idea to preprocess the data, reducing the
cardinality of the attributes. We can use, for example, the Ag-
glomerative Information Bottleneck (AIBN) method [Slonim
and Tishby, 1999] in this task. However, the process of re-
ducing the cardinality of one attribute is blind in respect to
the others (except to the class attribute), and thus it is un-
likely that cardinality reduction will result in any signiﬁcant
improvement in the ability to capture critical patterns, which
always depend on more than one attribute.

When the number of probabilities to be estimated is too
large when compared to the size of the training set and
we cannot ﬁll the traditional conditional probability tables
(CPTs) satisfactorily and [Pearl, 1988] recommends the
adoption of a model that resorts to causal independence as-
sumptions like the Noisy-Or gate. Using a Noisy-Or the num-
ber of parameters required to represent the conditional prob-
ability distribution (CPD) of a node given its parents, instead

of being proportional to the product of the cardinality of all
parents attributes, becomes proportional to the sum of their
cardinality. However, causal independence assumptions are
incompatible with our goal of capturing critical patterns.

It is possible to use more ﬂexible representations for the
conditional probability distributions of a node given its par-
ents, like Default Tables (DFs) [Friedman and Goldszmidt,
1996], Decision Trees (DTs) [Friedman and Goldszmidt,
1996] and Decision Graphs (DGs) [Chickering et al., 1997].
According to [Friedman and Goldszmidt, 1996], using such
representations together with adequate learning procedures
induces models that better emulate the real complexity of
the interactions present in the data and the resulting network
structures tend to be more complex (in terms of arcs) but
require fewer parameters. Fewer parameter may result in
smaller overﬁtting problems. On the other hand, using tra-
ditional CPTs, we assume that the probability distributions
for a node given any two combinations of values for the par-
ents are independent. If some of these distribution are actu-
ally identical, DTs, DFs and DGs, can reﬂect it and represent
the CPD using a variable number of parameters that is only
proportional to the number of actually different distributions.
Using DTs, DFs or DGs to represent the conditional distri-
bution of a node given its parents, we assume that the prob-
ability distribution of the node given two different combina-
tions of values for the parents may be either identical or com-
pletely independent. It is possible that neither of the two as-
sumptions hold.

In [Gelman et al., 2003] it is asserted that modeling hierar-
chical data nonhierarchically leads to poor results. With few
parameters nonhierarchical models cannot ﬁt the data accu-
rately. With many parameters they ﬁt the existing data well
but lead to inferior predictions for new data. In other words
they overﬁt. In contrast hierarchical models can ﬁt the data
well without overﬁtting. They can reﬂect similarities among
distributions without assuming equality.

Observing an slight modiﬁcation in equation 2 used
in [Friedman et al., 1997] in the deﬁnition of a smoothing
schema for TAN we can see that the data that is used to es-
timate the CPT of any node that has at least one parent is
hierarchical:

P (xji|πjk) = Njki + S · P (xji)

Njk + S

(3)

where S is a constant that deﬁnes the equivalent sample size
of the prior probability distribution. We call this Almost Di-
rect Estimation (ADE). ADE uses the probability distribution
assessed in a wider population to build an informative prior
probability distribution for a narrower population and so it
has a hierarchical nature. Such approach was also used, for
example, in [Cestnik, 1990]. ADE is the consequence of in-
stead of a noninformative Dirichlet prior probability distribu-
tion, adopting a Dirichlet prior probability Distribution where
αjki ∝ P (xji).

ADE gets closer to the true probability distribution, but its
discrimination power is not signiﬁcantly better than DE. It is
a linear combination of two factors Njki/Njk and P (xji).
The second factor is closer to the true probability distribution
than its constant counterpart in Direct Estimation but it is still

IJCAI-07

2505

equal for any combination of values of Πj and thus has no
discrimination power.

ADE jumps from a very speciﬁc population (the set of
training examples where Πj = πjk) to a very general pop-
ulation (the whole training set).
In contrast, we present a
model, that we call Hierarchical Pattern Bayes (HPB), which
moves slowly from smaller populations to larger ones bene-
ﬁting from the discrimination power available at each level.

2 The Hierarchical Pattern Bayes Classiﬁer
HPB is a generalization of ADE that employs a hierarchy of
patterns. It combines the inﬂuence of different level patterns
in a way that the most speciﬁc patterns always dominate if
they are well represented and combines patterns in the same
level making strong independence assumptions and a calibra-
tion mechanism.

HPB works for classiﬁcation problems where all attributes
are nominal. Given a pattern W and a training set of pairs
(X, C), where C is a class label and X is a pattern, HPB
calculates P (Cr|W ) for any class Cr where a pattern is as
deﬁned below:

Deﬁnition 1 A pattern is a set of pairs of
the form
(Attribute = V alue), where any attribute can appear at
most once. An attribute that is not in the set is said to be
undeﬁned or missing.

Deﬁnition 2 A pattern Y is more generic than a pattern W
if and only if Y ⊆ W . If Y is more generic than W , we say
that W satisﬁes Y .

Deﬁnition 3 A pattern Y is strictly more generic than W if
and only if Y ⊂ W .
Deﬁnition 4 The level of a pattern W , level(W ), is the num-
ber of attributes deﬁned in W .
Deﬁnition 5 G(W ) is the set of all patterns strictly more
generic than a pattern W

2.1 The Hierarchical Model
HPB calculates the posterior probability P (Cr|W ), us-
ing a strategy that is similar to Almost Direct Estimation,
but the prior probabilities are considered to be given by
P (Cr|G(W )).

The parameters of the Dirichlet prior probability distrib-
ution used by HPB are given by: αr = S · P (Cr|G(W )),
where S is a smoothing coefﬁcient. Consequently:
P (Cr|W ) = Nwr + S · P (Cr|G(W ))

(4)

Nw + S

Given equation 4,

where Nw is the number of patterns in the training set satisfy-
ing the pattern W and Nwr is the number of instances in the
training set satisfying the pattern W whose class label is Cr.
the problem becomes to calculate
P (Cr|G(W )). Our basic idea is to write P (Cr|G(W )) as a
function of the various P (Cr|Wj) where the Wj are patterns
belonging to G(W ) and calculate each P (Cr|Wj ) recursively
using equation 4.
Deﬁnition 6 g(W ) is the subset of G(W ) whose elements
have level equal to level(W ) − 1.

For example, if W is {A = a, B = b, C = c}, g(W ) is:
{ {B = b, C = c}, {A = a, C = c}, {A = a, B = b} }
We consider that only g(W ) inﬂuences P (Cr|G(W )) di-
rectly, so that P (Cr|G(W )) = P (Cr|g(W )). The inﬂuence
of the other patterns in G(W ) are captured by the recursive
process. The ﬁrst step for the decomposition of P (Cr|g(W ))
in an expression that can be evaluated recursively is to apply
Bayes theorem:

P (Cr|g(W )) = P (g(W )|Cr)P (Cr)

P (g(W ))

∝ P (W1, W2, . . . , WL|Cr)P (Cr)

where W1,W2,. . . ,WL are the elements of g(W ).

we

the

Then

probability
P (W1, W2, . . . , WL|Cr) by the product of the marginal
probabilities:

approximate

joint

P (cid:3)(Cr|g(W )) ∝ P (Cr)

L(cid:3)

j=1

P (Wj |Cr)

(5)

but apply a calibration mechanism:

P (Cr|g(W )) ∝ P (cid:3)(Cr|g(W )) + B.P (Cr)

(6)

where B is a calibration coefﬁcient.

Given equations 5 and 6 we need to calculate P (Wj |Cr).

Applying Bayes theorem:

P (Wj|Cr) = P (Cr|Wj)P (Wj )

P (Cr)

(7)

We estimate P (Cr) using the maximum likelihood ap-
proach: P (Cr) = Nr/N , where Nr is the number of ex-
amples in the training set belonging to class Cr, and N is the
total number of examples in the training set. If it happens
that Nr is zero we cannot use equation 7. In this case we just
deﬁne that P (Cr|W ) is zero for any pattern W .

We know that when we substitute P (Wj|Cr) by the right
side of equation 7 into equation 5 we are able to clear out the
factor P (Wj) because it is identical for all classes, so we do
not need to worry about it.

Since Wj is a pattern, the estimation of P (Cr|Wj ) can
be done recursively using equation 4. The recursion ends
when g(W ) contains only the empty pattern.
In this case
P (Cr|g(W )) becomes P (Cr|{{}}) = P (Cr).

2.2 Calibration Mechanism
In spite of its strong independence assumptions, Naive Bayes
is know to perform well in many domains when only misclas-
siﬁcation rate is considered [Domingos and Pazzani, 1997].
However, Naive Bayes is also know to produce unbalanced
probability estimates that are typically too “extreme” in the
sense that they are too close to zero or too close to one.
In the aim of obtaining better posterior probability distribu-
tions, calibration mechanisms which try to compensate the
overly conﬁdent predictions of Naive Bayes have been pro-
posed [Bennett, 2000; Zadrozny, 2001].

Using equation 5 we are making stronger independence
assumptions than Naive Bayes. Naive Bayes assumes that

IJCAI-07

2506

attributes are independent given the class, what is at least
possible. Equation 5 assumes that some aggregations of at-
tributes are independent given the class. Since many of these
aggregations have attributes in common we know that such
assumption is false. The main consequences of our stronger
and unrealistic assumption are even more extreme probabil-
ity estimates than Naive Bayes’ ones. This is compensated
by the calibration mechanism in equation 6. This calibration
mechanism is analogous to the one used in [Zadrozny, 2001]
in the calibration of decision tree probability estimates.

2.3 Selecting HPB Coefﬁcients
Equations 4 and 6 require respectively the speciﬁcations of
coefﬁcients S and B.
In the classiﬁcation of a single in-
stance, these equations are applied by HPB in the calculation
of P (Cr|W ) for several different patterns, W . The optimal
values of S and B can be different for each pattern.

In the case of the B coefﬁcients, we use an heuristic mo-
tivated by the fact that the level of any pattern in g(W ) is
level(W ) − 1. The higher such level is, the more attributes
in common the aggregations have, the more extreme proba-
bility estimates are and the stronger must be the effect of the
calibration mechanism. Thus, we made the coefﬁcient B in
equation 6 equal to b(level(W ) − 1) where b is an experi-
mental constant.

In the case of the S coefﬁcients, we employ a greed opti-
mization approach that starts from the most general pattern
family and move toward the more speciﬁc ones, where a pat-
tern family is the set containing all patterns that deﬁne exactly
the same attributes (possibly with different values).

Assuming that the S coefﬁcients have already been ﬁxed
for all pattern families that are more generic than a family
F , there is a single S coefﬁcient that needs to be speciﬁed
to allow the use of equation 4 to calculate P (Cr|W ) where
W is any pattern belonging to F . We select this coefﬁcient,
using leave one out cross validation, in order to maximize the
area under the hit curve that is induced when we calculate
P (Cr|W ) for all training patterns, W , in F .

3 Experimental results
All classiﬁcation methods were tested by the Weka Experi-
menter tool [Witten and Frank, 1999] using 5 fold cross val-
idation. We compared classiﬁers built using the following
methods:

• HPB: HPB as described in this paper;

• NB: Naive Bayes;

• Noisy-Or: BN with the Direct BN Structure using Noisy-Or instead of a CPT;

• TAN: TAN with traditional CPTs;

• ADE: Almost Direct Estimation. BN with the Direct BN Structure and the smoothing schema

described in [Friedman et al., 1997];

• DE: Direct Estimation. BN with the Direct BN Structure and traditional CPTs;

• AIBN/TAN: TAN with traditional CPTs trained over a dataset where cardinality reduction

using AIBN was previously applied;

• DG CBM: BN with DGs. Complete splits, binary splits and merges enabled;

• DG CB: BN with DGs. Complete splits and binary splits enabled;

• DG C: BN with DGs. Only complete splits enabled;

• DG CM: BN with DGs. Complete splits and merges enabled;

• HC DT: BN with Decision Trees learned using Hill Climbing (HC) and MDL as the scoring

metric;

• HC DF: BN with Default Tables learned using HC and MDL.

• PRIOR: Trivial classiﬁer that assigns the prior probability to every instance.

All models involving DGs were constructed follow-
ing [Chickering et al., 1997]. The models involving DFs and
DTs were constructed following [Friedman and Goldszmidt,
1996] using the MDL scoring metric.

We tried different parameterizations for each method and
sticked with the parameter set that provided the best results,
where best results mean best area under the hit curve 1 up to
20% of selection rate (AUC20) 2. In the y axis, we chose to
represent the Recall = NT rueP ositives/NP ositives, instead
of the absolute number of hits, because this does not change
the form of the curve and makes interpretation easier. We rep-
resented the selection rate in log scale to emphasize the begin-
ning of the curves. Besides using the hit curve, we compared
the probability distributions estimated by the models with the
distribution actually found in the test set using two measures:
Root Mean Squared Error (RMSE) and Mean Cross Entropy
(MCE). Figure 1, table 1 and table 2 show our results.
Selection of method parameters is explained below:
The smoothing coefﬁcients employed by HPB are all au-
tomatically optimized. Such optimization involves a leave
one out cross validation that takes place absolutely within
the current training set (the 5 fold cross validation varies the
current training set) eliminating the possibility of ﬁtting the
test set. The B coefﬁcients are deﬁned by the heuristic de-
scribed in section 2.3 and by the constant b. We varied b
over the enumeration {0.5, 1.0, 1.5, 2.0, 2.5, 3.0} and sticked
with 2.0, which was the constant that produced the best re-
sults in a 5 fold cross validation process. To avoid the effects
of ﬁne tuning, we reshufﬂed the data set before starting an-
other 5 fold cross validation process. The HPB results that
we present here came from the second process.

HPB
DG BSM CB
AIBN/TAN
NB
TAN
PRIOR

1

8

.

0

6

.

l
l

a
c
e
R

0

4
0

.

2

.

0

0

.

0

0

10

20

Selection rate

40

70

Figure 1: Selection Rate X Recall (to avoid pollution we
only present curves related to a subset of the tested meth-
ods)

The optimization of AIBN/TAN involves 3 parameters:
The TAN smoothing constant (ST AN ), the AIBN smooth-

1We employed hit curves, instead of the more popular ROC
curves, because they match the interests of the customs adminis-
trations directly, i.e, the human resource allocation system deﬁnes
a selection rate and needs an estimate for the number of positives
instances that will be detected.

2All selection rates of interest are below 20%

IJCAI-07

2507

ing constant SAIBN , and the minimum mutual informa-
tion constant M M I. Varying ST AN over the enumera-
tion {0.01, 0.05, 0.1, 0.2, 0.5, 1.0, 2.0}, SAIBN over the enu-
meration [0.1, 0.2, 0.5, 1.0] and M M I over the enumeration
{0.99, 0.999, 0.9999} we found that the best results are ob-
tained with the triple BestT riple = (Stan = 0.5, SAIBN =
0.5, M M I = 0.999). We did not cover the whole grid
but since we did not observe any abrupt variations in hit
curves and since we covered all immediate neighbors of the
BestT riple we believe that such exhaustive covering was not
necessary.

Method
HPB
TAN
AIBN/TAN
NB
Noisy-Or
BNDG CB
BNDG CBJ
BNDG C
ADE
DE
BNDG CJ
HC DF
HC DT
PRIOR

1%

2%

5%

10%

20%

17.8±3.2 25.4±1.3 43.2±2.3 56.4±2.1 72.3±5.0
8.8±2.6 17.4±1.3 34.0±2.0 48.6±3.3 67.1±3.4
10.8±2.3 17.2±2.7 32.2±2.7 47.6±3.2 68.2±2.7
8.8±0.9 14.2±3.1 28.9±3.9 47.4±4.6 65.4±5.8
8.6±2.1 15.2±2.1 30.3±1.5 45.9±3.3 61.5±1.5
17.6±3.4 21.8±4.5 28.6±3.3 40.8±4.8 53.7±6.5
14.7±2.6 20.6±3.0 32.2±3.5 40.6±2.9 51.5±2.6
9.1±2.2 12.2±2.5 21.1±2.9 30.1±2.2 46.4±1.6
14.0±2.8 15.4±2.8 20.5±2.4 28.1±3.3 43.4±4.0
10.2±2.0 12.0±2.5 18.1±2.2 24.7±3.1 41.1±3.6
7.8±0.7 15.5±3.7 24.0±2.4 39.3±3.4
5.0±3.0 10.8±3.9 22.2±3.1 35.4±1.8
6.7±2.4 11.5±2.5 24.7±3.8
1.3±1.1
4.2±0.0 10.2±0.0 20.3±0.0
1.7±0.0

3.7±0.7
4.0±1.8
1.0±1.0
0.8±0.0

Table 1: Recall for different selection rates with std. dev.

Method
HPB
TAN
AIBN/TAN
NB
Noisy-Or
BNDG CB
BNDG CBJ
BNDG C
ADE
DE
BNDG CJ
HC DF
HC DT
PRIOR

AUC

AUC20

MCE

RMSE

Parameterization
b = 2.0
4.0±0.1
84.5±1.6 53.5±2.3 10.6±0.0
7.1±0.4
s = 0.025
82.2±0.9 46.2±2.5 14.1±0.8
5.3±0.3 BestT riple
82.1±1.3 46.0±1.2 12.5±0.5
6.6±0.2
s = 0.025
81.0±2.1 43.6±3.4 14.5±0.1
inf inity
78.2±0.9 43.0±1.6 11.9±0.0
6.2±0.2
68.4±3.7 40.1±3.7 11.4±0.1
7.1±1.2
70.9±2.7 39.2±2.5 11.7±0.1
4.6±0.1
70.4±2.0 30.1±1.7 11.0±0.1
73.7±1.1 28.7±3.0 11.1±0.2
4.9±0.1
72.7±1.3 25.9±2.7 37.5±0.0 31.6±0.0
4.7±0.1
68.5±1.4 24.2±2.2 11.1±0.1
4.6±0.0
62.9±3.4 21.3±1.8 10.9±0.0
51.8±0.5 12.9±1.8 10.9±0.0
4.7±0.0
4.7±0.0
50.0±0.0 10.2±0.0 10.9±0.0

s = 0.5
s = 0.1
s = 0.01
s = 0.025
s = 2.0
s = 0.01
s = 0.05
s = 0.25

Table 2: Area Under Curve, Accuracy of Probability Esti-
mates and Optimal parametrization

Noisy-or and PRIOR have no parameters. The optimiza-
tion of all other methods involves only the smoothing con-
stant, which, in all cases, was exhaustively varied over the
enumeration {0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.0}. This
enumeration covers different magnitudes for the smoothing
constant and at the same time avoids ﬁne tuning.

Naive Bayes and Noisy-Or are both unable to capture inter-
actions among the attributes and cannot explore critical pat-
terns. This explains their performance in the very beginning
of the hit curve. Tree Augmented Naive Bayes explores in-
teractions among some attributes and performed better than
Naive Bayes or Noisy-Or. However, it cannot beneﬁt from
some critical patterns involving many attributes that are deci-
sive at the selection rate of 1% and 2%.

Applying cardinality reduction to the attributes before con-
structing the TAN model did not lead to any signiﬁcant im-
provements in the hit curve.

Substituting the traditional CPTs of Bayesian Network by
Decision Trees, Default Tables and Decision Graphs with bi-
nary splits disabled only made the hit curves worse. The

learned Default Tables included very few rows. The learned
Decision Trees and Decision Graphs involved very few splits.
As a consequence, in all cases, the resulting models had little
discrimination power.

Using Decision Graphs with binary splits enabled, the most
critical patterns were separated from the others, what re-
sulted in a signiﬁcant improvement in the beginning of the
hit curves. The other patterns were, almost all, left together
what resulted in loss of discrimination power for selection
rates above 5%.

Hypothesis tests, show that HPB is signiﬁcantly better than
all other classiﬁers in what regards to AUC, AUC20, RMSE
and MCE. We also performed Hypothesis tests for every se-
lection rate from 1% to 100% in steps of 1%. HPB is signif-
icantly better than all other classiﬁers for every selection rate
below 30% with the exceptions that it is not signiﬁcantly bet-
ter than: TAN in [17%, 19%] and [27%, 28%]; AIBN TAN in
[18%, 21%] and [24%, 28%]; BNDG CBJ at 1%; BNDG CB
at 1% and 2%.

HPB beneﬁts from critical patterns involving many or even
all attributes but also considers the inﬂuence of less speciﬁc
patterns. As a consequence, it performs well for any selection
rate.

4 Conclusions

In the domain of preselection of imported goods for veriﬁ-
cation some combinations of attribute values can constitute
critical patterns whose inﬂuence over the probability of ﬁnd-
ing a positive instance is very signiﬁcant. Due to the high
cardinality of the attributes in this domain, exploiting such
patterns without overﬁtting is challenging. We addressed the
problem using HPB a novel classiﬁcation method based on a
multilevel hierarchical Bayesian model.

HPB was shown capable of capturing the inﬂuence of crit-
ical patterns without overﬁtting and without loosing discrim-
ination power after the exhaustion of critical patterns in the
test set. HPB resulted in a hit curve that is almost unambigu-
ously better than any of the other methods. HPB also pro-
duced better probability estimates according to two accuracy
measures (table 2).

HPB was only validated in a specialized domain, however,
its equations are too simple to reﬂect any particularities of
the domain, except that it is characterized by few high cardi-
nality attributes and relevant interactions among them. Thus
the use of HPB may be a good option for domains with the
same characteristics or, at least, provide some light on how to
develop good models for such domains.

HPB training time is exponential in the number of at-
tributes, linear in the number of training instances and in-
dependent of the attributes cardinality. Thus HPB is only
applicable to domains where there are few attributes, but in
such domains it is much faster than methods whose training
time depends on the cardinality of the attributes.

HPB is not a full Bayesian model in the sense of [Gel-
man et al., 2003], where the parameters associated with a
sub-population are assumed to be drawn from a general dis-
tribution and the calculation of all involved probability dis-
tributions is done at once considering all available evidence.

IJCAI-07

2508

Instead, HPB estimates the probability distributions for the
more general populations ﬁrst and use the results in the es-
timation of the probability distributions related to the more
speciﬁc populations. HPB is a generalization of the smooth-
ing techniques used in [Cestnik, 1990] and [Friedman et al.,
1997]. In the sense of [Gelman et al., 2003], it is an empirical
model.

Hierarchical Bayesian models have been widely used in
the marketing community under the name of Hierarchical
Bayes [Allenby et al., 1999; Lenk et al., 1996]. These mod-
els have also been used in medical domains [Andreassen et
al., 2003] and robotics [Stewart et al., 2003]. However, we
are not aware of any hierarchical Bayesian model that can be
employed to handle high cardinality attributes with relevant
interactions in a classiﬁcation problem. This makes HPB rel-
evant. Moreover, HPB differs from other models by dealing
with a multi level hierarchy recursively and also handling the
fact that one sub-population is contained by several overlap-
ping super-populations and not only by one super-population.
Based on the literature [Friedman and Goldszmidt, 1996],
one can expect that Bayesian Networks with Default Tables,
Decision Trees or Decision Graphs can emulate the real com-
plexity of the interactions present in the data with without
serious overﬁtting problems. Another contribution of this pa-
per is to show that BNs with DFs, DTs or DGs, in spite of
their theoretical motivations, actually do not result in better
overall performance than simpler methods like NB or TAN,
in a practical domain where their abilities are truly necessary.
Preprocessing the data reducing the cardinality of the
attributes using the Agglomerative Information Bottleneck
method did not result in any signiﬁcant improvements in the
hit curves.

Our present mechanism for selecting the smoothing and
the calibration coefﬁcients in HPB equations is too simplistic.
We leave its improvement as future work.

References

[Allenby et al., 1999] Greg M. Allenby, Robert P. Leone,
and Lichung Jen. A dynamic model of purchase timing
with application to direct marketing. Journal of the Amer-
ican Statistical Association, 94(446):365–374, 1999.

[Andreassen et al., 2003] Steen Andreassen, Brian Kris-
tensen, Alina Zalounina, Leonard Leibovici, Uwe Frank,
and Henrik C. Schonheyder. Hierarchical dirichlet learn-
ing - ﬁlling in the thin spots in a database. In Michel Do-
jat, Elpida T. Keravnou, and Pedro Barahona, editors, Pro-
ceedings of the 9th Conference on Artiﬁcial Intelligence in
Medicine (AIME), volume 2780 of Lecture Notes in Com-
puter Science, pages 204–283. Springer, 2003.

[Bennett, 2000] Paul N. Bennett. Assessing the calibration of
naive bayes’ posterior estimates. Technical Report CMU-
CS-00-155, School of Computer Science, Carnegie Mel-
lon University, 2000.

[Cestnik, 1990] B. Cestnik. Estimating probabilities: a cru-
cial task in machine learning. In Proceedings of the Euro-
pean Conference on Artiﬁcial Intelligence, pages 147–149,
1990.

[Chawla et al., 2002] Nitesh V. Chawla, Kevin W. Bowyer,
Lawrence O. Hall, and W. Philip Kegelmeyer. Smote:
Synthetic minority over-sampling technique. Journal of
Artiﬁcial Intelligence and Research, 16:321–357, 2002.

[Chickering et al., 1997] David Maxwell Chickering, David
Heckerman, and Christopher Meek. A bayesian approach
to learning bayesian networks with local structure. Tech-
nical Report MSR-TR-97-07, Microsoft Research, Red-
mond, WA 98052, 1997.

[Domingos and Pazzani, 1997] Pedro

and
Michael J. Pazzani. On the optimality of the sim-
ple bayesian classiﬁer under zero-one loss. Machine
Learning, 29(2-3):103–130, 1997.

Domingos

[Duda and Hart, 1973] Richard O. Duda and Peter E. Hart.
Pattern Classiﬁcation and Scene Analysis. Wiley, New
York, 1973.

[Friedman and Goldszmidt, 1996] Nir Friedman and Moises
Goldszmidt. Learning bayesian networks with local struc-
ture. In Proceedings of the Twelfth Conference on Uncer-
tainty in Artiﬁcial Inteligence (UAI), pages 252–262, San
Francisco, CA, 1996. Morgan Kaufmann Publishers.

[Friedman et al., 1997] Nir Friedman, Dan Geiger, and Moi-
ses Goldszmidt. Bayesian network classiﬁers. Machine
Learning, 29(2-3):131–163, 1997.

[Gelman et al., 2003] Andrew B. Gelman, John S. Carlin,
Hal S. Stern, and Donald B. Rubin. Bayesian Data Analy-
sis. Chapman and Hall, second edition, 2003.

[Lenk et al., 1996] P. Lenk, W. DeSarbo, P. Green, and
M. Young. Hierarchical bayes conjoint analysis: recov-
ery of part worth heterogeneity from reduced experimental
designs. Marketing Science, 15:173–191, 1996.

[Pearl, 1988] Judea Pearl. Probabilistic Reasoning in Intel-
ligent Systems: Networks of Plausible Inference. Morgan
Kaufmann Publishers Inc., 1988.

Agglomerative information bottleneck.

[Slonim and Tishby, 1999] Noam Slonim and Naftali
In
Tishby.
Advances in Neural Information Processing Systems 12
(NIPS), pages 617–623, Denver, Colorado, USA, 1999.
The MIT Press.

[Stewart et al., 2003] Benjamin Stewart, Jonathan Ko, Dieter
Fox, and Kurt Konolige. The revisiting problem in mobile
robot map building: A hierarchical bayesian approach. In
Christopher Meek and Uffe Kjærulff, editors, Proceedings
of the 19th Conference in Uncertainty in Artiﬁcial Intel-
ligence (UAI), pages 551–558, Acapulco, Mexico, 2003.
Morgan Kaufmann.

[Witten and Frank, 1999] Ian H. Witten and Eibe Frank.
Data Mining: Practical Machine Learning Tools and
Techniques with Java Implementations. Morgan Kauf-
mann Publishers Inc., 1999.

[Zadrozny, 2001] Bianca Zadrozny. Reducing multiclass to
binary by coupling probability estimates. In Proceedings
of the Advances in Neural Information Processing Systems
14 (NIPS), Cambridge, MA, 2001. MIT Press.

IJCAI-07

2509

