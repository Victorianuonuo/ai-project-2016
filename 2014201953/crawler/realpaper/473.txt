On the Foundations of Expected Expected Utility 

Craig  Boutilier 

Department of Computer Science 

University  of Toronto 

Toronto, ON, M5S 3H5, CANADA 

cebIy@cs.toronto.edu 

Abstract 

Intelligent  agents  often  need  to  assess  user  utility 
functions  in  order  to  make  decisions  on  their  be-
half,  or  predict  their  behavior.  When  uncertainty 
exists over the precise nature of this utility function, 
one can model this uncertainty using a distribution 
over utility functions.  This view lies at the core of 
games with  incomplete  information and,  more  re(cid:173)
cently, several proposals for incremental preference 
elicitation.  In  such  cases,  decisions  (or predicted 
behavior) are based on computing the expected ex(cid:173)
pected utility (EEU) of decisions with respect to the 
distribution  over  utility  functions.  Unfortunately, 
decisions made under EEU are sensitive to the pre(cid:173)
cise  representation  of the  utility  function.  We  ex(cid:173)
amine  the  conditions  under  which  EEU  provides 
for sensible decisions by appeal to the foundational 
axioms of decision theory.  We also discuss the im(cid:173)
pact these conditions have on the enterprise of pref(cid:173)
erence elicitation more broadly. 

foundations  of  decision 

Introduction 
the 

1 
Most  work  on 
theory— 
specifically  on  the justification  of expected  utility—has  fo(cid:173)
cused on personal decision  making,  that  is,  settings where a 
decision  is  being  made  by  the  "holder"  of the  utility  func(cid:173)
tion.  Of course  the  decision  maker  may  not be  fully  aware 
of (or  have  fully  articulated)  her  utility  function.  The  pro(cid:173)
cess  of articulation  is  complex,  and  much  work  in  decision 
analysis deals with preference elicitation and decision fram(cid:173)
ing to help the decision maker formulate her decision problem 
[11].  However, this work  is primarily concerned with elicit(cid:173)
ing  enough  information  about  preference  tradeoffs  to  allow 
an  (approximately) optimal  decision  to  be  made.  While  an 
analyst can  never be  sure  about the  true  nature  of the  deci(cid:173)
sion maker's utility function, this uncertainty is not generally 
characterized explicitly, though its impact is often minimized 
though sensitivity analysis and related techniques. 

Recent  emphasis  has  been  placed  on  the  development  of 
automated  decision  tools,  where  a  decision  is  being  made 
on  behalf  of  a  user  whose  utility  function  is  imprecisely 
known.  As  in  goal  programming  or  other  forms  of  inter(cid:173)
active  optimization,  a  space  of possible  utility  functions  is 

usually  maintained (often by  imposing constraints on  trade(cid:173)
off weights).  A  decision  can  be  made  based  on  this  set  of 
feasible  utility  functions.  For example, Parcto optimal deci(cid:173)
sions  can  be  identified  [21;  18],  or models based  on  mini-
max regret can be used to choose a specific decision [11; 2; 
20].  In  each  of these  models,  the  uncertainty  regarding the 
utility function is characterized by the feasible utility set. 

Somewhat less common is work in which the system's un(cid:173)
certainty  about  a  user's  utility  function  is  quantified  proba(cid:173)
bilistically.  Some recent examples include [5;  6;  1].  In this 
work,  a  distribution  over  utility  functions  is  assumed.  The 
expected utility of a decision is determined not just by taking 
expectation  over the  outcomes  of that  decision,  but  also  ex(cid:173)
pectation over the space of possible utility functions.  We use 
the term expected expected utility  (EEU) to denote the  value 
of a decision computed in this way.  Elicitation strategies can 
be  informed  using  the  current distribution  over utility  func(cid:173)
tions.  For example, value of information can be used to de(cid:173)
termine  whether  the  improvement  in  decision  quality  given 
by  a  piece  of  information  outweighs  the  cost  of obtaining 
that information.  Thus, characterizing one's uncertainty over 
possible utility functions in a probabilistic fashion, and using 
EEU to determine decision quality, has much to recommend 
it  from the point of view of elicitation. 

Decision  making  using distributions  over utility  functions 
has  been  considered  in  other contexts.  For example,  Cyert 
and de Groot consider problems in sequential decision mak(cid:173)
ing  in which uncertainty  in the underlying utility  function is 
represented  probabilistically  [8;  9].  Fishbum  [10]  also  ad(cid:173)
dresses this problem (as we  discuss below).  Harsanyi's for(cid:173)
mulation of games with  incomplete  information as Bayesian 
games  [12;  13]  relies  critically  on  distributions  over payoff 
functions,  and  virtually  the  entire  literature  on  in  this  area 
adopts this perspective [7;  15].1 

In all  of this  work,  the  EEU  concept is  used  to determine 
the  value  of decisions  in  the  context  of an  uncertain  utility 
function.  Unfortunately, while EEU has an intuitive appeal, 
this  scheme  is  sensitive to positive  affine transformations of 

'in some sense, much work in collaborative filtering [3; 16] and 
related models [4] can be viewed as incorporating distributions over 
utility functions.  However,  these are used for purposes of classi(cid:173)
fication (i.e., determining a unique utility function for a particular 
user) and generally uncertainty in utility is not accounted for when 
making decisions. 

DECISION THEORY 

285 

It  is  well  known  that  utility  functions  are  invariant under 
positive affine transformations.  That is, the relative expected 
utility of any pair of decisions (in any decision scenario) will 
be  unaltered  by  such  a  transformation of a  utility  function. 
This  implies  that  the  optimal  decision  in  any  decision  sce(cid:173)
nario is unaffected by such a transformation. 

the  utility  functions  in  question.  Implicit in  such a  scheme 
is  a  commensurability assumption  that  allows the  quantities 
present  in  the  different  utility  functions  to  be  meaningfully 
compared and combined.  This is  not always the case.  The 
aim of this paper is to describe certain conditions under which 
this commensurability assumption can be justified by appeal 
to the foundational axioms for decision theory as proposed by 
von Neumann and Morgenstern [19] and Savage [17]. 

The setting we consider is one in which an agent for a de(cid:173)
cision maker or user is uncertain about the user's preferences, 
but wishes to recommend (or take) decisions on the user's be-
half.  Fishburn [10] has considered the problems of the foun(cid:173)
dations of expected expected utility  from a  somewhat differ(cid:173)
ent perspective. He considers the problem in which a decision 
maker is  uncertain  about the  set  of consequences she  might 
face and considers combining utility functions over different 
consequence  sets.  Unfortunately,  his  results  cannot  be  ap(cid:173)
plied (except in a trivial way) to the situation above.2 

We  begin  by  defining  the  problem  of  decision  making 
given  uncertainty  over  utility  functions  and  the  FEU  con(cid:173)
cept.  We then examine the sensitivity of EEU  to the precise 
representation  of the  underlying  utility  functions,  and  pro(cid:173)
pose an interpretation of utility uncertainty that allows one to 
prescribe  "canonical"  utility  function  representations  under 
specific circumstances.  We conclude with a brief discussion 
of the  implications these  considerations have  for "practical" 
elicitation. 

2  Expected Expected Utility 
We begin by establishing notation and basic background with 
a quick overview of expected utility and then define the notion 
of expected expected  utility formally. 

The  optimal  decision  d*  w.r.t.  u  is  that  with  maximum  ex(cid:173)
pected  utility  (MEU). 

2 While our results are general, it is unclear how profitable it is to 
model a decision maker's uncertainty about her own utility function. 
It can be argued that such uncertainty should be viewed as "tradi(cid:173)
tional" uncertainty about future outcomes, context, etc. Rather than 
take a stand on this issue, we simply emphasize that an agent can 
be genuinely uncertain about a user's utility function, and that our 
model and results apply (in a practical way) to such a setting. 

3 If u is represented using some more concise model, u is simply 

the vector of parameters required for that model. 

286 

DECISION THEORY 

a  utility  function—to  serve  as  a  concise  representation  of a 
preference  function  over  lotteries. 

This  gives  rise  to  the  question  of how  to  choose  a  repre(cid:173)
sentative utility  function from each equivalence class  [> ]  that 
allows  formal  justification  of the  M E EU  decision  rule,  and 
under what  circumstances  such  representatives  exist. 
3.2  A Lottery Interpretation of MEU 
We give a formal justification for the M E EU rule under a spe(cid:173)
cific  condition:  we  assume  the  existence  of  a  known  best  and 
worst  outcome.  That  is,  each  utility  function  with  positive 
support has the same best outcome  sT  and worst outcome ,s±. 
We  also  insist  that the  user  is  not  indifferent to  these  alterna(cid:173)
tives, that is, that ST  must be strictly preferred to . s .5  We call 
such  utility  functions  extremum  equivalent.  In  many  settings, 
such  as  those  involving active preference elicitation,  restrict(cid:173)
ing  attention  to  a  set  of extremum  equivalent  utility  functions 
is  not problematic.  One  simply  needs to  ask  the  user to  iden(cid:173)
tify  her most and  least preferred outcomes (these  need  not be 
unique, but only one  such  representative need be  identified). 

This definition is precisely that used in  [5;  6;  1]  in the con(cid:173)
text  of  utility  elicitation,  and  also  that  used  in  much  other 
work  involving  uncertainty  over  utility  [12;  8;  9]. 
In  such 
a  state  of  uncertainty—or  belief state—the  optimal  decision 
is  that  d*  with  maximum  EEU  EU(d*,P).  We  denote  by 
EU(P)  the  value  of being  in  belief state  P,  assuming  one  is 
forced to  make a decision: 

We  call  this  generic  decision  rule  the  MEEUdecision  rule,  by 
analogy  with  the  classical  M EU  decision  rule. 

EEU  seems  to  be  a  fairly  natural  concept  given  proba(cid:173)
bilistically  quantified  uncertainty  over  utilities.  The  fact  that 
it  occurs  in  many  different  contexts  certainly  attests  to  this 
fact.  Unfortunately,  the  proposed  definition  can  induce  cer(cid:173)
tain anomalies,  as we  examine below. 

3  Justifying MEEU 
3.1  Loss of Invariance 
The  results  of  von  Neumann  and  Morgenstern  suggest  that 
the  decisions  one  makes  with  respect  to  belief state  P  over 
U  should  be  invariant to  legitimate  transformations of the  el(cid:173)
ements  of U.  Certainly,  this  would  be  a  desirable  feature  of 
the  M E EU  decision  rule.  One  might  even  claim  that  the  de(cid:173)
cision  rule  can  only  be  considered  useful  if  it  satisfies  this 
condition.  In general,  unfortunately, this  is not the case. 

As  a  simple  illustration,  suppose  we  have  a  domain  with 
two  outcomes  s1  and  s2,  and  a  distribution  P  that  assigns 
probability  0.5  to  u1  = 
(1,3)  and  probability  0.5  to  u2  = 
(2,1).  Suppose  we  use  the  M E EU  decision  rule  in  this  con(cid:173)
text,  by  computing 

and  choosing  the  decision  d*  with  maximum  expected  utility 
EU(d*,  P).  Then  a  decision  that  accords  higher  probability 
to  s2  will  be  preferred  to  one  that  gives  lower  probability  to 
s2.  However,  if  we  transform  u2  into  ui2  = 
(20,10),  the 
relative  utilities of these  decisions will  be reversed.  Thus,  the 
M E EU  decision  rule  is  not  insensitive  to  transformations  of 
individual  utility  functions  with  positive  support.  Note  that 
we  are  not  suggesting  that  agent's  will  arbitrarily  transform 
some  utility  functions  and  not  others.4  Rather,  the  question 
is:  which  representation of a  specific  utility function (e.g.,  u2 
in  the  example)  should be  adopted in  the  first  place? 

One possible way to  deal  with  this problem  is to  recognize 
that a  utility  function  is  simply a  convenient (and  nonunique) 
way  of  expressing  preferences  over  lotteries.  Rather  than 
working  with  utility  functions,  we  could  work  explicitly  with 
a  density  over  preference  functions  (in  fact,  we  w i ll  do  this 
implicitly  below).  Unfortunately,  the  set  of  lotteries  over 
which  a preference ordering is defined is uncountable; there(cid:173)
fore,  some  compact  representation  (of the  individual  prefer(cid:173)
ence  functions)  is  needed.  But  this  is  precisely  the  role  of 

4If the same transformation is applied to all functions with posi(cid:173)

tive support, the MEEU decision is unchanged. 

DECISION THEORY 

287 

Here the first step refers to a compound lottery over an con(cid:173)
tinuous set of component (simple) lotteries, while we assume 
in second step that a such a compound lottery can be reduced 
to a simple lottery in an analogous way to the reduction of a 
finite compounded lottery. 

Thus under the assumption that one can identify a best and 
worst outcome, the MEEU decision rule can be justified for 
use with  normalized  (extremum equivalent) utility  functions 
by appeal to the foundational axioms of decision theory, and 
an  interpretation of uncertainty over utility  as  a lottery  over 
the lotteries defined by the component utility functions. 
We now formalize the legitimacy of EEU and MEE. 

Extremum equivalence is  thus  sufficient  to ensure commen-
surability, as it puts all utility functions on a common scale. It 
is important to realize that the scale dictated by the best and 
worst  outcomes  cannot  vary,  since  these  are  truly  best  and 
worst outcomes; we return to this  point below.  It appears to 
be much more difficult to apply this type of argument to den(cid:173)
sities over utility functions that are not extremum equivalent. 
Fishburn [101 considers the problem of EEU when a deci(cid:173)
sion  maker is uncertain about the nature of the consequence 
sets she will face.  He proposes foundational axioms that jus(cid:173)
tify the use EEU to compare decisions.  However, the setting 
is  rather  different:  specifically,  Fishburn  requires  that  any 
consequences that two  utility  functions  have  in  common  be 
ranked identically.  In our context, where each utility function 
lies over the same consequence set, the Fishburn axioms im(cid:173)
pose overly  stringent requirements.  It  is  interesting  to  note 
that  Fishburn  requires  something  akin  to  extremum  equiva(cid:173)
lence, namely, that there exist two consequences common to 
the domains of each utility function such that one of the con(cid:173)
sequences is preferred to the other in each function. 

4  Dealing with Small Worlds 
It  is  important  to  realize  that  the  best  and  worst  outcomes 
with which one calibrates must either be truly best and worst 
outcomes from the decision maker's standpoint, or they them(cid:173)
selves must be calibrated.  Using Savage's 117] terminology, 
we must be careful  to distinguish  "small  worlds" reasoning 
from "grand worlds." Consider the case where the set of out(cid:173)
comes is restricted to the subset of outcomes that are possible 
given the set of actions  in  a  specific  decision  scenario.  But 
assume  there  exist  outcomes  outside  the  domain  of the  re(cid:173)
stricted scenario for which the user has concrete preferences. 
Let's refer to the set of restricted outcomes as local, while the 
space of all  outcomes is global. 

288 

DECISION THEORY 

Unfortunately, this condition is not equivalent to the MEEU 
rule  in  the  original  small  worlds  domain.  Specifically,  this 
condition cannot generally be assessed without having some 
assessment  of the  global  tradeoff probabilities  p1,  etc. 
In 
other  words,  to  accurately  compare  two  small  world  out(cid:173)
comes given uncertainty about the local utility functions, we 
have  to  explicitly  assess  our  uncertainty  about  the  range  of 
values the  local  extrema can  take  with  respect  to  the global 
utility function. Thus while one can generally use small world 
reasoning  in  the  classic  decision-theoretic setting,  its  use  is 
problematic in the EEU framework. 

5  Consequences for Preference Elicitation 
The considerations above have implications for practical pref(cid:173)
erence elicitation.  From a foundational perspective, calibra(cid:173)
tion of utilities relative to known best and worst outcomes is 
required if decisions are to be based on  EEU.  In the case of 
incremental elicitation, where EEU is used to determine value 
of information, we must  first  obtain a prior over a  set of cx-
tremum equivalent utility  functions before engaging in  such 
deliberations.  Fortunately,  it  often  seems  to  make  sense  to 
determine best and worst outcomes beforehand, and engage 
in "serious" elicitation after this initial calibration. 

Another important question:  how does one determine pri(cid:173)
ors over utility functions? Utility function databases [4] could 
be used.  This poses some problems regarding interpersonal 
utility  comparison  for  which  there  are  no  especially  com(cid:173)
pelling solutions.  When using EEU, things are a bit worse: 
we  need to  construct priors conditioned on  the  observed or 

DECISION THEORY 

289 

elicited best and  worst outcomes.  Given a prior over arbitrary 
utility functions, as long as decisions using EEU are not made 
until  the  determination  of best  and  worst  outcomes  is  com(cid:173)
pleted,  this  poses  no  difficulties.  An  alternative,  in  certain 
scenarios,  is  to  suppose that certain outcomes are  universally 
most and  least preferred (e.g.,  in  medical  contexts,  death  can 
be  used  as  the  latter).  This  may  be  hard  to justify  formally, 
but  from  a  practical  point  of view  will  be  quite  useful  and 
(one  hopes)  have  little  impact on actual  decision  quality. 

The  issue  of  small  worlds  also  poses  certain  problems. 
From  the  point  of view  of practical  elicitation,  the  prospect 
of  calibrating  some  small  set  of  relevant  outcomes  using  a 
user's  "global"  utility  function  is  unappealing.  Fortunately, 
as  argued  above,  for  a  given  individual,  strength  of prefer(cid:173)
ence  can  be  assumed  fixed  for the  best  and  worst  outcomes, 
which  allows  things  to  carry  through.  Strength  of preference 
may  prove  to  be  important  however  when  trading  off the  in(cid:173)
crease  in  EEU  with  the  effort  associated  with  the  elicitation 
process.  Furthermore,  this  can  have  an  important  impact  on 
the  construction  of priors  from  databases  of utility  functions. 

6  Concluding Remarks 
Decision  making  when  the  underlying  utility  function  is  un(cid:173)
known  is  an  important  problem  in  game  theory,  interactive 
optimization, and preference elicitation.  Quantifying this un(cid:173)
certainty  using  distributions  over utility  functions has  a  num(cid:173)
ber of appealing qualities,  and  quite  naturally  leads to  the  no(cid:173)
tion  of expected expected  utility,  a  concept that  has  been  used 
in  several  different  lines  of research. 

The  aim  of this  paper is  to  point out that  expectations taken 
with  respect  to  utility  function  distributions  require  some 
care.  More precisely,  the operation of expected expected util(cid:173)
ity  only  makes  sense  (from  a  foundational  standpoint)  when 
the  distribution  is  over  extremal  equivalent  utility  functions. 
While  this  has  certain  implications  for  practical  utility  elic(cid:173)
itation,  we  have  argued  that  this  requirement  is  not  overly 
stringent  from  a practical  perspective. 

Acknowledgements 
Thanks to  Radford Neal  whose comments on preference elic(cid:173)
itation  led  to  this  investigation  and to  Moshe Tennenholtz for 
suggesting  interesting connections.  This  work was  supported 
by  the  Institute  for  Robotics  and  Intelligent  Systems  (IRIS), 
and  the  Natural  Sciences  and  Engineering  Research  Council 
of Canada  (NSERC). 

References 
[1]  Craig  Boutilier.  A  POMDP  formulation  of preference  elici(cid:173)
tation problems.  In Proc.  Eighteenth National Conference on 
Artificial Intelligence,  pages  239-246,  Edmonton,  2002. 

[2]  Craig Boutilier, Fahiem Bacchus, and Ronen I. Brafman. UCP-
Networks:  A  directed  graphical  representation  of conditional 
utilities. 
In  Proc.  Seventeenth  Conference on  Uncertainty  in 
Artificial Intelligence,  pages  56-64,  Seattle,  2001. 

[3]  Jack S. Breese, David Heckerman, and Carl Kadie.  Empirical 
analyis  of predictive  algorithms  for collaborative  filtering.  In 
Proc.  Fourteenth  Conference  on  Uncertainty in Artificial Intel-
ligence, pages 43-52, Madison, WI,  1998. 

[4]  U.  Chajewska,  L.  Getoor,  J.  Norman,  and  Y.  Shahar.  Util(cid:173)
ity elicitation as a classification problem.  In Proc. Fourteenth 
Conference  on  Uncertainty  in Artificial Intelligence,  pages  79-
88, Madison, WI, 1998. 

[5]  Urszula  Chajewska  and  Daphne  Koller.  Utilities  as  random 
variables:  Density estimation and structure discovery.  In Proc. 
Sixteenth  Conference  on  Uncertainty  in  Artificial Intelligence, 
pages 63  71, Stanford, 2000. 

[6]  Urszula  Chajewska,  Daphne  Koller,  and  Ronald  Parr.  Mak(cid:173)
ing  rational  decisions  using  adaptive  utility  elicitation. 
In 
Proc.  Seventeenth  National  Conference  on  Artificial  Intelli(cid:173)
gence, pages 363-369, Austin, TX, 2000. 

[7]  Tommy Chin-Chiu Chan and Sergio Ribciro da Costa Werlang. 
The  Bayesian  foundations  of the  solution  concepts  of games. 
Journal  of  Economic  Theory,  45:370-391,  1988. 

[8]  Richard M. Cyert and Morris H. de Groot.  Adaptive utility.  In 
Maurice  Allais  and  Ole  Hagen,  editors,  Expected  Utility  Hy(cid:173)
pothesis  and  the  Allais  Paradox,  pages  223-241.  D.  Reidel, 
Dordrecht,  1979. 

[9]  Morris H. de Groot.  Decision making with an uncertain utility 
function.  In Bcrnt P. Stigum and Fred Wenstop, editors, Foun(cid:173)
dations  of  Utility  and  Risk  Theory  with  Applications,  pages 
371-384. D. Reidel, Dordrecht,  1983. 

[10]  Peter  C.  Fishburn.  The  Foundations  of Expected  Utility.  D. 

Reidel, Dordrecht,  1982. 

[11]  Simon  French.  Decision  Theory.  Halsted  Press,  New  York, 

1986. 

[12]  John C. Harsanyi.  Games with incomplete information played 
by  Bayesian  players,  part  I:  The  basic  model.  Management 
Science,  14:159  182,  1967. 

[13]  John C. Harsanyi.  Games with incomplete information played 
by  Bayesian  players,  part  II:  Bayesian  equilibrium  points. 
Management Science,  14:320-334,  1968. 

[14]  R.  D.  Luce and H. Raiffa.  Games and Decisions.  Wiley, New 

York,  1957. 

[15]  Roger  B.  Myerson.  Game  Theory:  Analysis of Conflict.  Har(cid:173)

vard University Press, Cambridge,  1991. 

[16]  David  M.  Pennock  and  Eric  Horvitz.  Collaborative  filtering 
by personality diagnosis:  A  hybrid memory- and model-based 
approach. 
In  Proc.  Sixteenth  Conference  on  Uncertainty  in 
Artificial Intelligence,  pages  473-480,  Stanford,  2000. 

[17]  Leonard  J.  Savage.  The  Foundations  of  Statistics.  Wiley,  New 

York,  1954. 

[18]  Edward  A.  Sykes  and  Chelsea  C.  White,  III.  Multiobjective 
intelligent computer-aided design.  IEEE Transactions on Sys(cid:173)
tems, Man and Cybernetics, 21 (6): 1498- i 511, 1991. 

[ 19] John von Neumann and Oskkar Morgenstern. Theory of Games 
and Economic  Behavior.  Princeton  University  Press,  Prince(cid:173)
ton, 1944. 

[20]  Tianhan  Wang  and  Craig  Boutilier. 

Incremental  utility  elic(cid:173)
itation  with  the  minimax  regret  decision  criterion. 
In  Proc. 
Eighteenth  International  Joint  Conference  on  Artificial  Intelli(cid:173)
gence, this volume, Acapulco, 2003. 

[21]  Chelsea C. White, III, Andrew P. Sage, and Shigeru Dozono. 
A model of multiattribute decisionmaking and trade-off weight 
determination  under  uncertainty. 
IEEE  Transactions  on  Sys(cid:173)
tems, Man and Cybernetics,  14(2):223- 229,  1984. 

290 

DECISION THEORY 

