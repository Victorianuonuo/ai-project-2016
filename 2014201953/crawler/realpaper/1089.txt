A Machine Learning Approach for Statistical Software Testing ∗

Nicolas Baskiotis, Mich`ele Sebag, Marie-Claude Gaudel, Sandrine Gouraud

LRI, Universit´e de Paris-Sud, CNRS UMR 8623

Bˆat.490, 91405 Orsay Cedex (France)
{nbaskiot, sebag, mcg, gouraud}@lri.fr

Abstract

Some Statistical Software Testing approaches rely
on sampling the feasible paths in the control ﬂow
graph of the program; the difﬁculty comes from the
tiny ratio of feasible paths. This paper presents an
adaptive sampling mechanism called EXIST for Ex-
ploration/eXploitation Inference for Software Test-
ing, able to retrieve distinct feasible paths with high
probability. EXIST proceeds by alternatively ex-
ploiting and updating a distribution on the set of
program paths. An original representation of paths,
accommodating long-range dependencies and data
sparsity and based on extended Parikh maps, is pro-
posed. Experimental validation on real-world and
artiﬁcial problems demonstrates dramatic improve-
ments compared to the state of the art.

1 Introduction

Computer Science is becoming a new application domain for
Machine Learning (ML), motivated by the increasing com-
plexity of current systems [Rish et al., 2006]. Ideally, sys-
tems should be able to automatically adapt, maintain and re-
pair themselves; a ﬁrst step to this end is to build self-aware
systems, using ML to automatically model the system be-
haviour. Along these lines, various ML approaches have been
proposed for Software Testing [Br´eh´elin et al., 2001], Soft-
ware Modeling [Xiao et al., 2005] and Software Debugging
[Zheng et al., 2006].

In this paper, we revisit a Statistical Software Testing (SST)
approach presented in [Denise et al., 2004]. This approach is
based on the uniform sampling of the paths in the control ﬂow
graph of the program; to each path, a test case exerting this
path can be associated if the path is feasible. A problem with
this approach is that the control ﬂow graph provides an overly
general description of the program; in some cases, and very
often for large programs, the fraction of feasible paths is tiny
(ranging in 10−15, 10−5).

After a discriminant learning approach failed to charac-
terise the set of feasible paths because of the tiny support
of the target concept, a generative learning approach was

proposed. This approach, called EXIST for Exploration -
eXploitation Inference for Software Testing, is inspired by
both Estimation of Distribution Algorithms (EDAs) [Baluja
and Davies, 1998] and Online Learning [Auer et al., 2002;
Cesa-Bianchi and Lugosi, 2006]. EXIST proceeds by itera-
tively generating candidate paths based on the current distri-
bution on the program paths, and updating this distribution af-
ter the path has been labelled as feasible or infeasible. EXIST
was made possible by the use of an original representation,
extending the Parikh map [Hopcroft and Ullman, 1979] and
providing a powerful propositional description of long struc-
tured sequences (program paths). Another original contribu-
tion, compared to on-line learning [Cesa-Bianchi and Lugosi,
2006; Kocsis and Szepesv´ari, 2006] or reinforcement learn-
ing, is that our goal is to maximise the number of distinct fea-
sible paths found along the process, as opposed to learning a
concept or a ﬁxed policy.

The paper is organised as follows1. Section 2 brieﬂy re-
views some work relevant to Machine Learning and Soft-
ware Testing. Section 3 introduces the formal background
and prior knowledge related to the SST problem, and de-
scribes the extended Parikh representation. Section 4 gives
an overview of the EXIST system. Section 5 describes the
experimental setting and goals, and reports on the empirical
validation of the approach on real-world and artiﬁcial prob-
lems. The paper concludes with some perspectives for further
research.

2 Related Work

Interestingly, while Program Synthesis is among the grand
goals of Machine Learning,
the application of Machine
Learning to Software Testing (ST) has seldom been consid-
ered in the literature.

Ernst et al.

[1999] aim at detecting program invariants,
through instrumenting the program at hand and searching for
predetermined regularities (e.g. value ranges) in the traces.

Brehelin et al. [2001] consider a deterministic test proce-
dure, generating sequences of inputs for a PLA device. An
HMM is trained from these sequences and further used to
generate new sequences, increasing the test coverage.

∗The ﬁrst two authors gratefully acknowledge the support of

Pascal Network of Excellence IST-2002-506 778.

1Due to space limitations, the interested reader is referred to

[Baskiotis et al., 2006] for a more comprehensive presentation.

IJCAI-07

2274

In [Vardhan et al., 2004], the goal is to test a concur-
rent asynchronous program against user-supplied constraints
(model checking). Grammatical Inference is used to charac-
terise the paths relevant to the constraint checking.

Xiao et al. [2005] aim at testing a game player, e.g. dis-
covering the regions where the game is too easy/too difﬁcult;
they use active learning and rule learning to construct a model
of the program. A more remotely related work presented by
[Zheng et al., 2006], is actually concerned with software de-
bugging and the identiﬁcation of trace predicates related to
the program misbehaviours.

In [Ernst et al., 1999; Vardhan et al., 2004], ML is used
to provide better input to ST approaches; in [Br´eh´elin et al.,
2001], ML is used as a post-processor of ST. In [Xiao et al.,
2005], ML directly provides a model of the black box pro-
gram at hand; the test is done by manually inspecting this
model.

3 Prior knowledge and Representation

After [Denise et al., 2004], the program being tested is repre-
sented from its control ﬂow graph (Fig. 1).

4
3
i

2
2
i

2
2
I

3
2
B

3
2
b

4
2
i

5
2
C

4
2
I

v

T
I
N
I

0
a

0
i

0
I

1
C

1
e

1
t

3
i

2
i

4
C

4
e

4
t

3
2
s

6
s

3
3
i

6
2
e

2
3
i

5
2
e

5
2
t

6
2
C

6
2
t

7
2
I

7
2
i

8
2
C

8
e

0
2
i

5
i

5
I

6
B

6
b

7
i

7
I

8
C

3
1
C

1
1
e

1
2
i

8
t

9
e

1
1
C

9
C

9
t

1
1
t

0
1
i

0
3
i

9
2
i

9
1
i

4
1
i

1
3
i

5
1
e

5
1
t

5
1
C

8
2
e

8
2
t

3
1
e

3
1
t

2
1
i

vf

8
1
i

7
1
i

6
1
i

Figure 1: Program FCT4 includes 36 nodes and 46 edges.

Formally, the control ﬂow graph is a Finite State Automa-
ton (FSA) based on some ﬁnite alphabet Σ, where Σ includes
the program nodes (conditions, blocks of instructions), and
the FSA speciﬁes the transitions between the nodes. A pro-
gram path is represented as a ﬁnite length string on Σ, ob-
tained by iteratively choosing a node among the successors
of the current node until the ﬁnal node noted vf is found.

While the length of program paths is not upper bounded
in the general case, for practical reasons coverage-based ap-
proaches to software testing consider program paths with
bounded length T . Classical results from labelled combina-
torial structures [Flajolet et al., 1994] can thus be used to uni-
formly sample the set of program paths with length in [1, T ].
Each path sample is provided to a constraint solver and la-
belled as feasible or infeasible (see [Denise et al., 2004] and
references therein). The infeasibility of a given path arises if
it violates some subtle dependencies between different parts
of the program. Some general patterns of infeasibility can be
identiﬁed; due to space limitations, only two most general
such patterns will be considered in the rest of the paper.

XOR pattern When two nodes are correlated (for instance
two if nodes based on an unchanged expression),
then
their successors are correlated in every feasible path (if
the program path includes the then successor of the ﬁrst

if node, it must also include the then successor of the
second if node). This pattern is referred to as XOR pattern,
expressing the (possibly long-range) relations between the
fragments of the program paths.

Loop(n) pattern The number of times a loop is executed
happens to be restricted by the semantics of the problem; e.g.
when the problem involves 18 or 19 uranium beams to be
controlled, the control procedure will be executed exactly 18
or 19 times [Gouraud, 2004]. This pattern is referred to as
Loop(n) pattern.

Let us assume that some initial set E of labelled paths is
available, and consider the supervised learning problem de-
ﬁned from E = {(si, yi), si ∈ ΣT
, yi ∈ {−1, +1}, i =
1 . . . , n}, where si is a path with length at most T and yi
is 1 iff si is feasible.

This learning problem presents some speciﬁcities. Firstly,
it does not involve noise, i.e.
the oracle (constraint solver)
does not make errors2. Secondly, the complexity of the exam-
ple space is huge with respect to the number of available ex-
amples. In most real-world problems, Σ includes a few dozen
symbols; a few hundred or thousand paths are available, each
a few hundred symbols long. The number of available paths
is limited by the labelling cost, i.e.
the runtime of the con-
straint solver (on average a few seconds per program path).
Thirdly, the data distribution is severely imbalanced (infea-
sible paths outnumber the feasible ones by many orders of
magnitude); our attempts for increasing the number of feasi-
ble paths through active learning were unsuccessful, as could
have been expected from [Dasgupta, 2005]. Lastly, the label
of a path depends on its global structure; a Markovian repre-
sentation, e.g. [Begleiter et al., 2004], would require many
more examples to identify the desired long-range dependen-
cies between the transitions.

For these reasons, a frugal propositional representation of
strings inspired by Parikh maps [Hopcroft and Ullman, 1979]
was considered. For t = 1 . . . T , let s[t] denote the t-th sym-
bol in s, set to value vf if the length of s is less than t.
• To each symbol v, is associated an integer attribute av;
av(s) is the number of occurrences of symbol v in path s.
• To the i-th occurrence of a symbol v, is associated a cate-
gorical attribute av,i. Attribute av,i(s) gives the next infor-
mative3 symbol following the i-th occurrence of symbol v in
s (or vf if s contains less than i occurrences of v).

4 Overview of EXIST

This section presents a new learning framework devised for
SST, called EXIST for Exploration vs eXploitation Inference
for Software Testing.

2In all generality, three classes should be considered (feasible,
infeasible and undecidable) as the underlying constraint satisfaction
problem is undecidable. However the undecidable class depends on
the constraint solver and its support is negligible in practice.

3Formally, av,i(s) is set to s[t(i) + k], where t(i) is the index of
the i-th occurrence of symbol v in s; k is initially set to 1; in case
av,i takes on a constant value over all examples, k is incremented.
See [Baskiotis et al., 2006] for more details.

IJCAI-07

2275

4.1 Position of the problem
While [Denise et al., 2004] proceeds by uniformly sampling
the bounded length paths, the efﬁciency of the approach is
limited by the (high) ratio of infeasible paths. Our goal in
the present paper will thus be to provide a sampling mecha-
nism, EXIST, able to retrieve distinct feasible paths with high
probability based on a set E of feasible/infeasible paths. E is
initially set to a small set of labelled paths, and it is gradually
enriched with the paths generated by EXIST and labelled by
the constraint solver.

This goal differs from that of active learning, aimed at re-
trieving the most informative examples [Roy and McCallum,
2001]. Active learning is primarily interested in sampling the
frontier of the classes to be discriminated, whereas EXIST
is interested in sampling the feasible class only. Further, as
already mentioned active learning is hindered by the imbal-
anced class distribution [Dasgupta, 2005].

Our goal can also be viewed in the perspective of impor-
tance sampling and Estimation of Distribution Algorithms
(EDAs; see e.g. [Baluja and Davies, 1998]), aimed at iden-
tifying the optima of some ﬁtness function. EDAs iteratively
proceed by i) sampling the search space after the current dis-
tribution; ii) computing the ﬁtness of the samples; iii) up-
dating and biasing the distribution towards the samples with
maximal ﬁtness. The difference relates to the exploration vs
exploitation trade-off; while EDAs are supposed to gradu-
ally switch to exploitation at some point (the distribution con-
verges towards one or a few optima of the ﬁtness function),
the EXIST goal is to gather examples which are all different.
In particular, after a feasible path has been generated, the al-
gorithm must be prevented from generating it again.

The approach can also be compared to on-line learn-
ing and the multi-armed bandit problem, where the gam-
bler must choose the next machine to play based on the
past selections and rewards [Cesa-Bianchi and Lugosi, 2006;
Kocsis and Szepesv´ari, 2006]. The difference similarly re-
lates to the exploration/exploitation trade-off; while [Cesa-
Bianchi and Lugosi, 2006; Kocsis and Szepesv´ari, 2006] are
interested in identifying and running the best policy, we must
explicitly avoid repeating our past moves.

4.2 The search space
Borrowing from EDAs the principle of incrementally exploit-
ing and updating a distribution, EXIST builds a probabilistic
model on top of the extended Parikh map representation (sec-
tion 3). Formally, the probability of generating a feasible path
conditionally to events such as “w is the successor of the i-
th occurrence of v and w occurs at least j times”, denoted
Ev,i;w,j , is estimated from the set E of feasible/infeasible
paths currently available.

These estimate probabilities are used to gradually construct
the current path s, iteratively selecting the successor w of the
current symbol v, conditionally to the current number of oc-
currences of v and w in s.

This formalism is meant to avoid the limitations of proba-
bilistic FSAs and Variable Order Markov Models [Begleiter
et al., 2004]. Actually, probabilistic FSAs (and likewise sim-
ple Markov models) cannot model the long range dependen-
cies between transitions involved in the prior knowledge (sec-

tion 3). Variable Order Markov Models can accommodate
such dependencies; however they are ill-suited to the sparsity
of the initial data available. Rather, the probabilistic Parikh
map can be viewed as a most simple case of probabilistic
attribute-grammars [Abney, 1997], where the attributes only
take into account the number of occurrences of the symbols.
Finally, the EXIST system involves two modules: i) the Init
module determines how the conditional probabilities are es-
timated; ii) the Decision module uses these probabilities to
iteratively generate the candidate path. Let us ﬁrst describe
the Decision module.

4.3 Decision module
Let s denote the path under construction, initialised to the
start symbol. Let v denote the last node in s and let i be the
total number of occurrences of v in s.

The Decision module aims at selecting the successor w of
the last node in s. In order to do so, some additional infor-
mation can be exploited (look-ahead): if the w symbol is se-
lected, then the total number of w symbols in the ﬁnal path
will be at least the current number of occurrences of w in s,
plus one; let jw denote this number.

Formally, the probability p(s, w) of generating a feasible
path conditionally to event Ev,i;w,jw (the number of occur-
rences of v is i and the number of occurrences of w is at least
jw) is provided by the Init module; p(s, w) is conventionally
set to 1 if there is no path satisfying Ev,i;w,jw .

The selection of the next node w aims at maximising the
probability of ultimately ﬁnding a new feasible path. Three
options have been considered:

• The simplest option is the Greedy one, that selects the

successor node w maximising p(s, w).

• The RouletteWheel option stochastically selects node w

with probability proportional to p(s, w).

• The BandiST option follows the UCB1 algorithm [Auer
et al., 2002]; in the standard multi-armed bandit prob-
lem this algorithm is shown to achieve logarithmic regret
(reward loss compared to the optimal unknown policy)
with respect to the number of trials. BandiST determin-
istically selects the node w maximising

(cid:2)

p(s, w) +

2 log(e(s, ∗))

e(s, w)

(cid:3)

where e(s, w) is the total number of paths satisfying
Ev,i,w,jw and e(s, ∗) =

w successor of v e(s, w).

4.4 The Init module
The Init module determines how the conditional probabilities
used by the Decision module are estimated.

The baseline Init option computes p(s, w) as the fraction
of paths in E satisfying Ev,i,w,jw that are feasible. However,
this option fails to guide EXIST efﬁciently due to the disjunc-
tive nature of the target concept (section 3), as shown on the
following toy problem.

Let us assume that a path is feasible iff the ﬁrst and the third
occurrences of symbol v are followed by the same symbol (s
feasible iff av,1(s) = av,3(s)). Let us further assume that E

IJCAI-07

2276

includes s1 = vwvxvw, s2 = vxvwvx and s3 = vxvwvw;
s1 and s2 are feasible while s3 is infeasible. Consider the cur-
rent path s = vwvxv; the next step is to select the successor
of the 3rd occurrence of v. It can be seen that p(s, w) = .5
while p(s, x) = 1., as the ﬁrst event (the 3rd occurrence of v
is followed by w and there are at least 2 occurrences of w) is
satisﬁed by s1 and s3 while the second event (the 3rd occur-
rence of v is followed by x and there are at least 2 occurrences
of x) only covers s2.

Therefore, a Seeded Init option is devised to remedy the
above limitation. The idea is to estimate p(s, w) from a subset
of E, called Seed set, including feasible paths belonging to
one single conjunctive subconcept.

A necessary condition for a set of positive examples (fea-
sible paths) to represent a conjunctive sub-concept is that its
least general generalisation4 be correct, i.e. it does not cover
any negative example. In our toy example problem, the lgg
of s1 and s2 is not correct as it covers s3.

Seeded Procedure
E +: set of feasible paths; E −: set of infeasible paths
Let E + = {s1, . . . , sn} be randomly ordered
Let E = {s1}; h1 = s1
For t = 2 . . . n

Let h = lgg(ht−1, st)
If h is correct wrt E −

ht = h; E = E ∪ {st}

Else ht = ht−1

End For
Return E

Figure 2: Construction of a Seed set.

Seed sets are stochastically extracted from E using the
Seeded procedure (Fig. 2) inspired by [Torre, 2004]. At the
initialisation, the set E + of feasible paths is randomly ordered
and the seed set E is set to the ﬁrst path in E +
. Iteratively, one
considers the current feasible path st and constructs its lgg h
with the previously selected paths; if h is correct, i.e does not
cover any infeasible paths with respect to the extended Parikh
map representation, st is added to E. By construction, if the
set of infeasible paths is sufﬁciently representative, E will
only include feasible paths belonging to a conjunctive con-
cept (a single branch of the XORs); therefore the probabili-
ties estimated from E will reﬂect the long range dependencies
among the node transitions.

The exploration strength of EXIST is enforced by using a
restart mechanism to construct another seed set after a while,
and by discounting the events related to feasible paths that
have been found several times; see [Baskiotis et al., 2006] for
more details.

5 Experimental validation

This section describes the experimental setting used to vali-
date EXIST; it reports on the empirical results and discusses
the sensitivity of EXIST wrt the initial amount of labelled
paths.

5.1 Experimental setting and criteria
EXIST is ﬁrst validated on the real-world Fct4 problem, in-
cluding 36 nodes and 46 edges (Fig. 1). The ratio of feasible
paths is about 10−5 for a maximum path length T = 250.

A stochastic problem generator has also been designed
[Baskiotis et al., 2006] to fully assess the EXIST perfor-
mances. Due to space limitations, three series of results
will be presented, related to representative “Easy”, “Medium”
and “Hard” SST problems, where the ratio of feasible paths
respectively ranges in [5 × 10−3, 10−2] for the Easy prob-
in [10−5, 10−3] for the Medium problems, and in
lems,
[10−15, 10−14] for the Hard problems. The number of nodes
varies in [20, 40] and the path length varies in [120, 250].
Only 5 EXIST variants will be considered, Greedy and
SeededGreedy (SG), SeededRouletteWheel (SRW), and ﬁnally
BandiST (BST) and SeededBandiST (SBST).

For each EXIST variant and each problem, the reported
result is the number of distinct feasible paths found out of
10,000 generated paths, averaged over 10 independent runs.
The baseline (uniform sampling) approach, outperformed by
several orders of magnitude, is omitted in the following.

5.2 Results
For a better visualisation, the results obtained by each EXIST
variant are displayed in parallel coordinates for Easy (Fig. 3),
Medium (Fig. 4) and Hard (Fig. 5) problems, starting from
a 50 feasible/50 infeasible training set. The average results
and the standard deviation of all Seeded variants are shown in
Table 1.

The computational time ranges from 1 to 10 minutes on
PC Pentium 3 GHz depending on the problem and the variant
considered (labelling cost non included).

 10000

s
h

t

a
p

 

Easy Problems

l

i

e
b
s
a
e

f
 

d
e
t
a
r
e
n
e
g
 
f
o
 
r
e
b
m
u
N

 8000

 6000

 4000

 2000

 0

G
S

y
d
e
e
r
G

W
R
S

EXIST Variants

art1
art2
art3

T
S
B

T
S
B
S

Figure 3: Number of distinct feasible paths generated by EX-
IST out of 10,000 trials on Easy problems, starting from 50
feasible/50 infeasible paths.

4The least general generalisation (lgg) of a set of propositional
examples is the conjunction of constraints of the type [attribute =
value] that are satisﬁed by all examples. For instance, the lgg of
examples s1 and s2 in the extended Parikh representation is [av =
3] ∧ [aw,1 = v] ∧ [ax,1 = v].

In the considered range of problems, the best EXIST vari-
ant is SeededGreedy. On easy problems, BandiST and Seede-
dRouletteWheel are efﬁcient too (Fig. 3); but their efﬁciency
decreases as the ratio of feasible paths decreases.

IJCAI-07

2277

Medium Problems

art4
art5
art6

 10000

t

s
h
a
p

 

l

i

e
b
s
a
e

f
 

d
e

t

a
r
e
n
e
g

 
f

o

 
r
e
b
m
u
N

 8000

 6000

 4000

 2000

 0

G
S

y
d
e
e
r
G

W
R
S

T
S
B

T
S
B
S

EXIST Variants

Figure 4: EXIST results on Medium problems, with same set-
ting as in Fig. 3.

s
h

t

 10000

l

 

a
p
e
b
s
a
e

i

f
 

d
e

t

a
r
e
n
e
g

 
f

o

 
r
e
b
m
u
N

 8000

 6000

 4000

 2000

 0

Hard Problems

art7
art8
fct4

G
S

y
d
e
e
r
G

W
R
S

T
S
B

T
S
B
S

EXIST Variants

l

 

a
p
e
b
s
a
e

i

f
 

t

d
e
a
r
e
n
e
g

s
h

t

 10000

 8000

 6000

 4000

 2000

 0

where BandiST is dominated due to its exploration bias. Note
that both of BandiST and Greedy will explore a transition
which has not yet been explored in the current feasible paths
(p(s, w) = 1 when there are no paths satisfying the current
event, section 4.3). However, if this trial does not lead to
a feasible path, Greedy will never visit the transition again,
while BandiST may (and usually will) retry later on.

Note also that SeededGreedy displays a signiﬁcantly lower

standard deviation than the other Seeded variants (Table 1).

5.3 Sensitivity wrt initial conditions

The usability of EXIST would be compromised if a large
initial training set were necessary in order to get good re-
sults. Therefore experiments with various numbers of ini-
tial feasible and infeasible paths (independently selected in
50, 200, 1000) have been conducted, and the results obtained
on a representative medium problem are displayed in Fig. 6.

Problem art5

50/50
50/1000
200/200
1000/1000

Figure 5: EXIST results on Hard problems, with same setting
as in Fig. 3.

 
f

o

 
r
e
b
m
u
N

The Seeded option is almost always beneﬁcial, especially
so when combined with the Greedy and RouletteWheel op-
tions, and when applied on hard problems. For hard prob-
lems, the feasible region is divided among many tiny conjunc-
tive subconcepts. As the probabilities estimated from exam-
ples belonging to different subconcepts are misleading, they
most often result in generating infeasible examples. Usefully,
the Seeded option allows EXIST to generate infeasible paths
which separate the feasible subconcepts. The Seeded option
is comparatively less beneﬁcial for BandiST than for the other
options, as it increases the BandiST bias toward exploration;
unsurprisingly, exploration is poorly rewarded on hard prob-
lems.

The comparative performance of Greedy and BandiST de-
pends on the type of problem. On easy problems, BandiST
dominates Greedy. The reverse is true on hard problems,

Problems

Fct4

Easy

art1
art2
art3

Medium art4
art5
art6

Hard

art7
art8

SG

SBST

SRW

3754 ± 612
7226 ± 665
9331 ± 38
9365 ± 65
9025 ± 118
8368 ± 149
7840 ± 448
7582 ± 217
5496 ± 149

1409 ± 812
4520 ± 225
2439 ± 110
7879 ± 240
1744 ± 853
5106 ± 236
4588 ± 610

52 ± 8

777 ± 223

3332 ± 580
7270 ± 496
5600 ± 615
8592 ± 573
6078 ± 479
6519 ± 965
4920 ± 984
5590 ± 163
1757 ± 110

Table 1: Average number of paths and standard deviation of
Seeded variants of EXIST.

G
S

y
d
e
e
r
G

W
R
S

T
S
B

T
S
B
S

EXIST Variants

Figure 6: Sensitivity analysis. Average EXIST results on
some representative Medium problem, depending on the
number of initial feasible and infeasible paths.

A ﬁrst remark is that increasing the number of infeasi-
ble paths does not improve the results, everything else being
equal. Concretely, it makes almost no difference to provide
the system with 50 or 1000 infeasible paths besides 50 fea-
sible paths. Even more surprisingly, increasing the number
of feasible paths rather degrades the results (the 1000/1000
curve is usually well below the 50/50 curve in Fig. 6).

Both remarks can be explained by modeling the Seeded
procedure (Fig. 2) as a 3-state automaton. In each step t, the
Seeded procedure considers a feasible path st, and the result-
ing lgg is tested for correctness against the infeasible paths.
If st belongs to the same subconcept as the previous feasible
paths (state A), the lgg will be found correct, and the proce-
dure returns to state A. Otherwise (state B), the test against
the infeasible paths might reject the lgg (there exists an infea-
sible path covered by the resulting lgg), st is rejected and the
procedure returns to state A. Otherwise (state C), there exists
no infeasible path enforcing st rejection and preventing the
overgeneralisation of the seed set. As the seed set will from
now on contain examples from different subconcepts (state C
is absorbing), the probabilities estimated from the seed set are
misleading and will likely lead to generate infeasible paths.

The number and quality of infeasible paths governs the
transition from state B to either A (probability q) or C (prob-
ability 1 − q). Although q should exponentially increase wrt

IJCAI-07

2278

the number of infeasible paths, it turns out that initial infea-
sible paths are useless to detect incorrect lggs; actually, only
infeasible paths sufﬁciently close (wrt the Parikh representa-
tion) to the frontier of the subconcepts are useful. This remark
explains why increasing the number of initial infeasible paths
does not signiﬁcantly help the generation process.

On the other hand, the probability of ending up in the
absorbing state C (failure) exponentially increases with the
number of steps of the Seeded procedure, i.e. the number of
feasible paths (Fig. 2). Only when sufﬁciently many and suf-
ﬁciently relevant infeasible paths are available, is the wealth
of feasible paths useful for the generation process.

Complementary experiments ([Baskiotis et al., 2006])
done with 1000 feasible vs 1000 infeasible paths show that
i) the limitation related to the number of initial feasible ex-
amples can be overcome by limiting the number of feasible
paths considered by the Seeded procedure (e.g. considering
only the ﬁrst 200 feasible paths); ii) in order to be effective, an
adaptive control of the Seeded procedure is needed, depend-
ing on the disjunctivity of the target concept and the presence
of “near-miss” infeasible paths in E.

6 Conclusion and Perspectives

The presented application of Machine Learning to Software
Testing relies on an original representation of distributions on
strings, coping with long-range dependencies and data spar-
sity. Further research aims at a formal characterisation of the
potentialities and limitations of this extended Parikh repre-
sentation (see also [Clark et al., 2006]), in software testing
and in other structured domains.

The second contribution of the presented work is the
Seeded heuristics ﬁrst proposed in [Torre, 2004], used to ex-
tract relevant distributions from examples representing a va-
riety of conjunctive subconcepts. This heuristics is combined
with Exploration vs Exploitation strategies to construct a ﬂex-
ible sampling mechanism, able to retrieve distinct feasible
paths with high probability.

With respect to Statistical Software Testing, the presented
approach dramatically increases the ratio of (distinct) feasible
paths generated, compared to the former uniform sampling
approach [Denise et al., 2004].

Further research aims at estimating the distribution of the
feasible paths generated by EXIST, and providing PAC es-
timates of the number of trials needed to reach the feasible
paths (hitting time). In the longer run, the extension of this
approach to related applications such as equivalence testers
or reachability testers for huge automata [Yannakakis, 2004]
will be studied.

References
[Abney, 1997] S. P. Abney. Stochastic attribute-value grammars.

Computational Linguistics, 23(4):597–618, 1997.

[Auer et al., 2002] P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-
time analysis of the multiarmed bandit problem. Machine Learn-
ing, 47(2-3):235–256, 2002.

[Baluja and Davies, 1998] S. Baluja and S. Davies. Fast probabilis-
tic modeling for combinatorial optimization. In AAAI/IAAI, pages
469–476, 1998.

[Baskiotis et al., 2006] N. Baskiotis, M. Sebag, M.-C. Gaudel, and
S. Gouraud. Exploitation / exploration inference for hybrid sta-
tistical software testing. Technical report, LRI, Universit´e Paris-
Sud, http://www.lri.fr/˜nbaskiot, 2006.

[Begleiter et al., 2004] R. Begleiter, R. El-Yaniv, and G. Yona. On
prediction using variable order markov models. JAIR, 22:385–
421, 2004.

[Br´eh´elin et al., 2001] L. Br´eh´elin, O. Gascuel, and G. Caraux.
Hidden markov models with patterns to learn boolean vector se-
quences and application to the built-in self-test for integrated cir-
cuits. IEEE Trans. Pattern Anal. Mach. Intell., 23(9):997–1008,
2001.

[Cesa-Bianchi and Lugosi, 2006] N. Cesa-Bianchi and G. Lugosi.
Prediction, learning, and games. Cambridge University Press,
2006.

[Clark et al., 2006] A. Clark, C. C. Florencio, and C. Watkins. Lan-
guages as hyperplanes: Grammatical inference with string ker-
nels. In ECML, to appear, 2006.

[Dasgupta, 2005] S. Dasgupta. Coarse sample complexity bounds

for active learning. In NIPS, pages 235–242, 2005.

[Denise et al., 2004] A. Denise, M.-C. Gaudel, and S.-D. Gouraud.
A generic method for statistical testing. In ISSRE, pages 25–34,
2004.

[Ernst et al., 1999] M. D. Ernst, J. Cockrell, W. G. Griswold, and
D. Notkin. Dynamically discovering likely program invariants to
support program evolution. In ICSE, pages 213–224, 1999.

[Flajolet et al., 1994] P. Flajolet, P. Zimmermann, and B. Van Cut-
sem. A calculus for the random generation of labelled combina-
torial structures. Theor. Comput. Sci., 132(2):1–35, 1994.

[Gouraud, 2004] S.-D. Gouraud. Statistical Software Testing based
on Structural Combinatorics. PhD thesis, LRI, Universit´e Paris-
Sud, 2004.

[Hopcroft and Ullman, 1979] J. E. Hopcroft and J. D. Ullman. In-
troduction to Automata Theory, Languages and Computation.
Addison-Wesley, 1979.

[Kocsis and Szepesv´ari, 2006] L. Kocsis and C. Szepesv´ari. Bandit

based Monte-Carlo planning. In ECML, pages 282–293, 2006.

[Rish et al., 2006] I. Rish, R. Das, G. Tesauro, and J. Kephart.
Ecml-pkdd workshop automatic computing: a new challenge for
machine learning. 2006.

[Roy and McCallum, 2001] N. Roy and A. McCallum. Toward op-
timal active learning through sampling estimation of error reduc-
tion. In ICML, pages 441–448, 2001.

[Torre, 2004] F. Torre. Boosting correct least general generaliza-
tions. Technical Report GRAppA Report 0104, Universit´e Lille
III, 2004.

[Vardhan et al., 2004] A. Vardhan, K. Sen, M. Viswanathan, and
G. Agha. Actively learning to verify safety for FIFO automata.
In FSTTCS, pages 494–505, 2004.

[Xiao et al., 2005] G. Xiao, F. Southey, R. C. Holte, and D. F.
Wilkinson. Software testing by active learning for commercial
games. In AAAI, pages 898–903, 2005.

[Yannakakis, 2004] M. Yannakakis. Testing, optimization, and

games. In ICALP, pages 28–45, 2004.

[Zheng et al., 2006] A. X. Zheng, M. I. Jordan, B. Liblit, M. N.,
and A. Aiken. Statistical debugging: simultaneous identiﬁcation
of multiple bugs. In ICML, pages 1105–1112, 2006.

IJCAI-07

2279

