Self Adaptive Particle Filter

Alvaro Soto

Pontiﬁcia Universidad Catolica de Chile

Department of Computer Science

Vicuna Mackenna 4860 (143), Santiago 22, Chile

asoto@ing.puc.cl

Abstract

The particle ﬁlter has emerged as a useful tool for
problems requiring dynamic state estimation. The
efﬁciency and accuracy of the ﬁlter depend mostly
on the number of particles used in the estimation
and on the propagation function used to re-allocate
these particles at each iteration. Both features are
speciﬁed beforehand and are kept ﬁxed in the reg-
ular implementation of the ﬁlter.
In practice this
may be highly inappropriate since it ignores errors
in the models and the varying dynamics of the pro-
cesses. This work presents a self adaptive version
of the particle ﬁlter that uses statistical methods to
adapt the number of particles and the propagation
function at each iteration. Furthermore, our method
presents similar computational load than the stan-
dard particle ﬁlter. We show the advantages of the
self adaptive ﬁlter by applying it to a synthetic ex-
ample and to the visual tracking of targets in a real
video sequence.

Introduction

1
The particle ﬁlter is a useful tool to perform dynamic state es-
timation via Bayesian inference. It provides great efﬁciency
and extreme ﬂexibility to approximate any functional non-
linearity. The key idea is to use samples, also called particles,
to represent the posterior distribution of the state given a se-
quence of sensor measurements. As new information arrives,
these particles are constantly re-allocated to update the esti-
mation of the state of the system.

The efﬁciency and accuracy of the particle ﬁlter depend
mainly on two key factors: the number of particles used to
estimate the posterior distribution and the propagation func-
tion used to re-allocate these particles at each iteration. The
standard implementation of the ﬁlter speciﬁes both factors be-
forehand and keeps them ﬁxed during the entire operation of
the ﬁlter. In this paper, we present a self adaptive particle ﬁl-
ter that uses statistical methods to select an appropriate num-
ber of particles and a suitable propagation function at each
iteration.

This paper is organized as follows. Section 2 provides
background information about the standard particle ﬁlter.

Section 3 presents our method to adaptively estimate the num-
ber of particles. Section 4 presents our method to adaptively
improve the propagation function. Section 5 shows the re-
sults of applying the self adaptive ﬁlter to a visual tracking
task. Finally, Section 6 presents the main conclusions of this
work.

2 Particle Filter
In Bayesian terms, the posterior distribution of the state can
be expressed as:

p(xt/(cid:126)yt) = β p(yt/xt) p(xt/(cid:126)yt−1)

(1)

where β is a normalization factor; xt represents the state of
the system at time t; and (cid:126)yt represents all the information
collected until time t. Equation (1) assumes that xt totally
explains the current observation yt.

The particle ﬁlter provides an estimation of the poste-
rior in Equation (1) in 3 main steps: sampling, weighting,
and re-sampling. The sampling step consists of taking sam-
ples (particles) from the so-called dynamic prior distribution,
p(xt/(cid:126)yt−1). Next, in the weighting step, the resulting parti-
cles are weighted by the likelihood term p(yt/xt). Finally,
a re-sampling step is usually applied to avoid the degeneracy
of the particle set. The key point that explains the efﬁciency
of the ﬁlter comes from using a Markovian assumption and
expressing the dynamic prior by:

(cid:90)

p(xt/(cid:126)yt−1) =

p(xt/xt−1) p(xt−1/(cid:126)yt−1)dxt−1.

(2)

This expression provides a recursive implementation of the
ﬁlter that allows it to use the last estimation p(xt−1/(cid:126)yt−1)
to select the particles xi
t−1 in the next iteration. These par-
ticles are then propagated by the dynamics of the process
p(xt/xi

t−1) to complete the sampling step.

At each iteration the operation of the particle ﬁlter can be
seen as an importance sampling process [Tanner, 1996]. Im-
portance sampling provides an efﬁcient way to obtain sam-
ples from a density p(x), in cases where this function can be
evaluated, but it is not affordable or possible to sample from
it directly. The basic idea in importance sampling is to use
a proposal distribution q(x), also called importance function,
to obtain the samples xi, and then weigh each sample using
a compensatory term given by p(xi)/q(xi). It is possible to

show [Tanner, 1996] that under mild assumptions the set of
weighted-samples resembles the target distribution p(x).

The sampling and weighting steps of the particle ﬁlter cor-
respond to the basic steps of an importance sampling pro-
cess. In this case, given that the true posterior p(xt/(cid:126)yt) is
not known, the samples are drawn from an importance func-
tion that corresponds to the dynamic prior p(xt/(cid:126)yt−1). Using
this importance function, the compensatory terms are exactly
the non normalized weights used in the weighting step of the
particle ﬁlter. The methods presented in this paper use re-
sults from the theory of importance sampling to provide a
self adaptive version of the particle ﬁlter.

3 Adaptive Selection of the Number of

Particles

The selection of the number of particles is a key factor in the
efﬁciency and accuracy of the particle ﬁlter. The computa-
tional load and the convergence of the ﬁlter depend on this
number. Most applications select a ﬁxed number of parti-
cles in advance, using ad hoc criteria, or statistical methods
such as Monte Carlo simulations or some standard statistical
bound [Boers, 1999]. Unfortunately, the use of a ﬁxed num-
ber of particles is often inefﬁcient. The dynamics of most
processes usually produces great variability in the complex-
ity of the posterior distribution1. As a consequence, the initial
estimation of the number of particles can be much larger than
the real number of particles needed to perform a good esti-
mation of the posterior distribution or, worse, at some point,
the selected number of particles can be too small causing the
ﬁlter to diverge.

The effect of the number of particles on the accuracy of
the ﬁlter is determined by two factors: the complexity of the
true density and how closely the proposal density mimics the
true density. Both factors are very intuitive; the estimation
of a more complex pdf requires a greater number of sam-
ples to correctly represent the less predictable shape of the
function. Also, a greater mismatch between the proposal and
the true densities produces many wasted samples located in
irrelevant parts of the true distribution. Previous works to
adaptively determine an adequate number of particles have
failed to consider these two factors together [Fox et al., 1999;
Koeller and Fratkina, 1998; Fox, 2001].

Here, we propose two methods based in the theory of
Statistics that can be used to adaptively estimate the num-
ber of particles to represent the target posterior distribution
without adding a signiﬁcant load to the normal operation of
the ﬁlter. At each cycle of the particle ﬁlter, these techniques
estimate the number of particles that, with a certain level of
conﬁdence, limits the maximum error in the approximation.

3.1 KLD-Sampling Revised
The KLD-Sampling algorithm [Fox, 2001] is a method to
adaptively estimate the number of samples needed to bound
the error of the particle ﬁlter. The error is measured by
the Kullback-Leibler divergence (KL-divergence) between

the true posterior distribution and the empirical distribution,
which is a well known nonparametric maximum likelihood
estimate. KLD-Sampling is based on the assumption that the
true posterior can be represented by a discrete piecewise con-
stant distribution consisting of a set of multidimensional bins.
This assumption allows the use of the χ2 asymptotic conver-
gence of the likelihood ratio statistic to ﬁnd a bound for the
number of particles N:

N >

1
2

χ2

k−1,1−δ

(3)

where  is the upper bound for the error given by the KL-
divergence, (1 − δ) is the quantile of the χ2 distribution with
k − 1 degrees of freedom, and k is given by the number of
bins with support.

The problem with KLD-Sampling is the derivation of the
bound using the empirical distribution, which has the implicit
assumption that the samples comes from the true distribution.
This is not the case for particle ﬁlters where the samples come
from an importance function. Furthermore, the quality of the
match between this function and the true distribution is one of
the main elements that determines the accuracy of the ﬁlter,
hence the suitable number of particles. The bound given by
KLD-Sampling only uses information about the complexity
of the true posterior, but it ignores any mismatch between the
true and the proposal distribution.

To ﬁx the problem of KLD-Sampling we need a way to
quantify the degradation in the estimation using samples from
the importance function. The goal is to ﬁnd the equivalent
number of samples from the importance and the true densities
that capture the same amount of information about the latter.
In the context of Monte Carlo (MC) integration, [Geweke,
1989] introduced the concept of relative numerical efﬁciency
(RNE), which provides an index to quantify the inﬂuence of
sampling from an importance function. The idea behind RNE
is to compare the relative accuracy of solving an integral us-
ing samples coming from both the true and the proposal den-
sity. Accuracy is measured according to the variance of the
estimator of the integral.

If we use MC integration to estimate the mean value of
the state (EM C(x)), the variance of the estimator is given by
[Doucet et al., 2001] 2:
V ar[EN

M C(x)] = V arp(x)/N

(4)

where N is the number of samples coming from the true dis-
tribution p(x), and the subscript p expresses that the variance
involved is computed using the target distribution.

When the samples come from an importance function q(x),
the variance of the estimator corresponds to the variance
of Importance Sampling (IS), which is given by [Geweke,
1989]:
V ar[EN

IS(x)] = Eq((x−Ep(x))2 w(x)2)/NIS = σ2

IS/NIS,
(5)
where w(x) corresponds to p(x)/q(x) the weights of IS and
NIS is the number of samples coming from the importance
function.

1Here complexity is understood in terms of the amount of infor-

mation needed to code the distribution.

2In the rest of the section, we concentrate on one iteration of the

ﬁlter and we drop the subscript t.

To achieve similar levels of accuracy, the variance of both
estimators should be equal. This allow us to ﬁnd a relation
that quantiﬁes the equivalence between samples from the true
and the proposal density,

N = NIS V arp(x)

σ2
IS

(6)

Replacing (6) in (3) allows us to correct the bound given
by KLD-Sampling when the samples do not come from the
true distribution but from an importance function:

NIS >

σ2
IS

V arp(x)

1
2

χ2

k−1,1−δ.

(7)

Using MC integration, V arp(x) and σ2

IS can be estimated

by:
V arp(x) = Ep(x2) − Ep(x)2 ≈

(cid:80)N
(cid:80)N

and
IS ≈
σ2

−2

i w2
i

i=1 x2
i=1 wi

(cid:80)n

(cid:80)N
(cid:80)N
(cid:80)n

i=1 xi w2
i=1 wi

(cid:80)N
(cid:80)N

i=1 x2
i wi
i=1 wi

i Ep(x)

+

− Ep(x)2

(cid:80)N
(cid:80)N

i=1 w2

i Ep(x)2
i=1 wi

i=1 xi wi/

with Ep(x) =

(8)
i=1 wi. Equation (8) shows
that using appropriate accumulators, it is possible to calculate
the bound incrementally keeping the O(N) complexity of the
ﬁlter.
3.2 Asymptotic Normal Approximation
Usually, the particle ﬁlter keeps track of the posterior density
with the goal of estimating the mean or higher order moments
of the state. This suggests an alternative error metric to deter-
mine the number of particles. Instead of checking the accu-
racy of the estimation of the posterior, it is possible to check
the accuracy of a particle ﬁlter in the estimation of a moment
of this density.

Under weak assumptions and using the strong law of large
numbers, it is possible to show that at each iteration the esti-
mation of the mean given by the particle ﬁlter is asymptoti-
cally unbiased [DeGroot, 1989]. Furthermore, if the variance
of this estimator is ﬁnite, the central limit theorem justiﬁes
an asymptotic normal approximation for it [DeGroot, 1989],
which is given by:
(9)
where N (µ, σ2) denotes the normal distribution with mean µ
and standard deviation σ.

EP F (x) ∼ N (Ep(x), σ2

IS/NIS)

Using this approximation, it is possible to build a one sided
conﬁdence interval for the number of particles that limits the
error in the estimation of the mean:

P (| EP F (x) − Ep(x)

|≤ ) ≥ (1 − α)

Ep(x)

(10)
where | · | denotes absolute value; Ep(x) is the true mean
value of the state;  corresponds to the desired error; and (1−
α) corresponds to the conﬁdence level.

Following the usual derivation of conﬁdence intervals,
Equation (10) produces the following bound for the number
of particles:

NIS ≥ Z 2

1−α/2 σ2
IS
2 Ep(xt)2

(11)

3.3 Testing the Bounds
Figure 1 shows the distributions used to test the bounds.
The true distribution corresponds to p(x) = 0.5N (3, 2) +
0.5N (10, 2) and the importance function to q(x) =
0.5N (2, 4) + 0.5N (7, 4). In all the trials, the desired error
was set to 0.01 and the conﬁdence level to 95%.

Figure 1: Inefﬁcient allocation of samples due to a mismatch be-
tween p(x) and q(x).

Figure 2a shows the number of particles predicted by the
different bounds. The predicted number of particles is highly
consistent. Also, the revised versions of KLD-Sampling con-
sistently require a larger number of particles than the original
algorithm. This is expected because of the clear mismatch
between the proposal and the true densities.

Figure 2b shows the resulting KL-divergence for each
case. It is interesting to note how the practical results match
closely the theoretical ones. Using the original version of
KLD-Sampling, the error in the estimation is signiﬁcantly
greater than the one speciﬁed. However, when the same
predicted number of particles is sampled from the true dis-
tribution (solid-line), the resulting error matches closely the
one speciﬁed. This shows clearly that constraining the sam-
pling to the right assumption, the original bound predicted
by KLD-Sampling is correct. In the case of the revised ver-
sions of KLD-Sampling the resulting error using Equation (7)
matches closely the one speciﬁed. In the same way, the error
provided by the bound in Equation (11) also matches closely
the level speciﬁed.

4 Adaptive Propagation of the Particles
The regular implementation of the particle ﬁlter propagates
the particles using the dynamic prior p(xt/(cid:126)yt−1). This strat-
egy has the limitation of propagating the samples without
considering the most recently available observation, yt. Im-
portance sampling suggests that one can use alternative prop-
agation functions that can provide a better allocation of the
samples, for example, a suitable functional of yt. Unfor-
tunately, the use of an arbitrary importance function signif-
icantly increases the computational load of the particle ﬁlter.
In this case, as opposed to the standard particle ﬁlter, the esti-
mation of each weight requires the evaluation of the dynamic
prior. This section shows a method to build an importance
function that takes into account the most recent observation
yt without increasing the computational complexity of the ﬁl-
ter.

−50510152000.020.040.060.080.10.120.140.16xpr(x)Samples from p(x)True distribution p(x)___Samples from q(x)Proposal q(x)− − −Figure 2: a) Number of particles given by each bound. b) Resulting KL-divergence.

4.1 Previous Work
In the literature about particle ﬁlters and importance sam-
pling, it is possible to ﬁnd several techniques that help to
allocate the samples in areas of high likelihood under the tar-
get distribution. The most basic technique is rejection sam-
pling [Tanner, 1996]. The idea of rejection sampling is to
accept only the samples with an importance weight above a
suitable value. The drawback is efﬁciency: there is a high
rejection rate in cases where the proposal density does not
match closely the target distribution. In [West, 1993], West
presents a kernel-based approximation to build a suitable im-
portance function. However, the computational complexity
of the method is unaffordable. In the context of mobile robot
localization, Thrun et al. [Thrun et al., 2000] propose to sam-
ple directly from the likelihood function, but in many appli-
cations this is not feasible or prohibitive.

Pitt and Shephard propose the auxiliary particle ﬁlter [Pitt
and Shephard, 1999]. They augment the state representation
with an auxiliary variable. To sample from the resulting joint
density, they describe a generic scheme with computational
complexity of O(N). The disadvantage is the additional com-
plexity of ﬁnding a convenient importance function. Pitt and
Sheppard provide just general intuitions about the form of a
this function. In this paper we improve on this point by pre-
senting a method to ﬁnd a suitable importance function.

4.2 Adaptive Propagation of the Samples
Sampling from the dynamic prior in Equation (2) is equiva-
lent to sample from the following mixture distribution:

p(xt/(cid:126)yt−1) ≈ n(cid:88)

βk p(xt/xk

t−1)

(12)

k=1

where the mixture coefﬁcients βk are proportional
to
p(xt−1/(cid:126)yt−1). The key observation is that under this scheme
the selection of each propagation density depends on the mix-
ture coefﬁcients βk’s, which do not incorporate the most re-
cent observation yt. From an MC perspective, it is possible to
achieve a more efﬁcient allocation of the samples by includ-
ing yt in the generation of the coefﬁcients. The intuition is
that the incorporation of yt increases the number of samples

t−1) associated with

drawn from mixture components p(xt/xk
areas of high probability under the likelihood function.
Under the importance sampling approach, it is possible to
generate a new set of coefﬁcients β∗
k that takes into account yt
by sampling from the importance function p(xt−1/(cid:126)yt). In this
t from the dynamic prior p(xt/(cid:126)yt−1)
way, the set of samples xi
is generated by sampling from the mixture,

n(cid:88)

β∗
k p(xt/xk

t−1)

(13)

k=1

and then adding to each particle xi
given by,

t a compensatory weight

t−1)

(14)

t, wi

wi

t =

, with xi

p(xk
p(xk

t−1/(cid:126)yt−1)
t−1/(cid:126)yt)

t ∼ p(xt/xk
t}n
The resulting set of weighted samples {xi
i=1 still comes
from the dynamic prior, so the computational complexity of
the resulting ﬁlter is still O(N). The extra complexity of this
operation comes from the need to evaluate and to draw sam-
t−1/(cid:126)yt). Fortunately,
ples from the importance function p(xi
the calculation of this function can be obtained directly from
the operation of the regular particle ﬁlter. To see this clearly,
consider the following:
p(xt, xt−1/(cid:126)yt) ∝ p(yt/xt, xt−1, (cid:126)yt−1) p(xt, xt−1/(cid:126)yt−1)
∝ p(yt/xt) p(xt/xt−1, (cid:126)yt−1)p(xt−1/(cid:126)yt−1)
∝ p(yt/xt)p(xt/xt−1)p(xt−1/(cid:126)yt−1)
(15)

Equation (15) shows that, indeed, the regular steps of the
particle ﬁlter generate an approximation of the joint density
p(xt, xt−1/(cid:126)yt). After re-sampling from p(xt−1/(cid:126)yt−1), prop-
agating these samples with p(xt/xt−1), and calculating the
weights p(yt/xt), the set of resulting sample pairs (xi
t−1)
with correcting weights p(yt/xi
t) forms a valid set of sam-
ples from the joint density p(xt, xt−1/(cid:126)yt). Considering that
p(xt−1/(cid:126)yt) is just a marginal of this joint distribution, the set
of weighted-samples xi

t−1 are valid samples from it.

The previous description provides an adaptive algorithm
that allows the particle ﬁlter to use yt in the allocation of
the samples. First, N particles are used to generate the im-
portance function p(xt−1/(cid:126)yt). Then, starting from this im-
portance function, another N particles are used to generate

t, xi

05101520253035400.511.522.533.544.5x 104↓ Original KLD−Sampling↓ KLD−Sampling revised using Eq.(7)↓ Using asymptotic normal approximationIndependent RunsNumber of Particles a)051015202530354000.010.020.030.040.050.060.07← Original KLD−SamplingKLD−Sampling using samples from true distribution_____KLD−Sampling revised using Eq.(7)−o−o−Using asymptotic normal approximation−.−.−.Independent RunsKL−Divergence b)the desired posterior p(xt/(cid:126)yt). The relevant compensatory
weights are calculated according to Equation (14) and the
likelihood term P (yt/xt). The resulting ﬁlter has a computa-
tional complexity of O(2N).

In the previous algorithm the overlapping between a reg-
ular iteration of the regular particle ﬁlter and the process
of generating the importance function provides a convenient
way to perform an online evaluation of the beneﬁts of up-
dating the dynamic prior with information from the last ob-
servation. While in cases of a poor match between the dy-
namic prior and the posterior distribution the updating of the
dynamic prior can be beneﬁcial, in cases where these distri-
butions agree, the updating does not offer a real advantage,
and the extra processing should be avoided. To our current
knowledge, this issue has not been addressed before.

The basic idea is to quantify at each iteration of the par-
ticle ﬁlter the trade-off between continuing drawing samples
from a known but potentially inefﬁcient importance function
p(xt−1/(cid:126)yt−1) versus incurring in the cost of building a new
importance function p(xt−1/(cid:126)yt) that provides a better alloca-
tion of the samples under the likelihood function. The impor-
tant observation is that, once the regular particle ﬁlter reaches
an adequate estimate, it can be used to estimate both the pos-
terior distribution p(xt/(cid:126)yt) and the updated importance func-
tion p(xt−1/(cid:126)yt).

The last step of the algorithm is to ﬁnd a metric that pro-
vides a way to quantify the efﬁciency in the allocation of the
samples. Considering that the efﬁciency in the allocation of
the samples depends on how well the dynamic prior resem-
bles the posterior distribution, an estimation of the distance
between these two distributions is a suitable index to quan-
tify the effectiveness of the propagation step. We found a
convenient way to estimate the Kullback-Leibler divergence
(KL-divergence) between these distributions, and in general
between a target distribution p(x) and an importance function
q(x):

KL(p(x), q(x)) ≈ log(N) − H( ˆwi).

(16)
Equation (16) states that for a large number of particles,
the KL-divergence between the dynamic prior and the poste-
rior distribution can be estimated by calculating how far the
entropy of the distribution of the weights, H( ˆwi), is from the
entropy of a uniform distribution (log(N)). This is an intu-
itive result because in the ideal case of importance sampling,
where p(x) = q(x), all the weights are equal. In consequence
the entropy of the weights is a suitable value to quantify the
efﬁciency in the allocation of the samples.

5 Application
To illustrate the advantages of the self adaptive particle ﬁlter,
we use a set of frames of a video sequence consisting of two
children playing with a ball. The goal is to keep track of the
positions of the ball and the left side child. Each hypothesis
about the position of a target is given by a bounding box de-
ﬁned by its height, width, and the coordinates of its center.
The motion model used for the implementation of the parti-
cle ﬁlter corresponds to a Gaussian function of zero mean and
diagonal covariance matrix with standard deviations of 20 for
the center of each hypothesis and 0.5 for the width and height.

Figure 3 shows the results of tracking the targets using the
self adaptive particle ﬁlter. The bounding boxes correspond
to the most probable hypotheses in the sample set used to
estimate the posterior distributions of the states. In the esti-
mation of the number of particles, we just consider the x and
y coordinates of the center of the bounding boxes, assuming
independence to facilitate the use of Equation (7). We set
the desired error to 0.01 and the conﬁdence level to 95%. A
minimum number of 1000 samples is always used to ensure
that convergence has been achieved. In the adaptation of the
propagation function we set the threshold for the entropy of
the weights in 2.

Figure 4-left shows the number of particles needed to esti-
mate the posterior distribution of the ball at each frame with-
out adapting the propagation function. Figure 4-right shows
the number of particles in the case of adapting the importance
function. The tracking engine decides to adapt the importance
function at all the frames where the ball travels from one child
to the other (Frames 3-7).

In the case of tracking the child, the result shows that there
is not a major difference between the self adaptive particle
ﬁlter and the regular ﬁlter. The self adaptive ﬁlter needs a
roughly constant number of particles during the entire se-
quence without needing to adapt the importance function.
This is expected because the child has only a small and slow
motion around a center position during the entire sequence.
Therefore the stationary Gaussian motion model is highly ac-
curate and there is not a real advantage of adapting the num-
ber of particles or the propagation function.

In the case of the ball, the situation is different. During
the period that the ball travels from one child to the other
(Frames 3 to 7), it has a large and fast motion, therefore the
Gaussian motion model is a poor approximation of the real
motion. As a consequence there is a large mismatch between
the dynamic prior and the posterior distribution. This pro-
duces an inefﬁcient allocation of the samples and the estimate
without adapting the importance function needs a larger set of
samples to populate the relevant parts of the posterior. In con-
trast, when adapting the importance function during Frames
3 to 7 it is possible to observe a signiﬁcant reduction in the
number of samples due to a better allocation of them.

6 Conclusions
In this paper we present a self adaptive version of the parti-
cle ﬁlter that uses statistical techniques to estimate a suitable
number of particles and to improve the propagation function.
In terms of the estimation of the number of particles, the vali-
dation of the bounds using a synthetic example shows that the
empirical results match closely the theoretical predictions. In
particular, the results indicate that by considering the com-
plexity of the true density and how closely the proposal den-
sity mimics the true density, the new bounds show a clear im-
provement over previous techniques such as KLD-Sampling.
The mechanisms used by the self adaptive ﬁlter to adapt
the importance function and to identify when the adaptation
of the importance function may be beneﬁcial proved to be
highly relevant. Using these mechanisms to track targets in
a real video sequence, the self adaptive ﬁlter was able to ef-

Figure 3: Tracking results for the ball and the left side child for frame 1, 5, and 14. The bounding boxes correspond to the most
probable hypotheses in the sample set used to estimate the posterior distributions.

Figure 4: Number of particles used at each iteration to track the ball. Left: without adapting the importance function. Right:
Adapting the importance function.

In Proc. of the international conf. on machine learning
(ICML), 1998.

[Pitt and Shephard, 1999] M. Pitt and N. Shephard. Filtering
via simulation: Auxiliary particle ﬁlters. Journal of the
American Statistical Association, 94(446):590–599, June
1999.

[Tanner, 1996] M. Tanner. Tools for Statistical Inference.

Springer-Verlag, 3nd edition, 1996.

[Thrun et al., 2000] S. Thrun, D. Fox, and W. Burgard.
Monte Carlo localization with mixture proposal distribu-
tion.
In AAAI National Conf. on Artiﬁcial Intelligence,
pages 859–865, Austin, Tx, 2000.

[West, 1993] M. West. Approximating posterior distribu-
tions by mixtures. Journal of the Royal Statistical Society,
Serie B, 55(2):409–422, 1993.

ﬁciently track targets with different motions using a general
Gaussian motion model. Furthermore, by avoiding the need
of overestimating the number of particles and by allocating
these particles in areas of high likelihood, the self adaptive ﬁl-
ter proved to operate with a similar computational complexity
to the regular particle ﬁlter.

References
[Boers, 1999] Y. Boers. On the number of samples to be
drawn in particle ﬁltering. In IEE Colloquium on Target
Tracking: Algorithms and Applications, pages 5/1 –5/6,
1999.

[DeGroot, 1989] M. DeGroot. Probability and Statistics.

Addison Wesley, 2nd edition, 1989.

[Doucet et al., 2001] A. Doucet, N. de Freitas, and N. Gor-
don. An introduction to sequential Monte Carlo methods.
In Sequential Monte Carlo Methods in Practice, pages 3–
14. Springer, 2001.

[Fox et al., 1999] D. Fox, W. Burgard, F. Dellaert, and
S. Thrun. Monte Carlo localization: Efﬁcient position es-
timation for mobile robots. In Proc. of the nat. conf. on AI
(AAAI), 1999.

[Fox, 2001] D. Fox. KLD-Sampling: Adaptive particle ﬁl-
ters. In Advances in Neural Information Processing Sys-
tems 14 (NIPS), 2001.

[Geweke, 1989] J. Geweke. Bayesian inference in econo-
metric models using Monte Carlo integration. Economet-
rica, 57:1317–1339, 1989.

[Koeller and Fratkina, 1998] D. Koeller and R. Fratkina. Us-
ing learning for approximation in sthocastic processes.

StereoColoHStereoColorHStereoColorHColorHStereo0246810121450010001500200025003000350040004500Number of ParticlesFrame NumberX dimension−−x−−x−−Y dimension−−o−−o−−2468101214050010001500200025003000Number of ParticlesFrame NumberX dimension−−x−−x−−Y dimension−−o−−o−−