State Space Search for Risk-averse Agents

Patrice Perny

Olivier Spanjaard

Louis-Xavier Storme

LIP6 - University of Paris 6

LIP6 - University of Paris 6

LIP6 - University of Paris 6

4 Place Jussieu

4 Place Jussieu

4 Place Jussieu

75252 Paris Cedex 05, France

75252 Paris Cedex 05, France

patrice.perny@lip6.fr

olivier.spanjaard@lip6.fr

75252 Paris Cedex 05, France
louis-xavier.storme@lip6.fr

Abstract

We investigate search problems under risk in state-
space graphs, with the aim of ﬁnding optimal
paths for risk-averse agents. We consider prob-
lems where uncertainty is due to the existence of
different scenarios of known probabilities, with
different impacts on costs of solution-paths. We
consider various non-linear decision criteria (EU,
RDU, Yaari) to express risk averse preferences;
then we provide a general optimization procedure
for such criteria, based on a path-ranking algorithm
applied on a scalarized valuation of the graph. We
also consider partial preference models like second
order stochastic dominance (SSD) and propose a
multiobjective search algorithm to determine SSD-
optimal paths. Finally, the numerical performance
of our algorithms are presented and discussed.

transition-costs. For example, when costs are time dependent
and representable by random variables, the SDA∗ algorithm
has been introduced to determine the preferred paths accord-
ing to the stochastic dominance partial order [Wellman et al.,
1995]. An extension of this algorithm speciﬁcally designed
to cope with both uncertainty and multiple criteria has been
proposed by Wurman and Wellman [1996].

We consider here another variation of the search prob-
lem under uncertainty, that concerns the search of “robust”
solution-paths, as introduced by Kouvelis and Yu [1997]. Un-
der total uncertainty, it corresponds to situations where costs
of paths might depend on different possible scenarios (states
of the world), or different viewpoints (discordant sources of
information). Roughly speaking, the aim is to determine
paths with “reasonnable” cost in all scenarios. Under risk
(i.e. when probabilities are known) this problem generalizes
to the search of “low-cost/low-risk” paths. Let us consider a
simple example:

1 Introduction
Various problems investigated in Artiﬁcial Intelligence can be
formalized as shortest path problems in an implicit state space
graph (e.g. path-planning for mobile robots, VLSI layout, in-
ternet searching). Starting from a given state, we want to de-
termine an optimal sequence of admissible actions allowing
transitions from state to state until a goal state is reached.
Here, optimality refers to the minimization of one or sev-
eral cost functions attached to transitions, representing dis-
tances, times, energy consumptions...For such problems, con-
structive search algorithms like A∗ and A∗
ε [Hart et al., 1968;
Pearl, 1984] for single objective problems or MOA∗ for mul-
tiobjective problems [Stewart and White III, 1991] have been
proposed, performing the implicit enumeration of feasible so-
lutions.

An important source of complexity in path-planning prob-
lems is the uncertainty attached to some elements of the prob-
lem. In some situations, the consequences of actions are not
certain and the transitions are only known in probabilities. In
some other, the knowledge of the current state is imperfect
(partial observability). Finally, the costs of transitions might
itself be uncertain. Although many studies concentrate on the
two ﬁrst sources of uncertainty (see the important litterature
on MDPs and POMDPS, e.g. Puterman, 1994; Kaebling et
al., 1999), some others focus on the uncertainty attached to

1, xi

Example 1 Consider the network pictured on Figure 1 where
the initial state is 1 and the goal node is 6. Assume that only
two scenarios with known probabilities p1 and p2 are relevant
concerning the trafﬁc, yielding two different sets of costs on
the network. Hence, to each path P i
is associated a vector
2), one cost per scenario: P 1 = (cid:2)1, 3, 5, 6(cid:3) with x1 =
(xi
(5, 18), P 2 = (cid:2)1, 3, 6(cid:3) with x2 = (8, 15), P 3 = (cid:2)1, 3, 4, 6(cid:3)
with x3 = (16, 15), P 4 = (cid:2)1, 2, 5, 6(cid:3) with x4 = (13, 10),
P 5 = (cid:2)1, 2, 6(cid:3) with x5 = (16, 7), P 6 = (cid:2)1, 2, 4, 6(cid:3) with
x6 = (20, 2). Using cost-distributions X i = (xi
2; p1, p2),
i = 1, . . . , 6, we want to determine solutions paths associated
with low-risk cost-distributions.

1, xi

(2,10)
3
(1,0)

(3,4)

1

(8,1)

(3,1)

2

(1,0)

(6,5)

5
(2,8)

6

(8,6)

4
(11,1)

20

15

10

5

0

p1

2p

3p

5
p

p4

0

5

10

15

20

6

p

Figure 1: A 2-scenarios problem and its representation

IJCAI-07

2353

This simple problem might prove very hard to solve on
larger instances due to the coexistence of two difﬁculties: the
combinatorial nature of the solution space and the existence
of several conﬂicting scenarios on costs. It is important to
note that the vector-valued path problem introduced above
cannot be reduced to a standard shortest path problem by lin-
ear scalarization of cost-vectors without loosing signiﬁcant
information. Assume for example that the arcs of the graph
plotted on the left part of Figure 1 are valued accoding to
their expected cost, so that each path P i
receives a weight
w(xi, p) = p1xi
2. Then algorithm A∗ used with such
scalars weights might output P 1
, depending on the rel-
ative value of p1 and p2, but neither path P 4
. This
can easily be shown using the right part of Figure 1 where the
images of solution-paths are plotted in the valuation space;
we can indeed see that P 2
do not belong to the
boundary of the convex hull (grey triangle) of the images of
paths, thus being excluded from the set of potential winners,
as long as a linear criterion is used. This is not satisfactory
because P 4
presents a well-balanced proﬁle and might be pre-
ferred to P 1
or P 6
by a risk-averse agent. Similarly he might
or P 5
to P 1
prefers P 2

, depending on probabilities.

nor P 2, P 5

1 + p2xi

and P 5

or P 6

, P 4

to P 6

Example 1 shows the limitations of linear aggregation
functions in decision-making under risk on non-convex do-
mains. To overcome the difﬁculty, we need to resort to more
sophisticated decision criteria to compare cost distributions
in term of risk, as those introduced in decision theory. These
decision criteria escape linearity either by introducing a trans-
formation of costs as in the Expected Utility Model (EU
[von Neumann and Morgenstern, 1947]) or by introducing a
probability-transformation as in Yaari’s model [Yaari, 1987],
or even both as in the Rank-Dependent Utility model (RDU
[Quiggin, 1993]). Alternatively, partial comparison models
including an idea of risk might be used when the agent’s util-
ity function is not known (e.g. Second-order Stochastic Dom-
inance, SSD). The aim of this paper is to incorporate such
models in search algorithms to determine low-risk solution
paths in implicit graphs.

The paper is organized as follows: in Section 2, we intro-
duce preliminary formal material as well as decision crite-
ria modelling risk-sensitive decision behaviours. In Section
3, we propose a general optimization procedure to ﬁnd the
best paths with respect to such criteria. In Section 4, we pro-
pose a multiobjective search algorithm for the determination
of SSD-optimal paths. Finally, numerical experiments of al-
gorithms are given in Section 5.

2 Problem Formulation

2.1 Notations and Deﬁnitions
We consider a state space graph G = (N, A) where N is
a ﬁnite set of nodes (possible states), and A is a set of arcs
representing feasible transitions between nodes. Formally, we
have A = {(n, n(cid:3)), n ∈ N, n(cid:3) ∈ S(n)} where S(n) ⊆ N is
the set of all successors of node n (nodes that can be reached
from n by a feasible elementary transition). Then s ∈ N
denotes the source of the graph (the initial state), Γ ⊆ N the
subset of goal nodes, P(s, Γ) the set of all paths from s to a
goal node γ ∈ Γ, and P(n, n(cid:3)) the set of all paths linking n to

n(cid:3). We call solution-path a path from s to a goal node γ ∈ Γ.
Throughout the paper, we assume that there exists at least one
solution-path.

(cid:2)

Following a classical scheme in robust optimization [Kou-
velis and Yu, 1997], we consider a ﬁnite set S =
{s1, . . . , sm} of possible scenarios, each having possibly
a different impact on the transition-costs, and a scenario-
dependent valuation v : A × S → N giving, for any arc
a ∈ A and any scenario s ∈ S the cost v(a, s) of the tran-
sition represented by a. Costs over a path are supposed to
be additive, which allows valuation v to be extended from
arcs to paths by setting, for any path P and any scenario s,
a∈P v(a, s). In the sequel, we assume that the
v(P, s) =
cost of every solution path is (upper) bounded by a positive
constant M .

(cid:2)m

A cost-vector x = (x1, . . . , xm) ∈ Rm

+ is associated to
each path P in the graph in such a way that component
xi = v(P, si). Let pi denote the probability of scenario
si, with pi ≥ 0 for i = 1, . . . , m and
i=1 pi = 1, then
a path P with cost-vector x is represented by the distribu-
tion (x1, . . . , xm; p1, . . . , pm). Let L be the set of probabilis-
tic distributions having a ﬁnite support in [0, M ]. The cost
of each path is a random variable X characterized by law
PX ∈ L, deﬁned for any B ⊆ [0, M ], by PX (B) = P ({s ∈
S : X(s) ∈ B}). For any random variable X, the expected
value of X is given by E(X) =
i=1 pixi, the cumulative
function FX is given by FX (z) = P ({s ∈ S : X(s) ≤ z})
for all z ∈ [0, M ] and the associated decumulative function is
denoted GX (z) = 1 − FX (z).

(cid:2)m

2.2 Decision Criteria for Risk-Averse Agents

In the ﬁeld of decision making under risk, the concept of risk-
aversion has been widely investigated, ﬁrst in the framework
of EU theory and then in more general frameworks. Roughly
speaking, risk-aversion amounts to preferring a solution with
a guaranteed cost to any other risky solution with the same
expected cost. This was formalized by Pratt and Arrow [Pratt,
1964; Arrow, 1965] that deﬁne weak risk-aversion for a weak
preference relation (cid:2) on L as follows:

Deﬁnition 1 An agent is said to be weakly risk-averse if, for
any distribution X in L, he considers that E(X) is as least
as good as X, i.e. E(X) (cid:2) X.

In EU theory, risk-aversion means that the agent’s util-
ity function u on payoffs is increasing and concave, the co-
efﬁcient of risk-aversion of any agent being measured by
−u(cid:3)(cid:3)(x)/u(cid:3)(x) [Arrow, 1965]. In our context, the counterpart
of EU is given by the expected weight function:

EW (X) =

m(cid:3)

i=1

piw(xi)

(1)

where w :
[0, M ] → R is a strictly increasing function
such that w(xi) represents the subjective weight (disutility)
attached to cost xi by the agent. Criterion EW (X) is to be
minimized since it represents the disutility of any cost dis-
tribution X. In the EW model, risk aversion means choos-
ing an increasing and convex w in Equation (1), so as to get
EW (E(X)) ≤ EW (X) for all X ∈ L.

IJCAI-07

2354

Despite its intuitive appeal, EU theory does not explain
all rational decision making behaviors (e.g. the violation of
Savage’s sure thing principle [Ellsberg, 1961]). This has led
researchers to sophisticate the deﬁnition of expected utility.
Among the most popular generalizations of EU, let us men-
tion the rank dependent utility introduced by Quiggin [1993],
which can be reformulated in our context as follows:

RDW (X) = w(x(1)) +

(cid:2)m−1

i=1 ϕ(GX (x(i)))

(cid:4)

(cid:5)
w(x(i+1)) − w(x(i))

(2)

where (.) represents a permutation on {1, . . . , m} such that
x(1) ≤ . . . ≤ x(m), ϕ is a non-decreasing probability trans-
formation function, proper to any agent, such that ϕ(0) = 0
and ϕ(1) = 1, and w is a weight function assigning subjective
disutility to real costs. This criterion can be interpreted as fol-
lows: the weight of a path with cost-distribution X is at least
w(x(1)) with probability 1. Then the weight might increase
from w(x(1)) to w(x(2)) with probability mass ϕ(GX (x(1)));
the same applies from w(x(2)) to w(x(3)) with probability-
mass ϕ(GX (x(2))), and so on... When w(z) = z for all z,
RDW is known as Yaari’s model [Yaari, 1987].

Weak risk-aversion can be obtained in Yaari’s model by
choosing a probability transformation such that ϕ(p) ≥ p
for all p ∈ [0, 1]. This holds also for RDW provided
function w is convex [Quiggin, 1993]. On the other hand,
when ϕ is the identity function, then RDW boils down
Indeed, considering probabilities q(1) = 1 and
to EW .
k=i+1 p(k) for all i = 1, ..., m − 1,
q(i+1) = GX (x(i)) =
RDW criterion can be rewritten as follows:
(cid:4)

(cid:2)m

(cid:5)
ϕ(q(i)) − ϕ(q(i+1))

(cid:2)m−1
+ϕ(q(m))w(x(m))

i=1

RDW (X) =

w(x(i))

(3)

From this last equation, observing that q(i) − q(i+1) = p(i),
we can see that RDW reduces to EW when ϕ(z) = z for all
z. Hence, RDW generalizes both EW and Yaari’s model. For
the sake of generality, we consider RDW in the sequel and
investigate the following problem:

RDW Search Problem. We want to determine a RDW-
optimal distribution in the set of all cost distributions of paths
in P(s, Γ).
Indeed, choosing w(x) = x,
This problem is NP-hard.
ϕ(0) = 0 and ϕ(x) = 1 for all x ∈ (0, M ], we get
RDW(X) = x(m) = maxi xi. Hence RDW minimization
in a vector valued graph reduces to the min-max shortest path
problem, proved NP-hard by Murthy and Her [1992].

3 Search with RDW
As many other non-linear criteria, RDW breaks the Bellman
principle and one cannot directly resort to dynamic program-
ming to compute optimal paths. To overcome this difﬁculty,
we propose an exact algorithm which proceeds in three steps:
1) linear scalarization: the cost of every arc is deﬁned as the
expected value of its cost distribution; 2) ranking: enumera-
tion of paths by increasing order of expected costs; 3) stop-
ping condition: stops enumeration when we can prove that a
RDW-optimal distribution has been found. Step 2 can be per-
formed by kA∗, an extension of A∗ proposed by Galand and

Perny [2006] to enumerate the solution-paths of an implicit
graph by increasing order of costs. Before expliciting step 3,
we need to establish the following result:

+

i=2

w(x(i))

Proposition 1 For all non-decreasing probability transfor-
mations ϕ on [0, 1] such that ϕ(q) ≥ q for all q ∈ [0, 1], for
all non-decreasing and convex weight functions w on [0, M ],
for all X ∈ L we have: RDW (X) ≥ w (E(X))
Proof. Since x(i+1) ≥ x(i) for i = 1, . . . , m − 1 and w is
non-decreasing, we have: w(x(i+1)) − w(x(i)) ≥ 0 for all
i = 1, . . . , m − 1. Hence, from Equation (2), ϕ(q) ≥ q for
all q ∈ [0, 1] implies that: RDW (X)
(cid:2)m−1
≥ w(x(1)) +
i=1 GX (x(i))
(cid:4)
(cid:5)
=
1 − GX (x(1))
(cid:4)
(cid:2)m−1

(cid:5)
w(x(i+1)) − w(x(i))
w(x(1)) + GX (x(m−1))w(x(m))

(cid:4)

(cid:5)
GX (x(i−1)) − GX (x(i))
(cid:2)m−1

2

(cid:2)m

j
yields cost x

i=2 p(i)w(x(i))

let {P 1, . . . , P r} denotes

= p(1)w(x(1))+ p(m)w(x(m)) +
= EW (X) ≥ w(E(X)) by convexity of w.
the set of elemen-
Now,
tary solution-paths in P(s, Γ), with cost distributions
X 1, . . . , X r
, indexed in such a way that E(X 1) ≤ E(X 2) ≤
. . . ≤ E(X r). Each distribution X j
i =
v(P j, si) with probability pi for i = 1, . . . , m. The se-
quence of paths (P j)j=1,...,r can be generated by imple-
menting the ranking algorithm of step 2 on the initial graph
G = (N, A), using a scalar valuation v(cid:3) : A → R+ deﬁned
by v(cid:3)(a) =
i=1 piv(a, si). Indeed, the value of any path P j
in this graph is v(cid:3)(P j) = E(X j) by linearity of expectation.
Now, assume that, during the enumeration, we reach (at
such that: w(E(X k)) ≥ RDW (X β(k))
step k) a path P k
where β(k) is the index of a RDW -optimal path in
{P 1, . . . , P k}, then enumeration can be stopped thanks to:
Proposition 2 If w(E(X k)) ≥ RDW (X β(k)) for some k ∈
{1, . . . , r}, where β(k) is the index of a RDW -minimal path
in {P 1, . . . , P k}, then P β(k)
is a RDW -minimal solution-
path in P(s, Γ).
Proof. We know that P β(k)
is RDW -minimal among
the k-ﬁrst detected paths. We only have to show that
no other solution-path can have a lower weight accord-
For all j ∈ {k + 1, . . . , r} we have:
ing to RDW .
RDW (X j) ≥ w(E(X j )) thanks to Proposition 1. More-
over E(X j) ≥ E(X k) which implies w(E(X j)) ≥
w(E(X k)) ≥ RDW (X β(k)). Hence RDW (X j) ≥
RDW (X β(k)) which shows that P β(k)
is RDW -minimal
over P(s, Γ).
2
Propositions 1 and 2 show that the ranked enumeration of
solution-paths performed at step 2 can be interrupted with-
out loosing the RDW -optimal solution. This establishes the
admissibility of our 3-steps algorithm. Numerical tests per-
formed on different instances and presented in Section 5 in-
dicate that the stopping condition is activated early in the
enumeration, which shows the practical efﬁciency of the pro-
posed algorithm.

4 Dominance-based Search
Functions RDW and EW provide sharp evaluation crite-
ria but require a precise knowledge of the agent’s attitude

IJCAI-07

2355

towards risk (at least to assess the disutility function).
In
this section we consider less demanding models yet allowing
well-founded discrimination between some distributions.

4.1 Dominance Relations
A primary dominance concept to compare cost distributions
in L is the following:
Deﬁnition 2 For all X, Y ∈ L, Functional Dominance is
deﬁned by: X FD Y ⇔ [∀s ∈ S, X(s) ≤ Y (s)]

For relation FD and any other dominance relation (cid:11) de-
ﬁned in the sequel, the set of (cid:11)-optimal distributions in L ⊆
L is deﬁned by: {X ∈ L : ∀Y ∈ L, Y (cid:11) X ⇒ X (cid:11) Y }.

When the probabilities of scenarios are known, functional
dominance can be reﬁned by ﬁrst order stochastic dominance
deﬁned as follows:
Deﬁnition 3 For all X, Y ∈ L, the First order Stochastic
Dominance relation is deﬁned by:

X FSD Y ⇔ [∀z ∈ [0, M ], GX (z) ≤ GY (z)]

Actually, the usual deﬁnition of FSD involves cumulative
distributions FX applied to payoffs instead of decumulative
functions GX applied to costs. In Deﬁnition 3, X FSD Y
means that X assigns no more probability than Y to events
of type: “the cost of the path will go beyond z”. Hence it
is natural to consider that X is at least as good as Y when
X FSD Y .

Relation FSD is clearly related to the EW model since
X FSD Y if and only if EW (X) ≤ EW (Y ) for all increas-
ing weight function w [Quiggin, 1993]. This gives a nice
interpretation to Deﬁnition 3 within EU theory, with a use-
ful consequence: if the agent is a EW-minimizer (with any
increasing weight function w), then his preferred solutions
necessarily belong to the set of FSD-optimal solutions. Now,
an even richer dominance relation can be considered:
Deﬁnition 4 For all X, Y ∈ L, the Second order Stochastic
Dominance relation is deﬁned as follows:

X SSD Y ⇔ [∀z ∈ [0, M ], G2

Y (z)]
(cid:6) M
z GX (y)dy, for all z ∈ [0, M ].

X(z) ≤ G2

X (z) =

where G2
Stochastic Dominance is acknowledged as a standard way
of characterizing risk-averse behaviors independently of any
utility model. For example, Rotschild and Stiglitz [1970]
and Machina and Pratt [1997] provide axiomatic character-
izations of SSD in terms of risk using “mean preserving
spreads”. As a consequence, an agent is said to be strongly
risk-averse if he prefers X to Y whenever X SSD Y . More-
over, SSD has a natural interpretation within EU theory:
X SSD Y if and only if EW (X) ≤ EW (Y ) for all increas-
ing and convex weight function w [Quiggin, 1993]. As a nice
consequence, we know that whenever an agent is a risk-averse
EW-minimizer, then his preferred solutions necessarily be-
long to the set of SSD-optimal solutions. The same applies
to RDW provided φ(q) ≥ q for all q ∈ [0, 1] and function
w is convex (this directly follows from a result of Quiggin
[1993]). This shows that, even outside EU theory, SSD ap-
pears as a natural preference relation for risk-averse agents.
It can be used as a ﬁrst efﬁcient ﬁltering of risky paths.

Interestingly enough, relations FSD and SSD dominance

relations can equivalently be deﬁned by:

2

ˇG2

where

ˇG2

(4)

(5)

X (p) =

X FSD Y ⇔ [∀p ∈ [0, 1], ˇGX(p) ≤ ˇGY (p)]
X SSD Y ⇔ [∀p ∈ [0, 1], ˇG
2
Y (p)]
ˇGX and
ˇG2
(cid:6) p

X are inverse functions deﬁned by:

X(p) ≤ ˇG

ˇGX (q)dq, for p ∈ [0, 1]

X are piecewise linear functions. Function

ˇGX (p) = inf{z ∈ [0, M ] : GX (z) ≤ p} for p ∈ [0, 1],
ˇG2
Since S is ﬁnite in our context, X is a discrete distribu-
ˇGX are step functions. Moreover G2
tion; therefore GX and
X
X (z) is
and
known as the Lorenz function. It is commonly used for in-
equality ordering of positive random variables [Muliere and
Scarsini, 1989]. As an illustration, consider Example 1 with
p1 = 0.4 and p2 = 0.6. We have:
X 1 (p) = 18p for all
p ∈ [0, 0.6),
X 1 (p) = 7.8 + 5p for all p ∈ [0.6, 1], whereas
ˇG2
X 5 (p) = 3.6 + 7p for all
p ∈ [0.4, 1]; hence
X 1 (p) for all p and therefore
X 5
with
cost (16, 7) is less risky than path P 1

. This conﬁrms the intuition that path P 5
with cost (5, 18)

X 5 (p) = 16p for all p ∈ [0, 0.4),
ˇG2
X 5 (p) ≤ ˇG2

SSD X 1

ˇG2

ˇG2

0

ˇG2

The dominance relations introduced in this subsection be-
ing transitive, the sets of FD-optimal elements, FSD-optimal
elements and SSD-optimal elements are not empty. More-
over, these sets are nested thanks to the following impli-
cations: X FD Y ⇒ X FSD Y and X FSD Y ⇒
X SSD Y , for all distributions X, Y ∈ L.
In Exam-
ple 1 we have L = {X 1, X 2, X 3, X 4, X 5, X 6} and p1 =
0.4 and p2 = 0.6. Hence the set of FD-optimal ele-
ments is {X 1, X 2, X 4, X 5, X 6}, the set of FSD-optimal el-
ements is the same and the set of SSD-optimal elements is
{X 4, X 5, X 6}. The next section is devoted to the following:
SSD Search Problem. We want to determine all SSD-optimal
distributions in the set of cost distributions of paths in P(s, Γ)
and for each of them, at least one solution-path.

4.2 Problem Complexity
To assess complexity of the search, we ﬁrst make explicit a
link between SSD and Generalized Lorenz Dominance, as
deﬁned by Marshall and Olkin [1979]. Generalized Lorenz
dominance, denoted GLD in the sequel, is based on the deﬁ-
nition of Lorenz vector L(x) = (L1(x), . . . , Lm(x)) for any
vector x = (x1, . . . , xm) where Lk(x) is the sum of the k
greatest components of x. Then, relation GLD is deﬁned
as follows: x GLD y if L(x) Pareto dominates L(y), i.e.
Lk(x) ≤ Lk(y) for k = 1, . . . , m. Now, if pi = 1/m for
i = 1, . . . , m then SSD deﬁned by Equation (5) on distribu-
tions reduces to Lorenz dominance on the corresponding cost
vectors since Lk(x) = m ˇG2
X (k/m). Hence, in the particular
case of equally probable scenarios, the SSD search problem
reduces to the search of Lorenz non-dominated paths, a NP-
hard problem as shown by Perny and Spanjaard [2003]. This
shows that the SSD search problem is also NP-hard.

4.3 The SSDA∗ Algorithm
Consider Example 1 and assume that the two scenarios have
equal probabilities, we can see that the preferred subpath

IJCAI-07

2356

from node 1 to node 5 is P = (cid:2)1, 3, 5(cid:3) with cost xP = (3, 10)
which is preferred to path P (cid:3) = (cid:2)1, 2, 5(cid:3) with cost xP (cid:2) =
(11, 2) since (3, 10; 0.5, 0.5) SSD (11, 2; 0.5, 0.5). Indeed,
we are in the case of Subsection 4.2 (equally probable scenar-
ios) with L(xP ) = (10, 13) and L(xP (cid:2) ) = (11, 13) and ob-
viously (10, 13) Pareto dominates (11, 13). Now, appending
path P (cid:3)(cid:3) = (cid:2)5, 6(cid:3) with xP (cid:2)(cid:2) = (2, 8) to P and P (cid:3) respectively
yields path P 1 = P ∪ P (cid:3)(cid:3) with cost x1 = (5, 18) and path
P 4 = P (cid:3) ∪P (cid:3)(cid:3) with x4 = (13, 10). Hence L(x4) Pareto dom-
inates L(x1), therefore (13, 10; 0.5, 0.5) SSD (5, 18; 0.5, 0.5)
which constitutes a preference reversal and illustrates a viola-
tion of Bellman principle, thus invalidating a direct dynamic
programming approach (optimal path P 4
would be lost dur-
ing the search if P (cid:3) is pruned at node 5 due to P ).

However, the problem can be overcome knowing that: i)
SSD-optimal paths are also FD-optimal; ii) FD-optimality
satisﬁes the Bellman principle; iii) the set of scenarios be-
ing ﬁnite, FD-optimality on cost distributions is nothing else
but Pareto-optimality on cost-vectors. SSD-optimal distribu-
tions might indeed be obtained in two stages: 1) generate
FD-optimal solution-paths using Multiobjective A∗ (MOA∗,
Stewart and White III, 1991; Mandow and de la Cruz, 2005);
2) eliminate SSD-dominated solutions within the output set.
However, FD-optimal solutions being often numerous, it is
more efﬁcient to focus directly on SSD-optimal solutions dur-
ing the search. For this reason we introduce now a reﬁnement
of MOA∗ called SSDA∗ for the direct determination of SSD-
optimal solutions.

As in MOA∗, SSDA∗ expands vector-valued labels (at-
tached to subpaths) rather than nodes. Note that, unlike
the scalar case,
there possibly exists several Pareto non-
dominated paths with distinct cost-vectors to reach a given
node; hence several labels can be associate to a same node
n. At each step of the search, the set of generated labels is
divided into two disjoint sets: a set OPEN of not yet expanded
labels and a set CLOSED of already expanded labels. When-
ever the label selected for expansion is attached to a solution
path, it is stored in a set SOL. Initially, OPEN contains only the
label attached to the empty subpath on node s, while CLOSED
and SOL are empty. We describe below the essential features
of the SSDA∗ algorithm.
Output: it determines the set of SSD-optimal solution-paths,
i.e. solution-paths the distribution of which is SSD-optimal.
If several paths have the same G2
distribution, only one
path among them is stored using standard bookkeeping tech-
niques.
like in MOA∗, a set H(n) of heuristic cost-
Heuristics:
vectors is used at any node n since n may be on the path
of more than one non-dominated solution. This set estimates
the set H ∗(n) of non-dominated costs of paths from n to Γ.
to direct the search we use a set-valued label-
Priority:
evaluation function F deﬁned in such a way that, F ((cid:6)), at
any label (cid:6), estimates the set F ∗((cid:6)) of non-dominated costs
of solution paths extending the subpath associated with (cid:6).
This set F ((cid:6)) is computed from all possible combinations
{g((cid:6)) + h : h ∈ H(n)}, where g((cid:6)) denotes the value of
the subpath associated with (cid:6) and n the node to which (cid:6) is
attached. At each step of the search, SSDA∗ expands a label
(cid:6) in OPEN such that F ((cid:6)) contains at least one SSD-optimal

(cid:7)

(cid:4)∈OPEN F ((cid:6)). Such a label can be chosen,
cost-vector in
for instance, so as to minimize EW with a convex w function.
At goal nodes, this priority rule guarantees to expand only
labels attached to SSD-optimal paths.
Pruning: the pruning of labels cannot be done directly with
the SSD relation, as shown in the beginning of this subsec-
tion. The following pruning rules are used:
RULE 1: at node n, a label (cid:6) ∈ OPEN is pruned if there exists
another label (cid:6)(cid:3) at the same node n such that g((cid:6)(cid:3)) FD g((cid:6)).
This rule is essentially the same as in MOA∗ and is justiﬁed
by the fact that FD-optimality does satisfy the Bellman princi-
ple and FD dominance implies SSD dominance. Indeed, la-
bels pruned like this necessarily lead to a FD-dominated paths
and therefore cannot lead to SSD-optimal solution paths.
RULE 2: a label (cid:6) ∈ OPEN is pruned if for all f ∈ F ((cid:6)) there
exists (cid:6)(cid:3) ∈ SOL such that g((cid:6)(cid:3)) SSD f . This rule allows an
early elimination of uninteresting labels while keeping admis-
sibility of the algorithm provided heuristic H is admissible,
i.e. ∀n ∈ N , ∀h∗ ∈ H ∗(n), ∃h ∈ H(n) s.t. h FD h∗.
Indeed, if H is admissible, then for all f ∗ ∈ F ∗((cid:6)) there ex-
ists f ∈ F ((cid:6)) such that f = g((cid:6)) + h FD g((cid:6)) + h∗ = f ∗,
which implies that f SSD f ∗ and therefore g((cid:6)(cid:3)) SSD f ∗ by
transitivity of SSD.

ˇG2

ˇG2

X (p) and

Note that deciding whether X SSD Y can be performed
Y (p)
in constant time. Indeed, since functions
are piecewise linear as indicated in Section 2, their compar-
ison amounts to test for Pareto dominance on the union set
of break points of both functions, the cardinality of which is
upper bounded by 2m.
Termination: the process is kept running until the set OPEN
becomes empty, i.e.
there is no remaining subpath able to
reach a new SSD-optimal solution path. By construction,
SSDA∗ develops a subgraph of the one developped by MOA∗
and the termination derives from the termination of MOA∗.

5 Numerical Tests

Various tests have been performed to evaluate the perfor-
mance of algorithms on randomly generated graphs of dif-
ferent sizes. The number of nodes in these graphs varies from
(for 1000
1000 to 6000 and the number of arcs from 10
(for 6000 nodes). Cost vectors are integers
nodes) to 5.10
randomly drawn within interval [0, 100]. Algorithms were
implemented in C++. The computational experiments were
carried out with a Pentium IV CPU 3.2GHz PC.

6

5

Table 1 presents the average performance of algorithms for
different classes of instances, characterized by #nodes (the
number of nodes in the graph), and m (the number of sce-
narios). In each class, we give the average performance com-
puted over 20 different instances. For every class, we give
#SSD the average number of SSD-optimal distributions and
tSSD the average time (in seconds) to solve the SSD search
problem with SSDA∗. Results given in Table 1 show that
the average number of SSD-optimal distributions increases
slowly with the size of the graph; moreover SSDA∗ com-
putation times show a good efﬁciency (less than 15 sec-
onds in worst cases). The two rightmost columns of Table 1
concern the performance in determining RDW-optimal paths
with w(z) = z2
2 . We give #Gen, the aver-

and ϕ(p) = p

1

IJCAI-07

2357

2

m #nodes
1000
3500
6000
1000
3500
6000
1000
3500
6000

5

10

#N SSD

tN SSD

2.20
2.25
2.45
5.10
5.70
6.60
10.75
14.15
13.5

0.12
1.75
5.75
0.25
4.14
13.69
0.55
9.47
30.97

#Gen
2.70
3.35
3.10
14.90
33.05
30.95
83.35
261.1
314.5

tRDW
0.038
0.561
1.750
0.05
0.75
2.36
0.08
1.68
6.80

Table 1: Performance of the algorithms

age number of paths generated before reaching the stopping
condition of Proposition 2, and tRDW the average time of
the search in seconds. Values obtained for #Gen show that
path enumeration is stopped after a very reasonable number
of iterations and computation times are about one second in
worst cases. The gain in efﬁciency when compared to SSDA∗
is due to the preliminary scalarization of the graph valua-
tion which avoids numerous Pareto-dominance tests during
the exploration, but also to the fact that we only seek one
RDW-optimal path among NSSD paths. We have performed
other experiments which are not reported here to save space:
when ϕ(p) = p (EW model) or w(z) = z (Yaari’s model),
the performance is even slightly better. Moreover, when con-
vexity of w and concavity of ϕ are increased to enhance risk-
aversion, e.g. with w(z) = z10
10 , the perfor-
mance is not signiﬁcantly degraded.

and ϕ(p) = p

1

6 Conclusion
We have provided efﬁcient exact algorithms to determine
low-risk/low-cost solution paths. Algorithm SSDA∗ pro-
posed in Section 4 provides a subset of paths convenient for a
risk-averse agent, without requiring the deﬁnition of a disutil-
ity function. Moreover, when a disutility criterion is known,
more or less risky paths can be efﬁciently determined with
the algorithm proposed in Section 3. In the future, it should
be worth investigating optimization based on risk-sensitive
models in other dynamic decision making problems, e.g. de-
cision trees or Markov Decision Processes. In that direction,
the main problem to deal with is the existence of dynamic in-
consistencies induced by such nonlinear models. To face this
difﬁculty, adapting the approaches proposed here to bypass
the violation of Bellman principle might be of interest.

References
[Arrow, 1965] K. J. Arrow. The Theory of Risk Aversion.

Ynjo Jahnsonin Saatio, Helsinki, 1965.

[Ellsberg, 1961] D. Ellsberg. Risk, ambiguity and the Savage
axioms. Quaterly J. of Economics, 75(4):643–669, 1961.

[Galand and Perny, 2006] L. Galand and P. Perny. Compro-

mise search in state space graphs. Proc. of ECAI, 2006.

[Hart et al., 1968] P. E. Hart, N. J. Nilsson, and B. Raphael.
A formal basis for the heuristic determination of minimum
cost paths. IEEE Trans. Syst. and Cyb., SSC-4 (2):100–
107, 1968.

[Kaebling et al., 1999] L.P. Kaebling, M. Littman, and
A. Cassandra. Planning and acting in partially observ-
able stochastic domains. Artiﬁcial Intelligence, 101:99–
134, 1999.

[Kouvelis and Yu, 1997] P. Kouvelis and G. Yu. Robust dis-
crete optimization and its applications. Kluwer Academic
Publisher, 1997.

[Machina and Pratt, 1997] M.J. Machina and J. W. Pratt. In-
creasing risk: Some direct constructions. Journal of Risk
and Uncertainty, 14:103–127, 1997.

[Mandow and de la Cruz, 2005] L. Mandow and J.L. Prez
de la Cruz. A new approach to multiobjective A∗ search.
In Proceedings of IJCAI-05, pages 218–223, 2005.

[Marshall and Olkin, 1979] W. Marshall and I. Olkin.

In-
equalities: Theory of Majorization and its Applications.
Academic Press, London, 1979.

[Muliere and Scarsini, 1989] P. Muliere and M. Scarsini. A
note on stochastic dominance and inequality mesures.
Journal of Economic Theory, 49:314–323, 1989.

[Murthy and Her, 1992] I. Murthy and S. Her. Solving min-
max shortest-path problems on a network. Naval Research
Logistics, 39:669–689, 1992.

[Pearl, 1984] J. Pearl. Heuristics. Intelligent Search Strate-
gies for Computer Problem Solving. Addison Wesley,
1984.

[Perny and Spanjaard, 2003] P. Perny and O. Spanjaard. An
axiomatic approach to robustness in search problems with
multiple scenarios.
In Proc. of UAI’03, pages 469–476,
2003.

[Pratt, 1964] J. Pratt. Risk aversion in the small and in the

large. Econometrica, 32(1):122–136, 1964.

[Puterman, 1994] M.L. Puterman. Markov decision pro-
cesses, discrete stochastic dynamic programming. Wiley
& Sons, 1994.

[Quiggin, 1993] J. Quiggin. Generalized Expected Utility

Theory: The Rank-Dependent Model. Kluwer, 1993.

[Rotschild and Stiglitz, 1970] M. Rotschild and J. Stiglitz.
Increasing risk: I. a deﬁnition. Journal of Economic The-
ory, 2:225–243, 1970.

[Stewart and White III, 1991] B. S. Stewart and C. C.
White III. Multiobjective A∗. Journal of ACM, 38(4):775–
814, 1991.

[von Neumann and Morgenstern, 1947] J. von Neumann and
O. Morgenstern. Theory of games and economic behavior.
2nd Ed. Princeton University Press, 1947.

[Wellman et al., 1995] M.P. Wellman, K. Larson, M. Ford,
and P.R. Wurman. Path planning under time-dependent
uncertainty. In Proceedings of UAI, pages 532–539, 1995.
[Wurman and Wellman, 1996] P.R. Wurman and M.P. Well-
man. Optimal factory scheduling using stochastic domi-
nance A∗. In Proceedings of UAI, pages 554–563, 1996.

[Yaari, 1987] M.E. Yaari. The dual theory of choice under

risk. Econometrica, 55:95–115, 1987.

IJCAI-07

2358

