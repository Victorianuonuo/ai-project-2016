Learning User Clicks in Web Search

Ding Zhou, Levent Bolelli, Jia Li, C. Lee Giles, Hongyuan Zha

Department of Computer Science and Engineering

Department of Statistics

College of Information Sciences and Technology

The Pennsylvania State University, University Park, PA 16802

Abstract

Machine learning for predicting user clicks in Web-
based search offers automated explanation of user
activity. We address click prediction in the Web
search scenario by introducing a method for click
prediction based on observations of past queries
and the clicked documents. Due to the sparsity of
the problem space, commonly encountered when
learning for Web search, new approaches to learn
the probabilistic relationship between documents
and queries are proposed. Two probabilistic models
are developed, which differ in the interpretation of
the query-document co-occurrences. A novel tech-
nique, namely, conditional probability hierarchy,
ﬂexibly adjusts the level of granularity in parsing
queries, and, as a result, leverages the advantages
of both models.

1 Introduction
Predicting the next click of a user has gained increasing im-
portance. A successful prediction strategy makes it possible
to perform both prefetching and recommendations. In addi-
tion, the measurement of the likelihood of clicks can infer a
user’s judgement of search results and improve ranking.

As an important goal of Web usage mining [Srivastava et
al., 2000], predicting user clicks in Web site browsing has
been extensively studied. Browse click prediction typically
breaks down the process into three steps: (1) clean and pre-
pare the Web server log data; (2) extract usage patterns; and
(3) create a predictive model. There have been a variety of
techniques for usage pattern extraction, user session cluster-
ing [Banerjee and Ghosh, 2001; Gunduz and Ozsu, 2003],
page association rule discovery [Gunduz and Ozsu, 2003],
Markov modeling [Halvey et al., 2005], and implicit rele-
vance feedback [Joachims, 2002].

Contrary to the rich research in click prediction in Web site
browsing, the prediction of user clicks in Web search has not
been well addressed. The fundamental difference between
predicting click in Web search and Web site browsing is the
scale of the problem space. The modeling of site browsing
typically assumes a tractable number of pages with a reason-
able number of observations of the associations among these
pages. This assumption, however, no longer holds in the Web

search scenario. The vast amount of documents quickly result
in very high dimensional space and hence sparsiﬁes the prob-
lem space (or equivalently leads to a lack of observations ),
which effects model training. In order to reduce the problem
space, some previous work ﬁrst classiﬁes the large document
collection into a small number of categories so as to predict
topic transition in Web search [Shen et al., 2005]. However,
since the prediction of user clicks requires the granularity of
a single document, we do not consider issues in document
clustering but rather work on the full space of the document
collection.

Consider the problem of learning from Web search logs for
click prediction. We deﬁne the task as learning the statistical
relationship between queries and documents. The primary
assumption is that the clicks by users indicate their feedback
on the quality of query-document matching. Hypothesize that
the vocabulary of query in terms of words remains stable over
a period of time. Denote this by Σ. Ideally, if we were able to
collect sufﬁcient instances for every combination of words (
2Σ
) and the clicked documents with these queries, we would
be able to estimate the probability of future clicks based on
past observations. The feasibility of the approach, however,
relies on the assumptions that the training data exhausts all
the possible queries.

However, since the number of different queries in Web
search explodes with emerging concepts in user knowledge
and randomness in the formation of queries, the tracking of
all possible queries becomes infeasible both practically and
computationally. For example, Fig. 1 illustrates the increase
in the number of distinct queries submitted to CiteSeer over a
period of three months. The linear growth of distinct queries
over time indicates that we can hardly match even a small
fraction of the new queries exactly with the old queries. As a
result, prediction cannot be performed for new queries, yield-
ing low predictability. Furthermore, many new documents are
being clicked even after having accumulated documents that
were clicked on over considerably long time. Learning of the
relationship between the complete queries and the documents
is consequently a highly challenging problem.

An alternative naive solution to the lack of training in-
stances is to break down queries into words. An observation
of a query and the corresponding clicked document ( query-
document pair) is transformed into several independent ob-
servations of word and document, i.e. word-document pair.

IJCAI-07

1162

Number of different queries
Number of different words

x 105

9

8

7

6

5

4

3

2

1

s
n
o

i
t

a
v
r
e
s
b
O

0

0

2

4
Observation time (weeks)

6

8

10

12

Figure 1: Number of distinct queries and words in CiteSeer
over 12 weeks.

This solution can predict unknown queries as long as the new
query contains some known words. However, this solution
suffers in prediction accuracy due to the discarding of word
proximity information in existing queries.

We ﬁrst propose two probabilistic models, namely full
model and independent model, in order to capture the ideas
behind the above intuition, which interpret query-document
pairs differently. The full model tends to achieve high pre-
diction accuracy if sufﬁcient training instances are provided,
but it cannot be applied when new queries are encountered.
On the other hand, the independent model yields high pre-
dictability while suffering in accuracy. In order to tradeoff
the prediction accuracy with predictability, we suggest a new
conditional probability hierarchy technique that combines the
two models. We are not aware of any previous work study-
ing the click prediction problem for Web search on such large
scale search logs.
In addition, as a by-product of the new
combination approach, n-grams of words are discovered in-
crementally.

2 Related Work

User click prediction is based on understanding the naviga-
tional pattern of users and, in turn, modeling observed past
behavior to generate predictive future behavior. Usage pattern
modeling has been achieved traditionally by session cluster-
ing, Markov models, association rule generation, collabora-
tive ﬁltering and sequential pattern generation.

Markov model based prediction methods generally suffer
from high order, usually needing clustering of user clicks to
reduce the limitations stemming from high state-space com-
plexity and decreased coverage. On the other hand, lower
order Markov models are not very accurate in predicting
user’s browsing behavior, since these models keep a small
window to look back in the history, which is not sufﬁcient
to correctly discriminate observed patterns [Deshpande and
Karypis, 2004]. Markov models seem to be more suitable for
mobile applications [Halvey et al., 2005] where the number
of states is low due to the few links a user can navigate.

User session clustering [Banerjee and Ghosh, 2001; Gun-
duz and Ozsu, 2003] identiﬁes users’ navigational paths from
web server logs and deﬁnes session similarity metrics based
on similarity of the paths and time spent on each page on a
path. Clustering is employed on the similarity graph which
are utilized for predicting users’ requests.

Beeferman and Berger [Beeferman and Berger, 2000] pro-
posed query clustering based on click-through data. Each

(query, clicked URL) pair is used to construct a bipartite
graph and queries that result in clicking to the same URL are
clustered. The content features in the queries and the docu-
ments are discarded. Joachims [Joachims, 2002] introduces
a supervised learning method that trains a retrieval function
based on click-through data that takes the relative positions of
clicks in a rank as training data set. We pursue a different ap-
proach that seeks to learn the statistical relationship between
queries and user actions in this paper.

3 Problem Statement
Descriptions of the problem is formalized. Let ℵ be the doc-
ument full set. {di} = D ∈ ℵ denotes the set of docu-
ments that have ever been shown to users in search results
and C ⊆ D is the document set that has been clicked on.
Σ = {wi} denotes the word vocabulary. The query set is
Q = {qj}, where qj = {wj1, ..., wjk} ∈ 2Σ
. Our observa-
tion of Web search log is abstracted as a sequence of query-
document pairs: Γ ⊆ Q × C. The posterior probability for
observing each click on a certain document d is P (d|q, dq),
where dq represents the document list returned with query q.
The problem is to predict P (d|q, dq, Γ), which measures
the probability of user clicking on document d for query q
when presented with the result list dq. The prediction of
user click for query q becomes: ˆd = arg maxd P (d|q, dq, Γ),
where d ∈ dq and Γ is the observation of query-document
click so far.

4 Probabilistic Models
The two probabilistic models we propose are for acquiring
estimations of P (d|q) for each d in dq given query q. De-
pending on interpretations of a click on d for q, two types of
models are introduced, namely, the independent model and
the full model.

Independent model

4.1
When we observe a query-document pair (cid:5)d, q(cid:6), how do we
interpret it? The independent model we propose ﬁrstly as-
sume each word in q is independent of each other. Formally,
the independent model we deﬁne interprets an instance (cid:5)d, q(cid:6)
as observing d and given d, observing the words w1, ..., wk
independently.

Let us consider how P (d|q) is estimated under the indepen-
dent model. In the case where the query consists of k words
q = [w1, ..., wk] and the clicked document is d, we measure
the probability P (d|w1, ..., wk) as:

P (d|w1, ..., wk) =

=

(cid:2)

=

(cid:3)k

(cid:3)k

P (d, w1, ..., wk)
P (w1, ..., wk)
P (d)P (w1|d)...P (wk|d)
d∈D P (d, w1, ..., wk)

(cid:2)

P (d)

i=1 P (wi|d)

d(cid:2)∈D P (d(cid:3))

i=1 P (wi|d(cid:3))

(1)

(2)

Eq. 1 is obtained using the Bayes formula. The transition
from Eq. 1 to Eq. 2 assumes the conditional independence

IJCAI-07

1163

between wi and wj according to the model deﬁnition. P (d) is
the marginal probability of document d, which is proportional
to the number of occurrences of d. The above derivations
show that for the purpose of calculation, each (cid:5)d, q(cid:6) can be
broken down to a collection of independent instances (cid:5)d, wi(cid:6),
where i = 1, ..., k.

As indicated in Eq. 2, the estimation requires calculation of
P (d) and P (wi|d). Since we are able to keep track of P (d)
easily, the computation for Eq. 2 then transforms to P (wi|d).
In § 6, we discuss the Bayesian estimation of P (wi|d) to ad-
dress the sparsity in training data.

4.2 Full model

While the independent model treats each query as a set of
independent single words, the full model reﬂects the other ex-
treme where all words within a query are treated as a group.
In our deﬁnition, the full model treats the q in an instance
(cid:5)d, q(cid:6) as a singleton. The combination of words in q is re-
garded as an entity.

The full model emphasizes a query as a group and hence
yields high prediction accuracy, provided that a large amount
of queries have been observed with large supports. However,
as noted before, the number of different queries grows so
quickly that the full model always suffers the lack of train-
ing data in practice. In the next section, we will introduce the
method to combine the full model and the independent model
in order to address the sparsity issue.

5 Probability Hierarchy

Ideally, if we are able to observe all future queries with the
documents being clicked in the log ﬁle, especially with de-
cent number of instances, the full model alone can be sufﬁ-
cient. However, new queries keep emerging which dramat-
ically enlarges the problem space if we simply learn from
the co-occurrence (cid:5)d, q(cid:6).
In order to address such sparsity
issues, we introduce this new conditional probability hier-
archy (CPH) method, which recursively generates multiple
intermediate combinations between the full and independent
models. The shrinkage rate is tunable according to the sup-
ports of the full model.

5.1 Hierarchical shrinkage

The conditional probability hierarchy (CPH) we propose
combines the full model and the independent model. It starts
with treating a query as a set of independent words, i.e. ob-
taining P (d|wj). Hierarchically, words are merged into n-
grams 1 (or units) of increasing length, getting P (d|uk). The
ﬁnal estimation of P (d|q) is the hierarchical combination
across several levels.

2

an

Fig.

example

illustrates

of
P (d(cid:3)|a, b, c, d, e).
Suppose we have a document d and
a word sequence u ( u can be either a single word of a
multiple word query ). Let P (d|u)α
denote the estimation of
P (d|u) under the full model and P (d|u)β
under independent
to denote the estimation of P (d|u)
model. We use P (d|u)h

estimation

P(d’|a,b,c,d,e)

P(d’|c,d,e)

P(d’|a,b)

P(d’|c,d)

a

b

c

d

e

L4

L3

L2

L1

Figure 2: CPH: Hierarchical combination of conditional
probabilities at different levels. To estimate P (d(cid:3)|a, b, c, d, e)
for document d(cid:3)
and query (cid:5)a, b, c, d, e(cid:6), P (d(cid:3)|a, b) and
P (d(cid:3)|c, d, e) are combined. P (d(cid:3)|a, b) is the combination of
P (d(cid:3)|a), P (d(cid:3)|b) and n(d(cid:3), a, b), where n(d(cid:3), a, b) denotes the
number clicks on d(cid:3)

with queries containing (cid:5)a, b(cid:6).

with the CPH. A query q = (cid:5)a, b, c, d, e(cid:6) consists of ﬁve
individual words a, b, c, d and e. Suppose we already have
the full model estimation of P (d(cid:3)|w)α
for w = a, b, c, d and
e. We set the P (d(cid:3)|w)’s at L1 as equivalent to full model
estimation:

L1 : P (d(cid:3)|w)h = P (d(cid:3)|w)α = P (d(cid:3)|w)β

(3)
where w = a, b, c, d, e. Note that at the single word level, full
model and independent model are equivalent. Thus we have
P (d(cid:3)|w)α = P (d(cid:3)|w)β

.

Then we arrive at the combination of probabilities in level

L1 to L2:

L2 : P (d(cid:3)|a, b)h = (1 − λ)P (d(cid:3)|a, b)β + λP (d(cid:3)|a, b)α
L2 : P (d(cid:3)|c, d)h = (1 − λ)P (d(cid:3)|c, d)β + λP (d(cid:3)|c, d)α
(5)
where λ is the shrinkage rate that we set according to our
conﬁdence with the full model in this case. Note that λ can
vary for every case and is tunable according to observation
supports of long units.

(4)

Similarly, the estimation P (d(cid:3)|c, d, e)h

at L3 is expressed

(6)

as:
L3 : P (d(cid:3)|c, d, e)h = (1 − λ)P (d(cid:3)|c, d, e)β + λP (d(cid:3)|c, d, e)α
where the independent model estimation of P (d(cid:3)|c, d, e)β
the combination of P (d(cid:3)|c, d)h

and P (d(cid:3)|e)h

by setting:

is

P (d(cid:3)|c, d, e)β =

(cid:2)

P (d(cid:3))P (c, d|d(cid:3))hP (e|d(cid:3))h
d(cid:2) P (d(cid:3))P (c, d|d(cid:3))hP (e|d(cid:3))h

.

(7)

Finally, the estimation P (d(cid:3)|a, b, c, d, e)h

becomes:

L4 :

P (d(cid:3)|a, b, c, d, e)h =
(1 − λ)P (d(cid:3)|a, b, c, d, e)β + λP (d(cid:3)|a, b, c, d, e)α

(8)

where, again, P (d(cid:3)|a, b, c, d, e)β
dent model on P (d(cid:3)|a, b)h

and P (d(cid:3)|c, d, e)h

.

is estimated using indepen-

In general, for a query q, and document d(cid:3)

,

the CPH

P (d(cid:3)|q)h

is:

1The n-gram (or unit) in our case is referred to as a word se-

quence of length n.

P (d(cid:3)|q)h = (1 − λ)P (d(cid:3)|q)β + λP (d(cid:3)|q)α.

(9)

IJCAI-07

1164

Then P (d(cid:3)|q)β

is estimated using:

P (d(cid:3)|q)β =

(cid:2)

P (d(cid:3))P (ql|d(cid:3))hP (qr|d(cid:3))h
d(cid:2) P (d(cid:3))P (ql|d(cid:3))hP (qr|d(cid:3))h

.

(10)

where ql ⊕ qr = q, i.e. ql and qr are a split of q, P (ql|d(cid:3))h
is
obtained using P (d(cid:3), ql)h/P (d(cid:3)), P (d(cid:3)|q)α
is the full model
estimation. The structure of the tree reﬂects a particular re-
cursive parsing of the queries into smaller word combinations
and ultimately single words. With the structure of the tree
ﬁxed, the probability P (d|q)h
can be computed recursively
by a bottom-up procedure. Eq. 9 and Eq. 10 illustrate the re-
cursion. We refer to the tree structure, exempliﬁed in Fig. 2,
as the conditional probability hierarchy (CPH).

The construction of the tree has much to do with the over-
all performance. Note that we only use 2-way tree here. A
greedy algorithm is used to produce the hierarchy. In particu-
lar, we iteratively search for the binary adjacent units (can be
a word) with largest support in each level and feed the merged
units to the higher level.

Now we need to determine the parameter λ in Eq. 9. In-
tuitively, λ should depend on the number of instances that
w1, ..., wk(cid:2) appear together. It is natural to give higher weight
to the full model when there are many such observations since
the full model tends to be more accurate. Accordingly, we
k(cid:2) )
weight λ as: λ =
k(cid:2) ) , where α > 0. A large α
α+n(w1,...,w
indicates a higher trust in previous estimations and a slower
update rate.

n(w1,...,w

6 Bayesian estimation

So far, we have seen that both models depend on obtaining es-
timation for the probability P (d|q) from the observations of
(cid:5)d, q(cid:6) or (cid:5)d, w(cid:6). In the estimation for the independent model,
the estimation of P (wi|d) is required but boils down to the
estimation of P (d|wi) using Bayesian formula. For brevity,
we only focus on deriving the estimation for P (d|w). We
apply Bayesian estimation due to the lack of sufﬁcient obser-
vations. Let P (d|w) = θ ∼ B(θ). We need to estimate θ. Let
n be the number of times that w has been clicked on with any
document, x be the number of clicks on d.

We assume users carry out queries and clicks indepen-
dently. Then P (x|θ) is a binomial distribution. If we use the
beta distribution Beta(α, β) as the conjugate prior for θ, we
will easily see that P (θ|x) also follows the beta distribution
and the beta distribution is parametrized as:

P (θ|x) ∼ Beta(α + x, n + β − x)

(11)
Now P (θ|x) ∼ Beta(α + x, n + β − x), we obtain the es-
timation of θ, conditioned on x, as the expectation of P (θ|x):

(cid:4) 1

ˆθ =

0

P (θ|x)θdθ =

α + x

α + β + n

.

(12)

The estimation of ˆθ in Eq. 12 will serve as our estimation
for P (d|w) in the problem. Eq. 12 gets around the sparsity
issue in training data and is capable to provide non-zero value
for P (d|w) even with no previous observation of (cid:5)d, w(cid:6).

The only question left for the Bayesian estimation of
P (θ|x) is the parametrization of the conjugate prior P (θ),
the determination of α and β for P (θ). Assume each
i.e.
document is equally likely to be clicked on2. We want to
set expectation E(P (θ)) as 1/m, where m is the number of
distinct documents in the whole collection. Since we have
E(Beta(α, β)) =
m , obtaining
α =

m−1 . The Bayesian estimation for P (d|w) becomes:

(α+β) = 1

(α+β) , we set

β

α

α

(cid:5)P (d|w) =

ˆθ =

β

m−1 + x

β

m−1 + β + n

(13)

where, again, x is the number of clicks on d and m repre-
sents the number of candidate documents. n is the number
of times that w has been clicked on with any document. We
need α, β > 0. In experiments, we tune β.

7 Experiments

For evaluation, we study the property of our approach from
three perspectives: (a) prediction accuracy; (b) query seg-
mentation quality and (c) prediction power, i.e. predictability.
The accuracy in prediction is evaluated using both MLE and
Bayesian estimation. The query segmentation quality exam-
ines the semantic structure in queries.

7.1 Data preparation

We apply our click model to the search environment in Cite-
Seer (citeseer.ist.psu.edu), a popular online search engine and
digital library. We collect the Apache access logs at one Cite-
Seer server over 90 days period. There are in total 56,452,022
requests in this period.

We remove the robots by their agent ﬁeld in Apache
logs and time constratints. We further identify the queries
performed at CiteSeer obtaining a total of 886,957 distinct
queries and 1,826,817 query-click pairs. There are in all
510,409 distinct documents ever shown in search results,
301,052 of which have been clicked on. For each query and
the document being clicked, we collect the ﬁrst 20 documents
from which this document was picked.

7.2 Evaluation metrics

Two important quantitative metrics for evaluation are (a) pre-
diction accuracy and (b) predictability.

We deﬁne a prediction accuracy in evaluation as propor-
tional to number of “correct” predictions of clicked docu-
ments from the candidate list. Formally, we have prediction
accuracy deﬁned as: ρ1 = nc
, where nc is the number of
ns
correct prediction and ns is the size of tested sample queries.
For each query, the original returned list of documents are
provided as candidates.

We deﬁne the predictability metric as the measurement of
the models’ robustness to new queries. Consider when the
model estimates the P (d|q) as 0 for all candidate d’s, the fail-
ure of prediction happens. We denote this percentage as Pf .
Quantitatively, the predictability of a model equals to 1 − Pf .

2We may change the assumption to take into consideration the

ranking of documents in the result list.

IJCAI-07

1165

0.75

0.7

0.65

0.6

0.55

0.5

0.45

0.4

0.35

y
c
a
r
u
c
c
a
n
o

 

i

i
t
c
d
e
r
P

0.3

10k

100k

Hierarchy
Full
Independent

300k

500k

700k

900k

Size of training set

0.7

0.65

0.6

0.55

0.5

0.45

0.4

y
c
a
r
u
c
c
a
n
o

 

i

i
t
c
d
e
r
P

0.35

10k

100k

Hierarchy
Full
Independent

300k

500k

700k

900k

Size of training set

(a) Maximum likelihood estimation.

(b) Bayesian estimation.

Figure 3: Prediction accuracy w.r.t. training size.

7.3 Prediction accuracy

We train the independent model, full model, and the CPH
model over different sized subsets of the collection of query-
click pairs. For each round of testing, we randomly choose
1,000 query-clicks complementary set of training.
In each
test, we evaluate the accuracy using the two metrics deﬁned
above. Since we will study the predictability later, the accu-
racy we show here is for predictable query-click pairs.

Fig. 3(a) and Fig. 3(b) give the experimental evaluation on
the accuracy for our three models w.r.t.
training size. Sub-
sets of the whole collection with sizes from 10K to 900K
query-document pair instances are experimented. Fig. 3(a)
presents the accuracy of prediction using MLE for P (d|w).
Comparatively, in Fig. 3(b), we present the accuracy compar-
ison using Bayesian estimation measurement. In both ﬁgures,
the shrinkage rate λ for CPH model is set to 0.6 so that we
give full model higher weight in combination. For Bayesian
estimation prediction, the β is set to 5.

We are able to see that the full model usually outperforms
independent model in terms of prediction accuracy, usually
by 15%. MLE works better in prediction than Bayesian es-
timation but the MLE leads to lower predictability ( we will
discuss the predictability in Sec. 7.5. ). The performance of
the new CPH technique is slightly lower than full model in
MLE but better than full model in Bayesian estimation. The
CPH technique gains signiﬁcantly higher accuracy in predic-
tion than the independent model.

In Fig. 4, we show the impacts of the setting of shrinkage
rate λ on the accuracy and predictability. We use the training
set sized 500K. As expected from Eq. 9, the accuracy tilts up
as λ increases and the predictability goes down.

Predictability
Prediction accuracy

1

0.8

t

e
g
a
n
e
c
r
e
P

0.6

0.4

0.2

0
0.1

0.3

0.5

Shrinkage rate

0.7

0.9

Figure 4: Prediction accuracy and power w.r.t. shrinkage rate.

The sensitivity of β for Bayesian estimation of three mod-
els are also tested. In Table. 1, we present the accuracy of

Table 1: Prediction accuracy w.r.t. β setting.

β

1
5
10
100

Full model

Independent model

Hierarchy

0.56
0.57
0.58
0.57

0.47
0.47
0.46
0.44

0.61
0.62
0.61
0.59

Table 2: Hierarchies discovered in sample queries.

1
2
3
4
5
6
7
8
9
10

[ tutorial, [target, tracking] ]

[ [machine, learning], [search, engine] ]
[ partial, [ [least, square], regression ] ]

[ [k, means], [cluster, analysis] ]
[ [markov, chain], [monte, carlo] ]

[ [spectral, clustering], jordan ]

[ [energy, efﬁcient], [matrix, multiplication], fpgas ]

[ distributed, [cache, architecture] ]

[ [ [code, red], worm ], paper ]

[[dynamic, [channel, allocation]], [cellular, telephone]]

CPH model w.r.t. setting of β for priors in hierarchy. As can
be seen, the accuracy remains relatively stable but the smaller
β gives higher accuracy.

7.4 Query segmentation

In this section, we present the quality of query segmentation
formed in discovered query hierarchies. A nice segmentation
of queries detects the n-grams in queries that provides the ba-
sis for the full model. Due to the limit of space, we present
10 randomly picked queries issued to CiteSeer and their seg-
mentations performed in the CPH.

The discovered hierarchies in queries are presented by
nesting square brackets in Table 2. We are able to see, from
the limited sample, that the hidden structure of words in plain
text queries are well discovered using the n-gram frequency.
With proper segmentations, discovered n-grams in queries are
feed to full models, and the hierarchical structures are fol-
lowed while evaluating Eq. 9 for probabilistic hierarchy. As
we have seen in Sec. 7.3, the use of n-grams for full model
boosts prediction accuracy of independent model. We will
see in Sec. 7.5 that the probabilistic hierarchy improves in
predictability from full model as well.

IJCAI-07

1166

Table 3: Predictability of CPH model w.r.t. shrinkage rate.

S \ λ

100k
300k
500k

0.1
0.20
0.28
0.31

0.3
0.19
0.27
0.30

0.5
0.18
0.27
0.29

0.7
0.18
0.26
0.29

0.9
0.16
0.24
0.26

7.5 Predictability
The deﬁnition of predictability is given in §. 7.2. The pre-
dictability of three models are compared. Fig. 5 compares
the predictability of three models w.r.t.
the size of training
set. Generally the predictability increases as the training size
grows. In particular, the full model has the worst predictabil-
ity and the independent model has the best. The CPH model
is between the two.

0.5

0.4

0.3

0.2

0.1

y
t
i
l
i

b
a

i

t
c
d
e
r
P

0
10k

Full
Independent
Hierarchy

100k

300k

Size of training set

500k

700k

Figure 5: Predictability w.r.t. training size.

We also present predictability of CPH model w.r.t.

the
shrinkage rate in Table 3. S is the training size. Note the
predictability drops slightly as λ grows.

One might expect an overall evaluation of the three models
combining prediction accuracy and predictability. We sum
up the comparisons among three models in Fig. 6. In Fig. 6,
we plot the product of accuracy and predictability w.r.t. the
training size. We are able to see that the CPH outperforms
both models overall.

y
t
i
l
i

b
a

i

 

t
c
d
e
r
p
X
 
y
c
a
r
u
c
c
A

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0
10K

Independent
Full
Hierarchy

100K

300K

Size of traing set

500K

700K

Figure 6: Combined evaluation of model performances w.r.t.
training size.

7.6 Computation complexity

Finally, training time for the independent model and full
model are compared. Analytically, complexity of training for
full model should be the training time of independent model
times the complexity of breaking queries. Let the training
size be N and the average length of queries be L. The com-
plexity for independent model training is O(LN ). Consider
the maximum length of units for full model is set as K. The

complexity for full model training is therefore bounded by
O(LKN ). Note that since normally, K and L are small inte-
gers, training for both models only requires linear time. Our
experiment shows that the CPU time of training for full model
is 3-4 times of that for independent model.

8 Conclusions and Future work
In this paper, we address the click prediction in the Web
search scenario and explore the sparsity of problem space
that often exists for machine learning methods for informa-
tion retrieval research. Our experiments on the CiteSeer data
show that large scale evaluation gives promising results for
our three models in terms of prediction accuracy and pre-
dictability.

For future work, we will propose more sophisticated for-
mulation methods for the conditional probability hierarchy
(CPH). It would also be useful to improve our methods by
considering and modeling the intent of users.

References
[Banerjee and Ghosh, 2001] A. Banerjee and J. Ghosh.
Clickstream clustering using weighted longest common
subsequences. In In Proceedings of the Web Mining Work-
shop at the 1 st SIAM Conference on Data Mining, 2001.
[Beeferman and Berger, 2000] Doug Beeferman and Adam
Berger. Agglomerative clustering of a search engine
query log.
In KDD ’00: Proceedings of the sixth ACM
SIGKDD international conference on Knowledge discov-
ery and data mining, 2000.

[Deshpande and Karypis, 2004] Mukund Deshpande

and
George Karypis.
Selective markov models for pre-
dicting web page accesses. ACM Trans. Inter. Tech.,
4(2):163–184, 2004.

[Gunduz and Ozsu, 2003] Sule Gunduz and M. Tamer Ozsu.
A web page prediction model based on click-stream tree
representation of user behavior.
In KDD ’03: Proceed-
ings of the ninth ACM SIGKDD international conference
on Knowledge discovery and data mining, 2003.

[Halvey et al., 2005] Martin Halvey, Mark T. Keane, and
Barry Smyth.
Predicting navigation patterns on the
mobile-internet using time of the week. In WWW ’05: Spe-
cial interest tracks and posters of the 14th international
conference on World Wide Web, pages 958–959, 2005.

[Joachims, 2002] Thorsten Joachims. Optimizing search en-
gines using clickthrough data. In KDD ’02: Proceedings
of the eighth ACM SIGKDD international conference on
Knowledge discovery and data mining, 2002.

[Shen et al., 2005] Xuehua Shen, Susan Dumais, and Eric
Horvitz. Analysis of topic dynamics in web search.
In
WWW ’05: Special interest tracks and posters of the 14th
international conference on World Wide Web, pages 1102–
1103, 2005.

[Srivastava et al., 2000] Jaideep Srivastava, Robert Cooley,
Mukund Deshpande, and Pang-Ning Tan. Web usage min-
ing: discovery and applications of usage patterns from web
data. SIGKDD Explor. Newsl., 1(2):12–23, 2000.

IJCAI-07

1167

