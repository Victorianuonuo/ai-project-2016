Image Modeling using Tree Structured Conditional Random Fields

Pranjal Awasthi

Aakanksha Gagrani

Balaraman Ravindran

IBM India Research Lab∗

New Delhi

Dept. of CSE
IIT Madras

Dept. of CSE
IIT Madras

prawasth@in.ibm.com

aksgag@cse.iitm.ernet.in

ravi@cs.iitm.ernet.in

Abstract

In this paper we present a discriminative framework
based on conditional random ﬁelds for stochas-
tic modeling of images in a hierarchical fashion.
The main advantage of the proposed framework is
its ability to incorporate a rich set of interactions
among the image sites. We achieve this by inducing
a hierarchy of hidden variables over the given label
ﬁeld. The proposed tree like structure of our model
eliminates the need for a huge parameter space and
at the same time permits the use of exact and ef-
ﬁcient inference procedures based on belief prop-
agation. We demonstrate the generality of our ap-
proach by applying it to two important computer
vision tasks, namely image labeling and object de-
tection. The model parameters are trained using
the contrastive divergence algorithm. We report the
performance on real world images and compare it
with the existing approaches.

1 Introduction

Probabilistic modeling techniques have been used effectively
in several computer vision related tasks such as image seg-
mentation, classiﬁcation, object detection etc. These tasks
typically require processing information available at different
levels of granularity. In this work we propose a probabilistic
framework that can incorporate image information at various
scales in a meaningful and tractable model. Our framework,
like many of the existing image modeling approaches, is built
on Random ﬁeld theory. Random ﬁeld theory models the
uncertain information by encoding it in terms of a set S of
random variables and an underlying graph structure G. The
graph structure represents the dependence relationship among
these variables. We are interested in the problem of inferenc-
ing which can be stated as: Given the values taken by some
subset X ∈ S, estimate the most probable values for another
subset Y ∈ S. Conventionally, we deﬁne the variables in the
set X as observations and the variables in the set Y as labels.
The information relevant for constructing an accurate
model of the image can be broadly classiﬁed into two cate-
gories widely known as bottom-up cues and top-down cues.

∗Part of this work was done while the author was at IIT Madras.

Bottom-up cues refer to the statistical properties of individual
pixels or a group of pixels derived from the outputs of various
ﬁlters. Top-down cues refer to the contextual features present
in the image. This information represents the interactions that
exist among the labels in the set Y. These top-down cues
need to be captured at different levels of scale for different
tasks as described in [Kumar and Hebert, 2005]. Bottom-up
cues such as color and texture features of the image are in-
sufﬁcient and ambiguous for discriminating the pixels with
similar spectral signatures. With reference to Figure 1 taken
from the Corel image database, it can be observed that {rhino,
land} and {sea, sky} pixels are closely related in terms of
their spectral properties. However, an expanded context win-
dow can resolve the ambiguity. It also obviates the improba-
ble conﬁgurations like the occurrence of a boundary between
snow and water pixels. Further enlarging the context win-
dow captures expected global relationships such as 1) polar
bear surrounded by snow and 2) sky at the top of the image
while water at the bottom. Any system that fails to capture
them is likely to make a large number of errors on difﬁcult
test images. In this work we try to model these relationships
by proposing a discriminative hierarchical framework.

Figure 1: Contextual features at multiple scales play a vital
role in discrimination when the use of local feature fails to
give a conclusive answer.

1.1 Related Work
[Geman and Geman, 1984] have proposed
In the past,
Markov Random Field (MRF) based models for joint mod-

IJCAI-07

2060

eling of the variables X and Y. The generative nature of
MRFs restricts the underlying graph structure to a simple
two dimensional lattice which can capture only local rela-
tionships among neighboring pixels, e.g. within a 4 × 4 or
a 8 × 8 window. The computational complexity of the train-
ing and inference procedures for MRFs rules out the pos-
sibility of using a larger window size. Multiscale Random
Fields (MSRFs) [Bouman and Shapiro, 1994] try to remove
this limitation by capturing the interactions among labels in a
hierarchical framework. Similar approach has been proposed
by [Feng et al., 2002] using Tree Structured Bayesian Net-
works (TSBNs). These approaches have the ability to capture
long range label relationships. In-spite of the advantage of-
fered by the hierarchical nature, these methods suffer from
the same limitations of the generative models, namely,

• Strong independence assumptions among the observa-

tions X.

• Introduction of a large number of parameters by model-

ing the joint probability P (Y, X).

• Need for large training data.
Recently, with the introduction of Conditional Random
Fields (CRFs), the use of discriminative models for classiﬁ-
cation tasks has become popular [Lafferty et al., 2001]. CRFs
offer a lot of advantages over the generative approaches by di-
rectly modeling the conditional probability P (Y | X). Since
no assumption is made about the underlying structure of the
observations X, the model is able to incorporate a rich set of
non-independent overlapping features of the observations. In
the context of images, various authors have successfully ap-
plied CRFs for classiﬁcation tasks and have reported signiﬁ-
cant improvement over the MRF based generative models [He
et al., 2004; Kumar and Hebert, 2003].

Discriminative Random Fields (DRFs) which closely re-
semble CRFs have been applied for the task of detecting man-
made structures in real world images [Kumar and Hebert,
2003]. Though the model outperforms traditional MRFs, it is
not strong enough to capture long range correlations among
the labels due to the rigid lattice based structure which allows
for only pairwise interactions. [He et al., 2004] propose Mul-
tiscale Conditional Random Fields (mCRFs) which are capa-
ble of modeling interactions among the labels over multiple
scales. Their work consists of a combination of three differ-
ent classiﬁers operating at local, regional and global contexts
respectively. However, it suffers from two main drawbacks

• Including additional classiﬁers operating at different
scales into the mCRF framework introduces a large
number of model parameters.

• The model assumes conditional independence of hidden

variables given the label ﬁeld.

Though a number of generative hierarchical models have
been proposed, similar work involving discriminative frame-
works is limited [Kumar and Hebert, 2005]. In this paper we
propose a Tree Structured Conditional Random Field (TCRF)
for modeling images. Our results demonstrate that TCRF is
able to capture long range label relationships and is robust
enough to be applied to different classiﬁcation tasks. The pri-
mary contribution of our work is a method which combines

the advantages offered by hierarchical models and discrimi-
native approaches in a single framework. The rest of the pa-
per is organized as follows: We formally present our frame-
work in Section 2. In the section we also discuss the graph
structure and the form of the probability distribution. Train-
ing and inference for a TCRF are discussed in sections 3 and
4 respectively. We present the results of our model on two
different tasks in section 5. A few possible extensions to our
framework are discussed in section 6. We ﬁnally conclude in
section 7.

2 Tree Structured Conditional Random Field

Let X be the observations and Y the corresponding labels.
Before presenting our framework we ﬁrst state the deﬁnition
of Conditional Random Fields as given by [Lafferty et al.,
2001].

2.1 CRF Deﬁnition

Let G = (V, E) be a graph such that Y is indexed by
the vertices of G. Then (X, Y) is a conditional random
ﬁeld if, when conditioned on X, the random variables yi ∈
Y obey the Markov property with respect to the graph:
p(yi | X, yj, i (cid:3)= j) = p(yi | X, yj, i ∼ j). Here i ∼ j implies
that yi and yj are neighbors in G.

By applying the Hammersley-Clifford theorem [Li, 2001],
the conditional probability p(Y | X) factors into a product of
potential functions. These real valued functions are deﬁned
over the cliques of the graph G.

(cid:2)

p(Y | X) =

1
Z

ψc(yc , X)

(1)

c ∈ C

In the above equation C is the set of cliques of the graph
G, yc is the set of variables in Y which belong to the clique
c and Z is a normalization factor.

2.2 TCRF Graph Structure
Consider a 2×2 neighborhood of pixels as shown in Figure 2.
One way to model the association between the labels of these
pixels is to introduce a weight vector for every edge (u, v)
which represents the compatibility between the labels of the
nodes u and v (Figure 2a). An alternative is to introduce a
hidden variable H which is connected to all the 4 nodes. For
every value which variable H takes, it induces a probability
distribution over the labels of the nodes connected to it (Fig-
ure 2b).

Figure 2: Two different ways of modeling interactions among
neighboring pixels.

IJCAI-07

2061

Dividing the whole image into regions of size m × m and
introducing a hidden variable for each of them gives a layer of
hidden variables over the given label ﬁeld. In such a conﬁgu-
ration each label node is associated with a hidden variable in
the layer above. The main advantage of following such an ap-
proach is that long range correlations among non-neighboring
pixels can be easily modeled as associations among the hid-
den variables in the layer above. Another attractive feature is
that the resulting graph structure induced is a tree which al-
lows inference to be carried out in a time linear in the number
of pixels [Felzenszwalb and Huttenlocher, 2004]. Motivated
by this, we introduce multiple layers of hidden variables over
the given label ﬁeld. Each layer of hidden variables tries to
capture label relationships at a different level of scale by af-
fecting the values of the hidden variables in the layer below.
In our work we take the value of m to be equal to 2. The
quadtree structure of our model is shown in Figure 3.

L, W is a matrix of weights of size L × F estimated from
the training data and f(.) is a transformation (possibly non-
linear) applied to the observations. Another approach is to
take Γi(yi, X) = log P (yi | X), where P (yi | X) is the prob-
ability estimate output by a separately trained local classi-
ﬁer [He et al., 2006].

Edge Potential
This is deﬁned over the edges of the tree. Let φt,b
be a matrix
of weights of size L × L which represents the compatibility
between the values of a hidden variable at level t and its bth
neighbor at level t + 1. For our quad-tree structure b = 1, 2, 3
or 4. Let L denote the number of levels in the tree, with the
root node at level 1 and the image sites at level L and Ht
denote the set of hidden variables present at level t. Then
for every edge (hi, yj) such that hi ∈ HL−1 and yj ∈ Y
i φL−1,byj ). In a
the edge potential can be deﬁned as exp(hT
similar manner the edge potential between the node hi at level
t and its bth
neighbor hj at level t + 1 can be represented as
exp(hT

i φt,bhj).

Figure 3: A tree structured conditional random ﬁeld.

Formally, let Y be the set of label nodes, X the set of
observations and H be the set of hidden variables. We call
({Y, H}, X) a TCRF if the following conditions hold:

1. There exists a connected acyclic graph G = (V , E)
whose vertices are in one-to-one correspondence with
the variables in Y ∪ H, and whose number of edges
|E| = |V | − 1.

(cid:3)
2. The node set V can be partitioned into subsets
i Vi = V , Vi ∩ Vj = ∅
(V1 , V2 , . . . , VL) such that
and the vertices in VL correspond to the variables in Y.

∀v ∈ VL.

3. deg(v) = 1,
Similar to CRFs, the conditional probability P (Y, H | X)
of a TCRF factors into a product of potential functions. We
next describe the form of these functions.

2.3 Potential Functions

Since the underlying graph for a TCRF is a tree, the set of
cliques C corresponds to nodes and edges of this graph. We
deﬁne two kinds of potentials over these cliques:

Local Potential
This is intended to represent the inﬂuence of the observations
X on the label nodes Y. For every yi ∈ Y this function takes
the form exp(Γi(yi, X)). Γi(yi, X) can be deﬁned as

Γi(yi, X) = yi

(2)
Let L be the number of classes and F be the number of
image statistics for each block. Then yi is a vector of length

T Wfi(X)

The overall joint probability distribution which is a product

of the potentials deﬁned above can be written as

(cid:4)

P (Y, H | X) ∝ exp(

T

yi

Wfi(X)
(cid:4)

L−1,b

T
i φ

h

(3)

yj

hi∈HL−1
(yj ,hi)∈E

(cid:4)

(cid:4)

t,b

T
i φ

h

hj)

yi∈Y

(cid:4)

+

+

yj ∈Y

L−2(cid:4)

t=1

hi∈Ht

hj ∈Ht+1
(hi,hj )∈E

3 Parameter Estimation
Given a set of training images T = {(Y1, X1) . . . (YN , XN )}
we want to estimate the parameters Θ = {W, Φ}. A standard
way to do this is to maximize the conditional log-likelihood
of the training data. This is equivalent to minimizing the
Kullback-Leibler (KL) divergence between the model distri-
bution P (Y|X, Θ) and the empirical distribution Q(Y|X)
deﬁned by the training set. The above approach, requires
calculating expectations under the model distribution. These
expectations are approximated using Markov Chain Monte
Carlo (MCMC) methods. As pointed by [Hinton, 2002],
these methods suffer from two main drawbacks

1. The Markov chain takes a long time to reach the equilib-

rium distribution.

2. The estimated gradients tend to be noisy, i.e. they have

a high variance.

Contrastive Divergence (CD) is an approximate learning
method which overcomes this problem by minimizing a dif-
ferent objective function [Hinton, 2002]. In this work we use
CD learning for estimating the parameters.

3.1 Contrastive Divergence Learning
Let P be the model distribution and Q
be the empirical dis-
tribution of label variables. CD learning tries to minimize the

0

IJCAI-07

2062

contrastive divergence which is deﬁned as
1 (cid:10) P

0 (cid:10) P − Q

D = Q
(cid:5)

y∈Y Q(y) log

where Q (cid:10) P =

Q(y)
P (y) is the Kullback-
Leibler divergence between Q & P . Q
is the distribution
deﬁned by the one step reconstruction of the training data
vectors [Hinton, 2002]. For any weight wij ,

1

(4)

Δwij = −η

∂D
∂wij

(5)

where η is the learning rate. Let Y1

be the one step re-
. The weight update equations

construction of training set Y0
speciﬁc to our model are
(cid:4)

Δwuv = η[

y

v

u
i (X) −
i f
(cid:4)

yi∈Y0

(cid:6) (cid:4)

(cid:4)

yi∈Y1

u
i f

v
i (X)]

y

(6)

EP (hi | Y0)[h

u
i y

v
j ]

(7)

Δφ

L−1,b
uv

= η

yj ∈Y

0

(cid:4)

−

hi∈HL−1
(yj ,hi)∈E

(cid:4)

(cid:7)
v
j ]

EP (hi | Y1)[h

u
i y

1

yj ∈Y

(cid:6) (cid:4)

Δφ

t,b
uv = η

hi∈HL−1
(yj ,hi)∈E

(cid:4)

EP (hi,hj | Y0)[h

u
i h

v
j ]

(8)

hi∈Ht

(cid:4)

hj ∈Ht+1
(hi,hj )∈E

(cid:4)

EP (hi,hj | Y1)[h

u
i h

(cid:7)
v
j ]

hi∈Ht

hj ∈Ht+1
(hi,hj )∈E

−

4 Inference

∗

The problem of inference is to ﬁnd the optimal label ﬁeld
= argmaxYP (Y|X). This can be done using the max-
Y
imum posterior marginals (MPM) criterion which minimizes
the expected number of incorrectly labeled sites. According
∗
to the MPM criterion, the optimal label for pixel i, y
i is given
as

∗
i = argmaxyi P (yi | X),
y

∀yi ∈ y

(9)

Due to the tree structure of our model the probability value
P (yi|X) can be exactly calculated using Belief Propaga-
tion [Pearl, 1988].

5 Experiments and Results

In order to evaluate the performance of our model, we ap-
plied it to two different classiﬁcation tasks, namely, object
detection and image labeling. Our main aim was to demon-
strate the ability of TCRF in capturing the label relationships.
We have also compared our approach with the existing tech-
niques both qualitatively and quantitatively. The predicted
label for each block is assigned to all the pixels contained
within it. This is done in order to compare the performance
against models like mCRF which operate directly at the pixel
level. We use a common set of local features as described
next.

5.1 Feature Extraction
Visual contents of an image such as color, texture, and spatial
layout are vital discriminatory features when considering real
world images. For extracting the color information we cal-
culate the ﬁrst three color moments of an image patch in the
CIEL

color space.

a

b

∗

∗

∗

We incorporate the entropy of a region to account for its
randomness. A uniform image patch has a signiﬁcantly lower
entropy value as compared to a non-uniform patch. Entropy
is calculated as shown in Equation 10

(cid:4)

E = −

(p ∗ log(p))

(10)

p

where, p contains the histogram counts. Texture is extracted
using the discrete wavelet transform [Mallat, 1996]. Spatial
layout is accounted for by including the coordinates of every
image site. This in all accounts for a total of 20 statistics
corresponding to one image region.

5.2 Object Detection
We apply our model to the task of detecting man-made struc-
tures in a set of natural images from the Corel image database.
Each image is 256 × 384 pixels. We divide each image into
blocks of size 8 × 12. Each block is labeled as either struc-
tured or unstructured. These blocks correspond to the leaf
nodes of the TCRF. In order to compare our performance with
DRFs, we use the same set of 108 training and 129 testing
images as used by [Kumar and Hebert, 2003]. We also im-
plement a simple Logistic Regression (LR) based classiﬁer in
order to demonstrate the performance improvement obtained
by capturing label relationships. As shown in Table 1, TCRF
achieves signiﬁcant improvement over the LR based classi-
ﬁer which considers only local image statistics into account.
Figure 4 shows some the results obtained by our model.

Table 1: Classiﬁcation Accuracy for detecting man-made
structures calculated for the test set containing 129 images.

Model Classiﬁcation
Accuracy (%)
69.82
72.541
85.83

LR
DRF
TCRF

Image Labeling

5.3
We now demonstrate the performance of our model on label-
ing real world images. We took a set of 100 images consisting
of wildlife scenes from the Corel database. The dataset con-
tains a total of 7 class labels: rhino/hippo, polar bear, vege-
tation, sky, water, snow and ground. This is a data set with
high variability among images. Each image is 128 × 192 pix-
els. We divide each image into blocks of size 4 × 6. A total of
60 images were chosen at random for training. The remaining

1This score as reported by [Kumar and Hebert, 2003] was ob-

tained by using a different region size.

IJCAI-07

2063

40 images were used for testing. We compare our results with
that of a logistic classiﬁer and our own implementation of the
mCRF [He et al., 2004].
It can be observed from Table 2
that TCRF signiﬁcantly improves over the logistic classiﬁer
by modeling the label interactions. Our model also outper-
forms the mCRF on the given test set. Qualitative results on
some of the test images are shown in Figure 5.

Table 2: Classiﬁcation accuracy for the task of image label-
ing on the Corel data set. A total of 40 testing images were
present each of size 128 × 192.

Model Classiﬁcation
Accuracy (%)
65.03
74.3
77.76

LR
mCRF
TCRF

6 Discussion
The framework proposed in this paper falls into the cat-
egory of multiscale models which have been successfully
applied by various authors [Bouman and Shapiro, 1994;
Feng et al., 2002]. The novelty of our work is that we extend
earlier hierarchical approaches to incorporate them into a dis-
criminative framework based on conditional random ﬁelds.
There are several immediate extensions possible to the basic
model presented in this work. One of them concerns with the
“blocky” nature of the labelings obtained. The reason for this
is the ﬁxed region size which is used in our experiments. This
behavior is typical of tree based models like TSBNs. One so-
lution to this problem is to directly model image pixels as
the leaves of the TCRF. This would require increasing the
number of levels of the tree. Although the number of model
parameters increase only linearly with the number of levels,
training and inference times can increase exponentially with
the number of levels. Recently, He et al. have reported good
results by applying their model over a super-pixelized repre-
sentation of the image [He et al., 2006]. This approach re-
duces the number of image sites and at the same time does
not deﬁne rigid region sizes. We are currently exploring the
possibility of incorporating super-pixelization into the TCRF
framework.

7 Conclusions
We have presented TCRF, a novel hierarchical model based
on CRFs for incorporating contextual features at several lev-
els of granularity. The discriminative nature of CRFs com-
bined with the tree like structure gives TCRFs several advan-
tages over other proposed multiscale models. TCRFs yield a
general framework which can be applied to a variety of image
classiﬁcation tasks. We have empirically demonstrated that a
TCRF outperforms existing approaches on two such tasks. In
future we wish to explore other training methods which can
handle larger number of parameters. Further we need to study
how our framework can be adapted for other image classiﬁ-
cation tasks.

References
[Bouman and Shapiro, 1994] Charles A. Bouman

and
Michael Shapiro. A multiscale random ﬁeld model for
bayesian image segmentation.
IEEE Transactions on
Image Processing, 3(2):162–177, 1994.

[Felzenszwalb and Huttenlocher, 2004] Pedro F. Felzen-
Efﬁcient belief
In CVPR (1), pages

szwalb and Daniel P. Huttenlocher.
propagation for early vision.
261–268, 2004.

[Feng et al., 2002] Xiaojuan Feng, Christopher K.

I.
Williams, and Stephen N. Felderhof. Combining belief
networks and neural networks for scene segmentation.
IEEE Trans. Pattern Anal. Mach. Intell, 24(4):467–483,
2002.

[Geman and Geman, 1984] Stuart Geman and Donald Ge-
man. Stochastic relaxation, gibbs distributions, and the
bayesian restoration of images. IEEE Transactions on Pat-
tern Analysis and Machine Intelligence, PAMI-6(6):721–
741, 1984.

[He et al., 2004] Xuming He, Richard S. Zemel,

and
Miguel ´A. Carreira-Perpi˜n´an. Multiscale conditional ran-
dom ﬁelds for image labeling. In CVPR (2), pages 695–
702, 2004.

[He et al., 2006] Xuming He, Richard S. Zemel, and Deba-
jyoti Ray. Learning and incorporating top-down cues in
image segmentation. In ICCV, 2006.

[Hinton, 2002] Geoffrey E. Hinton. Training products of ex-
perts by minimizing contrastive divergence. Neural Com-
putation, 14(8):1771–1800, 2002.

[Kumar and Hebert, 2003] Sanjiv Kumar

and Martial
Discriminative ﬁelds for modeling spatial
In NIPS. MIT Press,

Hebert.
dependencies in natural images.
2003.

[Kumar and Hebert, 2005] Sanjiv Kumar

and Martial
Hebert.
A hierarchical ﬁeld framework for uniﬁed
context-based classiﬁcation. In ICCV, pages 1284–1291.
IEEE Computer Society, 2005.

[Lafferty et al., 2001] John D. Lafferty, Andrew McCallum,
and Fernando C. N. Pereira. Conditional random ﬁelds:
Probabilistic models for segmenting and labeling sequence
data. In ICML, pages 282–289. Morgan Kaufmann, 2001.

[Li, 2001] S. Z. Li. Markov Random Field Modeling in Im-

age Analysis. Comp. Sci. Workbench. Springer, 2001.

[Mallat, 1996] S. Mallat. Wavelets for a vision. Proceedings

of the IEEE, 84(4):604–614, 1996.

[Pearl, 1988] J. Pearl. Probabilistic reasoning in intelligent
systems: Networks of plausible inference. Morgan Kauf-
mann, 1988.

IJCAI-07

2064

Figure 4: Man made structure detection results on the Corel image database. The grids in the output image represent the blocks
classiﬁed as structured. Note that TCRF is able to give good results on difﬁcult test images like b and e.

Figure 5: Image labeling results on the Corel test set. The TCRF achieves signiﬁcant improvement over the logistic classiﬁer
by taking label relationships into account. It also gives good performance in cases where the mCRF performs badly as shown
above.

IJCAI-07

2065

