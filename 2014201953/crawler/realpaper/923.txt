Iterated Weaker-than-Weak Dominance

Shih-Fen Cheng

Singapore Management University

Michael P. Wellman
University of Michigan

School of Information Systems

Computer Science & Engineering

80 Stamford Rd

Singapore 178902

sfcheng@smu.edu.sg

2260 Hayward St

Ann Arbor, MI 48109-2121 USA

wellman@umich.edu

Abstract

dominance

conditions,

We introduce a weakening of standard game-
δ-
called
theoretic
dominance, which enables more
aggressive
pruning of candidate strategies at the cost of solu-
tion accuracy. Equilibria of a game obtained by
eliminating a δ-dominated strategy are guaranteed
to be approximate equilibria of the original game,
with degree of approximation bounded by the
dominance parameter, δ. We can apply elimination
of δ-dominated strategies iteratively, but the δ for
which a strategy may be eliminated depends on
prior eliminations. We discuss implications of this
order independence, and propose greedy heuristics
for determining a sequence of eliminations to
reduce the game as far as possible while keeping
down costs. A case study analysis of an empirical
2-player game serves to illustrate the technique,
and demonstrate the utility of weaker-than-weak
dominance pruning.

1 Introduction

Analysis of games can often be simpliﬁed by pruning agents’
strategy sets. For instance, a strategy is strictly dominated
iff there exists a mixture (randomization) over the remaining
strategies that achieves strictly higher payoff regardless of the
strategies played by other agents. Elimination of strictly dom-
inated strategies is a venerated idea, established at the dawn
of game theory as a sound way to remove unworthy strate-
gies from consideration [Gale et al., 1950, Luce and Raiffa,
1957]. In particular, the dominated strategy cannot be part of
any Nash equilibrium (NE). Moreover, the elimination con-
serves solutions in that any NE of the pruned game is also an
NE of the original.

Weak dominance relaxes strict dominance by allowing that
the dominating strategy achieves payoffs only equally as
great. Although weakly dominated strategies may appear in
NE of the full game, it remains the case that NE of the pruned
game are NE of the original as well. Additional reﬁnements
and variants of dominance are possible, for example based
on rationalizability, or minimal sets of strategies closed under
rational behavior [Benisch et al., 2006].

Elimination of a dominated strategy for one player may en-
able new dominance relations for others, as it removes cases
for which the deﬁning inequality must hold. Therefore, we
generally invoke dominance pruning iteratively, until no fur-
ther reduction is possible. This requires some care in the case
of weak dominance, since the set of surviving strategies is
order dependent, that is, may differ based on the order of
eliminations [Gilboa et al., 1990, Myerson, 1991]. Whether a
strategy is eliminable through some sequence of removals of
weakly dominated strategies is a computationally hard prob-
lem, in general [Conitzer and Sandholm, 2005]. In contrast,
iterated strict dominance is order independent.

In this paper we investigate a further weakening of weak
dominance, which enables more aggressive pruning by allow-
ing that the “dominated” strategy actually be superior to the
“dominating” by up to a ﬁxed value δ in some contexts. Such
δ-dominated strategies may participate in NE of the original
game, and NE of the pruned game are not necessarily NE of
the original. However, any NE after pruning does correspond
to an approximate NE of the original game.

Iterated application of δ-dominance is likewise order de-
pendent. The order of removals dictates not only eliminabil-
ity, but also the degree of approximation that can be guaran-
teed for solutions to the reduced game. We explore alternative
elimination policies, focusing on greedy elimination based on
local assessment of δ.

We illustrate the techniques by applying them to a two-
player 27-strategy symmetric game derived from simulation
data. Our case study demonstrates the potential utility of the
weaker dominance condition, as it reduces the game substan-
tially with little loss in solution accuracy.

2 Preliminaries
A ﬁnite normal
form game is formally expressed as
[I, {Si}, {ui(s)}], where I refers to the set of players and
m = |I| is the number of players. Si is a ﬁnite set of pure
strategies available to player i ∈ I. Let S = S1 × · · · × Sm
be the space of joint strategies. Finally, ui : S → R gives the
payoff to player i when players jointly play s = (s1, . . . , sm),
with each sj ∈ Sj.

It is often convenient to refer to a strategy of player i sep-
arately from that of the remaining players. To accomodate
this, we use s−i to denote the joint strategy of all players
other than i.

IJCAI-07

1233

Let Σ(R) be the set of all probability distributions (mix-
tures) over a given set R. A mixture σi ∈ Σ(Si) is called
a mixed strategy for player i. The payoff ui(σ) of a mixed
strategy proﬁle, σ ∈ Σ(S), is given by the expectation of
ui(s) with respect to σ.

A conﬁguration where all agents play strategies that are

best responses to the others constitutes a Nash equilibrium.
Deﬁnition 1 A strategy proﬁle σ constitutes a Nash equilib-
rium (NE) of game [I, {Si}, {ui(s)}] iff for every i ∈ I,
σ(cid:2)
i ∈ Σ(Si), ui(σi, σ−i) ≥ ui(σ(cid:2)
i, σ−i).
We also deﬁne an approximate version.
Deﬁnition 2 A strategy proﬁle σ constitutes an -Nash equi-
librium (-NE) of game [I, {Si}, {ui(s)}] iff for every i ∈ I,
σ(cid:2)
i ∈ Σ(Si), ui(σi, σ−i) +  ≥ ui(σ(cid:2)
In this study we devote particular attention to games that

i, σ−i).

exhibit symmetry with respect to payoffs.
Deﬁnition 3 A game [I, {Si}, {ui(s)}]
is symmetric iff
∀i, j ∈ I, (a) Si = Sj and (b) ui(si, s−i) = uj(sj, s−j)
whenever si = sj and s−i = s−j
That is, the agents in symmetric games are strategically iden-
tical, since all elements of their strategic behavior are the
same.

i ∈ Si is δ-dominated iff there exists

3 δ-Dominance
We start by deﬁning our weaker-than-weak dominance con-
dition.
Deﬁnition 4 Strategy sd
i }) such that:
i ∈ Σ(Si \ {sd
σD
i , s−i) > ui(sd
δ + ui(σD
(1)
In other words, sd
i is δ-dominated if we can ﬁnd a mixed strat-
egy (on the set of pure strategies excluding sd
i ) that, when
compensated by δ, outperforms sd
i against all pure opponent
proﬁles. Notice that unlike the standard conditions, in con-
sidering whether strategy sd
i is dominated, we must exclude
it from the domain of potential dominators. Otherwise, sd
i
would be δ-dominated by itself.

i , s−i), ∀s−i ∈ S−i.

i = Si \ {sd

Suppose sd
i is δ-dominated in game Γ. As noted above,
if δ > 0, sd
i may well appear with positive probability in
NE proﬁles. We may nevertheless choose to eliminate sd
i ,
obtaining a new game Γ(cid:2) = Γ \ sd
i , which is identical to Γ
except that S(cid:2)
i }, and the payoff functions apply
only on the reduced joint-strategy space. Although Γ(cid:2)
does
not necessarily conserve solutions, we can in fact relate its
solutions to approximate solutions of Γ.1
Proposition 1 Let Γ be the original game and let sd
dominated in Γ. If σ is an -NE in Γ\sd
in Γ.
Note that with  = 0, the proposition states that exact NE of
Γ \ sd
i are δ-NE of Γ, where δ is the compensation needed to
support dominance.

i be δ-
i , then it is a (δ+)-NE

We may also eliminate δ-dominated strategies in an itera-

tive manner.

1The proofs of Proposition 1 and subsequent results are omitted

due to space limitations.

Proposition 2 Let Γ0, . . . , Γn
the original game, and Γj+1 = Γj \ tj
eliminated strategy tj
-NE in Γn

is δj -dominated in Γj
(cid:2)n−1

be a series of games, with Γ0
. Further, suppose the
. Then, if σ is an

δj + )-NE in Γ0.

, it is also a (

j=0

The result follows straightforwardly by induction on Propo-
sition 1.

4 Identifying δ-Dominated Strategies
Deﬁnition 4 characterizes the condition for δ-dominance of
a single strategy.
It is often expedient to eliminate many
strategies at once, hence we extend the deﬁnition to cover
δ-dominance of a subset of strategies.
Deﬁnition 5 The set of strategies T ⊂ Si is δ-dominated iff
i ∈ Σ(Si \ T )
there exists, for each t ∈ T , a mixed strategy σt
such that:

δ + ui(σt

i , s−i) > ui(t, s−i), ∀s−i ∈ S−i.

(2)

Propositions 1 and 2 can be straightforwardly generalized to
eliminations of subsets of strategies for a particular player.

It is well known that standard dominance criteria can be
evaluated through linear programming [Myerson, 1991]. The
same is true for δ-dominance, and moreover we can employ
such programs to identify the minimal δ for which the dom-
inance relation holds. The problem below characterizes the
minimum δ such that the set of strategies T is δ-dominated.
The problem for dominating a single strategy is a special case.

min δ
s.t. ∀ t ∈ T
(cid:3)

δ +

(3)

xt(s)ui(s, s−i) > ui(t, s−i), ∀ s−i ∈ S−i

s∈Si\T

(cid:3)

xt(s) = 1

s∈Si\T
0 ≤ xt(s) ≤ 1, ∀ s ∈ Si \ T

Problem (3) is not quite linear, due to the strict inequality
in the ﬁrst constraint. We can approximate it with a linear
constraint by introducing a small predeﬁned constant, τ . The
result is the linear program LP-A(S, T ).

min δ
s.t. ∀ t ∈ T
(cid:3)

δ +

xt(s)ui(s, s−i) ≥ ui(t, s−i), ∀s−i ∈ S−i

s∈Si\T

(cid:3)

xt(s) ≤ 1 − τ

s∈Si\T
0 ≤ xt(s) ≤ 1, ∀ s ∈ Si \ T

5 Controlling Iterated δ-Dominance
By Proposition 1, every time we eliminate a δ-dominated
strategy, we add δ to the potential error in solutions to the
pruned game. In deciding what to eliminate, we are generally

IJCAI-07

1234

interested in obtaining the greatest reduction in size for the
least cost in accuracy. We can pose the problem, for example,
as minimizing the total error to achieve a given reduction, or
maximizing the reduction subject to a given error tolerance.

In either case, we can view iterated elimination as operat-
ing in a state space, where nodes correspond to sets of remain-
ing strategies, and transitions to elimination of one or more
strategies. The cost of a transition from node S = (Si, S−i)
to (Si \ T, S−i) is the δ minimizing LP-A(S, T ). We can for-
mulate the overall problem as search from the original strat-
egy space. However, the exponential number of nodes and
exponential number of transitions from any given node ren-
der any straightforward exhaustive approach infeasible.

As indicated above, the problem is complicated by the or-
der dependence of strategy eliminations. Eliminating a strat-
egy from player i generally expands the set of δ-dominated
strategies for the others, though it may shrink its own δ-
dominated set. We can formalize this as follows. Let δ(t, Γ)
denote the minimum δ such that strategy t is δ-dominated in
Γ.2
Proposition 3 Let t(cid:2)

i ∈ Si.

1. δ(t, Γ \ t(cid:2)
2. δ(t, Γ \ t(cid:2)

i) ≤ δ(t, Γ) for all t ∈ Sj , j (cid:8)= i, and
i) ≥ δ(t, Γ) for all t ∈ Si \ t(cid:2)
i.

Because eliminating a strategy may decrease the cost of some
future eliminations and increase others, understanding the im-
plications of a pruning operation apparently requires some
lookahead.

i , t2

i , Γ \ t1

i ) = δ2.

Our choice at each point is what set of strategies to elim-
inate, which includes the question of how many to elim-
i , Γ) = δ1,
inate at one time. For example, suppose δ(t1
and δ(t2
In general, it can be shown that
δ2 ≤ δ({t1
i }, Γ) ≤ δ1 + δ2. In many instances, the cost
of eliminating both strategies will be far less than the upper
bound, which is the value that would be obtained by sequen-
tially eliminating the singletons. However, since the number
of candidate elimination sets of size k is exponential in k,
we will typically not be able to evaluate the cost of all such
candidates. Instead, we investigate heuristic approaches that
consider only sets up to a ﬁxed size for elimination in any
single iteration step.

5.1 Greedy Elimination Algorithms

We propose iterative elimination algorithms that employ
greedy heuristics for selecting strategies to prune for a given
player i. Extending these to consider player choice as well
is straightforward. The algorithms take as input a starting
set of strategies, and an error budget, Δ, placing an upper
bound on the cumulative error we will tolerate as a result of
δ-dominance pruning.

Algorithm 1, GREEDY(S, Δ), computes δ(ti, Γ) for each
ti ∈ Si, and eliminates the strategy that is δ-dominated at
minimal δ. The algorithm repeats this process one strategy
at a time, until such a removal would exceed the cumulative
error budget.

2Equivalently, δ(t, Γ) is the solution to LP-A(S, {t}) for S the
strategy space of Γ. We also overload the notation to write δ(T, Γ)
for the analogous function on strategy sets T .

Algorithm 1 Simple greedy heuristic. At each iteration, the
strategy with least δ is pruned.
GREEDY(S, Δ)
1: n ← 1, Sn ← S
2: while Δ > 0 do
i do
3:
4:
5:
6:

δ(s) ← LP-A(Sn, {s})

for s ∈ Sn

δ(s)

i \ {t}, Sn+1 ← (Sn+1

i

, S−i)

i

end for
t ← arg mins∈Sn
d ← δ(t)
if Δ ≥ d then
Δ ← Δ − d
Sn+1
i ← Sn
n ← n + 1

7:
8:
9:
10:
11:
12:
13:
14:
15: end while
16: return Sn

end if

else

Δ ← 0

Algorithm 2, GREEDY-K(S, Δ, k), is a simple extension
that prunes k strategies in one iteration. We identify the
k strategies with least δ when considered individually, and
group them into a set K. We then employ LP-A(S, K) to de-
termine the cost incurred for pruning them at once. Since the
set K is selected greedily, it will not necessarily be the largest
possible set that can be pruned at this cost, nor the minimum-
cost set of size k. Nevertheless, we adopt greedy selection to
optimizations it would take to consider all the
avoid the
candidates.

(cid:4)|Si|

(cid:5)

k

5.2 Computing Tighter Error Bounds

be the reduced game. Let {Si} and {S(cid:2)

We can reduce several players’ strategy spaces by running
Algorithm 2 sequentially. Let Γ be the original game, and
let Γ(cid:2)
i} be the set
of all players’ strategy spaces for Γ and Γ(cid:2)
respectively. For
each player i, let Δi be the accumulated error actually used
in GREEDY-K. The total error generated by these reductions,
i Δi. By taking
according to Proposition 2, is bounded by
into account the actual resulting game Γ(cid:2)
, however, we can
directly compute an error bound that is potentially tighter.

Let N be the set of all NE in Γ(cid:2)

. The overall error bound
is the maximum over N of the maximal gain available to any
player to unilaterally deviating to the original strategy space.

(cid:2)

 = max
σ∈N

max
i∈I

max
t∈Ti

[ui(t, σ−i) − ui(σi, σ−i)] ,

(4)

where Ti = Si \ S(cid:2)
i. To compute  with (4), we must ﬁrst ﬁnd
all NE for Γ(cid:2)
. However, computing all NE will generally not
be feasible. Therefore, we seek a bound that avoids explicit
reference to the set N .

Since σ is an NE in Γ(cid:2)
, we have that ui(σi, σ−i) ≥
ui(xi, σ−i), for all xi ∈ Σ(S(cid:2)
i). With each i ∈ I, t ∈ Ti, we
associate a mixed strategy xt
i. Replacing σi by xt
i in (4) can
only increase the error bound. The resulting expression no
longer involves i’s equilibrium strategy. We can further relax
the bound by replacing maximization wrt equilibrium mix-

IJCAI-07

1235

Algorithm 2 Generalized greedy heuristic, with k strategies
pruned in each iteration.
GREEDY-K(S, Δ, k)
1: n ← 1, Sn ← S
2: while Δ > 0 do
i do
3:
4:
end for
5:
6: K ← {}
7:
8:

δ(s) ← LP-A(Sn, {s})

for j = 1 to k do

for s ∈ Sn

δ(s)

tj ← arg mins∈Sn
K ← {K, tj}

i

\K

9:
10:
11:
12:
13:
14:
15:
16:
17:

end for
δK ← LP-A(Sn, K)
if Δ ≥ δK then
Δ ← Δ − δK
Sn+1
i ← Sn

i \ K, Sn+1 ← (Sn+1

i

, S−i)

else

if Δ ≥ t1 then

Δ ← Δ − δ(t1)
Sn+1
i ← Sn

i \ {t1}, Sn+1 ← (Sn+1

i

, S−i)

Δ ← 0

else

18:
19:
20:
21:
22:
23:
24: end while
25: return Sn

end if

end if
n ← n + 1

tures σ−i with maximization wrt any pure opponent strate-
gies, s−i, yielding

¯ = max
i∈I

max
t∈Ti

≥ max
σ∈N
≥ max
σ∈N

max
i∈I

max
i∈I

max
t∈Ti
max
t∈Ti

(cid:6)

ui(t, s−i) − ui(xt

max
s−i∈S (cid:2)
(cid:6)
ui(t, σ−i) − ui(xt

−i

(cid:7)
i, s−i)
(cid:7)
i, σ−i)

(5)

[ui(t, σ−i) − ui(σi, σ−i)] = .

According to (5), we can bound  by ¯, which does not refer
to the set N . We can ﬁnd ¯ by solving the following opti-
mization problem:

min ¯
s.t.

¯ ≥ ui(t, s−i) −

(cid:3)

si∈S (cid:2)

i

xt
i(si)ui(si, s−i),

(6)

(cid:3)

xt
i(si) = 1,

∀ i ∈ I, t ∈ Ti, s−i ∈ S(cid:2)
−i
∀ i ∈ I, t ∈ Ti

i

si∈S (cid:2)
0 ≤ xt

i(si) ≤ 1,

∀ i ∈ I, t ∈ Ti, si ∈ S(cid:2)
i.

Note that this formulation is very similar to LP-A(S, T ), de-
ﬁned in Section 4. The major difference is that LP-A(S, T )
is deﬁned for a particular player i, whereas (6) considers all
players at once. We employ this bound in experimental eval-
uation of our greedy heuristics, in Section 6.

5.3

δ-Dominance for Symmetric Games

Thus far, we have emphasized the operation of pruning one
or more strategies from a particular player’s strategy space.
The method of the previous section can improve the bound
by considering all players at once. For the special case of
symmetric games (Deﬁnition 3), we can directly strengthen
the pruning operation. Speciﬁcally, when we prune a δ-
dominated strategy for one player, we can at no additional
cost, prune this strategy from the strategy sets of all players.

Proposition 4 Let Γ be a symmetric game, and suppose
strategy s is δs-dominated in Γ. Let Γ(cid:2)
be the symmetric game
obtained by removing s from all players in Γ. If σ is an -NE
in Γ(cid:2)

, then it is a (δs + )-NE in Γ.

Based on Proposition 4, we can specialize our greedy elim-
ination algorithms for the case of symmetric games. For Al-
gorithm 1, we modify line 10, so that {t} is pruned from all
players’ strategy spaces within the same iteration. For Algo-
rithm 2, we modify lines 14 and 18 analogously.

When a game is symmetric, symmetric equilibria are guar-
anteed to exist [Nash, 1951]. As Kreps [1990] argues, such
equilibria are especially plausible. In our analysis of symmet-
ric games, therefore, we focus on the symmetric NE.

6 Iterative δ-Dominance Elimination: A Case

Study

To illustrate the use of δ-dominance pruning, we apply the
method to a particular game of interest. On this example,
we evaluate the greedy heuristics in terms of the tradeoff be-
tween reduction and accuracy. We also compare the theo-
retical bounds to actual approximation errors observed in the
reduced games.

6.1 The TAC↓2 Game
The subject of our experiment is a 2-player symmetric
game, based on the Trading Agent Competition (TAC) travel-
shopping game [Wellman et al., 2003]. TAC Travel is actually
an 8-player symmetric game, where agents interact through
markets to buy and sell travel goods serving their clients.
TAC↓2 is derivative from TAC Travel in several respects:

• TAC travel is a dynamic game with severely incomplete
and imperfect information, and highly-dimensional inﬁ-
nite strategy sets. TAC ↓2 restricts agents to a discrete
set of strategies, all parametrized versions of the Uni-
versity of Michigan agent, Walverine [Wellman et al.,
2005b]. The restricted game is thus representable in nor-
mal form.

• Payoffs for TAC↓2 are determined empirically through

Monte Carlo simulation.

• The game is reduced to two players by constraining
groups of four agents each to play the same strategy.
This can be viewed as assigning a leader for each group
to select a strategy for all to play. The game among
leaders is in this case a 2-player game. The transfor-
mation from TAC ↓8 to TAC ↓2 is an example of the
hierarchical reduction technique proposed by Wellman

IJCAI-07

1236

et al. [2005a] for approximating games with many play-
ers. Note that this form of reduction is orthogonal to
the reduction achieved by eliminating strategies through
dominance analysis.

Although TAC↓2 is a highly simpliﬁed version of the ac-
tual TAC game, Wellman et al. [2005b] argue that analyzing
such approximations can be useful, in particular for focusing
on a limited set of candidate strategies to play in the actual
game. Toward that end, dominance pruning can play a com-
plementary role to other methods of analysis.

The actual instance of TAC↓2 we investigate comprises 27
strategies (378 distinct strategy proﬁles) for which sufﬁcient
samples (at least 20 per proﬁle) were collected to estimate
payoffs.

6.2 Comparison of Greedy Heuristics
Since the game is symmetric, we eliminate strategies from
all players at once rather than one at a time (see Section 5.3).
Starting with our 27-strategy TAC↓2 game, we ﬁrst apply iter-
ative elimination of strictly dominated strategies. This prunes
nine strategies, leaving us with an 18-strategy game that can-
not be further reduced without incurring potential approxima-
tion error. We then applied both GREEDY-1 and GREEDY-2,
each with a budget of Δ = 200. Figure 1 plots, for each algo-
rithm, the cumulative error cost incurred to reach the associ-
ated number of remaining strategies. Each elimination oper-
ation takes a step down (by the number of strategies pruned)
and across (by the error δ added to the total). Note that the
ﬁrst large step down at cost zero corresponds to the initial
pruning by strict dominance.

i

s
e
g
e
a
r
t
s
 
f

t

o

 
r
e
b
m
u
N

30

25

20

15

10

5

0

0

20

40

60

Greedy-1
Greedy-2

140

160

180

200

80
Accumulated δ

100

120

Figure 1: Number of strategies versus accumulated δ, for
GREEDY-1 and GREEDY-2.

As the graph apparently indicates, GREEDY-2 reaches any
particular reduction level at a cost less than or equal to
GREEDY-1. With the error tolerance Δ = 200, GREEDY-1
prunes the game down to ten strategies, whereas GREEDY-2
takes us all the way down to two. However, we must decouple
two factors behind the difference in measured results. First,

the algorithms may prune strategies in a different order. Sec-
ond, the algorithm GREEDY-K computes the bound for each
iteration taking into account all k strategies pruned at once.

In this instance, in fact the sequence of eliminations is quite
similar. The ﬁrst four strategies eliminated by GREEDY-1 and
GREEDY-2 are the same, and the next four are the same ex-
cept for a one-pair order swap. Thus, we can attribute the
difference in apparent cumulative error after eight removals
(169 versus 78) entirely to the distinction in how they tally
error bounds.
In general, the elimination orders can differ
almost arbitrarily, though we might expect them typically to
be similar. In another instance of TAC↓2 (based on an earlier
snapshot of the database with 26 strategies), we also observed
that the ﬁrst eight δ-eliminations differed only in a one-pair
swap. We have not to date undertaken an empirical study of
the comparison.

A more accurate assessment of the cost of iterated elimi-
nation can be obtained by computing the tighter bounds de-
scribed in Section 5.2, or directly assessing the error. Figure 2
presents the data from Figure 1 (axes inverted), along with the
more precise error measurements.

)
l
a
u

 

t
c
a
 
r
o
d
n
u
o
b
(
 
r
o
r
r

E

180

160

140

120

100

80

60

40

20

0

Greedy-1

Greedy-2

Tighter bound

Actual epsilon

18

17

16

15

13

14
Strategies Remaining

12

11

10

9

8

7

6

5

4

Figure 2: Error bounds derived from GREEDY-1 and
GREEDY-2, compared to tighter bound estimates as well as
actual errors.

Tighter bounds reported in Figure 2 are those derived from
the linear program (6), applied to the respective strategy sets.
We use the remaining strategy sets based on GREEDY-1 down
to 10 remaining, and the sets for GREEDY-2 thereafter. We
also determined the actual error for a given reduced strat-
egy set, by computing all symmetric NE of the reduced game
(using GAMBIT [McKelvey and McLennan, 1996]),3 and for
each ﬁnding the best deviation to eliminated strategies. The
maximum of all these is the error for that strategy set.

As we can see from the ﬁgure, the cumulative error bounds
reported by the algorithms (based on Proposition 2) are quite

3In some instances, GAMBIT was unable to solve our reduced
games in reasonable time due to numerical difﬁculties.
In these
cases, we tried small random (symmetry-preserving) perturbations
of the game until we were able to solve one for all NE. The er-
rors reported are with respect to the solutions we found, which thus
tend to overstate the error due to elimination because they include
an additional source of noise.

IJCAI-07

1237

conservative. In all cases, after a few eliminations the tighter
bounds are far more accurate. The actual errors are in many
cases quite small (often zero). That is, in at least this (real) ex-
ample game, we can aggressively prune weaker-than-weakly
dominated strategies and then still have games where all so-
lutions are near equilibria of the original game.4

6.3 Loss of Equilibria

The preceding analysis considers the accuracy of solutions to
the reduced game with respect to the original. We may also be
concerned about losing solutions to the original that may in-
clude δ-dominated strategies. To examine this issue, we track
the 21 symmetric NE found for the instance of TAC↓2 ana-
lyzed above, which has 18 strategies after eliminating those
strictly dominated.5 Figure 3 shows how many of these orig-
inal NE survive after successive rounds of eliminating a δ-
dominated strategy, using the GREEDY-1 algorithm. As seen
in the ﬁgure, all solutions survive the ﬁrst three eliminations,
and two still remain after the eight iterations of GREEDY-1.

 

E
N
g
n
v
v
r
u
S

i

i

21

18

15

12

9

6

3

0

0

1

2

3

4

5

6

7

8

iteration

Figure 3: Original NE surviving after successive iterations of
δ-dominated strategy elimination.

For situations where the purpose of analysis is to char-
acterize all or most (approximate) equilibria, eliminating δ-
dominated strategies sacriﬁces potentially desired coverage.
If the objective, in contrast, is to identify samples (i.e., partic-
ular examples) of relatively stable proﬁles, this loss of equi-
libria is not a paramount concern.

7 Conclusion

Eliminating strategies that are only nearly dominated enables
signiﬁcantly more aggressive pruning than standard domi-
nance, while introducing a controllable amount of solution
error. Our δ-dominance concept represents such a relaxation,
and we exhibit bounds on the degree of approximation for
solutions of the reduced game with respect to the original,
for individual or iterated eliminations of single strategies or

4Again, we have not to date performed a comprehensive empiri-
cal study. The other instance of TAC↓2 mentioned above exhibited
similar results.

5Of course if we knew these equilibria, we would not eliminate
strategies for purposes of simplifying equilibrium computation. Our
point here and in the preceding section is to analyze the effect of
elimination using the known solutions to measure error.

strategy sets. Results are generally order dependent, how-
ever greedy selection techniques may work well in practice.
The bounds for iterated elimination are quite conservative,
and can be tightened by retrospective analysis of the actual
set of strategies eliminated.

A case study applying iterated elimination of δ-dominated
strategies to an empirical game illustrates the approach. The
exercise demonstrates the possibility of identifying a much
smaller subgame with solutions that are excellent approxi-
mations wrt the original. Further work should evaluate the
methods more broadly over a range of games.

Acknowledgments

We thank Kevin Lochner and Daniel Reeves for assistance
with the TAC↓2 analysis. This work was supported in part by
grant IIS-0414710 from the National Science Foundation.

References

Michael Benisch, George Davis, and Tuomas Sandholm. Al-
gorithms for rationalizability and CURB sets. In Twenty-
First National Conference on Artiﬁcial Intelligence, pages
598–604, Boston, 2006.

Vincent Conitzer and Tuomas Sandholm. Complexity of (iter-
ated) dominance. In Sixth ACM Conference on Electronic
Commerce, pages 88–97, Vancouver, 2005.

D. Gale, H. W. Kuhn, and A. W. Tucker. Reductions of game
matrices. In Contributions to the Theory of Games, vol-
ume 1, pages 89–96. Princeton University Press, 1950.

I. Gilboa, E. Kalai, and E. Zemel. On the order of eliminating
dominated strategies. Operations Research Letters, 9:85–
89, 1990.

David M. Kreps. Game Theory and Economic Modelling.

Oxford University Press, 1990.

R. D. Luce and H. Raiffa. Games and Decisions. Wiley, New

York, 1957.

Richard D. McKelvey and Andrew McLennan. Computation
In Handbook of Computa-

of equilibria in ﬁnite games.
tional Economics, volume 1. Elsevier, 1996.

Roger B. Myerson. Game Theory: Analysis of Conﬂict. Har-

vard University Press, 1991.

John Nash. Non-cooperative games. Annals of Mathematics,

54:286–295, 1951.

Michael P. Wellman, Amy Greenwald, Peter Stone, and Pe-
ter R. Wurman. The 2001 trading agent competition. Elec-
tronic Markets, 13:4–12, 2003.

Michael P. Wellman, Daniel M. Reeves, Kevin M. Lochner,
Shih-Fen Cheng, and Rahul Suri. Approximate strategic
reasoning through hierarchical reduction of large symmet-
ric games. In Twentieth National Conference on Artiﬁcial
Intelligence, pages 502–508, Pittsburgh, 2005a.

Michael P. Wellman, Daniel M. Reeves, Kevin M. Lochner,
and Rahul Suri. Searching for Walverine 2005. In IJCAI-
05 Workshop on Trading Agent Design and Analysis, Ed-
inburgh, 2005b.

IJCAI-07

1238

