Hierarchical Semantic Classification: 

Word Sense Disambiguation with World Knowledge* 

Massimiliano Ciaramita 

Brown University 

massi@brown.edu 

Thomas Hofmann 
Brown University 
th@cs.brown.edu 

Mark Johnson 
Brown University 

mark.j ohnson@brown.edu 

Abstract 

We  present  a  learning  architecture  for  lexical  se(cid:173)
mantic  classification  problems  that  supplements 
task-specific training data with background data en(cid:173)
coding  general  "world  knowledge".  The  model 
compiles  knowledge  contained  in  a  dictionary-
ontology  into  additional  training  data,  and  inte(cid:173)
grates  task-specific  and  background  data  through 
a novel hierarchical  learning architecture.  Experi(cid:173)
ments on a word sense disambiguation task provide 
empirical evidence that this "hierarchical classifier" 
outperforms a state-of-the-art standard "flat" one. 

Introduction 

1 
There  is  an  increasing  interest  in  natural  language  pro(cid:173)
cessing  (NLP)  and  information  retrieval  (IR)  for  research 
on  lexical  semantics,  in  particular  with  respect  to  word 
sense  disambiguation  [Yoong  and  Hwee,  2002],  informa(cid:173)
tion  extraction 
[Riloff  and  Jones,  1999],  named  entity 
recognition  [Collins,  2002],  and  automatic thesaurus exten(cid:173)
sion [Hearst,  1992].  In general terms, the goal in these tasks 
is that of automatically associating words in text with seman(cid:173)
tic labels.  In information extraction and named-entity recog(cid:173)
nition noun phrases or proper nouns are assigned to semantic 
categories such as "organization", "person", or "location". In 
word sense disambiguation and thesaurus extension the goal 
is to assign  words to  finer-grained  categories defined by ex(cid:173)
isting dictionaries and ontologies. 

Lexical semantic  information can be useful  in many NLP 
and IR applications such as text categorization, parsing, and 
language  modeling  for  speech  recognition.  Furthermore  it 
can  be  crucial  for tasks  that  require  complex  inferences  in(cid:173)
volving world knowledge, such as question answering. 

One  of the  main  difficulties  in  learning  semantic  annota(cid:173)
tions stems from the fact that training instances are often nar(cid:173)
rowly focused on very specific class labels and relatively few 

*Wc would like to thank our colleagues in the Information Re(cid:173)
trieval and Machine Learning Group (IRML) and Brown Labora(cid:173)
tory for Linguistic Information Processing (BLLIP), as well as Jesse 
Hochstadt for his editing advice.  This material is based upon work 
supported  by  the  National  Science  Foundation  under  Grant  No. 
0085940. 

in number.  It thus seems intuitive to supplement task-specific 
training data, for example, sense-annotated training instances 
for a  specific word,  with background data encoding general 
"world knowledge".  The latter are typically available in suf(cid:173)
ficient quantities and need not to be generated separately for 
each classification task.  To carry out this idea two crucial is(cid:173)
sues need to be addressed:  How exactly can world knowledge 
be compiled into additional training data, and how can task-
specific and background data be systematically integrated? 

To address the  first  challenge, we propose to generate ad(cid:173)
ditional  training  data  about  broader  semantic  categories  by 
extracting training sentences from a hierarchically structured 
ontology, WordNet1 [Fellbaum, 1998]. We assumed that each 
example sentence associated with a lexical entry provides ev(cid:173)
idence for the kind of contexts in which that  specific concept 
and all its ancestors in the hierarchy can appear. As far as the 
second challenge is concerned, we introduce a novel  hierar(cid:173)
chical learning architecture for semantic classification.  More 
specifically, we present a simple and efficient on-line training 
algorithm  generalizing  the  multiclass  perceptron  of  [Cram(cid:173)
mer and Singer, 2002]. 

Finally, we carry out an experimental evaluation on a word 
sense disambiguation task, providing empirical evidence that 
the hierarchical  classifier outperforms a state-of-the-art stan(cid:173)
dard "flat" classifier for this task. 

The paper is structured as follows. Section 2 introduces the 
main idea in more detail.  In Section 3 we introduce WordNet 
and the  simplified  ontology derived  from  it  that we  used as 
the source of world knowledge.  Section 4 deals with the ba(cid:173)
sic multiclass perceptron and the proposed hierarchical mul-
ticomponent classifier.  Finally, Sections 5 and 6 describe the 
data set used and the empirical results, respectively. 

2  Word Sense Disambiguation and World 

Knowledge 

Word sense disambiguation  is  the  task  of assigning  to  each 
occurrence of an ambiguous word in a text one of its possible 
senses. A dictionary is used to decide if a lexical entry is am(cid:173)
biguous or not, and to specify its set of possible senses.  The 
most  widely  used  lexical  resource  for this task  is  WordNet, 
which we describe in detail in the next section. 

1 In this paper we always refer to WordNet version 1.71. 

NATURAL  LANGUAGE 

817 

Figure 1. The simplified two-layer hierarchy for the noun chair. 

As an illustration consider the noun "chair", which accord(cid:173)
ing to  WordNet is ambiguous.  Two possible  senses are ex(cid:173)
plained in the following WordNet entries: 

•  chairi  -  a  seat  for one  person,  with  a  support  for  the 

back; 

•  chairi  -  (president,  chairman,  chairwoman,  chair, 
chairperson),  the  officer  who  presides  at  the  meetings 
of an organization; 

Word  sense  disambiguation  is  often  framed  as  a  multi-
class pattern classification task.  Useftil  features  include co-
occurring words, word bigrams or trigrams, and properties of 
the syntactic context that contains the target word. Most com(cid:173)
monly systems are trained on labeled data for a specific word, 
for each and tested on unseen items of the same word. The set 
of possible labels is the set of senses of the ambiguous word. 
One limitation of such a strategy is that the system bases its 
decision exclusively on what it has been able to learn about a 
few very specific concepts;  e.g., chair i  and chair2.  Further(cid:173)
more,  since  manually  sense-tagging  words  for the  required 
training data is slow and expensive, the data is quite sparse. 
A  great  deal  of  information  about  objects  like  "chairs" 
is  indirect  and  can  be  derived  from  more  general  world 
knowledge  through  generalization  and  inference  processes. 
Suppose  that  the  task  is  to  disambiguate  between  the  two 
simple senses of chair in the following context: 

1)  "Here  the  quality  of  the  finest  chair  components  is 
merged with art." 

In  this  sentence  components  is  a  useful  hint  that  we  are 
dealing  with  the  sense  chairi.  Chairs  are  artifacts,  and 
artifacts  can  have  components.  Conversely,  even  though 
in  principle  people  could  "have  components"  as  well,  this 
sounds a little odd.  Intuitively,  if a word sense disambigua(cid:173)
tion  system  had  access  to  this  type  of  information  -  that 
"chairs" are subordinates of broader concepts like "artifacts" 
and  "people"  -  and  some  knowledge  about  these  broader 
semantic  categories,  it  might  achieve  a  higher  accuracy  in 
disambiguating  words.  Notice  that  the  system  might  never 
have  previously  observed  any  instance  of the  noun  "chair", 
in either sense, as "having components". 

The  goal  hence  is  to  complement  specific  but  limited 
knowledge about narrow classes  with richer,  if less  specific, 
knowledge about more general classes. We can easily recover 
the fact that chairs are kinds of furniture or people from dic(cid:173)
tionaries and hierarchically organized ontologies like Word-
Net. Learning information about such general concepts, how(cid:173)
ever, is complicated.  One source of complication is the very 
problem we are trying to solve,  lexical ambiguity.  If we  do 

not  know  whether  something  is  a  person  or an  artifact  we 
cannot  learn  reliable  information  about  those  more  general 
concepts.  One  way  of addressing these problems  is  offered 
by WordNet itself. 

3  The Ontology 
3.1  WordNet 
WordNet  is  a  broad-coverage,  machine-readable  dictionary 
widely  used  in  NLP.  The  English  version  contains  around 
150,000 entries, mostly nouns, but also verbs, adjectives, and 
adverbs. WordNet is organized as a network of lexical ized 
concepts, called synsets, that comprise sets of synonyms. For 
example, the nouns {president, chairman, chairwoman, chair, 
chairperson}  form a synsct.  A  word that belongs to  several 
synsets  is ambiguous.  Synsets  are  linked by  semantic  rela(cid:173)
tions, the most important of which for nouns and verbs is the 
is-a relation, or hyponymy;  e.g.,  "car" is a hyponym of "ve(cid:173)
hicle".  The  verb  and  noun  databases  form  is-a  hierarchies 
with a few general concepts at the top and several thousand 
specific concepts at the leaf level. 

The hierarchical structure of the database has aroused some 
interest  in  NLP,  because  it  can  support  interesting  compu(cid:173)
tational  language  learning models,  for example,  in  learning 
predicate selectional preferences [Light and Greif, 2002]. We 
aim  to  use  the  hierarchy  to  improve  lexical  classification 
methods.  The model  we present here can in principle make 
use of the full hierarchy.  However,  for the sake of simplicity 
we have focused on a less complex hierarchy, which has been 
derived from WordNet as described below. 

3.2  A  simple  two-level  hierarchy 
WordNet  was built,  and  is  regularly  updated,  by  lexicogra(cid:173)
phers.  Lexicographers  group  words together in  synsets  and 
individuate  the relevant  semantic  relations between  synsets. 
This process includes the classification of lexical entries into 
one  of 26 broad  semantic  classes.  In this paper we  refer to 
these broad classes with the term supersenses.  A few exam(cid:173)
ples of supersense labels are person, animal, artifact, food, lo(cid:173)
cation, time, plant, process, attribute, substance, and relation. 
This  set  of labels  is  fairly  general  and  therefore  small.  At 
the same time the labels are not too abstract.  In other words, 
these classes seem natural and easily recognizable, and that 
is probably why lexicographers use them.  In fact the level of 
generality is very close to that used in named-entity recogni(cid:173)
tion ("location", "person", "organization", etc.). 

Each synset in WordNet is associated with one supersense 
label.  As a result the database implicitly defines, in addition 
to  the  full  hierarchy,  a  simpler  two-layer hierarchy.  Figure 

818 

NATURAL  LANGUAGE 

1  above illustrates the synsets and supersenses chair belongs 
to. 
3.3  The hierarchy as a source of world knowledge 
For  a  few  thousand  concepts  WordNet  lists,  among  other 
types  of semantic  information,  one  or  more  example  sen(cid:173)
tences.  For the sense  of chair above the  example  sentences 
are the following: 

•  chairi  - "he  put his  coat  over the back  of the  chair and 

sat down" 

•  chair2  - "address  your remarks  to  the chairperson" 

Overall  there  are 9,258  of these  sentences.  Since  each  one 
is  associated  with one  synset,  that  is  in fact a  sense-tagged 
instance  of the  word.  In  other  words,  WordNet  provides  a 
few thousand potential sense-tagged training instances. 

Unfortunately, this additional data in itself would not be of 
much help:  for most  of the  synsets there  are no sentences2, 
and typically the sentences are very short and do not provide 
much context.  However, the situation appears  in a different 
light if we take into account the hierarchy. Considering an ex(cid:173)
ample sentence for a synset also as an example sentence for 
its  ancestors  (synsets  at higher  levels  in  the  hierarchy),  the 
number  of sentences  grows  larger  at  the  superordinate  lev(cid:173)
els.  If we  consider the  supersense  level,  the  set  of example 
sentences  constitutes  in  fact  a  small  corpus  of supersense-
annotated data.  Our hypothesis  is  that  the  several  hundred 
sentences associated with each supersense can provide a use(cid:173)
ful source of general world knowledge. In the next section we 
describe a general multicomponent learning architecture that 
can be used to exploit this supplementary training data. 

4  Multicomponent  Learning  Architecture 
The  idea  of using  the  hierarchical  structure  of a  domain  to 
overcome sparseness problems has been explored in text cat(cid:173)
egorization. These methods show improved accuracy and ef(cid:173)
ficiency  [Toutanova et al.,  2001;  Dumais and Chen,  2000]. 
In NLP the hierarchical  structure of WordNet has been used 
to  overcome  sparseness  data  problems  for  estimating  class 
distributions  [Clark and Weir, 2002], and to exploit morpho(cid:173)
logical information to improve lexical acquisition [Ciaramita, 
2002]. 

4.1  Multiclass  perceptron 
The  architecture  we  propose  is  a  generalization  of "ultra-
conservative" on-line learning  [Crammer and Singer, 2002], 
which is itself an extension of perceptron learning to the mul(cid:173)
ticlass  case.  We  describe  this  "flat"  version  of the  classi(cid:173)
fier  first.  For each noun  w  we  are  given  a  training set  S  = 
 

,  where each instance 

and 

Y(w)  is  the  set  of synsets  that  WordNet assigns  to  w.  Thus 
5  summarizes  n  instances  of noun  w,  where  each  instance 
i  is represented as a vector of features X{  extracted from the 
context in which w occurred; d is the total number of features 
and yi is the true label  of   

2Therc are in total around 75,000 synsets in the noun database. 
3Since some instances are labeled with multiple senses, in cases 
where the taggers were uncertain, y» may actually be a set of labels. 

Algorithm 1 Multiclass Perceptron 

l: 
2: 
3: 
4: 
5: 
6: 
7: 
8: 
9: 
10: 
11: 
12: 

In general, a multiclass classifier for word it; is a function 
to  one  of 
.  In the multiclass perceptron, one 
and 

that  maps  feature  vectors 

the possible senses  of 
introduces a weight vector 
defines 

implicitly by the so-called winner-take-all rule: 

for every 

(1) 

Here 
umn corresponding to one of the weight vectors  

refers to the matrix of weights,  every  col(cid:173)

The learning algorithm works as follows: Training patterns 
arc presented one at a time  in the  standard on-line  learning 
setting.  Whenever 
an  update step  is per(cid:173)
formed; otherwise the weight vectors remain unchanged.  To 
perform  the update,  one  first  computes the error set El  con(cid:173)
taining  those  class  labels  that  have  received a  higher score 
than the correct class: 

(2) 
An ultraconservative update scheme in its most general  form 
is then defined as follows:  U p d a t e w i
ing rates fulfilling the constraints  
and 
Hence  changes  are  lim(cid:173)
ited to 
.  The  sum constraint ensures 
that the update is balanced, which is crucial to guaranteeing 
the convergence of the learning procedure (cf. [Crammer and 
Singer, 2002]).  We have focused on the simplest case of uni(cid:173)
form update weights, 
. The algorithm 
is summarized in Algorithm  1. 

th learn(cid:173)

Notice that the presented multiclass perceptron algorithm 
learns all  weight vectors in a coupled manner,  in contrast to 
methods that perform multiclass classification by combining 
binary classifiers,  for example,  training  a classifier for each 
class in a one-against-the-rest manner. 
4.2  Hierarchical multiclass perceptron 
The  hierarchical  multiclass  perceptron  is  inspired  by  the 
framework  for learning  over  structured output  spaces  intro(cid:173)
duced in  [Hofmann et al.,  2002].  The key  idea is  to  intro(cid:173)
duce a weight vector not only for every (leaf-level) class, but 
also  for every  inner node  in  a given class  taxonomy.  In the 
current application to  word  sense  disambiguation,  the  inner 
nodes correspond to the 26 supersenses 5 and we will hence 

NATURAL  LANGUAGE 

819 

introduce  additional  weight vectors 
S(w)  refers  to  the  subset  of supersenses  induced  by 
We will use the notation 
sponding to a synset y.  Then discriminant  functions 
can be defined in an additive manner by 

for 

to refer to the supersense corre(cid:173)

, where 

(3) 
If one thinks o f/ in terms of a compatibility function between 
an observation vector x and a synset y, then the compatibility 
score is simply the sum of two independent contributions, one 
stemming from the supersense level and the other one coming 
from the more detailed synset level.  The multiclass classifier 
is then again defined using the winner-take-all rule, 

(4) 

Algorithm 2 Hierarchical Multiclass Perception 

The  complete  algorithm  is  summarized  in  Algorithm  2. 
The  first  part  of the  algorithm  concerns  the  different nature 
of the  two  types  of training  data.  As  we  explained  in  Sec(cid:173)
tion  3,  the  supplementary  data  derived  from  WordNet  only 
provides annotations at the supersense level.  We cannot use 
this information to perform updates for weight vectors vy, but 
. Hence for supersense-annotated 
only to adjust the weights 
we  compute  the  error  set  on  the 
training  instances 
supersense  level as 
and 
with 
perform  the  standard  multiclass  update  step  tor all 

.  If the classifier makes  a mistake on pattern 

The second part concerns training on the task specific data 
error 
sets  are  computed  for its  individual  components both at the 
synset and supersense levels (lines  15 and  19 above), which 
are updated according to the standard multiclass update rule. 
As an example, suppose that given a pattern Xi of chair the 

synset  error  set  is 
while  the correct  label  is   
PERSON.  The  update  vector 
vectors relative to the labels  in  Ei  while 
If at  the  supersense  level  the  error  set  Ef  =  {ARTIFACT}, 
Xi  is  subtracted  from  the  vector  for  ARTIFACT  and  added 
to 
. Therefore, through the supersense weight vectors, the 
background data affects classification at the synset level. 

is  subtracted from  the 

is added to 

5  Data Set and Features 
5.1  The Senseval data 
We tested our system on a standard word sense disambigua(cid:173)
tion data set.  The training and test data are those used in the 
last  Senseval  workshop  (Senseval-2/ACL-01,  2001),  which 
focused exclusively on word sense disambiguation. The train(cid:173)
ing set consists of 8,611  paragraphs that contain an ambigu(cid:173)
ous  word  whose  sense  has  been  manually  annotated.  The 
inventory  of senses  is  taken  from  WordNet.  Similarly,  the 
test  set  consists  of 4,328  unlabeled  pairs.  We  only  ran  ex(cid:173)
periments on the noun data, which consists of 3,512 training 
instances and  1,754 test instances.  Each instance consists of 
a short passage taken from one of various sources:  e.g., the 
Wall Street Journal, British National Corpus, and web pages. 
The task-specific training data,  T y ,  is typically  smaller than 
the general one, Ts>  The average ratio 
is equal to 
20.3. 

5.2  Features 
We used the same feature set described in  [Yoong and Hwee, 
2002],  which  is  compact  but  includes  most  of the  features 
that have been found useful in this task:  surrounding words, 
bigrams and trigrams, and syntactic information.  Yoong and 
Hwee  report  results  for  several  classifiers  broken  down  by 
part of speech,  which makes it possible to compare our sys(cid:173)
tem's performance with that of several others. 

There are  four types  of features.  The  following sentence 
serves to illustrate them:  "the dinner table and chairs are ele(cid:173)
gant yet comfortable".  The feature set is described in greater 
details in [Yoong and Hwee, 2002]: 

• p a rt  of  speech  of  the  neighboring  w o r d s :=  CC, 

=  NNS, P+1  =  AUX,... 

•  single words in the surrounding context: C == elegant, 

C  = dinner, C  = t a b l e, C  =  the,... 

•  bigrams 

and 

trigrams: 

C_i,+i  =  and.are, 

•  head  of  the  syntactic  phrase  that  governs  the  tar(cid:173)

get: 
G_RELP0S  =  l e f t. 

Syntactic  features  and part  of speech  tags  were  extracted 
from the syntactic parse trees of the  Senseval-2 training and 

820 

NATURAL LANGUAGE 

Figure  2.  Test  accuracy  of  the  flat  multiclass  perceptron 
(dashed line) and the hierarchical multiclass perceptron (con(cid:173)
tinuous line) on the word sense evaluation data set. 

Figure 3.  Test accuracy of the  hierarchical (continuous  line) 
vs.  flat (dashed line) multiclass perceptron.  The hierarchical 
multiclass perceptron was trained using supplementary super-
sense training data. 

test data produced using Charniak's parser LCharniak, 2000]. 
In this way we created the training data Ty  from the Senseval 
data. 
In  exactly  the  same  way  we  extracted  features  from 
the example sentences in WordNet to produce the additional 
training set for the supersense-level classes,  Ts.  Overall there 
are around 250,000 features. 

6  Experiments 
6.1  Experimental setup 
We tested two models described in Section 4:  the flat multi-
class perceptron, trained and tested at the synset level, and the 
hierarchical one, trained on both the standard synset data and 
the training data for the supersenses extracted from WordNet. 
We also trained and tested a simple "flat" naive Bayes clas(cid:173)
sifier.  A  different  classifier  was  trained and  tested  for each 
word. We treated compounds such as easy chair and chair as 
different words. 

All the results we report are given as accuracy: 

6.2  Results 
Figure 2 shows the performance of the flat perceptron (dotted 
line) during each iteration.  The perceptron in fact converges 
very quickly.  This  is probably due to the fact that  there are 
relatively few training items:  Normally the size of Ty  is be(cid:173)
tween one and two hundred.  To check whether an improve(cid:173)
ment was due to the algorithm alone and not to the combina(cid:173)
tion of the algorithm and the additional, supersense data set, 
we also trained a hierarchical perceptron exclusively on the 
synset data.  Figure 2 also plots the performance of the hier(cid:173)
archical perceptron trained only on Ty.  The two  curves  are 
virtually  indistinguishable,  meaning  that  without  additional 
information not much can be gained from using the hierarchi(cid:173)
cal classifier alone.  In other words, with "flat" data a "flat" 
classifier is as good as a "hierarchical" one. 

Figure 3  plots the performances of the  flat and the hierar(cid:173)
chical perceptron when also trained on Ts-  The two patterns 
are very different.  The hierarchical model converges only af(cid:173)
ter more than 350 iterations. 

Table 1. Test accuracy on the Senseval-2 test data. 

This  might  be  due  to  several  facts.  First,  the  amount  of 
data  is  much greater due to the addition of  Ts,  and  it takes 
longer to learn.  Second, the supersense data and the synset 
data are probably very different and noisy; as a consequence 
the weight vectors are continually readjusted, possibly along 
very different dimensions.  The interesting thing, though,  is 
that even in the midst of very wide oscillations there is a clear 
improvement, particularly between 50 and  100 iterations. 

We present also a comparative table. Table 1 illustrates the 
results  of our  systems  and  other state-of-the-art  word  sense 
disambiguation  ones.  We  set  the number of iterations  to  a 
fixed number for all words equal  to  100.  Given that we  set 
this value "knowing" that  it is a good one for both our sys(cid:173)
tems,  our  results  and  those  of other  systems  are  not  really 
comparable.  However,  it  is  reasonable  to  expect  that  it  is 
possible to set this stopping criterion well enough using held 
out data.  Thus this comparison gives us an approximate idea 
of where  our  systems  stand  with  respect  to  state-of-the-art 
ones in terms of performance.  AdaBoost is the classifier that 
gave the best result on  nouns  in  [Yoong  and  Hwee,  2002], 
Best  S2  [Mihalcea and Moldovan,  2001]  refers to the best-
performing system on nouns among the Senseval-2 workshop 
systems. These results show that our systems' performance is 

NATURAL  LANGUAGE 

821 

Table 2.  Example results on a few words.  F = flat, H = hierar(cid:173)
chical. 

comparable  to  that  of state-of-the-art  ones  and  that  our  hier(cid:173)
archical  model  trained  on  background  and  specific  data  out(cid:173)
performs the  flat  one. 

Results  for a few individual words are presented  in Table 2. 
They  show  that  the  improvements  are  not  uniform,  but  vary 
from  word  to  word.  Overall  we  identified  105  nouns.  The 
great  majority  of  these  are  compounds  that  typically  occur 
only  once  in  the  test  data.  Both  systems  achieve  approxi(cid:173)
mately  the  same  score  on  these  data.  On  the  bulk  of the  test 
data, however, the  systems perform  differently.  Of the  21  test 
words  on  which  the  classifiers  achieve  different  scores,  the 
hierarchical  perceptron  is  more  accurate  than  the  flat  one  on 
15  words, or 71.5% of the time. 

This  finding  suggests  a  simple  improvement  for the  hierar(cid:173)
chical  system.  The  contribution of the  individual  components 
of the  classifier  could  be  weighted  setting  the  weights,  after 
training,  using  held  out  data. 
In  the  simplest  setting  binary 
weights  could  be  used;  e.g.,  either  the  background  informa(cid:173)
tion  is  used  or  not.  Thus  the  background  model  would  be 
used  only  when  useful,  otherwise  its  contributions  would  be 
ignored. 

7  Conclusion 
We  have presented  a  learning  architecture  for  lexical  seman(cid:173)
tic  classification  that  supplements  task-specific  training  data 
with  background  data  encoding  general  "world  knowledge" 
extracted 
from  a  widely  used  broad-coverage,  machine-
readable  dictionary.  The  model  integrates  task-specific  and 
general  information through  a novel  hierarchical  learning ar(cid:173)
chitecture  based  on  the  multiclass  perceptron.  Experiments 
on  a  word  sense  disambiguation  task  showed  that  the  hierar(cid:173)
chical  model  achieves  improved performance  over a  state-of-
the-art standard "flat"  system. 

This  new  framework  has  a  number  of  promising  exten(cid:173)
sions.  Additional  accuracy  gains  are  expected  by  using 
more sophisticated perceptron learning algorithms such as the 
voted  perceptron  [Freund  and  Schapire,  1998]  and  by  using 
the  dual  perceptron  with  non-linear  kernels.  We  have  only 
made  use  of  the  simplest  possible  form  of  hierarchy  (two-
stage),  in  reality the  hierarchical  structure  of WordNet  is  very 
complex  and  much  more  informative.  The  model  presented 
here  can  be  extended  to  include  this  type  of structure  as  well 
as  other  sources  of  information. 
In  addition,  the  two-layer 
model  can  be  applied  to  all  other open-class  words  in  Word-
Net  and  a  ftill-hierarchy-based  model  could  be  applied  to 
verbs  and  nouns.  There  is  also  more  information  to  extract 
from WordNet,  for example,  from the  glosses,  which  can po(cid:173)
tentially  be  utilized  as  additional  training  data.  Lastly,  the 

ideas  we  presented  here  might  be  used  with  other  learning 
methods.  We  leave these  topics  for future research. 

References 
[Charniak, 2000]  E.  Charniak. 

A  Maximum-Entropy-Inspircd 
In  Proceedings  of the  1st  Meeting  of the  North  Amer(cid:173)
Parser. 
ican  Chapter  of the  Association  for  Computational  Linguistics, 
NAACL-00,  2000. 

[Ciaramita, 2002]  M.  Ciaramita.  Boosting Automatic  Lexical  Ac(cid:173)
quisition with Morphological Information. In Proceedings of the 
Workshop  on  Unsupervised Lexical Acquisition,  ACL-02,  2002. 
[Clark and Weir, 2002]  S.  Clark  and  D.  Weir.  Class-Based Prob-
ability  Estimation  using  a  Semantic  Hierarchy.  Computational 
Linguistics, 28, 2002. 

[Collins, 2002]  M.  Collins.  Ranking Algorithms  for Named-Entity 
Hxtraction:  Boosting and the Voted Perceptron.  In Proceedings 
of the  40th  Meeting  of the  Association  for  Computational  Lin(cid:173)
guistics,  ACL-02,  2002. 

[Crammer and Singer, 2002]  K. Crammer and Y. Singer.  Ultracon-
scrvative On line Algorithms for Multiclass Problems.  Technical 
Report [2001-18], School  of Computer Science and Engineering, 
Hebrew University, Jerusalem, Israel, 2002. 

[Dumais and Chen, 2000]  S.  Dumais  and  H.  Chen.  Hierarchical 
Classification  of Web Content.  In Proceedings ofSIGIR-00,  23rd 
ACM International Conference  on  Research  and Development  in 
Information  Retrieval,  2000. 

[Fellbaum,  1998]  C.  Fcllbaum.  WordNet:  An  Electronic  Lexical 

Database.  MIT Press, Cambridge, Massachusetts,  1998. 

[Freund and Schapire,  1998]  Y.  Freund  and  R.E.  Schapire.  Large 
Margin  Classification  Using  the  Perceptron  Algorithm.  Machine 
Learning, 37, 1999. 

[Hearst,  1992]  M.  Hearst.  Automatic  Acquisition  of Hyponyms 
In  Proceedings  of the  Nth  Interna(cid:173)

from  Large  Text  Corpora. 
tional  Conference  on  Computational  Linguistics,  1992. 

[Hofmann ct al., 2002]  T. Hofmann, I. Tsochantaridis and Y Altun. 
Learning  over  Discrete  Output  Spaces  via  Joint  Kernel  Func(cid:173)
In  Advances  in  Neural  Information  Processing  Systems, 
tions. 
Workshop on Kernel Methods, 2002. 

[Light  and Grcif, 2002]  M. Light and  W.  GreitT.  Statistical Models 
for  the  Induction  and  Use  of  Selectional  Preferences.  In  Cogni(cid:173)
tive Science, 87, 2002. 

[Mihaleea and Moldovan, 2001]  R.  Mihalcca  and  D.I.  Moldovan. 
Pattern  Learning  and  Automatic  Feature  Selection  for  Word 
In  Proceedings  of the  Second  interna(cid:173)
Sense  Disambiguation. 
tional  Workshop on  Evaluating  Word Sense Disambiguation Sys(cid:173)
tems (SENSEVAL-2), 2001. 

[Riloff and Jones,  1999]  E.  Riloff and  R.  Jones.  Learning  Dictio(cid:173)
naries  for Information Extraction by  Multi-Level  Bootstrapping. 
In Proceedings of the Sixteenth National Conference on Artificial 
Intelligence,  1999. 

[Toutanovaetal.,2001]  K.  Toutanova,  F.  Chen,  K.  Popat  and  T. 
Hofmann.  Text  Classification  in  a  Hierarchical  Mixture  Model 
for Small Training Sets. In Proceedings of the 10th International 
Conference  on  Information  and Knowledge  Management,  2001. 
[Yoong and Hwee, 2002]  K.L Yoong and T.N. Hwee. An Empirical 
Evaluation  of Knowledge  Sources  and Learning  Algorithms  for 
In  Proceedings  of the 2002  Con(cid:173)
Word  Sense  Disambiguation. 
ference  on  Empirical Methods  in  Natural  Language  Processing 
(EMNLP-2002),  2002. 

822 

NATURAL  LANGUAGE 

