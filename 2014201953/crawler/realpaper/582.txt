Compiling Control Knowledge into Preconditions for Planning in the Situation 

Calculus 

Alfredo Gabaldon 

Department of Computer Science 

University of Toronto 
alfredo@cs.toronto.edu 

Abstract 

A promising technique used in some planning sys(cid:173)
tems  to  improve  their  performance  is  the  use  of 
domain dependent search  control knowledge.  We 
present  a  procedure  for  compiling  search  control 
knowledge, expressed declaratively in a logic, into 
the  preconditions  of the  plan  actions  (operators). 
We  do  this  within  the  framework  of the  situation 
calculus  by  introducing  a  transformation  of non-
Markovian action theories into classical Markovian 
situation calculus theories. 

Introduction 

1 
One  of the  strategies  used  in  planning to  mitigate the  com(cid:173)
plexity  of the  general  problem  is  to  employ  some  form  of 
domain  specific  knowledge  to  assist  the  search  for  a  plan. 
For  instance,  Hierarchical  Task  Network  (HTN)  planning 
systems  [Sacerdoti,  1974; Wilkins,  1988;  Erol et  al,  1996] 
use  domain  specific  procedural  knowledge  in  the  form  of 
task decomposition methods.  The forward-chaining planners 
TLPlan [Bacchus and Kabanza, 2000], TALPlanner [Kvarn-
strom and Doherty,  2000]  and the  SAT based planner SAT-
Plan  [Kautz  and  Selman,  1998]  use  domain  knowledge  in 
the form of declarative constraints expressed in a logical lan(cid:173)
guage.  This strategy has been shown experimentally to yield 
remarkable improvements in performance.  Both TLPlan and 
TALPlanner use control constraints expressed in the form of 
temporal  logic  formulas.  These  formulas are  used  to  elim(cid:173)
inate  plan  prefixes which  will  lead  to  a  suboptimal  plan  or 
cannot be extended into a complete plan at all. 

Most practical planning systems use STRIPS, ADL or ex(cid:173)
tensions of these to describe  actions and their effects.  How(cid:173)
ever,  the  first  formal  specification  of the  classical  planning 
problem,  due  to  [Green,  1969],  was  postulated in  the  lan(cid:173)
guage  of the  situation  calculus  [McCarthy,  1963].  The  sit(cid:173)
uation calculus has proven to be a very powerful formalism 
and has been employed in the  formalization  of many differ(cid:173)
ent  aspects  of dynamical  systems  (see  e.g. 
[Reiter,  2001]). 
In  this  paper,  we  use  the  situation  calculus  as  our  formal 
framework  and  consider  how  to  incorporate  search  control 
into  action  theories.  Specifically,  we  show that control  for(cid:173)
mulas with a certain syntactic form can be incorporated into 

nonMarkovian action theories in the situation calculus, as re(cid:173)
cently  introduced  in  [Gabaldon,  2002],  in  a similar way  as 
[Lin and Reiter,  1994] treat qualification state constraints.  In 
these nonMarkovian action theories, the effects and precon(cid:173)
ditions  of actions  are  not  assumed  to  depend  solely  on  the 
current situation, but on any past situation.  This nonMarko(cid:173)
vian property of the theories allows an easier incorporation of 
dynamic constraints into database specifications, a more nat(cid:173)
ural and concise axiomatization of nonMarkovian operations 
like  rollback in  transaction  systems  and  other  domains  with 
nonMarkovian properties. 
In  this  paper,  we  are  concerned 
with another problem where these theories are useful:  incor(cid:173)
porating search control knowledge by treating it as dynamic, 
qualification state constraints.  Dynamic in the sense that they 
may  refer to  the  current and  any past  situation,  as  opposed 
to static state constraints which refer only to the current state. 
Moreover, they are understood as qualification constraints be(cid:173)
cause they pose  further restrictions on  the "executability" of 
actions.  (We do not consider the use of these constraints for 
expressing ramifications, i.e.  indirect effects of actions.) 

Furthermore, we present a transformation from nonMarko(cid:173)
vian  action theories  into  Markovian ones.  This transforma(cid:173)
tion  takes  an  action  theory  with  nonMarkovian axioms  and 
by  applying regression  steps  and  introducing additional  flu(cid:173)
ents and their corresponding successor state axioms, produces 
a classical Markovian theory as introduced by [Reiter, 1991 J. 
We then show how this transformation can be used for com(cid:173)
piling search control knowledge into normal action precondi(cid:173)
tions.  This nonMarkovian to Markovian transformation pro(cid:173)
cedure is of independent interest.  Toward the end we extend 
this approach for theories with explicit time and close with a 
discussion. 

2  Formal Preliminaries 
In this section we give an  overview of the situation calculus 
and the main definitions necessary for action theories without 
the Markov assumption. 

The Situation  Calculus 

2.1 
The  situation  calculus  is  a  first  order  logic  language  with 
three basic components:  actions, situations, and fluents. Ac(cid:173)
tions are responsible for all the changes in the world.  Situa(cid:173)
tions  are  sequences  of actions  which  represent possible  his(cid:173)
tories  of the  world.  Fluents  are  properties of the  world  that 

REASONING ABOUT ACTIONS AND CHANGE 

1061 

change  from  situation  to  situation  as  a  result  of the  execu(cid:173)
tion  of actions.  Formally,  the  language has  three  sorts:  ac-
tiony  situation  and  fluent. 
In  addition  to  variables  of these 
sorts,  the  language  includes  functions  such  as  move 
to  represent  actions,  a  constant  So  and  a  function do\ 
and predicates for 
for situations such as 
representing fluents such as  atLoccition\ 
.  The 
initial situation, or empty history,  is denoted by the constant 
So-  Non-empty histories  are built by  means of the  function 
do.  For a complete  description  see  [Pirri  and  Reiter,  1999; 
Reiter,2001]. 

A  situation calculus  axiomatization of a domain,  includes 

the  following set of axioms: 

4.  Axioms  describing the  initial  situation  of the  world:  a 
finite  set  of sentences  whose  only  situation  term  is  the 
constant So. 

A set of these axioms, together with a set of domain inde(cid:173)
is called a (Markovian) basic 

pendent foundational axioms 
action  theory. 

2.2  A  nonMarkovian  Situation  Calculus 
For a basic action theory without the Markov assumption, we 
need some definitions.  These are based on those in  [Gabal-
don, 2002]. 

Wc  will  use the  following abbreviations in the definitions 

to follow: 

where 

stands  for  either 

then  we  may  write 
instead. 

and variable .s appears in 
W  and 

Definition 1  (Bounded Formulas)  For 
a  term 

be 
The  formulas  of 
bounded by  o  are  the  smallest set  of formulas  such 

rooted  at 

let 

that: 

1.  If W  is an atom whose situation terms are all  rooted at 

then W is bounded by 

2.  If  W, W"  are  formulas  bounded  by  situation  terms 

rooted at s and 

, respectively, then 

W  and 

W  are  formulas bounded 

by  where 

is rooted at s and W 

3.  If  Wi,W2  are  formulas  bounded  by  situation  terms 
where 

rooted at 

then 

and 

is of sort action or object, are formulas bounded by 

The  set  of formulas  strictly  bounded by 

is similarly de(cid:173)
fined by requiring in item (1) above that all situation terms of 
in  item  (2)  that  W  be  strictly bounded 
W  be subterms  of 
and W" by a subterm of rr; and in item (3) 
by a subterm of 
that W\, W2 be strictly bounded by subterms  of 
Example 1  Past temporal logic connectives can be expressed 
in the situation calculus with strictly bounded formulas as fol(cid:173)
lows: 

NonMarkovian basic action theories differ from those which 
include the Markov assumption in  that preconditions and ef(cid:173)
fects of actions may depend on any past situation, not only on 
the current one. 

Hence the rhs, 

of action  precondition 
axioms  in  a  nonMarkovian basic  action  theory are  formulas 
bounded by situation term s which do not mention predicate 
Poss  and  may  refer  to  past  situations.  Similarly,  the  rhs, 
of successor state  axioms  are  formulas 

strictly bounded by .s. 

2.3  Regression 
For basic action theories with the Markov assumption,  [Pirri 
and Reiter,  1999] define a provenly correct regression mech(cid:173)
anism that takes a situation calculus sentence and, under cer(cid:173)
tain  restrictions  on  the  form  of this  sentence,  transforms  it 
into an equivalent sentence whose only situation term is 5(>. 
This allows proving sentences without appealing to the foun(cid:173)
dational axioms  which include a second order axiom. This 
regression operator was generalized for nonMarkovian theo(cid:173)
ries in [Gabaldon, 2002]. 

In  a  nutshell, 

the  regression  operator,  denoted  by 
takes  a  sentence  and  recursively  replaces  each  flu(cid:173)
by  its  definition  according  to  its 
ent  atom 
i.e. 
Atoms 
successor  state  axiom, 
Poss 
are  similarly  replaced by  their defini(cid:173)
tions  given  by  the  action  precondition  axioms.  Regression 
recursively replaces these  atoms until  all  the situation terms 
are  reduced to  So-  For  lack  of space  we  refer the  reader to 
[Pirri and Reiter, 1999; Reiter, 2001; Gabaldon, 2002] for the 
formal details. 

by 

In  the  transformation  operator  we  introduce  later,  we 
will  use  a  one-step  version  of  the  regression  operator: 
TV 
stands  for  the  regression  of  a  sentence 
W 
that results in a sentence 
bounded by o. 
3  Control Knowledge and the Qualification 

bounded by 

Problem 

As  mentioned  earlier,  the  use  of search  control  knowledge 
has proven to be a promising recourse for improving the per(cid:173)
formance  of planning  systems.  Both  TLPlan  [Bacchus  and 

1062 

REASONING ABOUT ACTIONS AND CHANGE 

Kabanza, 2000] and TALPlanner [Kvarnstrom and Doherty, 
2000] use declarative control knowledge in the form of tem(cid:173)
poral  logic  and  have  shown  substantial  computational  im(cid:173)
provement. 

Since  our goal  is  to  compile  search  control  into  precon(cid:173)
ditions,  we  express control  knowledge in  terms  of the  past, 
not the  future as  it is done  in TLPlan and TALPlanner (this 
is further discussed in the last section).  However, declarative 
search  control  knowledge  is  typically  expressed  in  a  future 
temporal  logic  and  we  believe  that  obtaining  preconditions 
from knowledge in that form is an important problem.  In the 
last section we comment on how we are approaching this. 

From the point of view of logical theories of action, such as 
the  situation  calculus axiomatizations we discuss  in this pa(cid:173)
per, taking control knowledge into account is closely related 
to the classical qualification problem [McCarthy,  1977].  This 
is the problem of determining all  the conditions that need to 
be satisfied for an action to be executable and control knowl(cid:173)
edge is effectively a set of additional constraints on the cxe-
cutability of actions,  i.e.  on what actions can be considered 
part of an executable plan. 

Lin & Reiter [1994] have considered the qualification prob(cid:173)
lem for situation calculus basic action theories with state con(cid:173)
straints, which are formulas of the form 
uniform in 
cS.  Their solution is to add the qualifications to the precondi(cid:173)
tion axiom of each action type: 

R1 

[Q(do(A 

where 
After adding the qualifi(cid:173)
cations to the precondition axioms, one can discard the con(cid:173)
straints if two conditions are satisfied: all the state constraints 
hold  initially,  i.e.  Q(So)  holds  for each  Q\  and  the  domain 
closure assumption on actions is included in the theory. 

Control formulas are similar to state constraints in that they 
pose  additional  qualifications on  actions,  but they  are more 
general since they may quantify over past situations. 

In the nonMarkovian situation calculus, successor state ax(cid:173)
ioms and action precondition axioms can refer to past situa(cid:173)
tions  in  addition to the  current situation.  This permits con(cid:173)
trol  knowledge  to  be  incorporated  into  action  precondition 
axioms  in  the  same  way  Lin  &  Reiter do.  Formally,  if C(s) 
is a  formula bounded by  .s  representing some piece of con(cid:173)
trol knowledge, we take this into account by adding it as an 
additional precondition for actions: 

(1) 
Precondition axioms  in  nonMarkovian action  theories  allow 
situation  terms  rooted  at  s  such  as  do 
to  appear 
in their rhs, so we can add  C(do(A 
directly  without 
modification. By including the domain closure assumption on 
actions, we are then guaranteed that a situation is executable 
only if it  satisfies the constraints. 
Example 2  (Logistics  domain  constraint)  Consider  a  con(cid:173)
straint from a logistics domain, which involves vehicles de(cid:173)
livering packages to  locations,  saying  that  a truck  must re(cid:173)
main  in  a  location  if there  is a  package at that  location  and 
it's  never been  in  the  truck  (so  it  hasn't just been  delivered 
and needs to be moved): 

Suppose 

that 

is: 

the  action  precondition  axiom 

for 
to  a  location  loc 

driving  a  truck 

We  can  add 

the  control 

formula  as  a  new  con(cid:173)

junct  in  the  rhs  after  simply  replacing  $  with 

In the next section, we introduce an operator which takes a ba(cid:173)
sic action theory with such nonMarkovian axioms, and trans(cid:173)
forms it into one with Markovian ones. 

4  Transforming a nonMarkovian Theory into 

Markovian 

In order simplify the presentation, let us first make some sim(cid:173)
plifying assumptions on the form and the nesting of formulas 
on which we define the transformation. 

Formally, in reference to item  (2) of Definition  1, we will 

assume that formulas are of the forms: 

(2) 

(3) 

where  all  (if any)  free  variables  of  W2  are  among  the  free 
variables of the  full  formula.  Other combinations of quanti(cid:173)
fiers and logical connectives reduce to these two cases.  The 
restriction on the free variables of W2 does make the transfor(cid:173)
mation simpler.  We treat the general case in the full version 
of this paper.  Next, we restrict the nesting of formulas in the 
following way.  By  definition, W2 must itself be of the  form 
where  W'  is  bounded  by  s"  and  \Y"  by  s. 
W', 

We will restrict W-i  by requiring it to be of the form  
i.e.  without the  conjunct  W". 

Notice however that,  even  with this  restrictions,  arbitrary 
nesting of the past temporal logic abbreviations (Example  1) 
is still expressible. 

The  transformation performs a  combination  of regression 

and of replacement of formulas by new  fluents: 

ingforms: 

REASONING ABOUT ACTIONS AND CHANGE 

1063 

The result  of 

comes: 

is similar.  Then the constraint be(cid:173)

Finally, we add the constraint to action precondition axioms: 

Example 4  (Closed form  solution for  a fluent)  Consider  a 
fluent  F(x, s) and its closed form solution [Reiter, 2001]: 

Now, we can apply the transformation to a nonMarkovian 
action theory  whose action precondition axioms have as an 
additional  condition a constraint C(s),  and obtain a Marko-
vian theory 
that enforces the constraint. This produces a 
theory with precondition axioms of the form: 

Clearly,  the  rhs  of  the  above  sentence  is  formed  by 
F 
and two formulas which are almost of the form (2). 
The  difference  is  in  the 
immediately  after  the  existen(cid:173)
tial  quantifiers on  situations  s1,s2,  which  would need to be 
to  fit  form  (2),  and  the  subformulas  of  the  form 
strict 
The  latter  will  be  simplified  away. 
Further,  it  is  easy  to  modify  the  transformation  on  (2)  to 
In  general,  all  we  need  to  do  is  replace 
handle  the 
However, in this ex(cid:173)

with 

ample the one step regression won't be necessary. 
Applying the transformation to the subformula 

Theorem 2  Let  C(s)  be  a  control  knowledge  formula 
bounded  by  s  and  let 
be  a  nonMarkovian  basic  action 
theory whose precondition axioms have the form (1) and in(cid:173)
cludes domain closure axioms for actions.  Then, 

results  in  a  predicate 
iom  (after  simplifying) 

with  successor  state  ax(cid:173)

The transformation of subformula 

Example 3  Consider again the logistics domain control for(cid:173)
mula from Example 2.  Let 
stand for premise and 
consequence,  respectively.  Both  formulas  are  of form  (2). 
The premise 

stands for: 

and 

P1 
f< 

1064 

results  in  a  predicate  . 
iom  (after  simplifying) 

with  successor  state  ax(cid:173)

Noticeably, this successor state axiom  for 

is al(cid:173)
most identical to the canonical form successor state axiom for 

which  is 

Finally,  after applying  the  transformation  to  subformulas 
of the closed form formula (4), we obtain the follow(cid:173)

ing equivalent sentence: 

The  transformation  comes  close  to  producing  a  canoni(cid:173)
cal  Markovian  successor  state  axiom. 
It  does  not  because 
the closed form solution formula uses information about the 
value of F in the  initial  situation. 

REASONING ABOUT ACTIONS AND CHANGE 

5  Constraints with  explicit time 
In  this  section,  we  extend  our  approach  to  search  con(cid:173)
trol  knowledge  with  explicit  time. 
In  the  temporal  sit(cid:173)
uation  calculus  [Reiter,  2001],  actions  have  an  additional 
temporal  argument  denoting  the  time  of  occurrence,  e.g. 
drive(truck,loc,3.2) 
location 
loc  at  time  3.2.  There  are  also  some  additional  axioms: 

for  driving  a 

to  a 

truck 

For  a  formula 

of the  form  (5), , 

with a successor state axiom: 

yields  a  predicate 

(7) 

The initial 

and, 
database would include 

For a formula of the form (6), the successor state axiom for 

with . 
initial database would include 

The statement of the following theorem, which establishes 
the correctness of the transformation, requires adding the con(cid:173)
junct 

to formulas (5) and (6): 

(8) 

The 

Similarly  for formula (6). 

operator  introduces  into  a  theory  the  additional  fluents  and 
axioms  needed  for  keeping  track  of the  relevant  past  infor(cid:173)
mation.  We then showed how this operator can be used for 
compiling TLPlan style search control knowledge into action 
preconditions in the situation calculus. 

In  the  TLPlan  system,  control  knowledge  is  expressed 
in  terms  of linear  (future)  temporal  logic,  that  is,  temporal 
modalities next,  always in  the future,  until,  and sometime in 
the  future are  used.  Every time  a new  operator is  added to 
the  plan  prefix  being  considered,  a  control  formula  is  pro(cid:173)
gressed through  it. 
If the  formula  is  progressed  into  false, 
the  plan  prefix  is  pruned  since  a  plan  with  this  prefix  will 
violate the  constraint.  Although  it  is  easy to write  situation 
calculus formulas corresponding to future temporal logic, re(cid:173)
gression cannot be used on them.  However, we argue that if 
instead of progression, as in TLPlan, we evaluate the control 
formulas against plan prefixes, it is reasonable to use a logic 
that refers to  past situations  instead  of future situations.  In(cid:173)
deed, all the reasoning used by a planning system to decide if 
a partial plan should be discarded or not must be done relative 
to the properties of the partial plan itself.  Furthermore, some 
future temporal formulas are satisfied by all plan prefixes (e.g. 
"sometime in the future 
is not unsatisfiable) and 
are  not  useful  for  search  control.  Thus  it  seems  to  us  that 
restricting control formulas to refer exclusively to the past is 
appropriate. 

where 

logic 

Moreover,  using  past  temporal 

is  semantically 
cleaner for the following reason. The semantics of future tem(cid:173)
poral logic is defined in terms of infinite sequences of states. 
However, plans are  finite  sequences of actions and thus pro(cid:173)
duce a finite sequence of states. In order to deal with this tech(cid:173)
nical difficulty, TLPlan makes the assumption that the world 
never changes after the plan is completely executed and there(cid:173)
fore the last state  infinitely repeats.  This assumption is rea(cid:173)
sonable under another assumption typically made in classical 
planning:  that the agent executing the plan is the only agent 
that changes the world, so when this agent terminates execut(cid:173)
ing its plan, the world remains unchanged. This assumption is 
unnecessary if using past temporal  logic or bounded situation 
calculus formulas. 

Nevertheless,  it would be convenient to be able to handle 
control  knowledge  expressed  in  future  temporal  logic.  We 
are currently working on developing a procedure that would 
allow us to take a future temporal logic control formula, such 
as this Briefcase domain one: 

and produce a bounded situation calculus formula: 

6  Discussion and conclusion 
We have shown that incorporating control knowledge as addi(cid:173)
tional preconditions in nonMarkovian action theories is triv(cid:173)
ial  when  this  knowledge  is  in  the  form  of bounded  formu(cid:173)
las  (which  include encodings of Past temporal logic modali(cid:173)
ties).  We then  introduced an operator for transforming non(cid:173)
Markovian basic  action  theories  into  Markovian  ones.  This 

1Thc variable t is a fresh new variable so there is no effect on the 

meaning of the formulas. 

that a plan prefix must satisfy.  In turn, we can then apply the 
procedure introduced in this paper to compile these formulas 
into the preconditions of actions. 

Bacchus &  Kabanza  [1998]  have also  extended their sys(cid:173)
tem  for planning with  temporally extended goals,  which  are 
conditions  on  sequences  of states  and  not  only  on  the  final 
state  as in classical  planning.  They use  a  first-order  exten(cid:173)
sion  of the Metric  Interval Temporal  Logic  (MITL)  [Alur et 

REASONING ABOUT ACTIONS AND CHANGE 

1065 

ai,  1991]  to  specify  the  temporally  extended  goals.  Defin(cid:173)
ing plan correctness with respect to M1TL formulas as goals 
again requires one to make the assumption that the world re(cid:173)
mains  unchanged after the  plan  is  executed.  In  the  case  of 
temporally extended goals this is a further complication since 
testing if the current state satisfies the goal  means checking 
whether 
is true if the world were to indefinitely remain as 
it currently is.  (Past) MITL formulas can be encoded as for(cid:173)
mulas of the situation calculus with explicit time as discussed 
in  the  previous  section.  Hence  our approach  also  shows  a 
way  to reduce planning with temporally extended goals into 
planning with classical goals. 

Some preliminary experiments by  Bacchus &  Ady  [1999] 
have shown that compiling search control knowledge into ac(cid:173)
tion preconditions can result in better performance compared 
to systems such as TLPlan which keep control knowledge as 
a separate  set  of formulas.  A  general  method for compiling 
temporal  formulas into preconditions in their framework has 
not yet been developed. 

The  work  of [Rintanen,  2000]  is  also  concerned  with  the 
use of control  knowledge as additional preconditions of plan 
operators.  He uses "auxiliary facts" which is a similar to our 
introduction of new fluents in the transformation.  Like  Bac(cid:173)
chus & Kabanza, Rintanen uses  future  linear temporal logic 
for representing control knowledge for planers with ADL-like 
operators. With the help of these auxiliary facts, he then com(cid:173)
piles the control knowledge into the operators. The main dif(cid:173)
ference between his work  and ours  is that his  framework  is 
propositional, while ours is in the more expressive first order 
situation calculus.  Furthermore, he does not allow nesting of 
temporal operators-in our framework this would correspond 
to disallowing nesting  of quantifiers on  situations-which we 
do allow.  Also  related but with a different approach,  is the 
work of Sierra [1998].  There, domain knowledge in the form 
of action  selection  rules  is  used  for  controlling  a  STRIPS 
planner. Analyzing the relationship of Sierra's work with ours 
is among our future work. 

References 
[Alur etal.,  1991]  Rajeev  Alur,  Tomas  Feder,  and  Thomas 
Henzinger.  The benefits of relaxing punctuality.  In  Pro(cid:173)
ceedings of the Thenth Annual ACM Symposium on Prin-
ceples  of  Distributed  Computing  (PODC'91),  pages  139-
152,1991. 

[Bacchus and Ady,  1999]  Fahiem  Bacchus  and  Michael 

Ady.  Precondition control.  1999. 

[Bacchus and Kabanza,  1998]  Fahiem  Bacchus  and  Frodu-
ald Kabanza.  Planning for temporally extended goals. An(cid:173)
nals  of Mathematics  and  Artificial  Intelligence,  22:5-27, 
1998. 

[Bacchus and Kabanza, 2000]  Fahiem  Bacchus  and  Frodu-
ald  Kabanza.  Using  temporal  logics  to  express  search 
control  knowledge  for  planning.  Artificial  Intelligence, 
116:123-191,2000. 

[Erol et al,  1996]  Kutluhan  Erol,  James  A.  Hendler,  and 
Dana  S.  Nau.  Complexity  results  for  hierarchical  task-

network  planning.  Annals  of Mathematics  and Artificial 
Intelligence,  18:69-93,  1996. 

[Gabaldon, 2002]  Alfredo  Gabaldon.  Non-markovian con(cid:173)
In  Proceedings  of the 
trol  in  the  situation  calculus. 
Eighteenth  National  Conference  on  Artificial  Intelligence 
(AAAI'02), pages 519-524, Edmonton, Canada, 2002. 

[Green, 1969]  C.C. Green. Theorem proving by resolution as 
a basis for question-answering systems.  In B. Meltzer and 
D.  Michie,  editors,  Machine  Intelligence  4,  pages  183-
205. American Elsevier, New York,  1969. 

[Kautz and Selman,  1998]  Henry  Kautz  and  Bart  Selman. 
The role of domain-specific knowledge in the planning as 
satisfiability  framework.  In  Proceedings  of  the  Fourth  In(cid:173)
ternational  Conference  on  Artificial  Intelligence  Planning 
Systems (AIPS'98), pages  181-189,1998. 

[Kvarnstrom and Doherty, 2000]  Jonas  Kvarnstrom  and 
Patrick  Doherty.  TALplanner:  A  temporal  logic  based 
forward  chaining  planner.  Annals  of Mathematics  and 
Artificial  Intelligence,  30:119-169,2000. 

[Lin and Reiter,  1994]  Fangzen  Lin  and  Ray  Reiter.  State 
constraints  revisited.  Journal  of  Logic  and  Computation, 
4(5):655-678, October 1994. 
[McCarthy, 1963]  J.  McCarthy. 

Situations,  actions  and 
causal laws.  Technical report, Stanford University,  1963. 
Reprinted in Semantic Information Processing (M. Minsky 
ed.), MIT Press, Cambridge, Mass.,  1968, pp. 410-417. 

[McCarthy,  1977]  John  McCarthy.  Epistemological  prob(cid:173)
lems  of  artificial  intelligence.  In  Proceedings  of  the  Fifth 
International  Conference  on  Artificial  Intelligence 
(IJ-
CAI77),pages  1038-1044,1977. 

[Pirri and Reiter,  1999]  Fiora  Pirn  and  Ray  Reiter.  Some 
contributions to the metatheory of the  Situation  Calculus. 
Journal of the ACM, 46(3):325-364,1999. 

[Reiter,  1991]  R. Reiter.  The frame problem in the situation 
calculus:  A simple solution (sometimes) and a complete(cid:173)
ness result for goal regression.  In V. Lifschitz, editor, Arti(cid:173)
ficial  Intelligence  and  Mathematical  Theory  of Computa(cid:173)
tion, pages 359-380. Academic Press, 1991. 

[Reiter,  2001]  Ray  Reiter.  Knowledge  in  Action:  Logical 
Foundations  for  Describing  and  Implementing  Dynamical 
Systems. MIT Press, Cambridge, MA, 2001. 

[Rintanen, 2000]  Jussi  Rintanen.  Incorporation of temporal 
logic control into plan operators. In W. Horn, editor, Procs. 
of  the  14th  European  Conference  on  Artificial  Intelligence 
(ECAI'00), pages 526-530, Amsterdam, 2000. IOS Press. 
[Sacerdoti,  1974]  E.D.  Sacerdoti.  Planning  in  a  hierarchy 
of abstraction  spaces.  Artificial  Intelligence,  5:115-135, 

[Sierra,  1998]  Josefina  Sierra.  Declarative  formalization of 
In  Procs.  of the  7th  Intl. 

strategies  for  action  selection. 
Workshop on Nonmonotonic Reasoning NMR '98,  1998. 
[Wilkins,  1988]  David  E.  Wilkins.  Practical Planning:  Ex(cid:173)
tending  the  classic AI planning paradigm.  Morgan  Kauf-
mann, San Mateo, CA, 1988. 

1066 

REASONING ABOUT ACTIONS AND CHANGE 

