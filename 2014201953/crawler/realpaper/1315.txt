Session  15  Robot  Problem  Solving 

DECIDER-1:  A  SYSTEM  THAT  CHOOSES  AMONG  DIFFERENT  TYPES  OF  ACTS' 

Leonard  Uhr 

University  of  Wisconsin 

Madison,  Wisconsin 

Abstract 

This  paper  examines  a  programmed  model  (called 

DECIDER-1)  that  1)  recognizes  scenes  of  things, 
among  which  are  a)  objects  and  b)  words  that  form 
commands  (or  questions  or  other  types  of  statements), 
2) 
decides  whether  to  obey  one,  and  then  4)  uses  the 
command  to  guide  the  consequent  actions,  along  w i th 
any  necessary  perceptual  search. 

recognizes  the  import  of  these  commands, 

3) 

It  uses  the  same  mechanisms  to  handle  a)  the 
perceptual  processes  involved  w i th  recognizing  o b­
j e c ts  and  describing  scenes, 
b)  the  l i n g u i s t ic  p r o­
cesses  involved  w i th  parsing  sentences  and  under­
standing  their  meaning,  and  c)  the  retrieval  processes 
needed  to  access  pertinent  facts  in  pertinent  memory. 
This  is  in  sharp  contrast  to  most  of  today's  systems, 
which  receive  the  command  through  one  channel,  to  be 
"understood"  by  one  special-purpose  set  of  routines, 
and  perceive  their  environments  through  an  entirely 
different  channel. 

DECIDER-1  continues  to  characterize  patterns, 

parse  symbol  strings,  and  access  facts  implied  by 
input  questions  u n t il  an  action  is  chosen,  because  it 
is  sufficiently  implied  by  this  search  through  the 
memory  net  .  Then  it  executes  the  implied  a c t i o n. 
Possible  actions  include  Answering,  Describing, 
Finding,  M o v i n g,  and  Naming. 

Introduction 

The  basic  purpose  of  this  paper  is  to  examine  how 

word-things  recognized  in  the  external  environment 
can  help  trigger  actions  that  include  recognition  and 
manipulation  of  other,  o b j e c t - t h i n g s,  in  the  same 
environment.  To  do  this  we  must  examine  several 
issues  that  have  scarcely  been  touched  upon  in  the 
research  literature  of  psychology  or  computer  science: 

How  does  a  system  recognize  that  a  perceived 

that  it  is  a  command, 

input  is  a  symbol?  How  does  it  understand  the  import 
of  a  structure  of  symbols,  e . g. 
or  a  question?  How  does  it  understand  the  meaning  of 
that  structure  ?  How  does  it  decide  what  type  of  thing 
to  do  -  whether  to  obey  a  command,  and  which  com­
mand,  or  whether  to  continue  to  perceive,  to  respond 
to  internal  needs,  or  external  presses  from  perceived 
objects  ?  How  do  the  understanding  of  commands  and 
other  symbolic  percepts  and  the  recognition  of 
perceived  objects  interact,  helping  one  another;  e . g. 
how  does  it  recognize  which  objects  are  appropriate 
for  carrying  out  a  command?  How  does  a  system 
choose  and  execute  the  appropriate  response,  from 
variety  of  possible  responses  ? 

This  research  has  been  partially  supported  by  grants 
from  the  National  Institute  of  Mental  Health  ( M H-
12266),  the  National  Science  Foundation  (GJ-36312), 
NASA  (NGR-50-002-160)  and  the  University  of 
W i s c o n s in  Graduate  School. 

396 

These  are  extremely  complex  and  subtle  matters, 
and  the  work  presented  here  is  only  a  first  step.  But 
there  appear  to  be  relatively  simple  yet  powerful  ways 
In  which  we  can  begin  to  handle  them. 

Description  of  the  Problem,  Background  and  Motivation 

We  w i ll  examine  systems  that  a)  input  streams  of 
information  from  the  environment,  b)  attempt  to  recog­
nize  things, 
including  symbols,  and  larger  structures 
of  these  things,  c)  decide  whether  to  continue  in  this 
perceptual  process  or  to  respond,  and  d)  generate  the 
appropriate  response. 

Let's  look  at  recent  research  w i th  chimpanzees  and 

w i th  robots  for  some  examples. 

Chimps  that  Obey  Commands 

Two  chimps  have  been  taught  (by  Gardner  and 

Gardner,  19696,19715,  and by Premack,  I9701 0,  197I1J(  to 
learn  vocabularies  of  over  100  words,  and  to  learn  to 
use  these  words  in  simple  sentences.  One  of  the  most 
interesting  things  Sarah  (Premack's  chimp)  learned  was 
to  respond  to  a  sentence  like  "SARAH  PUT  BANANA 
BOX"  by  going  to  the  banana  ,  grasping  i t,  carrying  it 
over  to  the  box,  and  dropping  it  into  the  box.  SARAH  is 
in  an  experimental  room  w i th  a  number  of  objects, 
including  a  banana  and  a  box,  but  also  such  things  as 
a  p a i l,  an  apple,  a  cracker,  and  other  o b j e c t s,  and  a 
board  on  which  the  experimenter  places  the  words 
SARAH,  PUT,  BANANA,  and  BOX. 
(These  "words"  are 
colored  nonsense  shapes:  a ll  previous  attempts  to  get 
chimps  to  talk  failed  because  of  their  limited  vocal 
apparatus.)  Thus  words,  sentences  and  objects  are 
perceived  v i s u a l l y/  w i th  words  static  objects  much 
like  Chinese  ideograms. 

Words  are  things  that  have  symbolic  significance. 
They  come  in  through  the  same  input  channel  as  objects 
like  the  (image  of  the)  banana.  The  chimp  responds 
to 
the  command,  which  is  a  structure  of  several  w o r d-
things,  by  manipulating  the  objects  to  which  the  words 
refer:  Sarah  grasps  the  #BANANA,  not  the  symbol 
BANANA. 
(I  w i ll  use  stars  (*),  as  in  *BANANA,  *BOX, 
*APPLE,  to  indicate  the  actual  object,  as  opposed  to 
the  w o r d.  Note  that  the  star  is  not  a  b u i l t - in  symbol 
for  the  computer  program,  but  simply  helps  the  reader 
distinguish  between  the  word  and  the  simplified  repre­
sentation  of  the  object.) 

Today's  Pr6grams  Cannot  Model  such  Chimps 

The  above  description  may  appear  to  belabor  the 

o b v i o u s.  But  although  any  three  year  old  human  c h i l d, 
and  now  two  chimps,  can  successfully  sort  out  words 
and  o b j e c t s,  recognize  structures  of  words  as  c o m­
mands,  understand  the  import  of  the  commands,  and 
act  appropriately,  we  have  l i t t le  idea  how  a ll  this  is 
done.  Psychologists  have  given  us  no  theoretical 
models,  and  even  the  most  sophisticated  of  computer 
programs  for  pattern  recognition  or  language 

manipulation  are  designed  to  handle  only  small  pieces 
of  this  process, 

It  can 

In  comparison,  a  *BANANA  and  an  *APPLE 

A  sufficiently  powerful  pattern  recognizer  ( e . g. 
UhrandVossier,  I 9 6 I1 7; Andrewset.  aL,  19681;  Munson, 
19688;  zobrist,  197124)  can correctly name  many different 
examples  of  a  pattern,  a ll  distorted  in  extremely 
complex,  and  unanticipated,  non-linear ways. 
contend  w i th  very  complex  possible  confusions  between 
o b j e c t s. 
are  very  different,  and  the  symbols  Premack  has  chosen 
for  BANANA  and  for  APPLE  are  also  different  enough  so 
that  the  chimp  has  no  perceptual  d i f f i c u l t i e s. 
(This 
is  not  at  a ll  to  say  that  the  chimp  and  human  are  not 
sophisticated  pattern  recognizers,  but  simply  to  point 
out  that  the  particular  single-pattern  problem  we  are 
examining,  in  which  only  a  few  very  different  patterns 
need  be  recognized,  is  simple  compared  to  problems 
that  programs,  as  w e ll  as  chimps  and  people,  can 
handle.)  But  today's  pattern  recognizers  w i ll  not 
handle  scenes  of  several  t h i n g s,  much  less  compose 
things  Into  structures  like  sentences,  or  sort  out  the 
words  and  the  objects,  and  their  interrelationships. 

A  sufficiently  powerful  language  processor  ( e . g. 

Winograd,  19712 3; see Simmons,  196514,197015)  can handle 
more  complex  grammatical  structures  than  the  simple 
a c t o r - a c t - o b j e c t - i n d i r e ct  object  of  our  example 
SARAH  PUT  BANANA  BOX.  But  it  w i ll  handle  only  clean, 
clear-cut  sentences. 
It  cannot  content  w i th  sentences 
w i th  misspelled  words  and  noise  that  are  embedded  in 
larger  scenes  that  include  other  objects. 

At  the  very  least,  pattern  recognizers  must  be 
extended  to  handle  scenes  of  objects,  and  to  parse 
word-phrases  as  w e ll  as  characterize  parts  of  objects 
(see Sauvain and Uhr,  196913; Jordan,  19717;Uhr,  197218 
19?3c2 1). 

Robots  that  are  Pre-programmed  to  Obey  Commands 

Recent  work  w i th  robots,  in  which  they  deduce 

paths  to  cluster  boxes,  and  stack  blocks  ( e . g. 
Nilsson,  1969  Raphael,  196812; Feldman et. a l .,  19693), 
has  made  some  steps  toward  this  interaction.  But  it 
has  the  flavor  of  interconnecting  several  separate  black 
boxes,  each  performing  a  separate  function,  even 
though  there  often  appears  to  be  a  great  amount  of 
overlap.  Thus  the  reported  robots 
commands  and  perceptual  environment  completely 
separately. 

input  and  handle 

Today's  robots  use  extremely  complex  systems  of 
computer  programs,  almost  always  separated  into  four 
major  sub-systems,  to  1)  understand  the  command, 
2)  recognize  and  build  up  a  model  of  the  objects  in  the 
environment,  3)  deduce  the  set  of  actions  appropriate 
to  carrying  out  the  command,  and  4)  apply  them  to  the 
environment.  Each  subsystem  has  its  own  subsystems: 

1}  The  command  is  given  through  a  teletype,  and 

the  system  applies  language  "understanding"  programs, 
to  recognize  words,  parse  the  command  statement, 
and  derive  from  the  statement  a  goal  state  that  the 
robot  must  achieve,  to  obey  the  command. 

2)  Separate  perceptual  programs  are  used  to  handle 

the  robot's  perceived  spatial  environment,  which  a l­
most  always  includes  inputs  from  a 
tv  camera,  and 
occasionally  is  supplemented  with  inputs  from  range 
finders,  touch  sensors,  photocells,  or  sonar.  These 
programs  input  the  sensed  information,  take  a  sequence 
of  preprocessing  steps  (e.g.  to  eliminate  n o i s e,  find 
gradients  and  edges,  and  begin  to  connect  short  edge 
fragments  into  lines),  and  try  to  build  the  salient 
features  up  into  something  that  matches  some  internal 
description  of  some  object  ( e . g.  Brice  and  Fennema  , 
19702).  This  results  (if  a ll  goes  w e ll  -  which  today 
means  if  objects  are  sufficiently  simple,  with  enough 
background  space  between  them,  painted  in  colors  that 
contrast  sharply  enough  in  the  black-and-white  tv 
image,  and  amply  lighted)  in  the  assignment  of  names 
to  objects,  and  the  assignment  of  these  objects  to 
their  locations  within  the  perceived  environment. 

3)  A  deductive  problem-solving  program  (often  a 

theorem  prover)  Is  used  to  generate  a  sequence  of 
actions  that  the  robot  might  apply  to  the  objects  it  has 
tentatively  recognized  in  its  perceived  space,  in  order 
to  achieve  the  desired  goal  state  ( e . g.  Fikes  and 
N i l s s o n,  19714). 

4)  This  entails  binding  the  objects  (including  the 
robot  itself)  to  the  proposed  actions,  so  that  the  robot 
can  in  the  real  world  try  out  an  action  that  it  has 
deduced  would  make  progress  toward  satisfying  the 
overall  command. 

Perceiving  the  Import  of  Inputs 

Real-World  Commands  Must  first  be  Perceived 

In  the  real  world  there  is  no  separate  input  channel 

for  a  command,  and  there  is  no  god-given  a  priori 
s i g n a l,  known  to  commander  and  slave  a l i k e, 
that  says, 
"this  is  a  command,"  "this  is  a  q u e s t i o n ,"  "name  this 
o b j e c t ,"  "describe  this  s c e n e ,"  and  so  o n.  A  ques­
tion-answering  program  has  built  into  its  guts  that 
inputs  w i ll  be  questions,  and  it  is  straightforwardly 
pre-programmed  to  answer  them.  A  robot  program 
similarly  has  built  Into  it  that  teletype  inputs  are 
commands,  and  that  it  is  to  carry  them  out,  by  manipu­
lating  the  environment  that  it  perceives  through  its 
sensory  inputs. 

But  in  the  real  world  the  command  always  comes 

In  fact  the  command 

itself  a  complex  structure  of  perceived  objects. 

in  through  sensory  input  channels. 
is 
E.g.  the  command,  "PUT  THE  BANANA  IN  THE  BOX", 
is  made  up  of  a  string  of  words  that  are  further 
structured  grammatically  and,  more  importantly, 
semantically  (in  that  they  refer  to  things  like  bananas, 
relations  between  bananas  and  boxes,  an  understanding 
that  bananas  can  go  into  certain  boxes,  and  the  implied 
action  of  the  entity  being  commanded  -  that  it.  should 
put  the  banana 
in  the  box).  And  each  word  is  made 
up  of  parts  {letters  if  w r i t t e n,  phonemes  if  spoken), 
each  letter  or  phoneme  is  made  up  of  parts,  and  so  o n. 

The  command  may  sometimes  come  through  a 
separate  perceptual  mode  channel,  as  when  it  is 
spoken  and  refers  to  visually  perceived  objects.  But 
this  Is  not  the  issue,  for  commands  and  objects  often 
come  in  through  the  same  channel,  w i th  the  receiver 

hardly  n o t i c i n g. 
It  is  not  the  difference  in  channel  that 
allows  the  human  to  infer  "this  is  a  command  composed 
of  symbols"  and  "that  is  an  environment  of  o b j e c t s ". 
Rather,  the  hearer  first  recognizes  the  parts  of  the 
command  as  objects  and  only  later  as  symbols,  c o m­
bines  them  up  into  larger  and  larger  structures,  and 
recognizes  that  these  structures  have  symbolic  Import, 
and  are  commands. 

Deciding  Whether  to  Obey  Which  Command 

Closely  r e l a t e d,  the  hearer  has  no  b u i l t - in  under­

standing  that  it  w i ll  receive  one  command  at  a  t i m e, 
pointed  to  and  surrounded  by  special  symbols.  Rather, 
since  it  must  infer  that  parts  of  its  perceived  environ­
ment  are  commands, 
it  always  has  the  p o s s i b i l i ty  of 
receiving  more  than  one  command. 
whether  to  obey  a  command,  and  w h i c h.  And  for  any 
r e a l - w o r ld  receiver  there  w i ll  always  be  the 
issue  of 
whether  it  should  drop  everything  to  carry  out  whatever 
command  it  has  Just  received  and  understood,  or 
whether  it  should  do  something  else  -  what  it  was 
already  d o i n g,  or  what  w i ll  best  satisfy  some  internal 
need  ( e . g.  hunger)  that  is  a r i s i n g,  or what  w i ll  best 
respond  to  some  interesting  new  object  ( e . g.  a  steak). 

It  must  decide 

Thus  a  system  should  be  able  to  decide  which 
from  among  a  set  of  alternative  action-sequences  it 
wants  to  carry  out  -  whether  to  gather  more  information, 
or  to  obey  this  command  or  that,  or  to  satisfy  its  own 
needs  or  goals. 

Key  Problems  Being  Handled 

This  paper  focuses  on  the  problem  of  handling 
fields  of  things,  some  of  which  are  symbols,  where 
these  things  combine  into  larger  structures  ( e . g. 
e y e s,  nose,  mouth,  chin  combine  into  face;  SARAH  PUT 
BANANA  BOX  combines  into  a  command;  B , 0,  X  combine 
into  BOX),  some  of  which  imply  that  the  system  should 
respond  w i th  an  implied  action  upon  other  things  to 
w h i ch  reference  is  made. 

We  have  discussed  one  example  of  such  a  s i t u a­

t i o n,  when  the  environment  contains  something  l i k e; 
♦CRACKER  SARAH  PUT  APPLE  PAIL  *BOX  *BANANA 
*APPLE  *PAIL  (or)  *BOX3  ROBOT  PUSH  BOX2  NEXT  BOX1 
*BOX4  *BOX1  *BOX5  *BOX2 

Such  a  system  can  handle  a  number  of  other 

problems,  for  example  an  input  l i k e: 
♦CRACKER  ♦BOX  DESCRIBE  *APPLE  THIS  SCENE  *BOX 
♦BANANA  *PAIL 
(In  which  case  it  must  recognize  the 
command  DESCRIBE  THIS  SCENE  and  as  a  result  output 
CRACKER  BOX  APPLE  BOX  BANANA  PAIL). 

Or  it  can  be  given  an  input  l i k e: 

♦ CRACKER  ♦BOX  FIND  A  BOX  ♦APPLE  *BANANA  ♦PAIL 
(in  which  case  It  must  recognize  the  command  FIND 
BOX  and  as  a  result  output  something  to  Indicate  the 
♦BOX  has  been  found.)  Or  it  can  be  asked  to  Move  an 
object,  or  to  Answer  a  query. 

A  Brief  Description  of  Decider's  Behavior1 

Overall  Flow 

DECIDER-1  inputs  a 

SCENE  that  contains  a ll 

physical  objects  and  verbal  utterances  mixed  together, 
as  the  above  argument  has  shown  is  inevitably  the  case 
for  real  world  i n t e l l i g e n c e s. 
It  applies  two  types  of 
pattern  recognition  techniques  to  begin  sensing  this 
scene: 

1)  A  set  of  primitive  perceptual  transforms  is  put 

onto  the  IDEAS  l i s t,  thus  i n i t i a l i z i ng  IDEAS  to  look  for 
whatever  the  primitives  suggest  are  the  b a s i c s. 

2)  Delimiters  (such  as  the  edges,  gradients  and 

background  spaces  that  often  delineate  objects  and 
verbal  utterances)  are  used  to  decompose  the  SCENE, 
giving  a  first  tentative  set  of  possible  objects.  Then 
DECIDER-1  searches  Its  memory  for  anything  that  these 
objects  might  imply,  a n d,  if  it  finds  any,  merges  them 
onto  the  IDEAS  l i s t. 

DECIDER-!  applies  the  set  of  IDEAS,  s e r i a l l y,  to 

the  input  SCENE.  Each  idea  that  succeeds  implies  a 
variety  of  different  o b j e c t s,  new  ideas  to  apply,  and 
a c t s.  The  single  most  highly  implied  idea  is  applied 
in  turn  to  further  characterize  the  SCENE  -  until  it  is 
a  response  act  like  Answer,  Describe,  Find,  M o v e,  or 
Name,  in  which  case  it  is  carried  out,  and  the  next 
SCENE  is  input. 
perceptual  characterizers,  verbal  rewrite  r u l e s,  and 
action  transforms  depend  upon  what  the  programmer 
(or  learning)  has  tabled  into  DECIDER-1,  just  as  par­
sers  or  table-driven  compilers  depend  upon  the  gram­
mars  given  them.) 

(Note  that  the  particular  p r i m i t i v e s, 

Perceiving  Sensed  Objects  and  Understanding  Verbal 
Utterances 

DECIDER-1  acts  much 

like  a  typical  pattern 

recognizer  v i s - a - v is  sensory  patterns  to  recognize  and 
name,  and  much  like  a  t y p i c al  parser  v i s - a - v is  verbal 
utterances.  So  it  can  handle  mixed  inputs  of  objects 
and  w o r d s. 
It  handles  both  the  recognition  character­
izers  and  the  parsing  rewrite  rules  (let's  c a ll  them  both 
"transforms")  in  the  same  way: 
It  gets  the  most  highly 
implied  transform  from  the  IDEAS  l i s t,  applies  it  to  the 
input  SCENE  (which  includes  a ll  previously-effected 
transforms),  evaluates  whether  this  transform  succeeds 
a n d, 
onto  the  IDEAS  l i s t,  and  the  objects  that  it  implies  onto 
the  SCENE. 
n - t u p l e,  of  which  parsing  rewrite  rules  are  simple 
examples  (see  Uhr, 

if  it  does,  merges  the  transforms  that  it  implies 

(A  transform  looks  for  a  configurational 

I 9 7 I1 6,  1973d2 2).) 

The  IDEAS  l i st  starts  w i th  primitive  perceptual 

characterizers.  As  these  transforms  succeed,  they 
w i ll  imply  higher-level  characterizers  a n d, 
DECIDER-1  recognizes  verbal  utterances,  verbal 
rewrite  r u l e s.  These  w i ll  continue  to  imply  perceptual 

If 

See  Uhr,  1973d  for  more  detailed  descriptions,  and 
the  actual  DECIDER-1  program. 
Caps  refer  to  major  constructs  in  the  DECIDER-1 
program. 

396 

and  verbal  transforms,  a)  for  s t i ll  higher  l e v e l s, 
b) 
to  glance  about  at  other  parts  of  the  scene  in  which 
what  has  so  far  been  recognized  suggests  other  things 
should  be  looked for,  and  c)  to  gather  more  information 
to  confirm  or  deny  the  presence  of  tentatively  implied 
objects  (including  words). 

Deciding  to  Act 

DECIDER-1'g  decision  to  act  is  deceptively 

simple.  Each  transform  on  IDEAS  has  a  type  associated 
w i th i t.  As  discussed up to now,  at first the  most highly 
implied transforms w i ll be of type  =  P  (to perceptually 
parse)  - until  the  system has  gathered enough  information 
about the  scene  to imply some response action with a  high 
enough  weight  to  be  chosen. 

DECIDER-1  chooses  the  single  most  highly  im-

plied  transform  from  IDEAS.  At  first  these  w i ll  be 
perceptual  and  verbal  transforms.  But  they  w i ll  begin 
to  imply  various  possible  a c t s,  which  w i ll  be  merged 
back  into  IDEAS-  Thus  IDEAS  serves  as  a  vehicle  for 
deciding  among  the  various  possible  a c t s,  at  the  same 
time  that  it  serves  to  decide  whether  to  continue 
looking  and  gathering  information,  or  whether  to 
respond. 

When  a  response  is  chosen,  as  the  most  highly 
weighted  transform  on  IDEAS,  DECIDER-1  branches  to 
effect  that  response  -  whether  to  Answer,  Describe, 
Find,  M o v e,  or  Name.  Thus  the  response  acts  and 
the  Information-gathering  acts  are  a ll  ordered  on  the 
single  IDEAS  l i s t,  from  which  DECIDER-1  continues 
to  choose  and  execute  the  single  most  highly  implied 
a c t,  until  a  response  act  is  chosen.  This  serves  to 
order  the  execution  of  each  type  of  act,  and  serves  to 
choose  when  to  decide  to  respond,  as  well  as  which 
response  to  make. 

Types  of  Response  Acts 

DECIDER-1  can  effect  g  variety  of  a c t s.  Since 

our  purpose  has  been  to  examine  how  a  system  can 
decide  to  a c t,  the  acts  themselves  are  kept  as  simple 
as  p o s s i b l e. 

Answer  outputs  the  piece  of  information  ( e . g .,  a 
f a c t,  or  a  document  name)  that  is  stored  in  the  Answer 
transform  that  was  chosen  from  the  IDEAS  l i s t. 

Describe  outputs  the  names  of  a ll  objects  that 
have  been  recognized  and  placed  on  the  SCENE  w i th 
a  sufficiently  high  weight  to  exceed  a  CHOOSE  para­
meter. 

Find  searches  for  and  brackets  (in  order  to  i n d i­

cate  where  it  is)  an  object  of  the  class  specified  by 
the  particular  Find  transform  chosen. 

Move  finds  an  object  of  the  first  class  specified, 

and  moves  it  from  its  original  location  in  the  SCENE, 
so  that  it  Is  next  to  an  object  of  the  second  class 
s p e c i f i e d. 

Name  gets  and  outputs  the  single  most  highly 

implied  thing  that  is  the  name  of  an  object  in  the 
SCENE. 

399 

The  Flow  of  Processes  is  Multi-Determined 

Any  transform  that  succeeds  can  imply  any  potential 

act  of  any  type.  Characterizing  transforms  can  be  i m­
plied  by  what  has  been  found  so  far  about  the  input.  A 
recognized  and  understood  command  can  imply  the  act 
that  obeys 
( e . g.  to  Name,  or  Find  i t ).  And  internal  needs  can  im-
ply  acts  ( e . g.  hunger  can  imply  Find  an  object  of  the 
class  =  food). 

it.  But  an  object  can  also  imply  an  act 

Thus,  e . g .,  when  DECIDER-1  chooses  to  Name 

this  can  be  because  a)  a  number  of  nameable  objects 
have  been  perceived,  and  each  implies  the  act  of 
naming  w i th  a  low  weight,  b)  a  command  like  "NAME 
THIS"  or  a  query  like  "WHAT  IS  THIS"  has  been 
recognized,  as  implying  the  act  of  Naming,  and/or 
c)  an  internal  need  implies  that  the  act  of  naming  may 
lead  to  its  satisfaction. 
I  should  emphasize  again, 
because  It  Is  a  subtle  point,  that  an  act  like  Naming 
is  not  built  i n,  but  must  be  decided  upon. 

Some  Examples  of  DECIDER-1  's  Behavior1 

Recognizing,  Parsing,  "Understanding"  and  Naming 

DECIDER-1  is  given  input  SCENEs  that  contain 

mixtures  of words  and  objects. 
(These  should  be  t w o -, 
or  even  three-dimensional  scenes  that  extend  over  time. 
Then  a  written  or  spoken  word  like  "APPLE"  would 
extend  in  two  dimensions  Just  as  does  the  perceived 
apple.  We  reduce  these  to  1-dimensional  strings,  to 
keep  DECIDER-1's  characterizing  processes  from 
getting  cumbersome.  But  see  Uhr,  1973b,  1973c  for 
the  relatively  straightforward  extensions  that  allow  a 
system  to  handle  two-dimensional  scenes  that  extend 
over  a  third  time  dimension.) 

When  given  an  input  l i k e: 

NAME  THIS  ((along  w i th  the  representation  of  an 
object)) 

DECIDER-1  w i ll  (If l t h as been given,  or has  learned, 

the  needed transforms)  output that object's  name,  e . g. 
"APPLE"  or  "TABLE".  To do this  it applies whatever 
perceptual  transforms  have  been  given  it  as  primitives, 
and  continues  to  apply  linguistic  rewrite  transforms 
u n t il  the  Name  transform  is  triggered.  By  that  time 
enough  perceptual  transforms  have  already  been  applied 
♦o  imply  object  names,  and  DECIDER-1  chooses  and 
outputs  the  name  of  the  most  highly  implied  thing  that 
belongs  to  the  class  of  "OBJECT"s. 

The  objects  might  be  represented  at  any  level 

desired  -  from  a  linearized  2-dimenaional  matrix  of 
light  and  dark,  e . g .: 
000111000,001000100,010000010,001000100, 
000111000,000010000,  ((9  x  6  apple)) 
to  a  set  of  characteristics: 
STEM  APPLE-COLOR  RED  ROUND 
istics)) 
to  a  template-like  representation: 
OBJECT87 

((an  encoded  name  for  "apple"  objects)) 

((apple  character­

See  Uhr,  1973d  for  a  more  detailed  development  of  a 
wider  variety  of  examples,  showing  the  transforms 
used  and  the  ways  these  process  Inputs. 

Note  that words  can  similarly  be  given  at  any  of 

these  levels. 

Edges  {e.g.  01,  or  0011)  of objects  and  spaces 

afterwords,  characteristics,  or  templates,  are  used  to 
delimit  things.  And  the  primitives  that  are  initially 
put  on  the  IDEAS  list  (e.g.  the  letters  of  the  alphabet, 
and  simple  edges,  angles,  or other  pattern  recognition 
characterizers  that  are  commonly useful)  begin  to 
recognize  parts  of the  input.  Thus  the  letters,  and 
then words  like  "NAME" and  "THIS",  and  the  edges  of 
objects,  and  then  the  objects  themselves,  w i ll  all  be 
implied. 

But remember that  an  act  like  Finding  can be  im­

plied  not  only  by  verbal  utterances,  but  also  by  objects 
in  the  scene,  and  by  Internal  needs.  Thus,  e . g .,  the 
recognition of a  valued object,  HJce  a  banana,  or the 
partial  recognition  of  several  food  objects,  like  apples, 
bananas,  and  crackers,  can  serve  to  imply,  and, 
possibly,  lead  to  the  choice  of,  the  act  of finding 
(that  i s,  getting,  or  grasping)  the  banana,  or  the  food 
object.  Similarly,  an  internal  need-state  of  hunger 
can  imply  the  getting  of a  food  object  that  will  satisfy 
that  hunger. 

Moving  and  Manipulating  Objects 

These  In  turn  imply  still  other  transforms  that  build 
compounds  like  "NAME  THIS"  or larger  objects.  These 
in  turn  Imply  response  acts.  This  means  that  char­
acterizers  will  imply an  apple 
(and  probably  some 
other  objects,  e.g.  a  pear  and  a  face),  and  the  implied 
objects  may  themselves 
the  same  time  that  the  verbal  utterance  NAME  THIS 
also  implies  the  act  of  naming,  with  a  very  high  weight, 
so  that  it  is  very  likely  to  be  chosen. 

imply  the  act  of  naming  -  at 

An  input like: 

MOVE BOX1  TO  BOX2  ({a  scene of  objects)) 
will  lead  to  the  recognition  of the  particular  objects  to 
be  manipulated  and  the  overall  action  desired.  When 
Move  Is  chosen  as  response  act,  because  it  has  be­
come  the  most  highly implied  transform  on  IDEAS, 
DECIDER-1  will  look  for  the  specific  objects  or  class 
members  involved  in  the  action,  and  actually change 
the  SCENE,  as  specified. 

Describing 

An  input  of  the  sort; 

DESCRIBE  THIS  {(representation  of one  or  more  objects)) 
will  get  DECIDER-1  to  output a  simple  description,  of 
the  names  of all  things  belonging  to  the  "OBJECT"  class 
the  objects  implied  above  a  CHOOSE  level,  e.g. 
"APPLE  TABLE  CHAIR  BANANA".  The  recognition  of 
objects  is  much  as  for  Naming,  but  additional  linguistic 
transforms  w i ll recognize  the  word  "DESCRIBE"  and  the 
import  of  the  phrase  "DESCRIBE THIS"  -  as  implying  the 
Describing  act. 

Any  number of  variants  can  be  handled,  e . g .: 

WHAT IS  HERE  {(objects)) 
SAY WHAT YOU SEE  ((objects)) 
so long  as  the  needed  rewrite  rules  are  In  DECIDER-1's 
memory. 

Finding  Objects 

If the  verbal  utterances  within  the  scene  {and/or 
internal  needs)  are  recognized  as  Implying  the  act  of 
Finding,  DECIDER-1  w i ll branch  to  the  Find routine. 
This  searches  for an  implied  object  that  has  been 
put  into  the  transformed  SCENE  that  is  of  the  class 
designated  by  the  particular  Find  transform  being 
executed. 
by  the  placement  of brackets,  as  though  pincers, 
around  i t. 

If  the  object  is  found,  success  is  indicated 

Acts  are  Multi-Determined,,  by Words,  Things  and 
Internal  Needs 

The  verbal  utterance  can be  a  command,  e . g .: 

FIND  FOOD  ((a  scene  of objects)) 
WHERE  IS  FOOD  ((a  scene  of objects)) 
or a  request: 
IS ANY FOOD AROUND  ((a  scene  of objects)) 
or  any  other  kind  of utterance  that,  when  parsed  and 
understood,  implies  that a  food  object be  found. 

((or)) 

DECIDER-1  assumes  that  the  action will  not be 

triggered  until  all  the  needed  objects  have  been 
recognized.  So  the  perceptual  characterizers  must  be 
implied  with  high weights,  so they are  merged  onto 
IDEAS  with  higher weights  than  are  the  response 
actions.  But  it  would  be  quite  easy  to  extend 
DECIDER-1  so that it continued to try to  perceive  objects 
not  yet  recognized,  but  needed  to  effect  an  act  that  it 
had  decided  to  do 

{see  Uhr,  1973c21). 

Answering  Queries 

DECIDER-1  can  output  internally  stored  informa­
tion  in  response  to an  input.  Thus  we  see  it  a)  talk 
about  parts  of  the  scene  (Naming,  Describing),  b) 
manipulating  parts  of  the  scene  (Finding,  Moving), 
and  c) Answering,  by  accessing  information  stored  in 
its  memory  in  response  to  questions,  either  direct  or 
implied,  in  the  scene.  Thus,  e . g .; 
WHO  IS  THE  PRESIDENT 
might  lead  to  the  response  "NIXON". 

Now  the  scene  is  treated  as  a  purely verbal 

utterance,  simply  because  only  verbal  rewrite  trans­
forms  succeed  on  i t.  But  note  how  similar  this  Is  to 
the  situation  in  which  a  request  like: 
WHAT  IS  THIS  {(scene  of objects)) 
is  intermingled  with  objects  in  a  scene,  in which  case 
the  act  refers  to  information  that  has  been  extracted 
and recognized  from  that  scene,  rather  than  to  informa­
tion  that  has  been  stored  In  memory. 

Further  Examples  and  Future  Extensions 

DECIDER-I  is  described  more  fully,  with  a  number 
of examples  worked  out  in  detail,  in  Uhr,  1973d22,  The 
actual  program  is  presented,  explained,  and  dis­
cussed. 
gramming  language  (a  variant  of  SNOBOL)  designed  to 
be  easy to understand  (Uhr,  1973a19). 

It is  coded  to  EASEy,  an  English-like  pro­

400 

18.  Uhr,  L.  Layered  "recognition  cone"  networks  that 
preprocess,  classify  and  describe.  JEEE.  Trans . 
Comput.  ,  1972,  2]_,  758-768. 

19.  Uhr,  L. 

EASEy-2 

-an  English-like  Programming 

Language.  Computer  Sciences  Dept.  Tech. 
Report  178,  Univ.  of  Wisconsin,  Madison,  1973.  a 
20.  Uhr,  L.  Pattern  Recognition,  Learning  and  Thought. 

Englewood-CIiffs:  Prentice-Hall,  1973.  b 

2 1.  Uhr,  L .,  The  Description  of  Scenes  Over  Time  and 

Space,  Proceedings  First  National  Computer 
Conference,  New  York,  June,  1973.  c 

22.  u h r,  L.  Recognizing,  "understanding,"  deciding 

whether  to  obey,  and  executing  commands. 
Computer  Sciences  Dept.  Tech.  Report  173,  U n i v. 
of  W i s c o n s i n,  1973.  d 

23.  Winograd,  T.  Procedures  as  a  Representation  for 

Data  In  a  Computer  Program  for  Understanding 
Natural  Language.  Unpubl.  P h . D.  D i s s .,  MIT, 
1971. 

24.  Zobrist,  A,  L.  The  organization  of  extracted 

features  for  pattern  recognition.  Pattern 
Recognition,  1971,  3,  23-30. 

DECIDER-1  is  presently  being  extended  to  handle 

In  this  extension, 

scenes  that  continue  over  time. 
perceiving,  responding,  and  problem-solving  a ll  go  on 
In  p a r a l l e l.  The  system  decides  when  to  respond.  But 
to  respond  it  may  need  to  perceive  further  objects 
its  response.  Or  it  may  need  to  solve 
appropriate  to 
problems,  to  deduce  a  sequence  of  actions  appropriate 
to  the  chosen  response.  Or  it  may  output  a  request 
for  needed  objects,  or  for  h e l p.  Thus  perceiving, 
problem-solving,  and  acting  are  a ll  intermingled.  Each 
may  c a ll  upon,  and  depend  upon  the  other. 

References 

2. 

1.  Andrews,  D.  R.,  Atrubin,  A.  J .,  and  H u,  K.  The 
IBM  1975  optical  page  reader:  Part  I I I:  Recogni­
tion  and  logic  development,  IBM  J.  Res,  and 
D e v e l .,  1968,  12,  364-372. 
Brice,  C.  R.  and  Fennema,  C.  L.  Scene  analysis 
using  regions .  Artificial  Intelligence,  1970,2./ 
205-226. 
Feldman,  J.  A.  et  a l .,  The  Stanford  hand-eye 
project.  Proc.  1st  Joint  Int.  Conf.  on  Artificial 
Intelligence,  Washington,  D.  C,  1969,  521-526. 
Fikes,  R.  E.  and  N i l s s o n,  N.  J.  STRIPS:  A  new 
approach  to  the  application  of  theorem  proving  to 
problem  s o l v i n g.  Proc.  2d  Joint  I n t.  Conf.  on 
A r t i f i c i al  I n t e l ! .,  London,  1971,  608-620. 

3. 

4. 

5.  Gardner,  Beatrice  T.  and  Gardner,  R.  A.  Two-way 

communication  with  an  Infant  chimpanzee. 
Behavior  of  Nonhuman  Primates,  V o l.  4  (A.  Schrier 
and  F.  Stollnitz,  Eds.)  New  York:  Academic  Press, 
1971,  117-184. 

I n; 

6.  Gardner,  R.  A.  and  Gardner,  Beatrice  T.  Teaching 

7. 

sign  language  to  a  chimpanzee.  Science,  1969, 
165,  664-672. 
Jordan,  Sara  R.  Learning  to  Use  Contextual 
Patterns  In  Language  Processing.  Unpubl.  P h . D. 
D i s s .,  University  of W i s c o n s i n,  Madison,  1971. 
8.  Munson,  J.  H.  Experiments  in  the  recognition  of 
hand-printed  text.  AFIPS  Proc.  ,  1968,  33,  1125-
1138. 

9.  N i l s s o n,  N.  J.  A  mobile automaton:  an  application 

of  a r t i f i c i al  intelligence  techniques.  Proc.  1st 
Tolnt  I n t.  Conf.  on  Artificial  Intelligence, 
Washington,  D.  C,  1969,  509-520. 

10.  Premack,  D.  The  education  of  Sarah.  Psychology 

Today,  1970,  ±,  September,  54-58. 

11.  Premack,  D.  Language  in  Chimpanzee?  Science, 

1 9 7 1,  172,<  808-822, 

12.  Raphael,  B.  Programming  a  robot.  Proc.  IFIP 

Congress  68.  Edinburgh,  1968,  H135-H14D. 
13.  Sauvain,  R.  and  Uhr,  L.  A  teachable  pattern 
describing  and  recognizing  program.  Pattern 
Recognition,  1969,  I,  219-232. 

14.  Simmons,  R.  F.  Answering  English  questions  by 

computer:  a  survey,  Comm.  Asspc.  Comput. 
M a c h .,  1965,  8_,  53-70. 

15.  Simmons,  R.  F.  Natural  language  question-

answering  systems:  1969,  Comm.  Assoc.  Comput. 
M a c h .,  1970,  1 3,  15-30. 

16.  Uhr,  L.  Flexible  linguistic  pattern  recognition. 

Pattern  Recognition,  1971,  3,  363-384. 

17.  Uhr,  L.  and  Vossler,  C.  A  pattern  recognition 

program  that  generates,  evaluates  and  adjusts  its 
own  operators.  AFIPS  WJCC  Conf.  Proc.,  1961, 
19,  555-569. 

401 

