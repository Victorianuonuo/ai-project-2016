Thin Junction Tree Filters for Simultaneous Localization and Mapping 

Mark A. Paskin 

Computer Science Division 

University of California, Berkeley 

Berkeley, CA 94720 

paskin@cs.berkeley.edu 

Abstract 

Simultaneous Localization and Mapping ( S L A M) is 
a  fundamental  problem  in  mobile  robotics:  while 
a  robot  navigates  in  an  unknown  environment,  it 
must  incrementally  build  a  map  of  its  surround(cid:173)
ings  and,  at  the  same  time,  localize  itself within 
that  map.  One  popular  solution  is  to  treat  SLAM 
as an estimation problem and apply the Kalman fil(cid:173)
ter;  this  approach  is  elegant,  but  it does  not  scale 
well:  the size of the belief state and the time com(cid:173)
plexity  of the  filter  update both  grow quadratically 
in  the  number of landmarks  in  the  map.  This pa(cid:173)
per presents  a  filtering  technique  that maintains  a 
tractable approximation of the belief state as a thin 
junction  tree.  The junction tree  grows under filter 
updates  and  is  periodically  "thinned"  via  efficient 
maximum  likelihood  projections  so  inference  re(cid:173)
mains tractable.  When applied to the  SLAM prob(cid:173)
lem,  these  thin junction  tree  filters  have  a  linear-
space belief state and a linear-time  filtering  opera(cid:173)
tion.  Further approximation yields a  filtering  oper(cid:173)
ation that is often constant-time.  Experiments on a 
suite of SLAM  problems validate the approach. 

Introduction 

1 
Simultaneous Localization and Mapping (SLAM)—where a 
robot  navigating  in  an  unknown  environment  must  incre(cid:173)
mentally  build  a  map  of its  surroundings  and  localize  itself 
within that  map—has  attracted  significant  attention because 
it is required by many applications in mobile robotics [Thrun, 
2002].  Typically the environment is idealized so that it con(cid:173)
sists  of an  unknown  number  of stationary  "landmarks";  for 
example,  in a given  SLAM  application these  landmarks may 
be  low-level  visual  features  or  structural  features  such  as 
walls  and  corners,  S L AM  can  then be  viewed as  the prob(cid:173)
lem of incrementally estimating the locations of the robot and 
landmarks from noisy and incomplete observations. 

is represented by a random variable 

One popular approach treats  SLAM  as a  filtering  problem 
[Smith et al., 1990].  The hidden state of the system at time 
which  includes  Xt 
the state of the robot at time  and 
, the locations 
of the 
Thus, the size of 
the state vector is linear in the number of observed landmarks 

landmarks observed up to time 

and grows over time.  The Kalman  filter  is used to compute 
the filtered belief state 
observations to  t i m e w h i ch 
in this case takes the form of a multivariate Gaussian distribu(cid:173)
We regard the  m e a n as  the estimate of the 
tion 
map and the covariance matrix 
a measure of confidence. 

The Kalman  filter  solution is elegant, but it does not scale 
well to large  SLAM  problems.  Because 
explicitly  repre(cid:173)
sents  correlations  between  all  pairs  of variables,  the  size  of 
the  belief state  grows as 
and  because  each  of these 
correlations  must  be  updated  whenever  a  landmark  is  re-
obscrved,  the  time  complexity  of its  filter  operation  is  also 
This  quadratic  complexity  renders  the  Kalman  fil(cid:173)
ter inapplicable to large SLAM problems and gives rise to the 
need for principled, efficient approximations. 

Unfortunately, the simplest approach—discarding correla(cid:173)
tions  so  each  variable  is estimated  independently—presents 
problems.  Ignoring correlations between the robot state and 
the landmarks' states leads to overconfidence and divergence 
because  correlated  observations  are  treated  as  if they  con(cid:173)
veyed  independent  information  [Hebert  et  al.,  1996].  Fur(cid:173)
thermore,  correlations  between  pairs  of landmark  states  are 
required for quick convergence when the robot closes a loop, 
i.e.,  it  reobserves  known  landmarks  after  an  extended  pe(cid:173)
riod  of mapping  unknown  territory  (see  Figure  1).  When 
the  robot  closes  a  loop,  it reobserves  landmarks  whose po(cid:173)
sitions are known with relative certainty; this helps the robot 
localize.  The  robot-landmark  correlations  translate  this  im(cid:173)
proved localization estimate into improved position estimates 
for recently-observed  landmarks.  The  inter-landmark  corre(cid:173)
lations  translate  these  improved  position  estimates  into  im(cid:173)
provements for the remaining landmarks on the tour.1  Thus, 
the  correlations  give  the  Kalman  filter  a  valuable  property 
normally  associated  with  smoothing  algorithms:  it  can  use 
current observations to improve estimates "from the past". 

Because  quadratically  many  correlations  are  necessary  to 
close loops, we view the challenge of scalable SLAM filtering 
as  that  of estimating and reasoning  with  quadratically many 
correlations  without  quadratic  time  or space  complexity. 
In 
this paper, we present a novel and general approximate filter(cid:173)
ing  method  satisfying  this  criterion.  Our point  of departure 

1 Robot-landmark correlations, which decay over time due to mo(cid:173)
tion noise, cannot translate an improved localization estimate into 
improvements for landmarks observed in the distant past;  in con(cid:173)
trast, inter-landmark correlations do not decay over time. 

ROBOTICS 

1157 

tree to grow, making inference more expensive;  in Section 4 
we present a novel  "thinning"  operation  over junction  trees 
called variable contraction.  We prove that each variable con(cid:173)
traction  is a maximum  likelihood projection  that  removes  a 
set of edges from the corresponding graphical model. The ap(cid:173)
proximation error introduced by a variable contraction can be 
computed efficiently, which allows us to choose which edges 
to remove at each time step so as to minimize the error. 

In Section 5 we apply these techniques to the SLAM  prob(cid:173)

lem and obtain a thin junction tree filter (TJTF) with a O 
space belief state  representation  and  a O 
time  filter  op(cid:173)
eration.  By  delaying  the  incorporation  of  recent  evidence 
into the majority of the map, we can improve the  filter's  time 
complexity;  we  present  a  method  of evaluating  the  signifi(cid:173)
cance  evidence  has  on  different  portions  of the  map,  which 
can  be  used  to  adaptively  interpolate  between  constant  and 
linear-time  filter  operations.  Empirically,  we  find  that these 
adaptive  filters  choose  constant-time updates when mapping 
new  territory,  and  when  closing  a  loop,  they  use  time  lin(cid:173)
ear in  the  length  of the  loop.  This  is  perhaps  the  best  time 
complexity one would hope  for in the  SLAM  problem,  since 
linearly-many estimates cannot be improved in constant time. 
Section 6 presents the results of simulation experiments that 
compare TJTF to other SLAM  filters  and Section 7 concludes. 
A companion technical  report contains  proofs of all  proposi(cid:173)
tions as well as additional background, analysis, and experi(cid:173)
ments [Paskin, 2002]. 

1.1  Related  w o rk 
Significant  interest in the  SLAM  complexity problem  has  led 
to a number of approaches [Thrun, 2002]. For example, there 
are  several  submap  approaches  that  decompose  the  prob(cid:173)
lem  into a set  of small  mapping problems yielding  a block-
diagonal  landmark covariance matrix.  These techniques can 
achieve  constant  time  complexity,  but  converge  slowly  be(cid:173)
cause information cannot pass between the submaps. 

Recently,  the  FastSLAM  algorithm  [Montemcrlo  et  al., 
2002]—a Rao-Blackwellized particle filter—has attracted at(cid:173)
tention because of its logarithmic time complexity.  However, 
our experiments show FastSLAM  is susceptible to divergence 
in large, noisy SLAM problems. We believe this is because the 
number  of particles  required  for  a  satisfactory  solution  can 
grow exponentially over time; see [Paskin, 2002] for details. 
Sparse  extended  information  filters  (SEIF)  [Thrun  et  al, 
2002]  can  be  viewed  in  terms  of the  graphical  model  rep(cid:173)
resentation described above; at each time-step, edges are re(cid:173)
moved so that a constant-time  filter  operation can be guaran(cid:173)
teed.  To  avoid the  additional  complexity of inference,  SEIF 
employs approximate inference over this approximate model. 
Thus, the SEIF paper provided the valuable insight that sparse 
graphical models can constitute an efficient solution to SLAM. 
Implementing this insight while avoiding additional approxi(cid:173)
mation was one of the primary motivations of this work. 

Each of these approaches described above uses a sublinear-
time  filter  update, and therefore, none can improve all of the 
landmark  estimates  in  a  single  update  (like  the  Kalman  fil(cid:173)
ter).  TJTF has the best of both worlds:  its update step takes 
constant time unless the observation  is significant enough to 
warrant a linear-time update. 

Figure  1:  The  robot  is  travelling  counter-clockwise  on  a 
square path.  Dots represent landmarks;  the  true position  of 
the  robot  is  shown  by  a  square;  the  filter  belief state  is  vi(cid:173)
sualized  using  the  95%  confidence  ellipses  of the  variable 
marginals (bold for the robot).  Left:  accumulated noise and 
error has led to uncertain and  drifted estimates for the robot 
and  landmark positions.  Right:  after closing the  loop, all of 
the position estimates improve and their confidences increase. 

(in Section 2) is to view the filtered belief state of the Kalman 
filter as a Gaussian graphical model [Cowell et  al,  1999] that 
evolves  over time;  this  allows  us  to  express  correlations  in 
terms  of direct dependencies  (edges)  and  indirect dependen(cid:173)
cies (paths).  Analyzing the evolution of this graphical model 
reveals that  filter  updates add  edges  to the  graphical model, 
making inference more expensive.  This motivates an approx(cid:173)
imation scheme in which weak or redundant edges are period(cid:173)
ically removed to improve the complexity of inference.  Note 
that edge removal is very different than simply discarding cor(cid:173)
relations; because other edges are left intact, paths—and thus 
correlations—persist between each pair of variables. 

Graphical  models  give  us  valuable  insight  into how good 
approximate  filters  can be designed,  but  using them  to  rep(cid:173)
resent  the  belief  state  presents  problems.  First,  variable 
marginals  like the robot's current position  would not be im(cid:173)
mediately  available  as  they  are  in  the  Kalman  filter  repre(cid:173)
sentation;  we would  require inference to obtain them.  Sec(cid:173)
ond,  while  it  is  possible  to  remove  edges  from  a  Gaussian 
graphical model using the Iterative Proportional Fitting algo(cid:173)
rithm [Speed and Kiiveri, 1986], its application in this context 
would be prohibitively slow.  Finally, choosing edges whose 
removal leaves a distribution for which inference is tractable 
is itself a complicated process [Kjaerulff,  1993]. 

Our  solution  to  these  problems  is  to  use  a  different  rep(cid:173)
resentation  of the  belief state.  Exact  inference  in  graphical 
models is often implemented by message passing on a junc(cid:173)
tion tree [Cowell et ah,  1999].  Rather than view the junction 
tree algorithm as an "inference engine", we use the junction 
tree itself as our representation of the belief state.  This repre(cid:173)
sentation has many advantages:  the belief state has a "built-
in"  inference  algorithm  (namely,  message passing);  it gives 
immediate access to the marginal  distribution over any vari(cid:173)
able; and as we demonstrate, it gives us efficient methods of 
selecting edges to prune and pruning them. 

To implement such a junction tree filter, we develop meth(cid:173)
ods for updating the junction tree to reflect filtering updates in 
Section 3.  These updates can cause the width of the junction 

1158 

ROBOTICS 

change in our treatment.  When a landmark is first observed, 
its  state  variable is  added  to the  belief state  with  a  uninfor-
mative (infinite variance, zero covariance) prior; the measure(cid:173)
ment update yields an informed posterior estimate of its state. 

2.2  Gaussian graphical  models 
Under the assumptions outlined above, the filtered belief state 
is a multivariate Gaussian distribution.  The 
Kalman  filter  represents  this  distribution  using  the  moment 
parameters—the  mean  vector 
If 

then its probability distribution is 

and covariance  matrix 

(4) 

where  d  is  the  length  of u.  In  contrast,  Gaussian  graphical 
models  are  usually  based  upon  the  canonical parameters— 
the information vector r/ and matrix 

(5) 

Let 

where 
is the (log) nor(cid:173)
malization constant.  The canonical  and moment parameters 
are related by 
An advantage of the 
canonical  parameterization  is  that  multiplication/division  of 
Gaussians reduces to addition/subtraction of the parameters. 
be  a  set  of random  variables  indexed 
by elements of the  finite  set  V.  We will call  a subset of V  a 
family.  For  a  family 
be the 
associated set of random  variables.  A potential over a family 
Let  F  be  a set of 
be  a  set  of potential 

families  and  let 
functions over these families.  (F, \P) defines a distribution 

is a non-negative function  of 

(6) 

when the normalizer 

The  Markov  graph  associated  with 

is  finite. 
has  vertex  set 
V  and  a  clique  of edges  over each 
there is an 
edge between 
are bound by a potential. 
The primary value of the Markov graph representation comes 
from  the Hammersley-Clifford  theorem,  which  states that  s 
separates 
iff 
In  other  words,  graph 
separation in the Markov graph encodes the conditional inde(cid:173)
pendence properties  of  Because conditional  independence 
properties  often  translate  into  efficient  inference  algorithms 
(e.g., junction tree), the Markov graph gives good intuitions 
into the design of efficient approximations. 

in  the  Markov  graph 

from 

(provided 

We  can  represent  the  Gaussian  (5)  by  a  Markov  graph, 

since if we partition the vector 

Outside  of the  SLAM  literature,  there  are  two  works  that 
are especially relevant.  Kjairulff [1993]  investigated edge re(cid:173)
moval  as  a  means  of reducing  the  complexity  of  inference 
in graphical  models.  Our approach  is somewhat simpler,  as 
it operates  directly  on  the junction  tree  without  referring  to 
the  underlying  graphical  model.  Kjaerulff's  analysis  of the 
approximation error inspired ours,  and  several  of his  results 
apply directly to our case. 

Thin junction tree filtering is an assumed density filtering 
(ADF) algorithm because it periodically "projects" the filter's 
belief state  to some  tractable  family of distributions—in  this 
case,  the  family  of  Gaussian  distributions  characterized  by 
thin junction trees.  This makes other work on ADF relevant, 
especially that of Boyen and Koller  [1998],  in  which the be(cid:173)
lief state of a dynamic Bayesian network is periodically pro(cid:173)
jected to a product-of-marginals approximation.  In fact, the 
connection to this work is stronger:  Boyen and Koller [1999] 
extended their earlier analysis to filters where the belief state 
is represented by a junction tree whose structure evolves over 
time; however, no algorithms were presented.  To our knowl(cid:173)
edge, TJTF is the first algorithm to which this analysis applies. 
Here we apply TJTF to a Gaussian graphical model, but noth(cid:173)
ing prevents its application to the discrete variable networks 
considered by Boyen and Koller. 

2  A graphical model perspective on  S L AM 
We begin by presenting the SLAM model and then formulat(cid:173)
ing SLAM  filtering  in terms of graphical models. 

2.1  The  SLAM model 
We assume a general  SLAM  model  where in each  time step 
the  robot  moves,  obtains  an  odometry  measurement  of  its 
motion,  and  makes  several  observations  of  landmarks.  As 
in the Kalman filter context,  we assume that the motion and 
measurement  models  are  known  and  that  they  are  linear-
Gaussian.2 The robot motion at time / is governed by 

(1) 

and the odometry measurement yt  at time t is governed by 

(2) 
yt  is typically a noisy measurement of the robot's velocities. 
Landmark measurements are typically assumed  to depend 
only upon the state of the robot and the state of the observed 
landmark;  for  example  the  observation  may  consist  of  the 
range  and  bearing to  the  landmark  in  the robot's coordinate 
frame.  If the zth landmark measurement at time 
issued from 
landmark 

it is governed by 

(3) 
For simplicity,  we assume the correspondence between each 
measurement  and  the  landmark  from  which  it  issued  is 
known.  This  question  of data  association,  while  critically 
important  in  SLAM,  is  largely  orthogonal  to  the  issues  we 
address here;  in particular,  the standard  technique of choos(cid:173)
ing the maximum likelihood data association applies without 

2When these models are not linear-Gaussian, they can be approx(cid:173)

imated as such as in the Extended or Unscented Kalman Filter. 

ROBOTICS 

1159 

and 
is the normalization constant. Thus, all the po(cid:173)
tentials of a Gaussian graphical model are either unary (node 
potentials) or binary  (edge potentials).  We also have the im(cid:173)
portant  interpretation  that  if 
is 
unity  (and  therefore superfluous),  meaning there  is no edge 
between i and j  in the corresponding Markov graph. 

then 

2.3  Filtering in  Gaussian  graphical  models 
Filtering can  be viewed  as  a three-step procedure:  estima(cid:173)
tion,  in  which  we  incorporate  the  current  time  step's  mea(cid:173)
surements; prediction,  in  which  we  augment the  model  with 
the state variables of the next time step; and roll-up, in which 
we  marginalize  out  the  state  variables  from  the  past  time 
step.  When the measurement and motion models are linear-
Gaussian, the prediction and estimation steps reduce to mul(cid:173)
tiplying small Gaussian potentials into the model;  these up(cid:173)
dates are summarized by 
Proposition  1 .3  Ignoring irrelevant normalization  constants, 
the motion update of equation (1) can be implemented by mul(cid:173)
tiplying  the potential 

into the model; the odometry measurement update of equation 
(2) can be implemented by multiplying in  the potential 

and the landmark measurement update of equation (3) can be 
implemented by  multiplying  in  the potential 

The  final  step  of  filtering  is  roll-up,  or  marginalizing  out 
the  past  state.  The  standard  rule  for marginalization  in  the 
canonical parameterization is given by [Cowell et al.,  1999] 
Fact  1. 

If a  =  V\i  and 

(10) 

( ID 
(12) 

The time complexity of computing (11) and (12) is quadratic 
in the dimension  of 

and cubic in the dimension of 

The additive updates above can also be viewed as multiply(cid:173)
into 
ing in a new potential 
the model.  The Markov blanket 
is the set of z's 
neighbors in the Markov graph. Because missing edges in the 
Markov graph correspond to zeros in A, we can infer that this 
is  really  a potential  over 
and  therefore  that  marginal(cid:173)
izing  Ui  out  of the  model  places  a  clique  of edges  over  the 
Markov  blanket  of i. 

3Model parameter indices are omitted for notational simplicity. 

Figure 2: Example evolution of a SLAM graphical model,  (a) 
In  the  initial  belief state,  the  robot's  state 
and the land(cid:173)
are  marginally  independent,  (b) 
marks'  states 
and 
Observing each landmark 
induces a correlation between 
and 
adds the new robot state 
current  robot  state 

resulting  in  a  new  edge,  (c)  The  prediction  update 
to the  model  and joins  it to the 
.  (d)  The  roll-up  phase  marginalizes 
's 

out of the model,  adding  a clique edges over all  of 

neighbors. 

Filtering  the  S L AM  graphical  model 

2.4 
Using these results  we can characterize how the structure of 
the  SLAM  belief state evolves over time  (see Figure 2).  For 
each observed landmark  we multiply a measurement poten(cid:173)
into the graphical model; this adds an edge be(cid:173)
tial 
tween  xt  and 
Thus, after the estimation phase, the robot's 
state  will  be connected  to  the  states  of all  landmarks  it  has 
observed.  The prediction phase then connects 
Finally,  the  roll-up  phase  marginalizes  out 
this places a 
potential over the Markov blanket  of 
which now includes 
all  observed  landmarks  and 
Now the  SLAM  graphical 
model  takes  the  form  of a  complete  graph—i.e.,  the  belief 
state has no conditional  independencies.  By  induction,  this 
will be true after every time step. 

and 

An  intuition  for  why  the  graphical  model  becomes  dense 
over time is valuable.  When the robot measures a landmark, 
the landmark's state becomes directly correlated  with  that of 
the robot, and thus indirectly correlated with all covariates of 
the robot state, e.g., other landmark states.  When the robot's 
state is eliminated from the model during roll-up, these indi(cid:173)
rect correlations must be expressed directly via new edges. 

Importantly,  these  indirect  correlations  are  often  much 
weaker  than  the  direct ones.  Thus,  even  though  the  SLAM 
belief state has no true conditional independencies, there are 
many  "approximate"  conditional  independencies;  e.g.,  the 
landmarks  observed  at  the  beginning  and  end  of a  tour  are 
almost independent given those observed  in  the  middle.  By 
removing "weak" edges from the graphical model we can en(cid:173)
force these approximate conditional  independencies  so  they 
can be used to speed inference. 

Junction tree  filtering 

3 
As discussed in the introduction, the graphical  model repre(cid:173)
sentation is valuable for motivating our approximate filter, but 
it is not an appropriate representation for its implementation. 
Instead, we represent the belief state of the filter using a junc(cid:173)
tion tree.  We begin by briefly summarizing the relevant con(cid:173)
cepts; see [Cowell et  al,  1999]  for details. 

1160 

ROBOTICS 

Junction  trees 

3.1 
Let p be a distribution of the form (6) with families F and po(cid:173)
(C, E) be an undirected 
tentials 
graph where each vertex (or cluster) 
C is a subset of V\ T 
is ^junction tree for p if the following three properties hold: 

1.  Singly connected property: T is a tree. 
2.  Potential  property:  For  every  family 

some cluster  such that 

F  there  is 

3.  Running intersection  property: 

is present in two 
of T, it is also present in all clusters on 

clusters  and 
the (unique) path between 

and 

With each edge 

E  we  associate  a separator  s  = 

let S be the set of T\s separators. 

Given  a junction  tree  7\  we  can  perform  inference  in  the 
model  by passing messages between the clusters of T.  We 
begin by  associating with T a set of potential  functions 

one  for  each  cluster  and 

separator.  The charge on T is defined to be 

We initialize 
to unity, multiplying each potential 

by setting all cluster and separator potentials 
for some 
C (which is possible by the potential property), and mul(cid:173)

into 

tiplying 

into an arbitrary 

then 

Let c and  be adjacent clusters with separator 

d. 
Passing a message from c to d updates the separator potential 

and the cluster potential 

as follows: 

(14) 

(15) 

Importantly, these updates leave the charge (13) invariant, so 
Thus,  we  can  view them  as reparameterizing the 
distribution p.  When messages are passed along every edge 
in both directions (in an appropriate schedule), the cluster and 
separator potentials are updated so that they are marginals of 
over their respective variables.  A junction tree in this state 
is called consistent and it can be used to obtain marginals over 
any set of variables that reside together in some cluster. 

When  T  has  no  nonmaximal  clusters, 

so the 
number of messages required for inference is bounded by 2 • 
In the case of a Gaussian graphical model, the cluster and 
separator potentials are Gaussians; if they are represented by 
their canonical  parameters, the time complexity of passing a 
message  is  dominated  by  the  cost  of the  marginalization  in 
(14)  which  is  implemented  via  (11)  and  (12);  thus,  it  is  at 
worst  cubic  in  the  size  of the  cluster. 
In  sum,  inference  is 
and cubic in the width of T, traditionally defined 
linear in 
as the size of the largest cluster minus one. 

Incremental junction  tree  maintenance 

3.2 
We adopt consistent junction trees as the belief state represen(cid:173)
tation of our  filter;  i.e., the belief state will be represented by 
the charge (13) of a consistent junction tree. Recall from Sec(cid:173)
tion 2.3 that the prediction and estimation phases of the filter 

update can  be  implemented  by multiplying in  small,  simple 
potentials  to  the  probability  distribution,  and  that  the  roll-
up  phase  is  implemented  by  marginalizing  variables  out  of 
the model.  In this section we describe how to incrementally 
maintain a consistent junction tree under these updates. 

In what follows we will make use of three nonstandard op(cid:173)

erations to restructure a consistent junction tree. 

•  Cloning:  To clone a cluster  we create a copy d, attach 

d to c with separator 

and set 

•  Merging:  Let c and d be neighboring clusters with sep(cid:173)
d; 
(3) swing all edges incident 

arator s.  To merge d into c, we:  (1) update 
(2) update 
to d over to c; and (4) remove d from C and s from 5. 
•  Pushing:  Let c and d be neighboring clusters with sep(cid:173)
To push  i from  c 
arator  s  such  that 
to  we  update 
and 
to  d  to  update 
By 
pass a message  from 
from c to  a nonadjacent  clus(cid:173)
extension we can push 
ter  by successive pushes along the unique path from r 
to 
(Any nonmaximal  clusters created by pushing are 
subsequently merged into their subsuming neighbors.) 

and 

and 

but 

It  is  easy  to  check  that  all  of these  operations  preserve  the 
three structural constraints as well as the charge and consis(cid:173)
tency of a junction tree. 
Multiplying in  potentials 
Assume  our belief state  is  represented  by  a consistent junc(cid:173)
tion  tree  T.  In  order to  update  the  charge  of T  to reflect  the 
multiplication  of a  potential 
we  must find a 
into 
cluster 
To restore consistency, 
we  could  pass  messages  throughout  7\  but this  is twice  the 
work  needed:  a  simple consequence of the message-passing 
updates (14) and (15) is that we need only distribute evidence 
from 
i.e, we must pass messages along edges in a preorder 
traversal from c. 

and  m u l t i p l y i n to  

If there is no cluster that covers the family a of the new po(cid:173)
tential, then we must first modify the junction tree T to create 
one.  Draper [1995] presents several techniques to do this; in 
the Gaussian case the problem is somewhat simpler, since the 
potentials bind at most two variables.  When multiplying in an 
requires us to create a cluster cover(cid:173)
edge potential 
ing 
such 
d and push / from c to d. We then multiply 
that 

,  we  find  the  closest  pair  of clusters  and 
and 
into 

and distribute evidence from d. 

It  is  worth  noting  that  in  several  cases,  conditional  inde(cid:173)
pendencies obviate the evidence distribution step.  This is  a 
significant optimization,  since message passing  is by  far the 
most  expensive  operation.  This  occurs,  for example,  when 
performing  the  prediction  step  (because 
is  an  unob(cid:173)
served directed leaf of the graphical model and therefore does 
not  impact  the  distributions  of the  other  nodes),  when  ob(cid:173)
serving a landmark for the first time (due to its uninformative 
prior), and in certain types of odometry updates. 
Marginalizing  out variables 
Assume again that we have a consistent junction tree T rep(cid:173)
resenting 
out of p places a potential over the Markov blanket of 
. Be(cid:173)
cause the junction tree must have a cluster that covers this new 

As  described  in  Section  2.3,  marginalizing 

ROBOTICS 

1161 

The following proposition relates the original distribution and 
the distribution resulting from a variable contraction: 
Proposition 4.  Let 
variable  contraction  of  Definition  1.  Then 
Kullback-Liebler  divergence 
in  which 

be the junction tree obtained from the 
minimizes the 
over  all  distributions 

Alternatively,  the  probability  distribution  represented  by 
has  maximum  likelihood  (under  the  original junction  tree's 
distribution) over all distributions in which 
is conditionally 
independent  of 
g i v e n T h u s,  we can consider each 
variable  contraction  to  be  a  maximum  likelihood projection 
that cuts edges between  and c  -  s. 

To  reduce  the  width  of a  given junction  tree,  we  should 
choose  the  variable  contraction that  minimizes  the  approxi(cid:173)
mation  error,  which  we  take  to  be  the  Kullback-Liebler  di(cid:173)
vergence  from  the  original  to  the  approximate  distribution, 
This approximation error can be computed effi(cid:173)
ciently, as shown by the following result (cf.  [Kjaerulff,  1993, 
Theorem  11]): 
Proposition  5.  Let  T  be  the  junction  tree  obtained  from  the 
variable  contraction  of  Definition  I.  Then 

(16) 
To compute the conditional mutual information (16) we need 
only  the  marginal 
.  In  a consistent junction  tree,  this 
marginal  is  simply 
,  and therefore  the  approximation  er(cid:173)
ror of a variable contraction can be computed locally.  When 
is  a  Gaussian  distribution,  the  computation  is  espe(cid:173)

cially efficient:  its cost depends  only  the dimension of ui. 
Proposition  6.  Let  c  index  a  set  of Gaussian  random  vari-

(17) 

and 

are parameters of the potentials 

so we 
can simply extract from each the sub-blocks corresponding to 
ui  and compute the difference of their log determinants. 

and 

5  Thin junction tree filters for  S L AM 
We  have  now  assembled  most  of the  machinery  required  to 
design  a thin junction  tree  filter  for the  SLAM  problem.  All 
that remains is the logic to decide into which clusters new po(cid:173)
tentials are multiplied and also how variable contractions are 
employed to thin the junction tree.  There are many possibil(cid:173)
ities; the method below presents a nice compromise between 
simplicity and performance.  We  then  describe a refinement 
that can reduce the time complexity from linear to constant. 

Linear-time  approximate  filtering 

5.1 
Recall  from  Section 3.1  that if the width  of our junction  tree 
is  k,  then  it  will  require 
space and message pass(cid:173)
ing will take 
 we 
i me  filter opera(cid:173)
can obtain a 
tion by periodically thinning the junction tree so that its width 
remains bounded by a constant 

time.  In  S L A M so

space  filter  with  a t

Figure  3:  Illustration  of variable  contraction.  Clusters  are 
is shaded,  (a) i can 
circles and separators are rectangles; 
be  contracted  from 
cannot be contracted from  because the running intersection 
property would be violated,  (b) Contracting i from c removes 
it from c and s and marginalizes 

or  c  because  they  are  leaves  of 

out  of 

and 

Let 

be  the  Markov  blanket  of 

Because  T  has  the 

potential, marginalizing out 
izing it out of all the cluster potentials that bind it. 

is not as simple as marginal(cid:173)

potential property, we are guaranteed that 
's  Markov  blanket  is  covered by  the  clusters  con(cid:173)
i.e.,  that 
taining 
(In fact, in the sequel this containment will often be 
strict equality.)  Moreover,  because  T  has  the  running  inter(cid:173)
section property, all clusters containing i constitute a subtree 
of T,  which we denote 
By successively merging the clus(cid:173)
into each other, we can obtain a new junction tree 
ters  of 
where i resides in a single  cluster 
Marginalizing 
Ui  out  of this junction  tree  is  simple:  we remove  i  from c* 
and marginalize 
. It is simple to check that this 
operation results in a consistent junction tree for 

out  of 

4  Thinning the junction tree 
The updates described in the previous section  can cause the 
clusters of the junction tree to grow; in particular, the merging 
of clusters  required by  marginalizations  can cause the width 
of the junction  tree  to  increase  quickly.  The  complexity  of 
message  passing  scales  with  the  width  of the junction  tree, 
and therefore our goal is to define a "thinning" operation that 
reduces the width (see Figure 3): 
Definition  1.  Let  i 
V  appear  in  more  than  one  cluster  of 
the consistent junction tree T, let c be a leaf of Ti (the subtree 
of T induced by i), and let s be the separator joining c to 
A  variable  contraction  of i from  c  removes 
and  marginalizes  ux  out  of 
subsuming neighbor if it becomes nonmaximal.) 

from c and s 
.  (c is merged into its 

and 

We now consider some properties of variable contraction. 
Proposition  2.  Variable  contractions preserve  consistency 
and the singly connected and running intersection properties. 
Thus,  the  new junction  tree  is  valid  for  some  distribution, 
although perhaps  not p:  the potential  property  may  be  vio(cid:173)
lated.  Variable contraction  is  local and efficient:  it requires 
marginalizing a variable out of one cluster potential  and one 
separator potential, which in the Gaussian case can be accom(cid:173)
plished  in 
time using  (11)  and (12).  Also,  variable 
contraction is a general method of "thinning" a junction tree: 
Proposition  3.  In  combination  with  cloning,  variable  con(cid:173)
traction can reduce the width of any junction tree. 

1162 

ROBOTICS 

We start with roll-up. When the robot state 

is marginal(cid:173)
ized out, we must merge all of the clusters in which it resides. 
In the worst case 
can reside in all of the clusters, in which 
case our belief state will collapse to one large cluster. To pre(cid:173)
vent this, we iteratively contract 
(choosing the contraction 
that minimizes the error (17) each time) until it resides in only 
one cluster c.  Then, we perform the time update, which con(cid:173)
sists of multiplying the motion potential 
marginalizing 
into 

out  of  multiplying the odometry potential 
and distributing evidence from 

When  multiplying  in  a  landmark  measurement  potential 
for a  landmark  that  is  currently  in  the  model,  we 
until it resides 
use the method of Section 3.2, i.e., we push 
(This  may  increase the sizes  of some 
in a cluster  with 
clusters, but the subsequent contraction of 
in the next roll-
up ensures this increase in cluster size is temporary.) We then 
multiply 

i n t o a nd  distribute evidence from c. 

into 

If instead the landmark j has not previously been observed, 
we must add the new variable 
to the model.  If the smallest 
cluster that contains 
(call it  c) can  admit another variable 
without violating the width  limit   we add 
to c and multi(cid:173)
If not, then we clone c to obtain d, con(cid:173)
ply 
tract xt  until  it  resides  only  in  d,  and  thin  d  via  a  sequence 
of  greedy  optimal  variable  contractions.  A  cluster  overlap 
parameter  governs the size to which d is thinned, and there(cid:173)
fore how  many  variables  reside  in  the  separator  s  that joins 
it  to  c  (since  in  this case 
is small,  d will 
admit  more  new  landmark  variables  before  another  cloning 
is  required;  the  trade-off is  that  its  separator  s  will  shrink, 
reducing the amount of information it can transmit. 

If 

5.2  Constant-time  approximate  filtering 
The  linear  time  complexity  of the  filter  above  arises  mainly 
because we pass messages to every cluster each time we dis(cid:173)
tribute evidence from some cluster c.  We can get a constant-
time  filter  operation  by  employing  a  lazy  message passing 
scheme,  where  we  distribute  evidence  only  to  constantly 
many nearby clusters; the approximation is that the marginals 
of the remaining clusters will not be conditioned on the obser(cid:173)
vation. This introduces minimal error when the observation is 
uninformative about distant variables; this occurs, e.g., when 
the  robot  is  mapping  new  territory.  Moreover,  because  we 
are still  updating the charge correctly,  this  approximation is 
temporary:  at any later time a full round of message passing 
(taking  linear  time)  will  yield  the  same  estimate  we  would 
have obtained by passing all messages at every time step. 

Alternatively,  we  can  interpolate  between  the  linear-time 
update and this constant-time update by employing an adap(cid:173)
tive message passing scheme in  which  messages are propa(cid:173)
gated only as long as they  induce significant changes in the 
belief state.  If we define  "significant"  sensibly,  this  scheme 
will  take  constant  time  when  mapping  new  territory;  when 
closing loops, it will take time linear in the length of the loop. 
over 
the  separator  s  by . 
the  Kullback-Liebler  diver(cid:173)
gence from the new separator marginal to the original separa(cid:173)
tor marginal. In the Gaussian case this is 

We  measure  the  significance  of a message 

where 
Importantly, 
the  significance of evidence propagated  from  a cluster  c,  to 
another cluster c*  (measured in this way) decreases  with the 
distance between  them  in the junction  tree  [Kjaerulff,  1993, 
Theorem  13].  Thus,  if a  message  was  not  significant  for  a 
cluster, it need not continue the evidence distribution. 
6  Experiments 
Here we present a summary of our findings; the technical re(cid:173)
port contains more detail and further experiments. 

We compared  TJTF,  the  Kalman  filter,  and  FastSLAM  on 
large-scale SLAM simulations in which a robot moves around 
in a square world that is populated with uniformly distributed 
point-landmarks.  Its motion and measurement models are all 
subject to  significant noise and  are  linearized  using  the  un-
scented transformation.  We used two types of trajectories:  a 
square  loop  (similar to  that  a  robot  mapping  an  indoor  en(cid:173)
vironment  might  travel)  and  a  switchback  trajectory  (which 
could be used to map a large open area).  Noise and controls 
were determined in advance so the robot followed the desired 
path and each filter received identical observations. 

Figure  4  shows  two  examples  of  our  simulations.  The 
filters  are  evaluated  by  their  computational  cost  (millions 
of floating point operations),  localization error  (the  distance 
from the robot's position to the  filter's  estimate) and map er(cid:173)
ror  (the  average  distance  from  each  landmark  to  the  filter's 
estimate).  TJTF  was  run  with  the  width  limit  k  —  16,  the 
cluster overlap h — 4, and adaptive message passing with the 
significance threshold set at 0.1 nats; FastSLAM was run with 
100 particles, as recommended in [Montemerlo et a/., 2002]. 
We  found  that  the  estimation  error  of  TJTF  with  maxi(cid:173)
mum cluster sizes as small as 16 can be comparable with the 
Kalman  filter,  and  that  it  gets  smaller  as  k  increases.  This 
indicates that the edges removed by TJTF  indeed carry  little 
information; it also suggests that the estimation error of TJTF 
will be at least competitive with that of SEIF (an approximate 
form of the  Kalman  filter)  and  less  than  that of the  submap 
approaches (which neglect long-distance correlations). 

We also found that TJTF is good at closing loops; in Figure 
4(b)  we  can  see  the  localization  and  mapping error of TJTF 
suddenly drop at t  —  780, when the robot first reobserves its 
starting point; also evident is a sudden increase in the compu(cid:173)
tational cost:  the filter is choosing to update the entire map in 
linear time rather than  using cheaper constant-time  updates. 
We  found  that  FastSLAM  had  difficulty  closing  large  loops 
(notice its divergence  in Figure 4(b))  and  that  its estimation 
error in general was larger than that of TJTF. 

Finally, using accurate counts of floating point operations, 
we found that TJTF can  be as  fast as FastSLAM,  and that it 
becomes more efficient than the Kalman  filter  when the map 
contains a few hundred or more landmarks. 

7  Conclusion 
We  believe  thin  junction  tree  filters  are  a  promising  ap(cid:173)
proximation  technique  for  dynamic  probabilistic  inference. 
First,  they  are  flexible,  in  that  they  allow  the practitioner to 
trade  computational  complexity  for  approximation  accuracy 
by  varying  the  width  of the junction  tree  and  the  depth  of 

ROBOTICS 

1163 

Figure 4:  In (a) and (c):  the solid line is the actual  robot path;  the dashed  line is the integrated  odometry;  the dash-dotted  line is 
the integrated  control  signal;  circles  are  landmarks;  dots are  landmark  observations  (relative to  the  unknown  actual  viewpoint); 
for clarity,  only  some  of the  1000  landmarks  are  plotted.  In  (b)  and  (d)  the  floating  point  counts  arc  time-averaged  for clarity. 

evidence  propagation.  Second,  the  error  of  each  local  ap(cid:173)
proximation  can  be  computed  exactly,  giving  an  important 
indication  of how  trustworthy  the  approximate  estimates  aic. 
Finally,  the  TJTF  approximation  is  context  sensitive  in  that  it 
is  not chosen  in  advance;  rather,  the  approximation  is  chosen 
adaptively  to  minimize  the  approximation  error. 

When  applied  to  the  SLAM  problem,  TJTF  performs  com(cid:173)
petitively  with  the  exact  filter,  but  with  superior  asymptotic-
space  and  time  complexity. 
Interestingly,  the  approach  pre(cid:173)
sented  here  has  significant  connections  to  both  the  submap 
approach  and  SEIF.  First,  like  SK1F,  TJTF  cuts  "weak"  edges 
from  the  graphical  model  to  speed  inference;  however,  in 
TJTF we can use exact inference over this approximate model, 
whereas  SEIF  must  use  approximate  inference.  Second,  the 
belief state  of a TJTF  has  a natural  interpretation as a coupled 
set  of local  maps, just  as  in  the  submap  approaches.  In  par(cid:173)
ticular,  each  cluster  of the junction  tree  can  be  viewed  as  a 
submap.  The  TJTF  formulation  gives  concrete  semantics  to 
the  relationships  between  the maps,  including  how  they  must 
be  updated,  how  consistency  is  maintained,  and  how  the  set 
of local  maps  can  be  determined  online  to  minimize  the  ap(cid:173)
proximation  error  subject  to  a  complexity  constraint. 

Acknowledgements 
I  gratefully acknowledge  Intel  Corporation  for supporting this 
research  via  an  Intel  Research  Internship,  as  well  as  Bar(cid:173)
bara  Engelhardt,  Kevin  Murphy,  Stuart  Russell,  and  Sekhar 
Tatikonda  for  valuable  comments  on  a  draft  of this  paper. 

References 
[Boycn and Roller,  1998]  X. Boyen and D. Koller.  Tractable infer(cid:173)
ence for complex stochastic processes. In Proceedings of the 14th 
Annual Conference on  Uncertainty in AI, pages 33-42,  1998. 

[Boyen and Koller,  1999]  X.  Boyen and  D.  Koller.  Exploiting the 
In  Proceedings  of the  16th 
architecture  of dynamic  systems. 
National  Conference  on  Artificial  Intelligence  (AAAI-99),  pages 
313-320, 1999. 

[Cowell et al., 1999]  R.  Cowell,  P.  Dawid,  S.  Lauritzcn,  and 
D.  Spiegelhaltcr.  Probabilistic  Networks  and  Expert  Systems. 
Springer, New York, NY,  1999. 

[Draper,  1995]  D.  Draper.  Clustering without (thinking about) tri-
angulation.  In  Uncertainty  in  Artificial Intelligence:  Proceedings 
of the Eleventh Conference (UAI-95), pages 125-133, 1995. 

[Hebert et  al,  1996]  P.  Hebert,  S.  Betgc-Brezetz,  and  R.  Chatila. 
In 
Probabilistic  map  learning:  Necessity  and  difficulties. 
L. Dorst, M. van Lambalgcn, and F. Voorbraak, editors, Reason(cid:173)
ing  with  Uncertainty in  Robotics,  volume  1093  of Lecture  Notes 
in Computer Science. Springer,  1996. 

[KjacruliT,  1993]  U.  Kjaerulff.  Approximation of bayesian networks 
through edge removals. Dept. of Mathematics and Computer Sci(cid:173)
ence Research Report 1R-93-2007, Aalborg University,  1993. 

[Montemerlo et al., 2002]  M. Montemerlo, S. Thrun, D. Koller, and 
B. Wegbreit.  FastSLAM:  A factored solution to the simultaneous 
localization  and  mapping problem.  In  Proceedings of the Eigh(cid:173)
teenth  National  Conference  on  Artificial  Intelligence  (AAAI-02), 
pages 593-598,2002. 

[Paskin, 2002]  M.  Paskin.  Thin junction  tree filters  for simultane(cid:173)
ous  localization  and  mapping.  Technical  Report CSD-02-1198, 
University of California, Berkeley,  September 2002. 

[Smith  etal.,  1990]  R.  C.  Smith,  M.  Self,  and P.  Cheeseman.  Es(cid:173)
timating uncertain  spatial relationships  in  robotics.  In  I.  J.  Cox 
and  G.  T.  Wilfong,  editors, Autonomous Robot  Vehicles,  pages 
167-193. Springer-Verlag,  1990. 

[Speed and Kiiveri,  1986]  T.  P.  Speed  and  H.  T.  Kiiveri.  Gaus(cid:173)
sian markov distributions over finite graphs. Annals of Statistics, 
14(1):138  150, March  1986. 

[Thrun etal, 2002]  S.  Thrun,  D.  Koller,  Z.  Ghahmarani, 
Simultaneous  localization 
H.  Durrant-Whyte,  and  A.  Ng. 
and  mapping  with  sparse  extended  information  filters:  Theory 
and initial results.  Technical Report CMU-CS-02-112, Carnegie 
Mellon University, September 2002. 

[Thrun, 2002]  S. Thrun.  Robotic mapping:  A survey.  In G. Lakc-
meycr  and  B.  Nebel,  editors,  Exploring Artificial  Intelligence  in 
the New Millenium.  Morgan  Kaufmann,  2002. 

1164 

ROBOTICS 

