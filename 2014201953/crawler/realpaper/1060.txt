Dealing with Perception Errors in Multi-Robot System Coordination

Alessandro Farinelli and Daniele Nardi

Paul Scerri

Dip. di Informatica e Sistemistica,
University of Rome, “La Sapienza”,

Robotics Institute,

Alberto Ingenito
Dataspazio S.p.A.,

Carnegie Mellon University,

Alberto.Ingenito@dataspazio.it

lastname@dis.uniroma1.it

pscerri@cs.cmu.edu

Abstract

A prerequisite to efﬁcient behavior by a multi-robot
team is the ability to accurately perceive the en-
vironment. In this paper, we present an approach
to deal with sensing uncertainty at the coordina-
tion level. Speciﬁcally, robots attach information
regarding features that caused the initiation of a
course of action, to any coordination message for
that activity. Further information regarding such
features, acquired by the team, are then combined
and the expected utility of the started action is
re-evaluated accordingly. Experiments show that
the approach allows to coordinate a large group of
robots, addressing sensing uncertainty in a tractable
way.

1 Introduction

Emerging, large multi-robot teams hold great promise for rev-
olutionizing the way some important, complex and danger-
ous tasks, such as disaster response1 and space exploration2
are performed. Such teams, consist of multiple, heteroge-
neous robots with imperfect sensors, which must act efﬁ-
ciently in the face of considerable uncertainty and time pres-
sure. Speciﬁcally, in many complex environments, robots
have systematic sensor noise that leads individual robots to
incorrect perception of the objects in the environment. This
paper presents an approach that leverages multi-robot coop-
eration to overcome individual sensing limitations.

Dealing with sensing uncertainty is a key area of robot
and agent research. A variety of techniques attempt to ei-
ther reduce the uncertainty before deciding how to act, e.g.,
Bayesian ﬁlters [Fox et al., 1999], or explicitly deal with the
uncertainty when choosing a course of action, e.g., POMDPs
[Theocharous et al., 2001]. Such approaches, require that
each robot deals with its sensor noise on its own, thus fail-
ing to leverage any assistance the rest of the team might
be able to supply. Other work explicitly uses input from
other members of the team to allow a more accurate pic-
ture of the environment to be created. For example, DEC-
POMDPs have been used to devise a coordinated course of

1see http://www.ai.sri.com/project/Centibots
2see http://www.cs.cmu.edu/∼ﬁre/

action [Pynadath and Tambe, 2002]. Several approaches use
cooperative perception to deal with perception limitation of
the single robot [Rosencratz et al., 2003; Dietl et al., 2001;
Stroupe et al., 2001]. The general idea of these approaches is
to exchange sensor readings and aggregate them using differ-
ent ﬁltering techniques (e.g. Kalman ﬁlters [Dietl et al., 2001;
Stroupe et al., 2001] or particle ﬁlters [Rosencratz et al.,
2003]).

Coordination in Multi-Robot Systems has been success-
fully addressed using task assignment approaches [Parker,
1998; Werger and Mataric, 2000; Zlot et al., 2002]. While
task assignment has been deeply investigated in several sce-
narios and many different techniques have been proposed, lit-
tle attention has been devoted to the impact that limited and
noisy perception capabilities have on the task allocation pro-
cess. In many applications, tasks to be allocated are created
by the robots when particular features are extracted from the
environment. Such feature extraction process is subject to
errors, which can greatly impact the overall task assignment
process. Cooperative perception techniques can be used to
address this problem, however previous approaches to coop-
erative perception often require to exchange too many data
among robots. A key reason for this is that, typically, each
robot attempts to maintain an accurate model of the complete
state when, in practice, only a small part of the overall state
might be relevant to its activities.

This paper presents an approach to deal with perception
errors by exchanging information about observed features in
a task assignment coordination framework. This approach
comprises two key ideas, ﬁrst, when a robot senses an event
in the environment that might lead it to initiate a team ac-
tivity, it immediately computes expected utility of action and
inaction, given its conﬁdence in its sensors. If the expected
utility of acting is greater than that of not acting, it initiates
the team activity. For example, if a team of robots is search-
ing a sparsely occupied burning ofﬁce building, any sensors
suggesting the presence of a trapped civilian should imme-
diately trigger a team response. Over time, new information
acquired by the team can impact the conﬁdence in the occur-
rence of the event. At any point in time, if robots’ conﬁdence
in the event drops sufﬁciently low, the team activity can be
suspended. The idea of the approach is to balance the need
for a rapid response in a time critical domain and the high
costs of acting on incorrect sensor information.

IJCAI-07

2091

Once a team activity has been initiated, messages are typ-
ically passed around the team to coordinate the activity. The
second key idea to the proposed approach is to require that
these communication messages include the event that led to
the team activity being initiated. Such information is consid-
ered as a justiﬁcation for the team activity to be carried out.
Robots receiving such messages check whether they have any
information that can impact conﬁdence in the occurrence of
the event.
If so, the information are communicated to the
robot initiating the action. This technique focuses the in-
formation gathering process on events that are important for
team activities and, thus, prevents communication about ir-
relevant aspects of the state. Notice that, in order to refute
justiﬁcations, robots need to maintain a history of the areas
they have observed so that they can report not seeing some-
thing at a particular location. In this way, uncertainty in robot
perception is addressed at coordination level, focusing only
on information which are relevant to robot mission and thus
dramatically reducing the required communication overhead.
To evaluate the effectiveness of the proposed approach,
experiments were performed both in an abstract simula-
tion environment and in a simulation framework based on
Player/Stage3. The proposed approach was shown to perform
almost as good as an approach that broadcasts every detected
features to every other robots, while using orders of mag-
nitude less communication bandwidth. Unsurprisingly, the
proposed approach did not perform as well when the envi-
ronment was very sparse, because fewer robots had helpful
information, or when the environment was very dynamic be-
cause information from other robots were soon out-of-date.

2 Problem

e

, where O+

This section formally describes the problem addressed by this
paper. Mobile robots R = {r1, . . . , rm}, with imperfect sen-
sors, act in an environment with events E = {et
n}.
1, . . . , et
i =
The events are spread spatially across the environment. et
true iff event i is observable at time t. The robots make ob-
servations O[+|−]
e corresponds to a positive read-
ing for event e and O−
e corresponds to a negative reading. The
probability of a false positive reading is P (O+
e |¬e). Notice
that, false positive (or false negative) should be intended not
as direct sensor readings, but as errors in the feature extrac-
tion process. The proposed binary model for robot observa-
tions is therefore well suited and general enough to represent
such issues. Moreover, such model can consider both errors
due to systematic issues with sensors, and random errors of
the feature extraction process.
The prior probability of et

i = true is written P (et

i) →
[0, 1]. This is the probability an event occurs before robots
i = true,
acquire any observation. Robot r estimate of et
given acquired observation, is Belr(et
i) → [0, 1]. The
world changes dynamically according to P (et+1
i) and
P (¬et+1
ei to be t such
that ¬et−1
ei to be t such
that et

i). The start time of an event ts
i and the end time of the event tf
.

i ∧ et
i ∧ ¬et+1

|¬et

|et

i

i

i

3see playerstage.sourceforge.net/

When events occur, the robot team should take actions in
response. The function Ae(t) → {0, 1} returns 1 if the team
is acting in response to event e at time t and returns 0 oth-
erwise. Informally, the team receives reward (α), for acting
when an event is real, and costs for either not acting when the
event is real (β2), or acting when it is not (β1). Formally, the
problem for the team is to maximize:

(cid:2)

(cid:3) tf
e∈E α
(cid:3) tf
(cid:4)(cid:3) ts
e∈E −β2
−∞ Ae(t) +

e
ts
e
(1 − Ae(t))+

Ae(t)+
(cid:3) ∞

e
ts
e

e

tf
e

(cid:5)
Ae(t)

(1)

(cid:2)

(cid:2)

e∈E −β1

To maximize expected utility, the team should act on ei

only when:

αBel(et

i) − β1(1 − Bel(et

i)) > β2Bel(et

i).

(2)

2.1 Example

Figure 1: Example of scenario where cooperative perception
can enhance system performance

Figure 1 shows an example of the type of situation that co-
operative teams of robots should avoid at low cost. Unﬁlled
hexagons show mobile robots performing search and rescue
in an ofﬁce-like environment. Dotted lines indicate the paths
the robots have taken through the environment. The ﬁlled
hexagon is a robot that believes it sees an injured victim, in-
dicated by the emoticon. It should consider initiating a joint
activity to rescue the victim. However, there is not actually a
victim at that location. Since six other robots have recently
passed that same location without sensing a victim the team
should be able to quickly establish that the ﬁlled hexagon
robot is experiencing a perception error and avoid the costs
of the joint activity.

3 Approach

The key idea to this approach is to use input from team mates
to update conﬁdence in reasons for acting, while starting ac-
tions on initial observations. The technical elements of the
approach are: i) attach to coordination messages assumptions
that justify a coordinated action; ii) add observations to coor-
dination messages when relevant; iii) revise decisions to act

IJCAI-07

2092

based on observations attached from teammates to coordina-
tion messages.

When a robot detects a new event, it performs an expected
utility calculation to decide whether to act in response to that
event (see Equation 2).
If it decides to start a coordinated
action, it attaches the justiﬁcation for that coordinated action
to the coordination messages. When a robot receives a
coordination message, it evaluates whether it has relevant
observations about that event. If it is the case, it will attach
to the coordination message the relevant observations and
it will send a cooperative perception message back to the
robot that initiated the action. Finally, when the robot that
instantiated a coordinated action receives a cooperative
perception message, it integrates all observations attached
to the message and re-considers the expected utility, while
continuing to perform the coordinated action. In particular, if
robot r receives a cooperative perception message at time t
i (where t(cid:4) < t), it will update Belr(et
i)
related to the event et(cid:2)
using the observations attached to the message. With the
update Belr(et
i) robot r will then re-evaluate the expected
utility of continuing the activity.

World representation
To support or refute observations performed by other team
members, robots have to store their previous observations. In
particular, their representation should include not only ob-
served relevant features, but also in which parts of the en-
vironment they did not observe any relevant features. Thus
each robot maintains three main elements: i) a Set of Interest-
ing Points (IPS); ii) a representation of the Observable Space
(OS) iii) a set of positive observations (PO). An interesting
point is a portion of space where an event was detected at a
given time step. Each entry of the (IPS) comprises: i) in-
formation characterizing the location to which the event is
related (e.g., x and y for a bi-dimensional representation); ii)
a numerical value (belief) representing the robot’s estimates
that the observation is correct.

The OS is dependent on the robot’s sensors, but in general
it is a representation of the portion of the environment that
was observed by the robot’s sensors at a given time step. The
PO is the set of relevant features that were detected at each
time step. Given an event ei detected by a robot r, robot r(cid:4)
will perform the following operations to support or refute the
event.

For each entry of the OS history:
• If the portion of space related to ei is inside the current
OS and the corresponding PO set contains an observa-
tion for that feature, attach the observation to the coop-
erative perception message (supporting the event detec-
tion).

• If the portion of space related to ei is inside the cur-
rent OS but the current PO set does not contain any ob-
servation for that feature, create a negative observation
and attach the observation to the cooperative perception
message (refuting the event detection).

• If the portion of space related to ei is not inside the cur-

rent OS do nothing.

Figure 2: Supporting and refuting observations

Notice that, to relate observations to detected features (or
events), the data association problem has to be solved (i.e.
which feature is related to which observation). Data associ-
ation is a well known problem for robotic and tracking ap-
plications (see for example [Hall and Llinas, 2001]). Several
approaches have been used to address this problem, however,
since our method is based on a feature-level representation,
and the data association issue is not the main focus of our
work, a distance threshold is adopted. Other approaches to
address the data association problem can be used; in fact, the
decision process we described is general with respect to the
chosen data association method.

Figure 2 provides a graphical representation of supporting
and refuting observations, showing a robot with the current
laser readings and the ﬁeld of view of the camera. The OS, in
this case, is the intersection between the laser reading and the
camera ﬁeld of view. The point labeled as none in the ﬁgure
is a point for which the robot cannot provide any information,
because it can not observe that part of the environment.

Bayesian update of robot knowledge
In this work, the belief update of each robot is done using
a Bayes ﬁlter. Speciﬁcally, a Bayes ﬁlter is instantiated for
each relevant detected event in the environment (Equations 3
and 4).

(cid:6)

P r(Oj
et(cid:2)
i

|et

i)Bel(cid:4)(et
i)

Bel(et

i) = η
(cid:7)

j

(3)

(4)

Bel(cid:4)(et

i) =

P r(et

i|et−1

i

)Bel(et−1

i

)

et−1
i

Since readings Oj
et(cid:2)
i

obtained from team mates may be
older than present time t(cid:4) < t, they cannot be directly in-
tegrated using the ﬁlter equation, because, referring to a time
step in the past, they should have inﬂuenced the robot’s be-
lief up to the present time. When a reading referring to a
past time t(cid:4)
is obtained the ﬁlter is reinitialized with a state
Bel(e¯t
i ∈ IP S ∧ ¯t < t(cid:4)}. If the
event location is not inside the IPS a new interesting point is
added to the IPS. Observations for the locations are generated
using the PO and the OS. Maintaining the history for OS, PO

i) where ¯t = M ax{t | et

IJCAI-07

2093

and IPS for all the process has a cost in terms of memory that
grows with time. To limit such cost, a valid time window T
is used that goes from the current time tc back to tc − T . An
appropriate time window can be chosen by considering the
evolution model of the environment.

4 Experiments and Results

To evaluate the approach, we have tested our method both in
an abstract simulation environment and in a simulation frame-
work based on Player/Stage. The former simulator has been
used to test our method with a very large team of robots (100
team members). Moreover, the behavior of our method has
been tested under varying environmental conditions such as
the world dynamism and the world size. The latter simu-
lation environment allowed us to consider important issues
such as sensor occlusion or message delay among team mem-
bers. Overall, the ﬁrst experimental setting allows to test the
general behavior of the method, while the second set of exper-
iments provides more accurate indications on speciﬁc robotic
issues. Two metrics were used to measure performance: the
percentage of stopped actions out of the total number of ac-
tions incorrectly instantiated (percentage found, pFound on
graphs) and the percentage of correctly stopped actions out
of all the actions that were stopped (percentage good, pGood
on graphs). In both cases, higher is better. Notice that, the
percentage good measure is related to the correctness of the
approach while the percentage found measure is related to
the completeness. These metrics are the key values under-
lying Equation 1 and hence, with knowledge of the relative
costs of action and inaction, allow for the computation of the
team performance. In the experiments presented below, each
robot initiates a coordinated action according to Equation 2.
The communication overhead is evaluated using two mea-
sures: i) number of messages exchanged at each time step by
each robot; ii) size of the messages (in bytes) exchanged at
each time step by each robot. We assume that the overhead of
a broadcast message is higher than the overhead of a point to
point message. In particular, we count a broadcast message as
point to point message times the number of robots. While for
a more precise analysis of the overhead one should consider
the speciﬁc network used, this provides a general cost model
for communication which is suitable for our level of analysis.
In our experiments we used a task assignment algorithm
based on token passing [Scerri et al., 2005]. Tokens, repre-
senting tasks to be accomplished, get propagated through the
team until a robot accepts the task. The algorithm has been
chosen, because it requires a very low communication over-
head and is thus well suited for our interest domain.

The proposed approach (referred as ShareRelInfo4 in the
following) was compared to a benchmark strategy, called
Share All, where each robot shares all its observations with
all other robots at each time step. Clearly, this type of ap-
proach is infeasible for large teams, but it provides an upper
bound on the performance that can be achieved by the coop-
erative perception process.

Experiments have been performed in a 2D ofﬁce-like en-
vironment. To exchange information about features present

4Because it shares only information relevant to the tasks.

in the environment, robots need to share a common refer-
ence framework. To simplify the experimental setting, we
do not explicitly consider localization errors. As a matter of
fact, standard localization techniques [Fox et al., 1999] can
be used for our experimental scenario, and localization errors
can be taken into account in the error model of the feature
extraction process. Each graph reports values averaged over
10 trials of the same experiment.

4.1 Abstract Simulator Results

The abstract simulator captures key features of the environ-
ment, while being sufﬁciently abstract to test a wide range
of parameters and conﬁgurations efﬁciently. The simulated
robots have limited knowledge of the overall team state and
can communicate only with a subset of the overall team. In
each experiment there were 100 simulated robots, each with
the same perception model.

Figure 3 shows that Share All does perform better and the
advantage increases as the world becomes more dynamic.
However, for less dynamic environments ShareRelInfo per-
forms almost as well. For this team size (100 robots) the com-
munication gain of ShareRelInfo is approximately two orders
of magnitude.

d
n
u
o
F
p

/

d
o
o
G
p

 120

 110

 100

 90

 80

 70

 60

pGood Share All
pFound Share All
pGood ShareRelInfo
pFound ShareRelInfo

 0

 0.002  0.004  0.006  0.008  0.01  0.012  0.014

World Change Rate

Figure 3: Comparison between Share All and ShareRelInfo,
varying world dynamics

Figure 4 shows performance as the size of the environment
is varied, while keeping the number of robots and the sen-
sor range constant. The performance decreases as the robot
density becomes lower. This is because, when the density
of robots decreases there will be less opportunity for mutual
observations of same features, therefore less information for
supporting or refuting observations can be provided.

4.2 Player/Stage results

In the Player/Stage experimental framework each robot is
equipped with a laser range ﬁnder and a color camera. Robot
controllers are run as distributed processes over a network of
PCs and messages are exchanged using the UDP protocol. In
this conﬁguration, we can validate the coordination method
with possible message loss and delay. Objects of various col-
ors are distributed over the map. The goal of the team is to
detect objects and locate them in the map (Figure 5 represents
the reference experimental scenario).

IJCAI-07

2094

pGood Share All
pFound Share All
pGood ShareRelInfo
pFound ShareRelInfo

 120

 110

 100

 90

 80

 70

d
n
u
o
F
p

/

d
o
o
G
p

 60

 10

 20

 30

 40

 50

 60

 70

World Size

d
n
u
o
F

 
.
c
r
e
P

 
/
 

d
o
o
G

 
.
c
r
e
P

 120

 110

 100

 90

 80

 70

 60

pGood ShareAll
pFound ShareAll
pGood ShareRelInfo
pFound ShareRelInfo

Sit. 1

Sit. 2

Situations

Sit. 3

Figure 4: Comparison among Share All and ShareRelInfo,
varying world size

Figure 6: Performance comparison among Share All and
ShareRelInfo in the tree different conﬁgurations

reached a robot, the chances to stop an invalid action remain
almost constant.

ShareRelInfo achieves results which are very close to the
Share All strategy. As for completeness, the proposed method
attains lower values and is more sensitive to the differences
among conﬁgurations. This is due to the smaller amount of
information that this method uses. In fact, when fewer obser-
vations are shared among robots, there is a lower chance that
coordination messages reach robots that can provide relevant
information to refute or support coordinated actions. How-
ever, the performance decrease is minimal while the gain in
communication is very high (see below).

As for correctness, ShareRelInfo attains slightly better re-
sults than the Share All strategy. This can be explained by
considering how actions are created and stopped in the two
policies.
In the ShareRelInfo a coordinated action can be
stopped only when a message containing observations of a
subset of the teammates is received and the computation of
Equation 2 indicates that the action should be stopped. In the
Share All strategy the policy to stop actions is different: each
robot monitors, at each time step, the belief associated with
features that originated corresponding actions, and actions are
stopped according to Equation 2. In this way, if at some time
step a subset of the robots experiences an error in the percep-
tion process for the same feature, the corresponding action
will be stopped immediately. Since the proposed approach
integrates measures over time before stopping a coordinated
action, it is less sensitive to this problem.

Figure 7 and 8 show that the proposed approach not only
requires a lower number of messages, but ensures also a
smaller communication overhead in terms of message size.
Since the communication overhead does not change signif-
icantly across the different conﬁgurations, we report results
referred to one particular conﬁguration (conﬁguration 2).

The graphs show the number of messages and communi-
cation load for different world change rate. For this team size
(10 robots) the communication gain is approximatively one
order of magnitude. When the world change rate is lower,
less coordinated actions will be instantiated. In such a situa-
tion, ShareRelInfo requires a lower communication overhead,
while the communication overhead for the Share All strategy
remains almost constant.

Notice that, having a smaller communication overhead can

Figure 5: Reference experimental scenario

The approach was tested in three different conﬁgurations,
where the object and robot positions are different. Specif-
ically, the ﬁrst conﬁguration comprises one group of eight
robots which observe the same group of objects. In this con-
ﬁguration the number of shared observations is very high.
However, due to occlusions in the visual ﬁeld the observa-
tions for each robot are not exactly the same. The second
conﬁguration includes two groups of robots. The ﬁrst one is
composed of eight robots which observe the same group of
objects, the second group is composed of two robots which
observe a group of other two objects. In this conﬁguration
the two groups of robots do not share any observations. Fi-
nally, the third conﬁguration (shown in Figure 5) shows three
groups of robots, in this case the number of shared observa-
tions among groups is very limited.

Figure 6 reports results obtained for the two methods in the
three described conﬁgurations. Figure 6 shows that the lower
number of shared observation has a negative impact for both
strategies and both measures. The completeness (pFound in
graph) is more disadvantaged by the lower availability of
shared observations than the correctness (pGood in graph).
This can be explained by considering that, when there are
fewer shared observations, there will be a lower chance that
a robot will obtain enough information to stop an invalid ac-
tion. On the other hand, once the relevant information has

IJCAI-07

2095

c
e
S

 
r
e
p

 
t

n
e
g
A

 
r
e
p

 
s
g
s
M

 
f

o

 
r
e
b
m
u
N

 60

 50

 40

 30

 20

 10

 0

ShareAll
ShareRelInfo

High Rate

Low Rate

World Change Rate

Figure 7: Communication comparison for different world
change rate (number of messages)

c
e
S

 
r
e
p

 
t

n
e
g
A

 

 
r
e
p
e
t
y
B
d
a
o
L

 

 
.

m
m
o
C

 140000

 120000

 100000

 80000

 60000

 40000

 20000

 0

ShareAll
ShareRelInfo

High Rate

Low Rate

World Change Rate

Figure 8: Communication comparison for different world
change rate (communication load)

be exploited to enhance the robustness of the system. For
example, it could be possible to use a reliable communica-
tion protocol (e.g., based on acknowledgment) to avoid or re-
duce message loss. Moreover, the available bandwidth could
be allocated to other processes to have a better coordination
among team members (e.g., to exchange the planned path to
avoid collision or complex maneuvers).

5 Conclusions

In this paper we proposed a novel approach to deal with dis-
tributed unreliable perception in dynamic environments. The
approach enables robots to integrate previously made sensor
readings to help refute incorrect sensing. The novelty of the
proposed approach lies in dealing with perception errors at
coordination level. This is achieved by introducing an ab-
stract representation of the state and by sharing information
driven by events.

While obtained results refer to a simulated environment
and thus deserve further investigation, this work is a ﬁrst im-
portant step to explicitly consider uncertainty at the coordina-
tion level in a tractable way.

Addressing the problem of sensor inaccuracy at the coor-
dination level provides several advantages: First of all the
method is general and does not strictly depend on the tasks
to be performed and on the types of sensors used. More-
over, it uses an explicit representation of beliefs about the
world, which is shared among team members. This could en-

able team members to reason about their states. For example,
a very interesting issue for future work would be to analyze
team member perception failures, based on coordination mes-
sages, and change the team coordination policy accordingly.

6 Acknowledgment
Alessandro Farinelli is supported by the European Ofﬁce of
Aerospace Research and Development under grant number
053015. The views and conclusions contained herein are
those of the authors and should not be interpreted as necessar-
ily representing the ofﬁcial policies or endorsements, either
expressed or implied, of the European Ofﬁce of Aerospace
Research and Development.

References
[Dietl et al., 2001] Dietl, J. S. Gutmann, and B. Nebel. Co-
In Proc. of

operative sensing in dynamic environments.
Int. Conf. on Intelligent Robots and Systems, 2001.

[Fox et al., 1999] D. Fox, W. Burgard, and S. Thrun. Markov
localization for mobile robots in dynamic environments.
Journal of Artiﬁcial Intelligence Research, 11:391–427,
1999.

[Hall and Llinas, 2001] D.L. Hall and J. Llinas, editors.
Handbook of Multisensor Data Fusion. CRC Press, 2001.

[Parker, 1998] L. E. Parker. ALLIANCE: An architecture for
fault tolerant multirobot cooperation. IEEE Transactions
on Robotics and Automation, 14(2):220–240, April 1998.
[Pynadath and Tambe, 2002] D. V. Pynadath and M. Tambe.
The communicative multiagent team decision problem:
Analyzing teamwork theories and models. Journal of Ar-
tiﬁcial Intelligence Research, 16:389–423, 2002.

[Rosencratz et al., 2003] M. Rosencratz, G. Gordon, and
Thrun S. Decentralized sensor fusion with distributed par-
ticle ﬁlters. In UAI-03, 2003.

[Scerri et al., 2005] P. Scerri, A. Farinelli, S. Okamoto, and
M. Tambe. Token approach for role allocation in extreme
teams. In In Proc. of AAMAS 05, pages 727–734, 2005.

[Stroupe et al., 2001] A.W. Stroupe, M.C. Martin,

and
T. Balch. Distributed sensor fusion for object position es-
timation by multi-robot systems. In Proc. of Int. Conf. on
Robotics and Automation (ICRA2001), volume 2, pages
1092–1098, 2001.

[Theocharous et al., 2001] Georgios Theocharous, Khasha-
yar Rohanimanesh, and Sridhar Mahadevan. Learning hi-
erarchical partially observable markov decision processes
for robot navigation. In IEEE Conference on Robotics and
Automation , (ICRA), Seoul, South Korea, 2001.

[Werger and Mataric, 2000] B. B. Werger and M. J. Mataric.
Broadcast of local eligibility for multi-target observation.
In DARS00, pages 347–356, 2000.

[Zlot et al., 2002] R. Zlot, A Stenz, M. B. Dias, and
S. Thayer. Multi robot exploration controlled by a mar-
ket economy. In Proc. of the Int. Conf. on Robotics and
Automation (ICRA’02), pages 3016–3023, 2002.

IJCAI-07

2096

