Coupling CSP Decomposition Methods and Diagnosis Algorithms for 

Tree-Structured  Systems* 

Markus Stumptner 

University of South Australia, 

Franz Wotawa  f 

Technische Universitat Graz 

Advanced Computing Research Centre 

Institute for Software Technology (1ST) 
5095 Mawson Lakes SA, Adelaide, Australia  8010 Graz, Inffeldgasse 16b/2, Austria 

mst@cs.unisa.edu.au wotawa@ist.tugraz.at 

Abstract 

Decomposition methods are used to convert general 
constraint satisfaction problems into an equivalent 
tree-structured problem that can be solved more ef(cid:173)
fectively.  Recently,  diagnosis  algorithms for tree-
structured  systems  have  been  introduced,  but  the 
prerequisites  of coupling  these  algorithms  to  the 
outcome of decomposition methods have not been 
analyzed in detail, thus limiting their diagnostic ap(cid:173)
plicability.  In this paper we generalize the TREE* 
algorithm and show how to  use  hypertree decom(cid:173)
position outcomes as input to the algorithm to com(cid:173)
pute the diagnoses of a general diagnosis problem. 

Introduction 

1 
The development of effective algorithms for diagnosing large 
and complex systems remains one of the key issues in model-
based reasoning.  Nonetheless, apart from various additional 
optimizations and control strategies  (e.g.,  [de Kleer,  1991]) 
the  main  architectures  for consistency-based  diagnosis  sys(cid:173)
tems,  TMS  [de  Kleer and  Williams,  1987]  and hitting  sets 
computation  [Reiter,  1987],  have remained remarkably sta(cid:173)
ble since the late  1980s.  Over the last years though, a num(cid:173)
ber of algorithms were published that exploited advantageous 
structural properties of the  systems to be  diagnosed for sig(cid:173)
nificant computational  speedups  [Fattah  and Dechter,  1995; 
Stumptner and Wotawa, 2001 ], enabling the very fast diagno(cid:173)
sis of large tree-structured systems. 

It  was  recognized  early  on  that  the  combination  of tree-
oriented  algorithms  could  in  principle  be  combined with  a 
second  class  of algorithms  aiming  at  the  decomposition  of 
cyclic problems to equivalent tree-structured problems so that 
the faster solution algorithms could be brought to bear  [Fat(cid:173)
tah and Dechter, 1995;Darwiche, 1998]. Again, this direction 
profits from recent new results relating the different decom(cid:173)
position algorithms [Gottlob et al., 2000] and analyzing their 
performance [Gottlob et al. , 2002].  This paper joins the two 
strands by  tying the  link  between the  recent work on prob(cid:173)
lem decomposition and the TREE* algorithm [Stumptner and 
Wotawa, 2001]. 

This work was partially supported by the Austrian Science Fund 

(FWF) under project grants P15163-1NF and P 15265-INF. 

Authors are listed in alphabetical order. 

This  combination  is  aided  by  the  fact  that  both  subar-
eas  tend to  use  Constraint  Satisfaction  Problems  (CSPs)  as 
their  representation  of choice.  The  diagnosis  computation 
work  [Fattah  and  Dechter,  1995;  Stumptner  and  Wotawa, 
2001; Mauss and Tatar, 2002] focuses on the relational com(cid:173)
bination of the different constraint relations,  while the prob(cid:173)
lem reformulation work views CSPs as (often cyclic) hyper-
graphs that are broken down into tree structures. 

A  CSP (V, D, C)  comprises a  set of variables  V,  their do(cid:173)
mains  D,  and a set of constraints C.  A constraint  Ci  is tuple 
(St,Ti)  where 
is its scope and  Ti  is a set of tuples of 
values for the  variables  in  Si.  We  assume two  functions tpl 
and scope on constraints that return the set of tuples and the 
scope respectively.  Each  constraint  Ci  restricts the possible 
values  of the  variables  with  respect  to  values  of other  vari(cid:173)
ables in the same scope.For example, the digital circuit from 
Figure 1 can be represented by the following constraints': 

A solution of a CSP is an assignment of values to all vari(cid:173)
ables  that satisfy  the  given  constraints.  All  values  must be 
elements of their variable's domain. The variable assignment 
b =  l ,a = 0,c = 0 ,/  = 0,g =  0,h  =  l,i  = 0 ,j  =  1 isa 
solution for the above CSP whereas b =  l,a  =  0,c  =  0,f  = 
0, y  =  0, h  =  1,i  =  0,j  =  0  is not because constraint  N4  is 
not satisfied. 

A standard approach for computing solutions for CSPs are 
backtracking algorithms,  which are  in the worst  case expo(cid:173)
nential  in  the  number of variables.  However,  for a  specific 

'Note that not all constraints arc components, N1 is the tabular 

representation of an equality constraint between connections). 

388 

DIAGNOSIS 

other techniques, we restrict our examination here to hyper(cid:173)
tree decomposition.  Note that the result of a decomposition 
method is always a hypertree. 

In  [Gottlob et al.,  2000] hypertree decomposition is char(cid:173)
acterized as follows. A hypertree of a hypergraph if is a triple 
I  is a rooted tree with vertices N 
are labeling functions which associate 
and a 
a set of variables 
for 

and edges E, 
to each vertex 
set of constraints 
a s u b t
for any 
denote the root  of a hypertree by root(T)  . 

denotes the subtree of T rooted at p.  We 

r e e of T 

_ 

edges(H).  We  further define 
nd 

a

a

s

Figure 2:  A hypergraph representing the constraints 

class of CSPs a solution can be computed in polynomial time. 
This  class  comprises  all  CSPs  that  have  an  acyclic  corre(cid:173)
sponding hypergraph2.  A hypergraph of a CSP can be eas(cid:173)
ily  constructed  by  mapping  all  variables  of the  CSP  to  ver(cid:173)
tices and the constraint scopes to hyperedges. A CSP with an 
acyclic hypergraph can be solved effectively in a backtrack-
free  manner  by  first  traversing  the  graph  from  the  leafs  to 
the  root and  computing possible  value  tuples  and secondly, 
traversing the graph from the root to the  leafs and  selecting 
one tuple of a node as a solution. The hypergraph correspond(cid:173)
ing to Fig. 1 is cyclic (see Figure 2). 

In  the  rest  of the  paper,  we  recapitulate  decomposition 
methods,  present  a  version  of TREE*  that  fits  these  meth(cid:173)
ods, show the interaction of decomposition and TREE*, and 
present an extension to  the algorithm that can be used with 
extended domains as presented in [Mauss and Tatar, 2002]. 

2  Decomposition methods 
Several  different  decomposition  methods  have  been  pub(cid:173)
lished,  most  recently  the  hypertree  decomposition  method 
[Gottlob  et al.,  1999a].  This  and  other structure-based de(cid:173)
composition  methods  make  compute  a  tree-structured  sys(cid:173)
tems  from  general  CSPs  by  elimination  of cycles  from  the 
CSP. A cycle can be eliminated by applying the relational al(cid:173)
gebra join operation to the constraints on the cycle. However, 
blindly joining all constraints in the cycle can result in expo(cid:173)
nential costs for computing the tuples of the joined constraint, 
and a key property of the different decomposition methods is 
the  different techniques they use  to  select the  constraints to 
be joined. Gottlob et al. [2000] compared different decompo(cid:173)
sition methods with respect to their width, i.e., the maximum 
number of constraints to be joined, and found that hypertree 
decomposition is superior with respect to the width. Since hy(cid:173)
pertree decomposition can be seen as a generalization of the 

Based  on  the  above  definitions,  the  hypertree  decompo(cid:173)
sition  of a  hypergraph  H  is  defined  as  a  hypertree  HD  — 
where  T  —  (TV, E)  which  satisfies  the  following 

conditions: 

1.  For each edge 

that  var(h) 

edges(H),  there  exists a 

such 

2.  For each  variable 

\(p)}  induces a connected subtree of T. 

3.  For each 

4.  For each 

Moreover, we say that h 

edges(H)  is  strongly  covered 
in HD if there exists a vertex p  N such that  var(h) 
(p) 
.  A  hypertree  decomposition  HD  of a  hyper(cid:173)
and 
graph H is a complete decomposition of H if every edge of ff 
is strongly covered in  HD.  Note that it is always possible to 
make an incomplete decomposition complete by adding new 
vertices to  the  decomposition.  Gottlob et al. 
[1999b]  gave 
an algorithm for computing (complete) hypertree decomposi(cid:173)
tions. 

Note that unlike other decomposition methods such as bi-
connected component decomposition and hinge decomposi(cid:173)
tion,  there  is  in  general no  unique hypertree decomposition 
of a given CSP.  Figure  3  shows  four possible hypertree de(cid:173)
compositions for the hypergraph depicted in Figure 2. 

3  Diagnosis with TREE* 

To be self contained we briefly recapitulate the TREE* algo(cid:173)
rithm.  Stumptner and Wotawa  [2001] introduced the TREE* 
algorithm as an extension of the TREE algorithm.  Both al(cid:173)
gorithms work on tree-structured constraint systems.  As op(cid:173)
posed to TREE which requires the constraints to be mathe(cid:173)
matical functions, TREE* imposes no limitations on the con(cid:173)
straints.  TREE* uses the following auxiliary functions asso(cid:173)
ciated  to  constraints:  constr  denotes  all  tuples  of the  con(cid:173)
straint,  val denotes the tuples remaining after the application 
of TREE*,  diags  denotes  the  diagnoses  that  correspond  to 
a given tuple.  Accordingly, a CSP that is to be used for di(cid:173)
agnosis purpose has to represent not only the tuples for each 
constraint but also the diagnoses that correspond to each tu(cid:173)
ple. For example, the small circuit from Figure 1 can be rep(cid:173)
resented by the following CSP: 

DIAGNOSIS 

389 

(a) 

(b) 

(c) 

(d) 

Figure 3:  Alternate hypertree decompositions of Figure 2 

(HD, p,  diagSize) 

Algorithm  TREE* 
Computes all diagnoses up to a pre-specified size for a given 
tree-structured diagnosis system. 
Input:  A decomposition HD  with edges E, the root vertex p, 
and the pre-specified diagnosis  size  diagSize. 
Output: The diagnoses for each value tuple. 

The tuples of form  <x x...  x>  in the above tables are in(cid:173)
tended to match all tuples that are not explicitly given in the 
table.  Note that the constraint N\  represents a connection and 
is therefore assumed to be always correct.  Hence, it always 
returns the empty set as a diagnosis. 

The  original  description  of  the  TREE*  algorithm  was 
based on the  underlying assumption that the  leaf vertices of 
the tree correspond only to one diagnosis component. This as(cid:173)
sumption has an impact on the description of the algorithm, 
but  not  on the  empirical  results.  If the  constraints  given to 
the algorithm do not satisfy this requirement, diagnoses of a 
size (i.e., number of faulty components) larger than specified 
might be  returned because there is  no  way to  remove these 
diagnoses  from  the  set  of tuples.  The  requirement  did  not 
constitute a hindrance since  [Stumptner and Wotawa,  2001] 
did  not  deal  with  CSPs  resulting  from  decomposition.  To 
explicitly  generalize  TREE*  to  interact  with  decomposition 
algorithms, we here present a modified version that removes 
this requirement. 

The  following  operations are  used by TREE*:  semi-join 
for  constraints,  Cartesian  product  ( x)  for  combining 

two  sets  of diagnoses,  i.e., 

and cardinality restriction (|) for remov(cid:173)
ing diagnoses from a set of diagnoses with a size greater than 
the given value, i.e., 

The TREE* algorithm is called using the root p of the hy(cid:173)
pertree, i.e., the result of a decomposition, as argument. After 
execution, the computed diagnoses can be found in the diay 
column of the tuples associated with the root p. 

The TREE* algorithm correctly computes all diagnoses up 

to the given size if the following requirements arc fulfilled: 
1.  Every constraint is at least used in one of tree vertices. 
2.  The induced subtree for every variable is connected. 

Theorem  1  (Correctness)  The  TREE*  algorithm  correctly 
computes diagnoses up to the pre-specified size. 

Proof. The proof is by induction over the size of the tree. 
Base step  For  each  leaf of the  tree  only  lines  (l)-(7)  and 
(18)  of TREE*  are  executed. 
In  these  lines,  all  tu(cid:173)
ples that contradict the given observations and all diag(cid:173)
noses larger than the specified size are removed. Tuples 
with  no  corresponding diagnoses  are  removed.  These 
steps do not prevent TREE* from computing a diagno(cid:173)
sis.  Hence,  all  diagnoses (up to the pre-specified size) 
are computed for leafs. 

390 

DIAGNOSIS 

Hypothesis  We assume that TREE* correctly computes di(cid:173)

agnoses for trees of size smaller than n. 

Induction step  We  now  prove  that  TREE*  correctly  com(cid:173)
putes the diagnoses for trees of size n.  The steps (l)-(7) 
only  reduce the number of diagnoses.  Tuples that con(cid:173)
tradict the observations are removed. Diagnoses that are 
larger than the pre-specified values are removed and tu(cid:173)
ples with a corresponding empty diagnosis set are also 
removed because they have no influence on the result.  In 
step (9) the TREE* algorithm is called recursively.  Be(cid:173)
cause of our induction hypothesis, the algorithm returns 
correct diagnoses for each tuple.  It remains to prove that 
the combination of these tuples with the tuple of the cur(cid:173)
rent node is done correctly.  Since every tuple that joins 
(line (11)) is considered and since that every diagnosis is 
combined with every diagnosis of the child vertices (line 
(12)), this process must lead to a correct result.  Hence, 
TREE*  correctly  computes  the  diagnoses  in  step  n  as 
well. 

Using  the  same  arguments  as  above  we  can  show  that 
TREE* allows for computing all diagnoses providing that all 
the diagnoses for each vertex of the hypertree are computed. 
We omit the actual proof here. 

Theorem 2 (Completeness)  The  TREE*  algorithm  com(cid:173)
putes all diagnoses up to the pre-specified size. 

The remaining issue now is to determine the conditions that 
a decomposition method must satisfy in order to be used with 
TREE*.  Moreover,  we examine the computation of the join 
relation  for those tree  vertices that  comprise  more than  one 
constraint. 

4  Decomposition and Joining of Constraints 
As  an  example  we  take  the  hypertree  decomposition  result 
from  Figure  3(b). 
In  order to  apply  TREE*,  we  first  have 
to  compute  the  tuples  for  the  constraints  that  occur  in  one 
vertex,  e.g.,  {N2,  N3}.  The tuples can be  computed by first 
joining the constraints, and second computing the diagnoses 
diags  for  each  tuple  of the joined  constraint  by  combining 
the diagnoses associated with the corresponding tuples of the 
original  constraints.  The  following  algorithm computes the 
join relation for the constraint of a hypertree vertex p. 

Algorithm JoinRelation 
Computes the join for a hypertree vertex 
Input:  A hypertree vertex p. 
Output:  The  coiistr  and  diags  function of the  vertex p. 

(p) 

In the above algorithm the diags  function is  indexed with 
the corresponding vertex of the hypertree or the correspond(cid:173)
ing constraint.  The function 
stands  for relational join and 
for relational projection.  Diagnoses are only combined if a 
constraint is  fully captured by the given  vertex of the hyper(cid:173)
tree.  Otherwise,  it is not considered.  Since every constraint 
must  be  fully  captured  by  at  least  one  hypertree  vertex,  no 
information is lost by this procedure. 

For example, the join of constraints N2 and N3 would lead 
with 25 tuples (when re(cid:173)

to the following constraint 
taining the  V  constants, and of course 64 otherwise): 

If, as in this example, the join operation is a Cartesian Prod(cid:173)
uct,  the  resulting relation  is  of course  very  large.  However, 
during the computation of diagnoses using TREE*, many tu(cid:173)
ples can generally be eliminated because of the given obser(cid:173)
vations and the pre-specificd maximum diagnosis size. 

To illustrate this, assume now that we have a set of obser(cid:173)
vations 
and that we arc 
searching only for single diagnoses, i.e., diagSize  —  1.  Us(cid:173)
ing the decomposition from Figure 3(b) TREE* is first called 
with  the vertex  (constraint)  [N1].  After executing  lines  (1)-
(7)  (including the  semijoin that results  in the removal of tu(cid:173)
ples  that  do  not  fit  the  operations)  the  constraint  of  [N1]  is 
given by: 

TREE*  is  then  recursively  called  on  vertex 

resulting  in  the  following  relation,  which  is  substantially 
smaller than the computed join relation for this vertex, even 
after  ail  x  entries  of the  original  tables  have  been  replaced 
by either 0  or  1,  while  avoiding  duplicated  entries (first ta(cid:173)
ble), then we again recursively call TREE* which leads to the 
computation of the following relation for vertex 
(second 
table): 

DIAGNOSIS 

391 

In the next step TREE*  continues the computation at line 
(10) for vertex  [N2,  N3].  After combining the  diagnoses and 
removing the tuples with diagnoses larger than diagSize we 
get the  following relation for [ N2, N3]: 

resulting hypertree) the  decomposition  is  not cyclic,  or that 
there  exists a variable that is  used  in  both  sub-trees but not 
in the parent.  In the latter case, the process that computes a 
solution cannot view the  sub-trees as  independent problems 
any  more,  and  TREE*  will  fail  to  compute  a  correct  out(cid:173)
come.  The  other conditions  of the  hypertree decomposition 
can be relaxed without affecting the result.  If condition 3  is 
not obeyed, that means some nodes contain variables that are 
not  constrained.  This  may  affect the  efficiency  of the  algo(cid:173)
rithm (because the node relations include a cartesian product 
with the values of those variables) but not the correctness.  If 
condition 4  is  not obeyed,  this  means  that  some  variable  z 
such that 
is not contained in the 
constraint associated with p, i.e.  in relational terms z has been 
projected away.  This means that some subtree of T  is going 
to  be  less  restrictive  in  execution,  leading to  excess  tuples. 
However, since the decomposition is required to be complete, 
all  constraints that contain  z  must exist in  unprojected  form 
somewhere in  T. 

These two conditions are true for hypertree decomposition 
[Gottlob  et  ai,  1999a],  biconnected  components  [Freuder, 
1985], hinge decomposition  [Gyssens et al.,  1994], and tree 
clustering [Dechter and Pearl,  1989]. 

The following algorithm summarizes the combined use of 
TREE*  and  a  decomposition  method  to  compute  the  diag(cid:173)
noses for any CSP C of the form described in Section 3. Given 
a  CSP  C,  using  any  decomposition  method  that  fulfills  the 
properties of Theorem 3. 
(1)  apply decomposition to C, i.e., compute a 

hypertree (TV, E)  for the corresponding hypergraph of C 
for 

do JoinRelation(f) end  for; 

(2) 
(3) 
(4) 

TREE*(root(T)); 

return  diags(roof(T')); 

Hence,  only  the  diagnosis  {N4}  is  a  single  diagnosis  for 

our example. 

5  Putting it all together 
In  order to  make  use  of TREE*  for general  CSPs,  we first 
apply a decomposition method and then apply the algorithm 
to the resulting acyclic problem. In this section we summarize 
the requirements placed on the decomposition method. 
Theorem 3 TREE* computes all consistent diagnoses for a 
given  (possibly  cyclic)  CSP  (V,D, C),  if it  is  applied  to  the 
decomposition  HDof(V,D,C) 
that  was produced  by  a  de(cid:173)
composition method h with the following properties: 

1.  The decomposition result,  i.e., a hypertree HD, must be 

complete. 

2.  The vertices that use a given  variable 

a connected subtree of the hypertree HD. 

must form 

Proof (sketch):  We  consider each  condition  in  turn.  As 
discussed in the previous section, the decomposition method 
must produce a complete decomposition, i.e., every constraint 
must be strongly covered, as this is a prerequisite for the cor(cid:173)
rect working of the join algorithm.  Concerning condition 2, 
assume  that  this  condition  were  not  satisfied,  i.e.,  that  for 
some  Y, 
does not induce a connected 
subtree. This implies either that (if we have no sub-tree of the 

The pre-compilation performance of the overall  algorithm 
is that of the decomposition algorithm (examined in  [Gottlob 
et al., 2002]) together with the required costs for joining con(cid:173)
straints using the JoinRelation algorithm. The diagnosis time 
is  the  running time  of TREE*.  Performance  and  scalability 
TREE* have been studied in [Stumptner and Wotawa, 2001 ]. 
Note that the TREE* run time depends on the size of the rela(cid:173)
tions that are stored in the vertices of the resulting hypertree. 
This size depends on the number of constraints that must be 
joined,  and  this  in  turn  corresponds to  the  width  of the  de(cid:173)
composed system. Hence, using a decomposition method that 
provides a  smaller width  leads  to  hypertrees  where  TREE* 
performs better. 

6  Extension to Intensional Relations 
In  [Stumptner and  Wotawa,  2001],  we  mentioned  the  pos(cid:173)
sibility to  use  other than  extensional relations  for constraint 
specifications for the TREE and TREE* algorithm, e.g., com(cid:173)
puted functions or equations with infinite domains.  Such do(cid:173)
mains require a  different interpretation  of the  operators that 
are  used  for joining  the  relations  associated  with  nodes  in 
the tree.  Conceptually,  however,  nothing is  changed since, 
as  we will  show,  the  definition of the TREE*  algorithm fits 
the  requirements.  We  show  this  by  adopting  the  notation 
used  for the basic  computational operations of the aggrega(cid:173)
tion paradigm described in  [Mauss and Tatar, 2002]. 

392 

DIAGNOSIS 

The  Rich  Constraint  Languages  approach  described 
in  [Mauss  and  Tatar,  2002]  consists  of three  inference pro(cid:173)
cedures, which are applied to a set of constraints It.  The pro(cid:173)
cedure  i s C o n s i s t e nt  produces  a  proof tree  (called  ag-
gregation  tree)  that  derives  consistency  or  inconsistency.  If 
consistent,  then,  applied  to  the  root  of this  tree,  the  proce(cid:173)
dure  s o l ve  computes (nondetcrministically) a solution that 
assigns a  value to every  variable  in  R.  If not, the procedure 
XC1  (and  its  extension  XE1)  computes  the  set  of minimal 
conflicts  for  A. 

The aggregation operation that gives the tree its name con(cid:173)
sists  of joining two  constraints A and  B  (expressed  as  rela(cid:173)
tions or equations) and then projecting out all variables except 
the set of variables X needed for joining to other constraints: 
, this can be written using the 
semijoin operator that we have used above: 
. Thus, 
the TREE* algorithm can be changed to approximate the ag(cid:173)
gregation paradigm purely  by  letting  s  and  /  refer to  tuples 
(for extensional constraints) or equations, and changing line 

The  JoinRelation  Algorithm  is  changed  by  replacing  the 

first line by 

In  terms  of algorithmic  structure,  the  approach  of  [Mauss 
and Tatar, 2002] bears many resemblances to the decompose-
and-diagnose paradigm  used  in  LFattah  and  Dechter,  1995; 
Darwiche,  1998;  Stumptner and Wotawa,  2001].  Computa(cid:173)
tionally,  there  are  however significant  differences.  The  out(cid:173)
come  of  i s C o n s i s t e nt  is  a  proof tree  whose  leaves  are 
the base constraints of the original CSP, not a hypertree whose 
nodes arc the constraints of a backtrack-free CSP equivalent 
to  the  original  CSP.  The  search  for  a  diagnosis  consists  of 
running i s C o n s i s t e n t, computing minimal conflicts, and 
the hitting sets.  In our case, we compute the decomposition 
hypertree, then apply the JoinRelation algorithm  and  finally 
apply TREE* to compute the diagnoses directly. 

While  the  nondeterministic  selection  of  arbitrary  con(cid:173)
straints from the given CSP to produce a proof tree is quite ef(cid:173)
fective in general, as indicated by the authors, there are cases 
where the "width" of the generated problem leads to a drastic 
growth in intermediate relations.  It is this situation where an 
approach based on hypertree decomposition (which is gener(cid:173)
ally the method with  lowest widths) fits best to the strengths 
of the TREE*  algorithm. 

7  Conclusion 
In this paper we introduced a framework that allows for com(cid:173)
bining  various  structure  decomposition  methods  and  algo(cid:173)
rithms  for  solving  tree-structured  diagnosis  problems.  The 
framework  comprises two  parts. 
In  the  first  part,  we  show 
how to construct a tree-shaped constraint system that can be 
used  directly  by  TREE*  for computing  diagnoses.  For  this 
purpose  we  introduced  the  join  relation  of constraints. 
In 
the  second part,  we  state  the  properties  of a  decomposition 
method  so  that  it  can  be  combined  with  TREE*.  Finally, 
we  show the  suitability of the TREE*  framework for the ex(cid:173)
tension  to  infinite domains and  intensional  constraints (e.g., 
equations), by  adopting a basic  operation from another,  not 
hypertree based framework. 

References 
[Darwiche,  1998]  Adnan Darwiche.  Compiling Devices:  A 
Structure-Based Approach. In Proceedings of the Interna(cid:173)
tional  Conference  on  Principles  of  Knowledge  Represen(cid:173)
tation and Reasoning, pages  156-166,  1998. 

[de Kleer and Williams,  1987]  Johan de Kleer and Brian  C. 
Williams.  Diagnosing  multiple  faults.  Artificial  Intelli-
g^cr,32(l):97-130,1987. 

[de Kleer, 1991]  Johan de  Kleer.  Focusing on probable di(cid:173)
In  Proceedings  of the  National  Conference  on 
agnoses. 
Artificial  Intelligence  (AAAI),  pages  842-848,  Anaheim, 
July 1991. 

[Dechter and Pearl,  1989]  Rina  Dechter  and  Judea  Pearl. 
Tree  clustering  for  constraint  networks.  Artificial  Intel(cid:173)
ligence, 38:353-366, 1989. 

[Fattah and Dechter,  1995]  Yousri  El  Fattah  and  Rina 
In 
International  Joint  Conf.  on  Artificial 

Dechter.  Diagnosing  tree-decomposable  circuits. 
Proceedings  14th 
Intelligence, pages  1742 -  1748,  1995. 

LFreuder,  1985]  Eugene  C.  Freudcr.  A  Sufficient Condition 
Artificial  Intelligence, 

for  Backtrack-Bounded  Search. 
32(4):755-761,1985. 

[Gottlob et al., 1999a]  Georg  Gottlob,  Nicola  Leone,  and 
Hypertree  Decomposition  and 
Francesco  Scarcello. 
Tractable Queries.  In Proc.  18th ACM SIGACT SIGMOD 
SIGART Symposium  on  Principles  of Database  Systems 
(PODS-99), pages 21-32, Philadelphia, PA,  1999.  ' 

[Gottlob etal,  1999b]  Georg  Gottlob,  Nicola  Leone,  and 
Francesco  Scarcello.  On  Tractable  Queries  and  Con(cid:173)
In  Proc.  12th  International  Conference  on 
straints. 
Database  and  Expert  Systems  Applications  DEXA  2001, 
Florence, Italy, 1999. 

[Gottlob et al., 2000]  Georg  Gottlob,  Nicola  Leone,  and 
Francesco Scarcello.  A comparison of structural CSP de(cid:173)
composition  methods.  Artificial Intelligence,  124(2):243-
282, December 2000. 

| G o t t l o b e . , 2 0 0 2]  Georg  Gottlob,  Martin  Hutle,  and 
Franz Wotawa.  Combining hypertree, bicomp, and hinge 
decomposition.  In F.  van Harmelen, editor, Proceedings 
of the 15 th European Conference on Artificial Intelligence 
(ECAI-02), Lyon, July 2002. IOS Press. 

[Gyssens et  al,  1994]  Marc Gyssens,  Peter G. Jeavons,  and 
David  A.  Cohen.  Decomposing  constraint  satisfaction 
problems  using  database  techniques.  Artificial  Intelli(cid:173)
gence, 66:57-89,1994. 

[Mauss and Tatar, 2002]  Jakob  Mauss  and  Mugur  Tatar. 
Computing  minimal  conflicts  for  rich  constraint  lan(cid:173)
In  F.  van  Harmelen,  editor,  Proc.  ECAI,  Ams(cid:173)
guages. 
terdam, 2002. IOS Press. 

[Reiter,  1987]  Raymond  Reiter.  A  theory of diagnosis from 
first  principles.  Artificial Intelligence,  32(l):57-95,1987. 
and 
Diagnosing  tree-structured  systems. 

[Stumptner and Wotawa, 2001]  Markus 

Franz  Wotawa. 
Artificial  Intelligence,  127(1):  1-29,2001. 

Stumptner 

DIAGNOSIS 

393 

