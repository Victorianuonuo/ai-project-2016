Propagate the Right Thing: 

How Preferences Can Speed-Up Constraint Solving 

Christian Bessiere 

Anais Fabre* 

Ulrich Junker 
ILOG S.A. 

1681, route des Dolines 

F-06560 Valbonne 
ujunker@ilog.fr 

LIRMM-CNRS (UMR 5506) 

161, rue Ada 

F-34392 Montpellier Cedex 5 
(bessiere,fabre}@lirmm.fr 

Abstract 

We present  an  algorithm  Pref-AC that limits arc 
consistency (AC) to the preferred choices of a tree 
search procedure and that makes constraint  solv(cid:173)
ing  more  efficient  without  changing  the  pruning 
and shape of the search tree.  Arc consistency thus 
becomes more scalable and usable for many real-
world constraint satisfaction problems such as con(cid:173)
figuration and scheduling.  Moreover, Pref-AC di(cid:173)
rectly  computes  a  preferred  solution  for tree-like 
constraint satisfaction problems. 

Introduction 

1 
In  the  last two  decades,  considerable  research  effort  in  Al 
has been spent on studying the complexity of reasoning and 
problem solving, and the identification of tractable cases has 
become an important goal of this research.  However, even 
if a problem can be solved by a polynomial algorithm, or if 
search effort can be reduced by polynomial algorithms, this 
might  not  be  sufficient  for real-world  AI  systems  that face 
challenges such as interactivity and real-time. We give some 
examples from constraint satisfaction,  where achieving arc 
consistency might be too costly, although it is tractable: 

1. Web-based  configuration  systems  must  provide  a  re(cid:173)
sponse in a few seconds while serving multiple users. 
Although arc consistency (AC) is an appropriate tech(cid:173)
nique to handle compatibility constraints, it will be too 
expensive in presence of large product catalogs. 

2.  Constraint-based  approaches  to  problems  such  as 
scheduling, vehicle routing, and personnel planning of(cid:173)
ten only maintain bound consistency in constraints in(cid:173)
volving time or other variables with large domains.  As 
a consequence, complex rules on breaks, rest-times, and 
days-off provide only a poor propagation, which could 
be improved by arc consistency. 

These examples illustrate that domain reduction does not de(cid:173)
velop its full power in many real-world applications of con(cid:173)
straint programming. Pruning power and, indirectly, solution 
quality are traded against short response times. In certain cir(cid:173)
cumstances, such a trade-off can be avoided if the system fo(cid:173)
cuses on the right deductions and computations. In this paper, 
* A. Fabre's work has been carried out during a stay at ILOG. 

we argue that preferences are one possible way for achiev(cid:173)
ing this.  As stated by Jon Doyle [Doyle, 2002], preferences 
can play different roles and need not only represent desider(cid:173)
ata or user preferences. Preferences can also control reason(cid:173)
ing meaning that only preferred inferences and domain reduc(cid:173)
tions are made. Non-interesting deductions are left apart, but 
may become preferred if additional information is added. 

We  can  easily  apply  this  idea  to  typical  backtrack  tree 
search algorithms that maintain arc consistency when solv(cid:173)
ing a constraint satisfaction problem. The crucial question is 
whether such an algorithm needs to achieve full arc consis(cid:173)
tency and to remove all values that are not in the maximal 
arc-consistent domains.  In  [Schiex  el al,  1996], it has been 
shown  that the fails of the algorithm can be preserved if it 
simply constructs some arc-consistent domains, thus reduc(cid:173)
ing the computation effort in average. In this paper, we show 
that the search algorithm can preserve its search strategy and 
the overall pruning if 1.  the search algorithm uses a vari(cid:173)
able and value ordering heuristics that can be described by 
(static) preference ordering between variables and values and 
2. we construct some arc-consistent domains that contain the 
preferred values.  The first condition is, for example, met by 
configuration problems [Junker and Mailharro, 2003].  The 
second condition needs some careful adaption of the defini(cid:173)
tion of arc consistency, which will be elaborated in this paper. 
We can thus cut down the propagation effort in each search 
node without changing the search tree, which leads to an over(cid:173)
all  gain  if the search tree will  not be explored completely. 
This happens if we are interested in one solution, the best so(cid:173)
lution in a given time frame, or preferred solutions as defined 
in [Junker, 2002].  Arc consistency thus becomes more scal(cid:173)
able and less dependent on the size of domains, which opens 
exciting perspectives for large-scale constraint programming. 
We first introduce preferences (Section 2), use them to de(cid:173)
fine a directed constraint graph (Section 3), and discuss arc 
consistency for preferred values  (Sections 4  and  5).  After 
introducing preferred supports (Section 6), we present the al(cid:173)
gorithm Pref-AC (Section 7). 
2  Preferred Solutions 
In this paper, we consider constraint satisfaction problems of 
the following form. Let X be a set of variables and V be a set 
of values.  A constraint c of arity kc has a sequence of vari(cid:173)
ables X(c)  = {x1 (r),..., Xkt (c)} from X and a relation Rc 

CONSTRAINTS 

191 

that  is  a set of tuples  from  
The  triple  ( X ' , D,  C)  is  then  called  a  constraint  network. 

.  Let C  be a set of constraints. 

A  solution  of  a  constraint  network  is  a  mapping  v  of  the 
variables  X  to  the  values  in  V  such  that each constraint is sat(cid:173)
isfied, i.e., 
for all  constraints 
c.  The  constraint  satisfaction  problem  (CSP)  involves  finding 
a  solution  of a  constraint  network. 

Alternatively,  we can  represent  the tuples  by  sets of assign(cid:173)
ments  of the  form  x  =  v  between  a  variable  :/:  and  a  value  v: 
then  let  f be  the 
if t  is  a tuple of the  form 
set  of  assignments 
.  Furthermore, 
let  Rc  be  the  set  of all  /.  such  that  t  is  in  Rc.  This  represen(cid:173)
tation  will  facilitate  definitions  and  permits  a  straightforward 
logical  characterization  of a  constraint  c: 

(1) 

We  further suppose  that the  following  kinds  of preferences 
are given.  For each variable  x,  we introduce a strict partial or(cid:173)
der 
among  the  possible  values  for  x.  This  order 
can  represent  user  preferences  as  occurring  in  configuration 
problems  (cf. 
[Junker  and  Mailharro,  2003]).  For  example, 
the user might prefer a red car to a white car.  Projecting pref(cid:173)
erences  on  criteria  to  decision  variables  [Junker,  2002]  also 
produces  such  an  order  (e.g. 
if  price  is  minimized  then  try 
cheaper choices  first).  Furthermore,  we  consider a  strict  par(cid:173)
tial  order 
between  variables.  For example,  we 
may state that choosing a color is more  important than  choos(cid:173)
ing  a  seat  material  and  should  therefore  be  done  first.  In  the 
sequel,  we  suppose  that  the  search  procedure  follows  these 
preferences as described  in  [Junker and Mailharro,  2003]  and 
always  chooses  a 
value  for 
x.  These  preferences  are  given  statically  and  thus  correspond 
to  a  static  variable  and  value  ordering  heuristics,  which  are 
usually  sufficient  for  configuration  problems. 

variable  and 

We  now  use  the  preferences  to  define  a  preferred  solu(cid:173)

in  form  of  total  orders  

of  the  variables  in  

tion.  First  of all  we  choose  a  linearization  of the  orders 
and 
that  are  super(cid:173)
sets  of the  strict  partial  orders.  Then  we  consider  a  ranking 
that  corresponds  to  the 
We  then  consider two 

order 
solutions  v1  and  v2  and  compare  them  lexicographically 

> 

(2) 
Definition  1  A  solution  v  of  a  constraint  network  P  := 
is  a  preferred  solution  ofV  iff there  exist  lineariza­
(X,D,C) 
tions 
is  the 
the  lexicographical  order  defined  by 
best  solution  of  P  w.r.t. 

These  preferred  solutions  correspond  to  the  extreme  solu(cid:173)
tions  in  [Junker,  20021  that  are  obtained  if  all  variables  are 
criteria.  If the  search  procedure  follows  the  preferences  then 
its  first  solution  is  a  preferred  solution.  Hence,  the  notion  of 
a  preferred  solution  helps  us  to  forecast  the  first  solution  in 
certain  cases. 

Figure  1:  Directed constraint graphs. 

3  Preference-based Constraint Graph 

In  order  to  find  a  preferred  solution,  the  search  procedure 
chooses  values  for  more  important  variables  first.  We  will 
see  later that,  in  some cases, we can anticipate a preferred so(cid:173)
lution  and  construct  it  by  a  constraint  propagation  procedure 
if this  procedure does not only follow  the constraints,  but also 
the order among  the  variables used  by the  search procedure. 
In  order  to  illustrate  this,  consider  the  bipartite  constraint 
graph  that  connects  the  constraints  with  their  variables.  Sup(cid:173)
pose  that  a variable  x  is  connected  via  a constraint c to a  less 
important  variable  y.  Search  will  then  assign  a  value  to  x 
and  cause  a  domain  reduction  of y.  We  can  thus  say  that  the 
preferences  ■<#  among variables impose an order on the con(cid:173)
straint  graph.  For  example,  we  will  say  that  the  arc  between 
x  and  c  leads  from  x  to  c  and  the  arc  between  y  and  c  leads 
from c to y. 

We  generalize  this  idea  for  arbitrary  constraints  and  par(cid:173)
tial  orders.  For  each  constraint  r,  we  consider  the  -<.v-best 
variables  in  X(c)  and  call  them  input  variables.  The  other 
variables  are  called  output  variables.  Arcs  lead  from  input 
variables  to  a  constraint  and  from  there  to  the  output  vari(cid:173)
ables. 

Definition  2  Let  ( X , D , C)  be  a  constraint  network  and 
be  a  strict  partial  order  between  the  variables  X.  A  variable 
x  of  a  constraint  c  is  called  input  variable  of  c  iff  there  is 
no  other  variable  y  of  c  s.t. 
x.  A  variable  x  of c  is 
called  output  variable  of c  iff it  is  not  an  input  variable  of c. 
The  directed  constraint  graph  of the  CSP  is  a  bipartite  graph 
and  the  set  of arcs  (x, c)  s.t.  x  is  an 
having  the  nodes 
input  variable  of c  and  (c,  y)  s.t.  y  is  an  output  variable  of c. 

Each  constraint  can  have  several  input  and  several  output 
variables  (cf.  figure  1).  If its  variables  are  not comparable  at 
all,  then  the constraint has no output variable, and it is a sink 
of  the  directed  graph.  However,  each  constraint  has  at  least 
one  input  variable.  As  a consequence,  no constraint can  be a 
source of the directed graph.  In general, the graph is not guar(cid:173)
anteed  to  be  acyclic,  but  it  satisfies  the  following  properties 
which  are needed  for our proofs:  1.  A ll  
variables  of 
the  set X  are  sources  of the  constraint graph  since  they cannot 
be  an output variable of any constraint.  However there can be 
variables.  2.  If x  is  a  ranking  of 
sources that are  not 
the  variables  X  that  is  a  linearization  of  
then  each output 
variable  of each  constraint  is  preceded  by  at  least  one  input 
variable  of the  same  constraint  in  the ranking. 

192 

CONSTRAINTS 

4  Arc Consistency 
A  typical  systematic  search  procedure  for  solving  CSPs  pro(cid:173)
ceeds as  follows.  In  each  search  node,  it picks an  assignment 
x  —  v  for  such  a  variable  and  creates  two  successor  nodes, 
one  for  x  =  v  and  one  for  
Throughout  the  paper, 
we  assume  that  a  variable  x  is  eliminated  from  the  CSP  of a 
successor node  by  a  preprocessing  step  iff it  has  only  a  single 
possible  value.  Usually,  the  search  procedure  will  not  select 
an  arbitrary  assignment  from  the  set  A  of  all  assignments, 
but  tries  to  anticipate  certain  cases  where  the  sub-tree  of  an 
assignment  does  not  contain  a  solution. 
If  such  an  assign(cid:173)
ment  is  detected  it  is  eliminated  from  A.  Hence,  the  search 
procedure maintains a set 
of possible  assignments  and 
considers  only  elements  of A.  Each  solution  can  be  charac(cid:173)
terized  by  a subset of A  that assigns exactly  one  value  to  each 
variable  and  that  satisfies  all  constraints.  As  a  consequence, 
if a  variable  x  has  no  assignment  in  A  then  no  solution  exists 
and  the  search  will  backtrack.  In  the  sequel,  we  write  Ax  for 
the set 
of possible  values  for  x  in  A. 
Assignments  can  be  eliminated  from  A  if they  lack  a  sup(cid:173)

port on  a constraint: 

Definition  3  A  set  of  assignments  S  is  a  support  for  x  —  v  in 
c  iff  1. 

is  an  element  of 

and  2. 

Let 
be  the  set  of  supports  for  x  =  v  in  c.  In  this  pa(cid:173)
per,  we  are  interested  in  search  procedures  that  maintain  arc 
consistency,  i.e.  that work  with  a  set A  where  all  assignments 
have  supports  S  that  are  subsets  of  A  and  this  on  all  relevant 
constraints: 

Definition  4  Let  A  be  a  set  of assignments.  A  subset  A  of A 
is  an  arc-consistent  set  of A  iff  I.  Ad 
is  non  empty for  any 
and  all  constraints  c  of 
x,  there  exists  a  support  S for  (x  =  v)  in  c  such  that  S  is  a 
subset  of  A. 

If  an  arc-consistent  set  A  contains  a  single  assignment  for 
each  variable  then  A  corresponds  to  a  single  solution.  If  no 
arc-consistent  set exists  then  the  CSP  has no  solution.  Other(cid:173)
wise,  there  is a unique  maximal  arc-consistent  set,  which is a 
superset  of all  arc-consistent  sets,  including  the  solutions. 

Alternatively,  we can consider a set  

of some  assignments 

for which  we  know  that  they  do  not  belong  to  any  solution: 

(3) 

This can  easily  be translated to a reflexive and monotonic  op(cid:173)
erator  that  eliminates  additional  assignments: 

Fixed-point  theory  then  tells  us  that  the  transitive  closure  of 
this operator is the unique minimal  set  
satisfying  equation 
3.  As  a  consequence,  the  set  A*  of all  assignments  that  are 
not eliminated (i.e.,  
is the unique maximal set 
satisfying  item 2 of def.  4.  If each  variable  has  an  assignment 
in  A*  then  A*  is  the  maximal  arc-consistent  assignment. 
If 
some  variable  has  no  assignment  in  A*  no  arc-consistent  as(cid:173)
signment exists.  In  this case,  no solution exists. 

Figure  2:  Activating  best  values  and  their supports. 

5  Arc Consistency for Preferred Values 
Maintaining arc consistency prunes the search tree as follows: 
PI 
if the current CSP is not  arc-consistent then  a fail  occurs. 
P2  if a value  v  is  not arc-consistent for a variable  x  then  the 
search  procedure  will  not assign  v  to x  inside the current 
subtree. 

In  general,  it  is  desirable to eliminate  as  many  values as  pos(cid:173)
sible  and  to  determine  A*  by  applying  an  algorithm  of  the 
AC-family.  The  worst-case  complexity  is  
for 
binary  constraints,  if domains  contain  thousands  or  more  el(cid:173)
ements  as  is  the case  for typical  scheduling  problems  and  for 
configuration  problems  with  large  catalogs,  then  maintaining 
arc  consistency  is  no  longer  feasible  in  practice. 

Interestingly,  it  is  not  necessary  to  eliminate  all  assign(cid:173)
ments  of  A  -  A*. 
[Schiex  et  al.,  1996]  try  to  construct  a 
small  arc-consistent  set  A.  If this  succeeds  then  prunning  rule 
PI  cannot be triggered.  This can  lead to saving time  in  search 
nodes  that  are  arc-consistent.  We  now  want  to  extend  this 
policy  to  pruning  rule  P2  in  the  case  that  the  original  search 
procedure  uses  the  given  preferences  between  variables  and 
values  in  order  to  select  an  assignment.  In each  search  state, 
the  search  procedure  will  pick  
variable  and  try out 
its  possible  values  starting  with  the  best  value 
is  not  in  the  maximal  arc-consistent  set  A*  then  we  must  en(cid:173)
sure  that  it will  be eliminated when  constructing the  subset A. 
However,  if 
then  we  must  ensure  that  it  will 
be  in  the  subset  A. 

If  x  is  a 

variable  and 

Instead  of doing  a  pure  elimination  process,  we  interleave 
construction  and  elimination  steps  and  determine  a  set  F  of 
activated assignments,  called  focus,  and  a  set 
of  eliminated 
assignments.  Both  sets  will  grow  during  the  process  and  our 
purpose  is  to  obtain 
as  arc-consistent  set.  This  set 
is  sufficient  for  our  search  procedure  if  some  properties  are 
satisfied:  1. 
among  the  non-eliminated  values  of  x  then  the  search  proce(cid:173)
dure might pick x  —  v as next assignment.  Hence, we have to 
activate  it.  2.  If an  activated  assignment does  not  have  a  sup(cid:173)
port on a constraint c then  it has to be eliminated.  3.  The sup(cid:173)
ports  for  the  activated,  but  non-eliminated  assignments  must 
only  contain  activated  and  non-eliminated  elements.  4.  We 
need  to  guarantee  that 
contains  at  least  one  value  per 
variable  if an  arc-consistent  set exists.  Since  all  variables  can 
be  reached  from  the  sources  via constraints,  we  activate  best 
values  for all  sources  of the  directed  constraint  graph. 

CONSTRAINTS 

193 

194 

CONSTRAINTS 

build  an  arc-consistent  set of assignments  that is  not  neces(cid:173)
sarily maximal.  We base Pref-AC on AC-6 [Bessiere,  1994] 
for keeping the discussion simple, although we could exploit 
the bi-directionality of supports  [Bessiere  et al.,  1999]. 

AC-6  assigns  an  ordering  of the  values  in  the  domain  of 
every variable x1, checks  one support (the first one or small(cid:173)
est  one  with  respect  to  the  ordering)  for  each  assignment 
(xi  =  a)  on each  constraint 
to prove that  (x1  =  a) 
is  currently  viable.  When  (xj  =  b)  is  found  as  the  small(cid:173)
est  support  of  (xi  —  a)  on  c{xiXj),  (xi  =  a)  is  added  to 
the  list of assignments  currently having  (xj  =  b) 
as  smallest  support.  If b  is  removed  from  the domain  of Xj 
then AC-6 looks for the next support in the domain of  xj  for 
each assignment 

Pref-AC uses the domain order 

, a chosen linearization 
of 
when looking for supports in the domain of a variable 
xi.  Furthermore,  Pref-AC  seeks  supports  only  for elements 
of  A,  the  current  set  of activated  and  non-eliminated  values 
(i.e., 

uses following data structure: 

•  Each variable x,  has a fixed initial domain  Dx,  ordered 
containing  all  values  from  V  except  those 

by 
that violate unary constraints on  xi.  The set 

contains the values  of 
been removed by arc consistency. 

that have not yet 

•  A  is the  arc-consistent set built by the algorithm. 
•  For each 

contains the 

assignments that are currently supported by  (xi  =  a). 

•  The  set  Pending  contains  all  the  4-tuples  (xia,Xj,b) 
such  that  a  support  for  (xt  =  a)  has  to  be  sought  on 
r ( xi, xj).
this  means  that  all  values  of Xj 
better than b have  already been removed. 

 

Pref-AC works as follows. We start by initializing 

Pref-AC uses two subprocedures (Algorithm 1).  Procedure 
A c t i v a t e ( xia)  adds  an  assignment  (xi  =  a)  to  A,  the 
set of current activated values.  It  initializes  its data structure 
CS,  and puts in  Pending all the information needed to look 
for  supports  for  (x,  =  a)  on  the  constraints  involving  xt. 
Function BestSup(x,, a, xj , b, B) looks for the best support 
for  (xi  =  a)  in  D  which  is  less  preferred  than  b  (we  know 
there is no support in B better than or equal to b).  B is 
or  AXj  depending on the status of  xi  (input variable or not). 
to 
DX, 
for each x1 (line  1  of Algorithm 2).  We activate  the best 
value of the best variable (line 2). Then, 4-tuples (x1, a,  xj,  b) 
are taken from the Pending set (line 4), and if (x1 = a) is still 
active (line 5), we must seek a (new) support c for it.  If x1 is 
an input variable of 
because 
we have to ensure that it will be a preferred support (lines 6 to 
7).  Otherwise, we first seek a support c among the activated, 
but non-eliminated elements (line 8).  If none exists, we seek 
a new best support c (line  10) following def.  6. If c exists, we 
activate  it  if not  yet done,  and  store  the  fact  that  it supports 
(x1  =  a)  (lines  11  to  13).  If no support exists for (xt  —  a), 
we  remove  it  from 
is empty, a 
wipe out stops the procedure (line  15).  If  xi  is a source of the 
is not in 
directed constraint graph and the best value  of 
, the best value 

we seek the support in 

and  A  (line  14).  If 

was the best of  AX,  and 

Figure 4:  A preferred solution as stable activation. 

Given a preferred solution, we cannot guarantee that each 
assignment has  a preferred  support  in all  constraints.  How(cid:173)
ever,  if certain  assignments  in  a  solution  S  have  preferred 
supports then S is preferred solution: 
Proposition 5  Let  S  be  a  solution  of V.  Suppose  that 
and  all 
are strict total orders.  If each assignment x  —  v 
to a source x of the direct constraint graph  is a  best assign(cid:173)
ment for x  in  the  unique  maximal arc-consistent set  A*  and 
all  activated  assignments  to  input  variables  of a  constraint 
c  have  a preferred support  on  c  in  S  then  S  is  a preferred 
solution of  P. 

When constructing a stable activation, we choose preferred 

and  all 

supports since this may result in a preferred solution: 
Proposition 6  Suppose  that 
are  strict  total 
orders.  Let  S1,...,  Sm  be an  activation  sequence and let 
be defined as in def  6.  If J.  each S1, is a preferred 
support for some x = v on some constraint c s.t. x is an input 
variable  of c  or x  =  v  is  unsupported on  c  in 
and 2. 
preferred solution of  P. 

The first condition in proposition 6 can be satisfied by al(cid:173)
ways activating preferred supports. The second condition can 
be met by CSPs of a special structure.  For example, consider 
a  binary  constraint  network  such  that  its  directed  constraint 
graph forms a tree (cf.  figure  4).  In  this case,  we only acti(cid:173)
vate  supports  for  assignments  to  input  variables,  but  not for 
assignments to output variables, since each variable can only 
be  an  output  variable  of a  single  constraint.  This  result  is, 
for  example,  interesting  for  certain  car  configuration  prob(cid:173)
lems  and  permits  us  to  efficiently  take  into  account  certain 
user preferences. 

Preferred solutions are also obtained in trivial cases: 

Proposition 7  Suppose  that 
are  strict  total 
orders. 
If there  is  a  preferred  solution  containing  all  best 
values  of all  variables  in  A  then  it  is  equal  to  all  activations 
produced by preferred supports. 

and  all 

7  Algorithm Pref-AC 
In this Section, we present Pref-AC, an algorithm for comput(cid:173)
ing an arc-consistent set A  from a binary constraint network 
[X,D,C).  This algorithm activates supports for unsupported 
elements and  meets the requirements of definitions 5  and 6, 
and  proposition  6.  An  algorithm  for  non-binary  constraints 
can be derived from this one.  Pref-AC follows the princi(cid:173)
ples  of lazy  arc  consistency  [Schiex  et al,  1996]  in  order  to 

CONSTRAINTS 

195 

is a source of 

The  space  complexity  of Pref-AC  is  the  same  as  AC-6, 
namely 
since  in  the  worst case,  all  the  values 
are  activated  and  have  a  support  stored  on  each  constraint. 
The time complexity is also bounded above by that of AC-6, 
n a m e l y s i n ce for each value in each domain, we 
perform at most 

constraint checks on each constraint. 

8  Conclusion 
We  have  shown  that  it  is  sufficient  to  maintain  an  arc-
consistent set for the preferred choices of a search procedure. 
This can significantly speed up constraint solving if the vari(cid:173)
able and value ordering heuristics of the search procedure can 
be described by preferences as is the case for typical configu(cid:173)
ration problems.  We developed an algorithm called Pref-AC 
for  achieving  this  reduction  and  are  currently  testing  it  for 
configuration problems with large domains. 

Many  real-world  applications  of  constraint  programming 
suffer  from  insufficient  propagation,  since  most  approaches 
support  only  bound  consistency  for  crucial  constraints  such 
as  precedences  of activities,  resources,  and  rest-time  rules. 
Adapting algorithm Pref-AC to those constraints provides an 
interesting  future  perspective  for  improving  constraint  solv(cid:173)
ing in areas such as scheduling, personnel planning, and other 
logistics  applications.  Future  work  will  be  devoted  to  im(cid:173)
prove Pref-AC such that it directly finds a preferred solution 
if the problem  structure permits  this  (e.g.  by  activating pre(cid:173)
ferred supports that are common to several variables). 

Acknowledgements 
We  would  like  to  thank  Jean-Charles  Regin  and  Olivier 
Lhomme for very helpful discussions. 

References 
[Bessiere et al., 1999]  C.  Bessiere,  E.C.  Freuder,  and  J.C. 
Regin.  Using  constraint  metaknowledge  to  reduce  arc 
consistency  computation.  Artificial  Intelligence,  107:125-
148, 1999. 

[Bessiere,  1994]  C.  Bessiere. 

Arc-consistency  and  arc-
consistency  again.  Artificial  Intelligence,  65:179-190, 

[Doyle, 2002]  Jon Doyle.  Preferences:  Some problems and 
prospects.  In AAAI-02  Workshop on Preferences in Al and 
CP: Symbolic Approaches. AAAI Press, 2002. 

[Junker and Mailharro, 2003]  Ulrich  Junker  and  Daniel 
Mailharro.  Preference programming:  Advanced problem 
solving for configuration.  AI-EDAM,  17(1), 2003. 

[Junker, 2002]  Ulrich  Junker.  Preference-based  search  and 
In  AAAI-02,  pages  34-40, 

multi-criteria  optimization. 
Menlo Park, CA, 2002. A A AI Press. 

[Schiex et al,  1996]  T.  Schiex,  J.C.  Regin,  C.  Gaspin,  and 
In  AAAI-96,  pages 

G.  Verfaillie.  Lazy  arc  consistency. 
216-221,  1996. 

If Pref-AC  terminates  with  an  empty set of pending prop(cid:173)
agations  (line  3),  A  only  contains  assignments  for  which  a 
support has been activated on each constraint (because of line 
12), and not deleted (because of line 19). In addition, this sup(cid:173)
port is the preferred support for this assignment on this con(cid:173)
straint if the variable was an input variable for the constraint 
(because of line 7 and the way BestSup works).  We know 
A contains at least an assignment per variable because of the 
activation of supports.  Therefore,  A is an arc-consistent set. 
And because of lines  16-18, we know that for each Xi  which 

196 

CONSTRAINTS 

