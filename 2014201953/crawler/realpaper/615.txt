Automatic Video Interpretation: 

A Novel Algorithm for Temporal Scenario Recognition 

Van-Thinh  VU,  Franeois  BREMOND,  Monique THONNAT 

Project  ORION  of I.N.R.I.A.  Sophia  Antipolis, 

2004 route des Lucioles, BP93-06902 Sophia Antipolis Cedex, France. 

{Thinh.Vu,Francois.Bremond,Monique.Thonnat}@sophia.  inria.fr 

http://www-sop.inria.fr/orion/orion-eng.html 

Abstract 

This  paper  presents  a  new  scenario  recognition 
algorithm  for  Video  Interpretation.  We  represent 
a  scenario  model  by  specifying  the  characters 
involved  in  the  scenario,  the  sub-scenarios  com(cid:173)
posing  the  scenario  and  the  constraints  combin(cid:173)
ing  the  sub-scenarios.  Various  types  of  con(cid:173)
straints  can  be  used  including  spatio-temporal 
and 
logical  constraints.  In  this  paper,  we  focus 
on  the performance  of the  recognition  algorithm. 
Our  goal  is  to  propose  an  efficient  algorithm  for 
processing  temporal  constraints  and  combining 
several actors defined within the  scenario.  By ef(cid:173)
ficient  we  mean  that  the  recognition  process  is 
linear  in  function  of the  number  of sub-scenarios 
and in  most  of the  cases  in  function  of the  num(cid:173)
ber  of  characters.  To  validate  this  algorithm  in 
term  of  correctness,  robustness  and  processing 
time  in  function  of scenario  and  scene  properties 
(e.g.  number  of persons  in  the  scene),  we  have 
tested  the  algorithm  on  several  videos  of a  bank 
branch  and  of  an  office,  in  on-line  and  off-line 
mode  and  on  simulated  data.  We  conclude  by 
comparing  our  algorithm  with  the  state  of the  art 
and  showing  how 
the  definition  of  scenario 
models  can  influence  the  results  of the  real-time 
scenario recognition. 

the  scene  and  a  stream  of individuals  tracked  by  a  vision 
module. 

To solve scenario recognition  issues, we  first  propose a 
language  to  describe  scenario  models  and  second  a  tem(cid:173)
poral  constraint  resolution  approach  to  recognize  in  real-
time  scenario  occurrences.  Our  scenario  representation  is 
mainly  based  on  the  representation  of  [Vu  et  al,  2002] 
and  inspired  by  the  work  of [Ghallab,  1996].  In  this  pa(cid:173)
per,  we  focus  on  the  optimization  of  the  recognition 
method.  We  first  enhance  the  processing  of temporal  op(cid:173)
erators  by  pre-compiling  scenario  models  to  decompose 
them  into  simpler  scenario  models.  By  this  way,  the  sce(cid:173)
nario  recognition  algorithm  uses  a  linear  search  com(cid:173)
pared  to  an  exponential  search  for  non-compiled  scenar(cid:173)
ios.  Secondly,  we propose a novel  algorithm to recognize 
composed  scenarios that  takes  advantages  of the  actors  of 
its  sub-scenarios  when  they  are  recognized  instead  of 
trying all  combinations  of actors as this  is often  the  cases 
for  similar  state  of the art algorithms. 

We  present  in  section  2  some  related  works.  Our  sce(cid:173)
nario representation  is described  in  section  3.  The recog(cid:173)
nition  algorithm  is detailed  in  section  4.  We  conclude our 
paper  by  showing  experimental  results  to  validate  this 
new algorithm. 

A priori knowledge 

Introduction 

1 
A  problem  of current  focus  in  cognitive  vision  is  Auto(cid:173)
matic  Video  Interpretation.  The  goal  is  to  develop  a  sys(cid:173)
tematic  methodology  for  the  design,  implementation  and 
integration  of  cognitive  vision  systems  for  recognizing 
scenarios  involved  in  a  scene  depicted  by  a  video  se(cid:173)
quence.  An  Automatic  Video  Interpretation  System  as 
described  in  Figure  1,  takes  as  input  (1)  a  priori  knowl(cid:173)
edge  containing  scenario  models  predefined  by  experts 
and  the  3D  geometric  and  semantic  information  of  the 
observed  environment  and  (2)  video  streams  acquired  by 
the  camera(s).  The  output  of the  system  is  the  set  of rec(cid:173)
ognized  scenarios at  each  instant.  In  this paper,  we  focus 
on  the  module  of scenario  recognition.  The  scenario  rec(cid:173)
ognition  module  takes  as  input  the  a  priori  knowledge  of 

Figure 1. Overview of an Automatic Video Interpretation System. 

TEMPORAL  REASONING 

1295 

2  Related  works 
Since  the  years  90s,  a  problem  of focus  in  cognitive  vi(cid:173)
sion  has  been  Automatic  Video  Interpretation.  There  are 
now  several  research  units  and  companies  defining  new 
approaches  to  design  systems  that  can  understand  human 
activities  in  dynamic  scenes.  Three  main  categories  of 
approaches  are  used  to  recognize  temporal  scenarios 
based  on  (1)  a  probabilistic/neural  network  combining 
potentially  recognized  scenarios,  (2)  a  symbolic  network 
that  Stores Totally  Recognized  Scenarios  (STRS)  and  (3) 
a  symbolic  network  that  Stores  Partially  Recognized  Sce(cid:173)
narios  (SPRS). 

For  the  computer  vision  community,  a  natural  ap(cid:173)
proach  consists  in  using  a  probabilistic/neural  network 
[Oliver  and  Pentland,  2000].  The  nodes  of this  network 
correspond  usually  to  scenarios  that  are  recognized  at  a 
given  instant  with  a  computed  probability.  For  example, 
[Howell  and  Buxton,  2002]  proposed an  approach  to rec(cid:173)
ognize a  scenario  based  on  a neuronal  network  (time de(cid:173)
lay  Radial  Basis  Function).  [Hongeng  et  al,  2000]  pro(cid:173)
posed  a  scenario  recognition  method  that  uses  concur(cid:173)
rence  Bayesian  threads  to  estimate  the  likelihood  of po(cid:173)
tential  scenarios.  Because  video  processing is  very  sensi(cid:173)
tive to noisy images, these probabilistic  methods are  use(cid:173)
ful  to give  an  interpretation  of the  scene  while taking  into 
account  the  stochastic  variations  of  the  analysis.  In  our 
case,  we  use  classical  filtering  techniques  to  get  rid  off 
these  variations  and  to  obtain  coherent  data  that  can  be 
associated with  symbolic  values. 

For  the  artificial  intelligent  community,  a  natural  way 
to  recognize  a  scenario  is  to  use  a  symbolic  network 
which  nodes  correspond  usually  to  the  boolean  recogni(cid:173)
tion  of scenarios.  For  example,  [Rota  and Thonnat,  2000] 
used  a  declarative  representation  of scenarios  defined  as 
a  set  of  spatio-temporal  and  logical  constraints.  They 
used  a  traditional  constraint  resolution  technique  to  rec(cid:173)
ognize  scenarios.  To  reduce  the  processing  time  for  the 
recognition  step,  they  proposed  to  check  the  consistency 
of the  constraint  network  using  the  AC4  algorithm.  More 
recently,  [Gerber et ai,  2002]  defined  a  method to recog(cid:173)
nize  a  scenario  based  on  a  fuzzy  temporal  logic.  In  the 
same  year,  [Vu  et al,  2002]  present  an  approach  to  opti(cid:173)
mize  the  temporal  constraint  resolution  by  ordering  in 
time  the  sub-scenarios  of the  scenario  to  be  recognized. 
The common  characteristic of these approaches  is to  store 
all  totally recognized scenarios  (recognized in the past). 

Another approach  consists in  using a  symbolic network 
and  to  store  partially  recognized  scenarios  (to  be  recog(cid:173)
nized  in  the  future).  For  example,  [Ghallab,  1996]  has 
used  the  terminology  chronicle  to  express  a  temporal 
scenario.  A  chronicle  is  represented  as  a  set  of temporal 
constraints  on  time-stamped  events.  The  recognition  al(cid:173)
gorithm  keeps  and  updates  partial  recognition  of scenar(cid:173)
ios  using  the  propagation  of  temporal  constraints  based 
on  RETE  algorithm.  Their  applications  are  dedicated  to 
the  control  of turbines  and  telephonic  networks.  [Chleq 
and Thonnat,  1996]  made an  adaptation  of temporal  con(cid:173)
straints  propagation  for  video  surveillance.  In  the  same 
period,  [Pinhanez  and  Bobick,  1997]  have  used  Allen's 

interval algebra to represent scenarios  and have  presented 
a  specific algorithm to reduce  its complexity. 

All  these  techniques  allow  an  efficient  recognition  of 
scenarios,  but  there  are  still  some  temporal  constraints 
which  cannot  be  processed.  For  example,  most  of these 
approaches require that the  scenarios  are bounded  in  time 
[Ghallab,  1996],  or  process  temporal  constraints  and 
atemporal  constraints  in  the  same  way  [Rota  and  Thon-
nat, 2000]. 

We  can  distinguish  two  main  categories  of approaches 
to recognize a scenario based  on  a  symbolic network:  the 
STRS approaches recognize scenarios based  on  an  analy(cid:173)
sis  of scenarios recognized  in  the past  [Rota  and Thonnat, 
2000;  Vu et al,  2002],  whereas the  SPRS  approaches  rec(cid:173)
ognize  scenarios  based  on  an  analysis  of  scenarios  that 
can  be  recognized  in  the  future  [Ghallab,  1996].  The 
STRS  approaches  recognize  a  scenario  by  searching  in 
the  set  of previously  recognized  scenarios  a  set  of  sub-
scenarios  matching  the  scenario  model  to  be  recognized. 
Thus,  if the  system  fails  to  recognize  a  scenario,  it  will 
have  to  retry  the  same  process  (re-verify  the  same  con(cid:173)
straints)  at  the  next  instant,  implying  a  costly  processing 
time.  A  second  problem  is  that  STRS  algorithms  have  to 
store  and  maintain  all  occurrences  of  previously  recog(cid:173)
nized  scenarios.  The  SPRS  approaches  recognize  a  sce(cid:173)
nario  by  predicting  the  expected  scenarios  to  be  recog(cid:173)
nized  at the next  instants.  Thus,  the  scenarios  have  to  be 
bounded  in  time  to  avoid  the  never  ending  expected  sce(cid:173)
narios.  A  second  problem  is  that  SPRS  algorithms  have 
to  store  and  maintain  all  occurrences  of partially  recog(cid:173)
nized scenarios,  implying a costly storing space. 

The  method  presented  in  this  article  is  a  STRS  ap(cid:173)
proach  taking  advantages  of  the  SPRS  approaches.  The 
objective  is 
to  reduce  the  processing  time  (1)  when 
searching  in  the  past  (list  of previously  recognized  sce(cid:173)
narios)  for  an  occurrence  of a  given  scenario  model  and 
(2)  when  trying to  recognize  a  scenario  involving  several 
actors  by avoiding checking  all  combinations of actors. 

3  Scenario  Representation 
Our  goal  is  to  make  explicit  all  the  knowledge  necessary 
for the system  to be  able to recognize  scenarios  occurring 
in  the  scene.  The  description  of this  knowledge  has  to  be 
declarative  and  intuitive  (in  natural  terms),  so  that  the 
experts  of the  application  domain  can  easily  define  and 
modify  it.  Thus,  the  recognition  process  uses  only  the 
knowledge  represented by  experts through  scenario  mod(cid:173)
els. 

Let 

be the set  of scenario models and 

be the set of 
scenario  instances  (recognized  scenarios).  For  a  scenario 
model 

and a scenario instance p 

, we note  

the scenario model  of p  and  we  note  p(W)  the  set  of 
A  scenario  is  com(cid:173)

recognized  scenarios  of the  model 
posed  of four  parts: 
a) 

is  the  set  of  actor  variables  (characters) 

in(cid:173)
volved  in  the  scenario 
(p)  corresponds  to  the  ac(cid:173)
tors.  An  actor  can  be  a person  tracked  as  a  mobile  ob(cid:173)
ject  by  a  vision  module  or  a  static  object  of  the  ob(cid:173)
served environment like a chair. 

1296 

TEMPORAL  REASONING 

if  

if  not,  

is  the  set  of  sub  scenarios  that  compose  

is 
an  elementary  scenario 
is  called 
a  composed  scenario.  Each  sub-scenario 
is  represented 
by  a  variable  v.  These  variables  are  called 
temporal 
variables  because  their  value  is  a  recognized  scenario 
defined  on  a  temporal  interval.  We  note  
a  scenario 
instance  corresponding 
the  value  of  the  temporal 
the  set  of  variables  corresponding 
variable  v,  and  
to  the  actors  of 

to 

 

is  the  set  of  sub-scenarios  that  should  not  occur 

during  the  recognition  of  the  scenario  
the  f o r b i d d en  sub  scenarios. 
bidden  actor  variables  involved  in  
defined  in   

We  call 

is  the  set  of for-
but  not  already 

and 
is  the  set  of  constraints  of  

are  called 

the  forbidden  variables. 

There  are  three 

types  of  constraints: 
-the  set  of t e m p o r al  constraints,  noted  
one  variable  of  
-the  set  of  a t e m p o r al  constraints,  noted  

on  at  least 
and  not  on  any  forbidden  variable, 
on  only 

on  any 

-the  set  of  f o r b i d d en  constraints,  noted  
forbidden  variable. 
The  three  subsets  

constitute  a 
partition  of  
We  use  the  operator  "and"  to  link  the 
constraints  within  a  set  of  constraints.  To  use  the  opera­
tor  "or",  we  propose  to  define  two  similar  scenario  mod­
els  with  different  constraints.  An  elementary  scenario  is 
only  composed  of  a  set  of  characters  and  atemporal  con­
straints. 

and 

Figure  2  represents  a  model  of  a  composed  scenario 
two  actors,  a 

involves 

"Bank  attack".  This  scenario 
cashier  and  a  robber. 

In  our  representation,  any  scenario 

involves  at  least 
one  person,  and  is  defined  on  a  time  interval.  An  interval 
is  represented  by 
times  noted 
start 
and  end 
Defining  the  scenarios  on  a  time 
interval  is  important  for  the  experts  to  describe  scenarios 
in  a  natural  way. 

its  starting  and  ending 

Figure  2.  One  example  of "Bank  attack"  scenario  is  composed  of 
four steps:  (1) the cashier is at his/her position behind the counter, 
(2)  the  robber  enters  the  bank  and  moves  toward  the  front  of the 
counter  then  (3)  both  of them  arrive  at  the  safe  door  and  (4)  no­
body  else  in  the  branch  during  the  attack.  The  forbidden  sub-
scenario  (step  4)  is  not  necessary  to  recognize  this  "Bank  attack" 
scenario.  We  have  included this  constraint just to  show  the  possi­
bility of modeling  forbidden  sub-scenarios. 

4  Scenario  R e c o g n i t i on 
The scenario recognition  process has to  detect  which  sce­
nario  is  happening  from  a  stream  of  observed  persons 
tracked  by  a  vision  module  at  each  instant.  The  recogni­
tion  process  takes  also  as  input the  a  priori  knowledge  of 
the  scene and  the scenario models.  As  defined  in  the pre­
vious  section,  there  are  two  types  of scenarios:  elemen­
tary and composed. 

we  say  that  the  elementary  scenario 

4.1  Recognition  of  elementary  scenarios 
The algorithm  to recognize an  elementary scenario model 
consists  in  a  loop  of  the  selection  of  a  set  of  actors 
then  the  verification  of the  corresponding  atemporal  con­
straints 
until  all  combinations  of actors  have  been 
tested.  Once  a  set  of  actors  satisfies  all  constraints 
is  recog­
nized and  we  generate  an  elementary  scenario  instance  p 
attached  with  the  corresponding  scenario  model,  the  set 
of  actors  and  the  recognition  time  t.  The  scenario  in­
stance  is then  stored  in  the  list  of recognized  scenarios.  If 
at  the  previous  instant,  a  scenario  instance  p'  of  same 
type (same model,  same actors)  was recognized on a time 
interval 
the  two  scenario  instances  are  merged 
into  a  scenario  instance  that  is  recognized  on  the  time 
interval  

The  selection  of actors  leads  the  recognition  algorithm 
to  an  exponential  combination  in  function  of the  number 
of  actor  variables.  However,  in  practice,  there  are  few 
actor  variables  in  elementary scenario models,  so the rec­
ognition algorithm  is still  real-time. 

4.2  C o m p i l a t i on  of  composed  scenarios 
A  composed  scenario  is  a  sequence  of  sub-scenarios  or­
dered in time.  Each  sub-scenario corresponds to a  tempo­
ral  variable  in  the  corresponding  scenario  model.  The 
STRS  algorithms  of the  state  of  the  art  perform  at  each 
instant  an  extensive  search  process  among  all  possible 
scenarios  and  sub-scenarios  leading  to  an  exponential 
algorithm.  For  example,  for  a given  scenario 
be­
fore 
);  if a  scenario  instance  pw3  of  w3  has 
been  recognized,  it  makes  sense  to  try  to  recognize  the 
main  scenario  ώ. Therefore,  the  STRS  algorithms  will  try 
all  combinations  of  scenario  instances 
with 
We propose  to  decompose  the  scenario  model  into  a 
set  of  simple  scenario  models  containing  at  most  two 
sub-scenarios. 

before 

To  compile  a  predefined  composed  scenario  model  co, 
we define three steps:  (1)  build a graph  with the temporal 
variables 
(2)  generate  intermediate  scenario  models 
for  co  and  (3)  link  the  generated  intermediate  scenario 
models based on the constraints   

As proposed by  [Ghallab,  1996],  we  first  build a graph 
which  nodes  correspond  to  the  temporal  variables  and 
which  arcs  correspond  to  the  temporal  constraints 
The  arcs  are  oriented  and  are  associated  with  a  time  in­
terval  corresponding  to  the  time  delay  between  the  end­
ing time  of the two  variables.  For  example,  the  constraint 
c, between  v„  v,  is associated with  an  interval  [a,  b]  indi-

TEMPORAL  REASONING 

1297 

in 

the 

interval 

that  v,  can  end 

eating 
[end(v i)+a, 
end(v,)+b].  The  constraint  before  is  associated  with  [ 1, 
oo].  After building the graph  (called  initial  graph)  with  all 
temporal  constraints  between  temporal  variables  a((ώ), 
we  compute  the  equivalent  complete  graph  and  we  check 
the  graph  consistency.  These  two  graphs  are  equivalent 
because  the  only  difference  between  them  is  the  redun­
dancy  of some  constraints.  Then,  we  simplify  the  com­
plete  graph  by  removing  unnecessary  arcs  to  obtain  the 
least  constrained  graph.  For  any  triangle  ABC  of  the 
graph,  an  arc  AC  is  redundant  (unnecessary),  if the  arcs 
AB  and  BC  imply  a  stronger  constraint.  The  simplified 
graph  is  equivalent  to  the  two  other  graphs.  The  initial 
and  simplified  graphs  for  the  scenario  "Bank  attack" 
(Figure  2)  are  shown  on  Figure  3.  Thanks  to  the  simpli­
fied  graph,  all  the temporal  variables  a( ώ)  are  ordered by 
their  ending  time. 

The  resulting  scenario  model 

is  equivalent  to  the 
initial  scenario  model 
This  two  scenarios  have  the 
same  actor  variables  and  equivalent  set  of  constraints. 
The  only  difference  is  that  the  constraints  of the  scenario 
ώ are  verified  at  several  intermediate  levels  correspond­
ing  to  the  intermediate  scenario  models  as  shown  on 
Figure  4.  Because  any  sequence  of  temporal  variables 
can  be  ordered  by  their  ending  time,  so  any  scenario 
model  can  be  decomposed  into  intermediate  scenarios 
containing only one  or two temporal  variables. 

The  recognition  of  compiled  scenario  models  is  de­
scribed  in the next  section.  The gain  in  processing time  is 
due  to  the  search  algorithm:  we just  try  several  times  to 
link  two  scenario  instances  instead  of trying  to  link  to­
gether  a  whole  set  of combinations  of scenario  instances. 

Figure 3. To compile the scenario "Bank attack", we build: (a) the 
graph with all temporal constraints KT(Ώ), (b) the simplified graph 
with only the necessary constraints and (c) the generated interme­
diate scenario models. 

Figure 4. Three intermediate scenario models are generated for the 
compilation  of the  scenario  model  "Bank_attack",  and the  initial 
model is equivalent to "Bank_attack_3". 
4.3  Recognition  of  composed  scenarios 
The  recognition  of a  composed  scenario  model  
is trig­
gered  by  a  scenario  template,  which  has  been  generated 
when  the  last  sub-scenario 
terminating 
has  been 
recognized.  The  scenario  template  contains 
and  the 
scenario  instance  pt  with  its  list  of actors  a(p t)  that  par­
tially  instanciates 
is  composed  of two  sub-
scenarios,  or 
to be found. 

As 

If such  a  scenario  instance 

has  been  previously  rec­
ognized in  the past,  then  we  are  able  to  finish  instanciat-
ing the  remaining  actors  of  
Thus, just  a  few  com­
binations  of actors need to  be  checked avoiding an  expo­
nential search. 

The  last  step  of  the  algorithm  consists  in  verifying 

are  satisfied  with 

whether  all  temporal  and  atemporal  constraints 
If  one  forbidden 
and 
cannot  be  satisfied  then  the  scenario 
constraint  of 
ώc is  recognized  and  stored  in  the  list  of recognized  sce­
narios. 

and 

1298 

TEMPORAL  REASONING 

[Ghallab,  1996] 

temporal  scenario 

4 .4  D i s c u s s i on 
In 
recognition  and 
the  domain  of 
among  SPRS  algorithms,  the  chronicle  recognition  algo(cid:173)
rithm 
is  one  of  the  most  popular.  By 
storing  partially  recognized  scenarios,  it  can  speed  up  the 
whole  recognition  process.  A  partially  recognized  sce(cid:173)
nario  corresponds  to  a  prediction  and  enables  to  store  all 
previous  computations  that  do  not  need  to  be  recomputed 
at  the  following  instants.  A  main  difference  between  the 
chronicle  algorithm  and  our  algorithm  is  that  the  chroni(cid:173)
cle  algorithm  has  been  developed 
to  process  scenarios 
defined  with  only  one  "actor"  and  can  only  recognize 
events  detected  at  one  time  point.  Thus,  this  algorithm  is 
efficient  for  the  configuration  "mono-actor".  However,  in 
the  chronicle  algorithm 
the  configuration  "multi-actors", 
has  to  duplicate  the  partially  recognized  scenarios 
for 
each  combination  of actors  not  already  instanciated.  This 
can  lead  to  an  explosion  of memory  allocation  and  to  an 
exponential  search.  Our  algorithm  is  as  efficient  for  the 
configuration  "mono-actor"  because  we  store  the  recog(cid:173)
nized  scenarios  which  have  been  compiled.  Moreover,  it 
is  efficient  for  the  configuration  "multi-actors"  because 
the  recognized  scenarios  do  not  need  to  be  duplicated 
even  if  some  actors  arc  not  instanciated.  The  worst  case 
occurs  with  elementary  scenarios  because  to  recognize 
them  at  the  current 
instant,  all  combinations  of  actors 
need  to  be  checked.  In  real  world  applications,  elemen(cid:173)
tary  scenarios  do  not  contain  many  actor  variables  (less 
than  3)  making  the  proposed  algorithm  sufficient  to  ob(cid:173)
tain  an  operational  real  time  video  interpretation  system. 

in 

the  cases  when 

eases.  The  interpretation  system  fails  to  recognize  some 
scenarios  only 
the  vision  module 
misses  to  detect  the  people  in  the  scene.  We  have  not 
detected  any  false  alarm  during  all  the  experiment.  The 
non-detection  of false  alarms  can  be  explained  by  the  fact 
that  the  scenarios  are  very  constrained  and  there  are  un(cid:173)
likely  to  be  recognized  by  error. 

In  the  second  experiment,  we  installed  the  interpreta(cid:173)
tion  system  in  an  office  and  in  a  bank  and  we  connected 
the  system  to  one  or  two  on-line  cameras  to  acquire  di(cid:173)
rectly  live  videos.  In  this  experiment,  we  used  the  bank 
scenarios  and  we  slightly  modified  them  to  use  them  in 
the  office.  We  ran  the  system  in  the  bank  for  few  hours 
and  continuously  during  4h  in  the  office.  As  in  the  first 
experiment,  the  scenarios  were  most  of the  time  correctly 
recognized,  showing  that  the  recognition  algorithm  can 
work  reliably  and  robustly  in  real-time  and  in  continuous 
mode. 

tested 

Recognition 

rate  (%) 

Number  of 

Average 
number  of 

Number 
of  false 
alarms 
Bank cam.  1 
0 
Bank cam.  2 
0 
Metro cam.  2 
0 
Table  1. The recognition of temporal  scenarios in videos of a bank 
branch and of a metro station. 

persons/frame 
4 
2 
2 

sequences 
10 
1 
3 

80 
100 
100 

5  Experiments  and  results 
To  validate  our  recognition  algorithm,  we  first  integrated 
the  algorithm  with  a  vision  module  to  obtain  an  opera(cid:173)
tional 
interpretation  system  and  then  we  have  realized 
four  types  of tests:  (1)  on  recorded  videos  taken  in  a  bank 
branch  and  in  two  metro  stations  (one  in  Belgium  and 
one  in  Spain)  to  verify  if the  algorithm  can  correctly  rec(cid:173)
ognize  the  predefined  scenario  models,  (2)  on  live  videos 
acquired  on-line  from  cameras  installed  in  an  office,  in  a 
metro  station  and  in  a  bank  branch  to  verify  if  the  algo(cid:173)
rithm  can  work  robustly  on  a  long  time  mode,  (3)  on  re(cid:173)
corded  videos  taken  in  a  bank  branch  and  on  simulated 
data  to  study  how  the  complexity  of  the  algorithm  de(cid:173)
pends  on 
(i.e.  number  of  sub-
scenarios  and  of  actor  variables)  and  (4)  on  simulated 
data  to  study  how  the  complexity  of  the  algorithm  de(cid:173)
pends  on  the  complexity  of the  scene  (i.e.  number  of per(cid:173)
sons  in  the  scene). 

the  scenario  models 

In  the  first  experiment,  we  verify  on  recorded  videos 
that  the  algorithm  correctly  recognizes  several  types  of 
"Bank  attack"  scenarios  and  several  types  of  "Vandalism 
against  a  ticket  machine"  scenarios  in  a  metro  station. 
The  vandalism  scenario  involves  in  general  two  individu(cid:173)
is 
als,  one 
coming  and  the  other  one  attempting  several 
to 
break  the  ticket  machine.  Table  1  shows  that  the  prede(cid:173)
fined  scenarios  were  correctly  recognized  in  most  of  the 

to  check  whether  nobody 
times 

looking  around 

Figure  5.  The  processing  time  of  the  new  algorithm  is  closely 
linear time  in  function of the number of sub-scenarios. 

Number of actor variables/model 

Figure  6.  The  processing  time  (a)  of the  old  algorithm  and  (b)  of 
the new algorithm  depend on the number of actor variables  of pre(cid:173)
defined scenario models. 

In  the  third  experiment,  we  studied  the  processing  time 
of  the  recognition  algorithm  in  function  of  the  scenario 
models.  First,  we  studied  the  processing  time  of the  algo(cid:173)
rithm  focusing  on  the  resolution  of  temporal  constraints. 
In  this  experiment  (shown  on  Figure  5),  we  tested  eight 

TEMPORAL  REASONING 

1299 

configurations  of scenario  models:  the  first  configuration 
is  made  of scenarios  containing  3  sub-scenarios  and  the 
last configuration  is made of scenarios containing  10  sub-
scenarios.  On  the  bank  videos  containing  about  300 
frames,  we  found that the processing time  of the classical 
STRS  algorithm  is  exponential  in  function  of the  number 
of sub-scenarios,  whereas  the  processing  time  of our  al(cid:173)
gorithm  is  closely  linear  in  function  of  the  number  of 
sub-scenarios. 

Second,  we  studied  the  processing  time  of  the  algo(cid:173)
rithm  focusing  on  the  number  of  actor  variables  of  the 
scenario models.  In  this  experiment  (shown  on  Figure  6), 
we  tested  nine  configurations  of  scenario  models:  the 
first  configuration  is  made  of scenarios  involving  2  actor 
variables  and  the  last  configuration  is  made  of scenarios 
involving  10  actor  variables.  To  run  the  algorithm  with 
enough  actors,  we  simulated  bank  videos  containing  35 
persons.  On  these  videos,  we  found  that  the  processing 
time  of  the  classical  STRS  algorithm  is  exponential  in 
function  of  the  number  of  actor  variables,  whereas  the 
processing  time  of  our  algorithm  is  closely  linear  in 
function  of the  number  of actor  variables. 

in 

In  the  fourth  experiment,  we  studied  the  processing 
time  of  the  recognition  algorithm 
function  of  the 
scene.  To  have  a  continuous  variation  of the  scene,  we 
simulated  the  scene.  We  built  a  scene  environment  with 
eight  zones  of  interest  and  ten  pieces  of equipment.  We 
simulated  the  individuals  evolving  in  the  scene  at  each 
instant.  In  these  simulated  videos,  the  number  of  indi(cid:173)
viduals changed  from  30  up to  240.  To  verify  if our  algo(cid:173)
rithm can recognize in real-time the predefined  scenarios, 
we  measured the maximal processing time per  frame.  We 
found that, the maximal processing time for each  frame  is 
100ms for a scene of 240 persons.  We also  found that the 
average  processing  time  for  each  frame  is  closely  linear 
in  function  of  the  number  of  persons.  Figure  7  shows 
several tests  of this  experiment  to  illustrate  how the  proc(cid:173)
essing time depends on the complexity of the scene. 

With  the  fourth  experiment,  we  can  conclude  that  our 
recognition  algorithm  can  recognized  in  real-time  the 
predefined  scenarios  if  the  number  of  persons/frame  is 

CPU  700MHz,  320MB  RAM. 

6  Conclusion 
In  the  literature,  there  are  two  categories  of  symbolic  ap(cid:173)
proaches  to  recognize  temporal  scenarios:  the  STRS  algo(cid:173)
rithms reasoning on the  past and  the  SPRS  algorithms  rea(cid:173)
soning  on  the  future.  First,  we  have  shown  that  the  STRS 
algorithms  recognize  usually  a  scenario  by  performing  an 
exponential  combination  search.  Then,  we  have  explained 
that even  if our proposed algorithm  is a  STRS  algorithm,  it 
checks  temporal  constraints  nevertheless  by  performing  a 
linear search  thanks  to  a  step  of pre-compilation  of scenar(cid:173)
ios.  Second, we  have also shown that the  SPRS algorithms 
have to try all combinations of actors to be able to recognize 
"multi-actors" scenarios. Thanks to the pre-compilation step 
this  drawback  for  our  algorithm  is  limited  to  elementary 

scenarios.  Thus,  processing  time  can  still  be  an  issue  de(cid:173)
pending on the  complexity  of scenarios.  For these  two  rea(cid:173)
sons,  the  proposed  algorithm  enables  the  integrated  video 
interpretation  system  to be real-time.  Up to our knowledge, 
this  video  interpretation  system  is  the  first  operational  sys(cid:173)
tem able to recognize complex temporal scenarios. 

Our  future  work  consists  in  taking  care  of  the  errors 
and  the  uncertainty  of the  vision  module.  The  goal  is  to 
be  able  to  continue  the  interpretation  of the  videos  even 
when  the  vision  module  cannot  cope  with  the  real  world 
complexity  and  then  to  be  able  to  recognize  more  com(cid:173)
plex  scenarios. 

Figure 7. The (a) maximal and (b) average processing time/frame 
of the new algorithm depend on the number of detected persons. 

References 
[Chlcq  and  Thonnat,  1996]  Nicolas  Chlcq  and  Moniquc 
Thonnat.  Real-time  image sequence  interpretation for  video-
surveillance  applications.  International  conference  on  Im(cid:173)
age  Processing  (ICIP96).  Proceeding  IEEE  ICIP'96.  Vol  2. 
pp 801-804. Switzerland. 09/1996. 
[Ghallab,  1996]  Malik  Ghallab.  On  Chronicles:  Represen(cid:173)
tation,  On-line  Recognition  and  Learning.  5th  International 
Conference  on  Principles  of Knowledge  Representation  and 
Reasoning (KR'96), USA,  11/1996. 
[Gerber et al.,  2002] R.  Gerber,  H.  Nagel  and  II.  Schreiber. 
Deriving  Textual  Descriptions  of Road  Traffic  Queues from 
Video Sequences. The 15-th European Conference on Artifi(cid:173)
cial Intelligence (ECAI2002), Lyon, France, 21-26/07/2002. 
[Hongeng et al,  2000]  S.  Hongeng,  F.  Bremond and R.  Ne(cid:173)
vada.  Representation  and  Optimal  Recognition  of  Human 
Activities.  In  IEEE  Proceedings  of  Computer  Vision  and 
Pattern Recognition, USA, 2000. 
[Howell  and  Buxton,  2002]  A.J.  Howell  and  H.  Buxton. 
Active  vision  techniques  for  visually  mediated  interaction. 
Image and Vision Computing, 2002. 
[Oliver  and  Pentland,  2000]  Nuria  Oliver  and  Alex  Pcn-
tland.  Graphical  Models for  Driver  Behavior  Recognition  in 
a SmartCar.  Proceedings  of IEEE  Intl.  Conference  on  Intel(cid:173)
ligent Vehicles 2000 Detroit. Michigan,  10/2000. 
[Pinhanez  and  Bobick,  1997]  Claudio  Pinhanez  and  Aaron 
Bobick.  Human  Action  Detection  Using  PNF  Propagation 
of  Temporal  Constraints.  M.T.T  Media  Laboratory  Percep(cid:173)
tual Section Report No. 423, 04/1997. 
[Rota  and  Thonnat,  2000]  Nathanael  Rota  and  Monique 
Thonnat.  Activity  Recognition from  Video  Sequences  using 
Declarative  Models.  14  European  Conference  on  Artificial 
Intelligence (ECAI  2000),  Berlin, W.  Horn  (ed.)  IOS  Press, 
Amsterdam, 20-25/08/2000. 
[Vu  et  al,  2002]  Van-Thinh  Vu,  Francois  Bremond  and 
Monique  Thonnat.  Temporal  Constraints  for  Video  Inter(cid:173)
pretation.  The  15-th  European  Conference  on  Artificial  In(cid:173)
telligence (ECAI'2002), Lyon, France, 21-26/07/2002. 

1300 

TEMPORAL  REASONING 

