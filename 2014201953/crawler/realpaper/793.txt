Improving Author Coreference by

Resource-bounded Information Gathering from the Web

Pallika Kanani, Andrew McCallum, Chris Pal

Department of Computer Science

University of Massachusetts Amherst
{pallika, mccallum, pal} @ cs.umass.edu

Amherst, MA 01003 USA

Abstract

Accurate entity resolution is sometimes impossi-
ble simply due to insufﬁcient information. For ex-
ample, in research paper author name resolution,
even clever use of venue, title and co-authorship
relations are often not enough to make a conﬁ-
dent coreference decision. This paper presents sev-
eral methods for increasing accuracy by gather-
ing and integrating additional evidence from the
web. We formulate the coreference problem as one
of graph partitioning with discriminatively-trained
edge weights, and then incorporate web informa-
tion either as additional features or as additional
nodes in the graph. Since the web is too large to
incorporate all its data, we need an efﬁcient pro-
cedure for selecting a subset of web queries and
data. We formally describe the problem of re-
source bounded information gathering in each of
these contexts, and show signiﬁcant accuracy im-
provement with low cost.

Introduction

1
Machine learning and web mining researchers are increas-
ingly interested in using search engines to gather information
for augmenting their models, e.g. [Etzioni et al., 2004], [Mc-
Callum and Li, 2003], [Dong et al., 2004]. However, it is
impossible to query for the entire web, and this gives rise to
the problem of efﬁciently selecting which queries will pro-
vide the most beneﬁt. We refer to this problem as resource-
bounded information gathering from the web.

We examine this problem in the domain of entity resolu-
tion. Given a large set of entity names (each in their own con-
text), the task is to determine which names are referring to
the same underlying entity. Often these coreference merging
decisions are best made, not merely by examining separate
pairs of names, but relationally, by accounting for transitive
dependencies among all merging decisions. Following previ-
ous work, we thus formulate entity resolution as graph par-
titioning with edge weights based on many features with pa-
rameters learned by maximum entropy [McCallum and Well-
ner, 2004], and in this paper explore a relational, graph-based
approach to resource-bounded information gathering.

The speciﬁc entity resolution domain we address is re-
search paper author coreference. The vertices in our coref-
erence graphs are citations, each containing an author name
with the same last name and ﬁrst initial.1 Coreference in this
domain is extremely difﬁcult. Although there is a rich and
complex set of features that are often helpful, in many sit-
uations they are not sufﬁcient to make a conﬁdent decision.
Consider, for example, the following two citations both con-
taining a “D. Miller.”
• Mark Orey and David Miller, Diagnostic Computer Sys-
tems for Arithmetic, Computers in the School, volume
3, #4, 1987
• Miller, D., Atkinson, D., Wilcox, B., Mishkin, A., Au-
tonomous Navigation and Control of a Mars Rover, Pro-
ceedings of the 11th IFAC Symposium on Automatic
Control in Aerospace, pp. 127-130, Tsukuba, Japan,
July 1989.

The publication years are close; and the titles both relate
to computer science, but there is not a speciﬁc topical over-
lap; “Miller” is a fairly common last name; and there are no
co-author names in common. Furthermore, in the rest of the
larger citation graph, there is not a length-two path of co-
author name matches indicating that some of the co-authors
here may have themselves co-authored a third paper. So there
is really insufﬁcient evidence to indicate a match despite the
fact that these citations do refer to the same “Miller”.

In this paper, we present two different mechanisms for aug-
menting the coreference graph partitioning problem by incor-
porating additional helpful information from the web. In both
cases, a web search engine query is formed by conjoining the
titles from two citations. The ﬁrst mechanism changes the
edge weight between the citation pair by adding a feature in-
dicating whether or not any web pages were returned by the
query. The second mechanism uses one of the returned pages
(if any) to create an additional vertex in the graph, for which
edge weights are then calculated to all the other vertices. The
additional transitive relations provided by the new vertex can
provide signiﬁcant helpful information. For example, if the
new vertex is a home page listing all of an author’s publica-
tions, it will pull together all the other vertices that should be
coreferent.

1Future work will address the problem of correctly merging

names with typographic errors in the ﬁrst initial and last name.

IJCAI-07

429

Gathering such external information for all vertex pairs in
the graph is prohibitively expensive, however. Thus, meth-
ods that acknowledge time, space and network resource lim-
itations, and effectively select just a subset of the possible
queries are of interest. Learning and inference under resource
limitations has been studied in various forms. For example,
the value of information, as studied in decision theory, mea-
sures the expected beneﬁt of queries [Zilberstein and Lesser,
1996]. Budgeted learning, rather than selecting training in-
stances, selects new features [Kapoor and Greiner, 2005].
Resource-bounded reasoning studies the trade offs between
computational commodities and value of the computed re-
sults [Zilberstein, 1996]. Active learning aims to request hu-
man labeling of a small set of unlabeled training examples
[Thompson et al., 1999], for example, aiming to reduce label
entropy on a sample [Roy and McCallum, 2001].

In this paper we employ a similar strategy, and com-
pare it with two baseline approaches, showing on 7 dif-
ferent data sets that leveraging web queries can reduce F1
error by 13.03%, and furthermore that, by using our pro-
posed resource-bounded approach, 53.5% of this gain can be
achieved with about 1% of the web queries. We also suggest
that our problem setting will be of interest to theoretical com-
puter science, since it is a rich extension to correlational clus-
tering [Bansal et al., 2002; Demaine and Immorlica, 2003].

2 Conditional Entity Resolution Models

We are interested in obtaining an optimal set of coreference
assignments for all mentions contained in our database. In our
approach, we ﬁrst learn maximum entropy or logistic regres-
sion models for pairwise binary coreference classiﬁcations.
We then combine the information from these pairwise mod-
els using graph-partitioning-based methods so as to achieve a
good global and consistent coreference decision. We use the
term, “mention” to indicate the appearance of an author name
in a citation and use xi to denote mention i = 1, . . . , n. Let
yij represent a binary random variable that is true when men-
tions xi and xj refer to the same underlying author “entity.”
For each pair of mentions we deﬁne a set of l feature func-
tions fl(xi, xj, yi,j) acting upon a pair of mentions. From
these feature functions we can construct a local model given
by

P (yi,j|xi, xj) =

1
Zx

exp(λlfl(xi, xj, yij)),

(1)

(cid:2)

y

where Zx =
exp(λlfl(xi, xj, yij)). In McCallum and
Wellner [2003] a conditional random ﬁeld with a form similar
to (1) is constructed which effectively couples a collection of
pairwise coreference models using equality transitivity func-
tions f∗(yij, yjk, yik) to ensure globally consistent conﬁgura-
tions. These functions ensure that the coupled model assigns
zero probability to inconsistent conﬁgurations by evaluating
to −∞ for inconsistent conﬁgurations and 0 for consistent
conﬁgurations. The complete model for the conditional dis-
tribution of all binary match variables given all mentions x

can then be expressed as

P (y|x) =

1

Z(x)

exp

(cid:3)(cid:4)
(cid:4)

i,j,l

λlfl(xi, xj, yij) +
(cid:5)
λ∗f∗(yij, yjk, yik)

,

(2)

where y = {yij : ∀i,j} and
Z(x) =

(cid:6)(cid:4)

(cid:4)

exp

i,j,k

λlfl(xi, xj, yij)+

(cid:4)

(cid:7)
λ∗f∗(yij, yjk, yik)

y

i,j,l

i,j,k

l

(cid:2)

(3)
As in Wellner and McCallum [2002], the parameters λ can
be estimated in local fashion by maximizing the product of
Equation 1 over all edges in a labeled graph exibiting the true
partitioning. When fl(xi, xj, 1) = −fl(xi, xj, 0) it is possi-
ble to construct a new undirected and fully connected graph
consisting of nodes for mentions, edge weights ∈ [−∞,∞]
λl(xi, xj, yij) and with sign deﬁned by the
deﬁned by
value of yij. In our work here we deﬁne a graph in a sim-
ilar fashion as follows.
Let G0 =< V0, E0 > be a weighted, undirected and fully
connected graph, where V0 = {v1, v2, ..., vn} is the set of
vertices representing mentions and E0 is the set of edges
where ei =< vj, vk > is an edge whose weight wij is given
by P (yij = 1|xi, xj) − P (yij = 0|xi, xj) or the differ-
ence in the probabilities that that the citations vj and vk are
by the same author. Note that the edge weights deﬁned in
this manner are in [−1, +1]. The edge weights in E0 are
noisy and may contain inconsistencies. For example, given
the nodes v1, v2 and v3, we might have a positive weight
on < v1, v2 > as well as on < v2, v3 >, but a high neg-
ative weight on < v1, v3 >. Our objective is to partition
the vertices in graph G0 into an unknown number of M non-
overlapping subsets, such that each subset represents the set
of citations corresponding to the same author. We deﬁne our
objective function as F =
wijf(i, j) where f(i, j) = 1
when xi and xj are in the same partition and −1 otherwise.
[Bansal et al., 2002] provide two polynomial-time approx-
imation schemes (PTAS) for partitioning graphs with mixed
positive and negative edge weights. We obtain good empir-
ical results with the following stochastic graph partitioning
technique, termed here N-run stochastic sampling.

(cid:2)

ij

Algorithm 1. – N-Run Stochastic Sampling:
We deﬁne a distribution over all edges in G0, P (wi) ∝
e− wi
T where T acts as temperature. At each iteration, we draw
an edge from this distribution and merge the two vertices.
Edge weights to the new vertex formulated by the merge are
set to the average of its constituents and the distribution over
the edges is recalculated. Merging stops when no positive
edges remain in the graph. This procedure is then repeated
r = 1...N times and the partitioning with the maximum F is
then selected.
3 Coreference Leveraging the Web
Now, consider that we have the ability to augment the graph
with additional information using two alternative methods:

IJCAI-07

430

(A)..., H. Wang, ... Background Initialization..., ICCV,...2005.
(B)..., H. Wang, ... Tracking and Segmenting People..., ICIP, 2005.
(C)..., H. Wang, ... Gaussian Background Modeling..., ICASSP, 2005.
(D)..., H. Wang, ... Facial Expression Decomposition..., ICCV, 2003.
(E)..., H. Wang, ... Tensor Approximation..., SIGGRAPH. 2005.
(F)..., H. Wang, ... High Speed Machining..., ASME, (JMSE), 2005.

Figure 1: Six Example References

(1) changing the weight on an existing edge, (2) adding a
new vertex and edges connecting it to existing vertices. This
new information can be obtained by querying some external
source, such as a database or the web.

The ﬁrst method may be accomplished in author corefer-
ence, for example, by querying a web search engine as fol-
lows. Clean and concatenate the titles of the citations, issue
this query and examine attributes of the returned hits. In this
case, a hit indicates the presence of a document on the web
that mentions both these titles and hence, some evidence that
they are by the same author. Let fg be this new boolean fea-
ture. This feature is then added to an augmented classiﬁer
that is then used to determine edge weights.

In the second method, a new vertex can be obtained by
querying the web in a similar fashion, but creating a new ver-
tex by using one of the returned web pages as a new mention.
Various features f(·) will measure compatibility between the
other “citation mentions” and the new “web mention,” and
with similarly estimated parameters λ, edge weights to the
rest of the graph can be set.

In this case, we expand the graph G0, by adding a new set
of vertices, V1 and the corresponding new set of edges, E1 to
create a new, fully connected graph, G(cid:3). Although we are not
interested in partitioning V1, we hypothesize that partitioning
G(cid:3) would improve the optimization of F on G0. This can
be explained as follows. Let v1, v2V0, v3V 1, and the edge
< v1, v2 > has an incorrect, but high negative edge weight.
However, the edges < v1, v3 > and < v2, v3 > have high
positive edge weights. Then, by transitivity, partitioning the
graph G(cid:3) will force v1 and v2 to be in the same subgraph and
improve the optimization of F on G0.

As an example, consider the references shown in Fig.1. Let
us assume that based on the evidence present in the citations,
we are fairly certain that the citations A, B and C are by H.
Wang 1 and that the citations E and F are by H. Wang 2. Let
us say we now need to determine the authorship of citation
D. We now add a set of additional mentions from the web,
{1, 2, .. 10}. The adjacency matrix of this expanded graph
is shown in Fig. 2. The darkness of the circle represents the
level of afﬁnity between two mentions. Let us assume that
the web mention 1 (e.g. the web page of H. Wang 1) is found
to have strong afﬁnity to the mentions D, E and F. Therefore,
by transitivity, we can conclude that mention D belongs to the
group 2. Similarly, values in the lower right region could also
help disambiguate the mentions through double transitivity.

4 Resource Bounded Web Usage
Under the constraint on resources, however, we must select
only a subset of edges in E0, for which we can obtain the cor-

Figure 2: Extending a pairwise similarity matrix with additional
web mentions. A..F are citations and 1..10 are web mentions.

responding piece of information ii. Let Es ⊂ E0, be this set
and Is be the subset of information obtained that corresponds
to each of the elements in Es. The size of Es is determined
by the amount of resources available. Our objective is to ﬁnd
the subset Es that will optimize the function F on graph G0
after obtaining Is and applying graph partitioning.
Similarly, in the case of expanded graph G(cid:3), given the
⊂ V1, to add to
constraint on resources, we must select V (cid:3)
the graph. Note that in the context of information gathering
from the web, |V1| is in the billions. Even in the case when
|V1| is much smaller, we may choose to calculate the edge
⊂ E1 be this set.
weights for only a subset of E1. Let E(cid:3)
The sizes of V (cid:3)
s are determined by the amount of
resources available. Our objective is to ﬁnd the subsets V (cid:3)
s that will optimize the function F on graph G0 by
and E(cid:3)
s
applying graph partitioning on the expanded graph. We now
present the procedure for the selection of Es.

s and E(cid:3)

s

s

Algorithm 2. – Centroid Based Resource Bounded In-
formation Gathering and Graph Partitioning For each clus-
ter of vertices that have been assigned the same label under a given
partitioning, we deﬁne the centroid as the vertex vc with the largest
sum of weights to other members in its cluster. Denote the subset
of vertex centroids obtained from clusters as Vc. (We can also op-
tionally pick multiple centroids from each cluster.) We begin with
graph G0 obtained from the base features of the classiﬁer. We use
the following criteria for ﬁnding the best order of queries: expected
entropy, gravitational force, uncertainty-based and random. The un-
certainty criteria uses the entropy of the binary classiﬁer for each
edge. For each of these criteria, we follow this procedure.
1. Partition graph G0 using N-run stochastic sampling.
2. From the highest scoring partitioned graph G∗

i , ﬁnd the subset

of vertex centroids Vc

3. Construct Es as the set of all edges connecting centroids in Vc.
4. Order edges Es into index list I based on the criteria.
5. Using index list I, for each edge ei ⊂ Es

(a) Execute the web query and evaluate additional features

from result

(b) Evaluate classiﬁer for edge ei with the additional features

and form graph Gi from graph Gi−1

(c) Using graph Gi, perform N-run stochastic sampling and

compute performance measures

Criterion 1 - Expected Entropy
1. Force merge of the vertex pair of ei to get a graph Gp

IJCAI-07

431

2. Peform N-run stochastic sampling on Gp. This gives the prob-

3. Calculate the entropy, Hp of the graph Gp as follows:

abilities pi for each of the edges in Gp
Hp = − P

i Pi log Pi

4. Force split of the vertex pair of ei to get a graph Gn
5. Repeat steps 2-3 to calculate entropy, Hn for graph Gn
6. The expected entropy, Hi for the edge ei is calculated as:
(Assuming equal probabilities for both out-

(Hp)+(Hn)

2

Hi =
comes)

d2

M1∗M2

Criterion 2 - Gravitational Force
This selection criteria is inspired by the inverse squared law of
the gravitational force between two bodies. It is deﬁned as F =
, where Γ is a constant, M1 and M2 are analogous to
Γ
masses of two bodies and d is the distance between them. This
criteria ranks highly partitions that are near each other and large,
and thus high-impact candidates for merging. Let vj and vk be the
two vertices connected by ei. Let Cj and Ck be their corresponding
clusters. We calculate the value of F as described above, where M1
and M2 are the number of vertices in Cj and Ck respectively. We
deﬁne d = 1
xwi , where wi is the weight on the edge ei and x is a
parameter that we tune for our method.

5 Theoretical Problem
There has been recent interest in the general problem of cor-
relational clustering [Bansal et al., 2002; Demaine and Im-
morlica, 2003]. We now present a new class of problems that
are concerned with resource bounded information gathering
under graph partitioning.

Consider the matrix as presented in Fig.2. Suppose we care
about the partitioning in the upper left part of the matrix, and
all the values in the upper right part of the matrix are hidden.
As we have seen before, obtaining these values would impact
the graph partitioning in the section that we care about.

Now, suppose, we have access to an adversarial oracle,
who unveils these values in the requested order. In the worst
case, no useful information is obtained till the last value is un-
veiled. In the best case, however, requesting a small fraction
of the values, leads to perfect partitioning in the section that
we care about. The question that we now ask is, what is the
best possible order to request these values. Making reason-
able assumptions about the nature of the oracle and imposing
restrictions on the edge weights makes this problem interest-
ing and useful. This is one way to formulate this problem.
This paper opens up many such possibilities for the theory
community.

6 Experimental Results
6.1 Dataset and Infrastructure
We use the Google API for searching the web. The data sets
used for these experiments are a collection of hand labeled
citations from the DBLP and Rexa corpora (see table 1). The
portion of DBLP data, which is labeled at Pennstate Univer-
sity is referred to as ’Penn’. Each dataset refers to the cita-
tions authored by people with the same last name and ﬁrst
initial. The hand labeling process involved carefully segre-
gating these into subsets where each subset represents papers
written by a single real author.

Corpus
DBLP
Rexa
Penn
Rbig

# Sets

18
8
7
18

# Authors

103
289
139
103

# Citations

945
1459
2021
1360

# Pairs
43338
207379
455155
126205

Table 1: Summary of Data set properties.

The ’Rbig’ corpus consists of a collection of web docu-
ments which is created as follows. For every dataset in the
DBLP corpus, we generate a pair of titles and issue queries
to Google. Then, we save the top ﬁve results and label them
to correspond with the authors in the original corpus. The
number of pairs in this case corresponds to the sum of the
products of the number of web documents and citations in
each dataset.

All the corpora are split into training and test sets roughly
based on the total number of citations in the datasets. We
keep the individual datasets intact because it would not be
possible to test graph partitioning performance on randomly
split citation pairs.

6.2 Baseline, Web Information as a Feature and

Effect of Graph Partitioning

The maximum entropy classiﬁer described in Section 2 is
built using the following features. We use the ﬁrst and middle
names of the author in question and the number of overlap-
ping co-authors. The US census data helps us determine how
rare the last name of the author is. We use several differ-
ent similarity measures on the titles of the two citations like
the cosine similarity between the words, string edit distance,
TF-IDF measure and the number of overlapping bigrams and
trigrams. We also look for similarity in author emails, in-
stitution afﬁliation and the venue of publication if available.
We use a greedy agglomerative graph partitioner in this set of
experiments and are interested in investigating the effect of
using a stochastic partitioner.

The baseline column in Table 2 shows the performance of
this classiﬁer. Note that there is a large number of negative
examples in this dataset and hence we prefer pairwise F1 over
accuracy as the main evaluation metric. Table 2 shows that
graph partitioning signiﬁcantly improves pairwise F1. We
also use area under the ROC curve for comparing the per-
formance of the pairwise classiﬁer, with and without the web
feature.

Note that these are some of the best results in author coref-
erence and hence qualify as a good baseline for our experi-
ments with the use of web. It is difﬁcult to make direct com-
parison with other coreference schemes [Han et al., 2005] due
to the difference in the evaluation metrics.

Table 2 compares the performance of our model in the ab-
sence and in the presence of the Google title feature. As
described before, these are two completely identical models,
with the difference of just one feature. The F1 values improve
signiﬁcantly after adding this feature and applying graph par-
titioning.

IJCAI-07

432

Method
Baseline
DBLP
W/ Google
DBLP
Baseline
Rexa
W/ Google
Rexa
Baseline
Penn
W/ Google
Penn

class.
part.
class.
part.
class.
part.
class.
part.
class.
part.
class.
part.

-

-

.866

.913

AROC Acc
.770
.847
.780
.883
.905
.837
.829
.865
.877
.838
.837
.913
.918

.910

.688

.880

-

-

-

-

Pr
.926
.814
.907
.949
.732
.634
.751
.701
.980
.835
.855
.945

Rec
.524
.683
.821
.830
.651
.913
.768
.972
.179
.211
.672
.617

F1
.669
.743
.862
.886
.689
.748
.759
.814
.303
.337
.752
.747

Table 2: Effect of using the Google feature. Top row in each corpus
indicates results for pairwise classiﬁcation and bottom row indicates
results after graph partitioning.

6.3 Expanding the Graph by Adding Web

Mentions

In this case, we augment the citation graph by adding docu-
ments obtained from the web. We build three different kinds
of pairwise classiﬁers to ﬁll the entries of the matrix shown in
Fig 2. The ﬁrst classiﬁer, between two citations, is the same
as the one described in the previous section. The second clas-
siﬁer, between a citation and a web mention, predicts whether
they both refer to the same real author. The features for this
second classiﬁer include, occurrence of the citation’s author
and coauthor names, title words, bigrams and trigrams in the
web page. The third classiﬁer, between two web mentions,
predicts if they both refer to the same real author or not. Due
to the sparsity of training data available at this time, we set
the value of zero in this region of the matrix, indicating no
preference. We now run the greedy agglomerative graph par-
titioner on this larger matrix and ﬁnally, measure the results
on the upper left matrix.

We compare the effects of using web as a feature and web
as a mention on the DBLP corpus. We use the Rbig corpus for
this experiment. Table 3 shows that the use of web as a men-
tion improves the performance on F1. Note that alternative
query schemes may yield better results.

Data
Baseline
Web Feature
Web Mention

Acc.
.7800
.9048
.8816

Pr.
.8143
.9494
.8634

Rec.
.6825
.8300
.9462

F1
.7426
.8857
.9029

Table 3: DBLP Results when using Web Pages found by Google as
Extra Mentions(Rbig).

6.4 Applying the Resource Bounded Criteria for

Selective Querying

We now turn to the experiments that use different criteria for
selectively querying the web. We present the results on test
datasets from DBLP and Rexa corpora. As described ear-
lier in Section 4, the query candidates are the edges connect-
ing centroids of initial clustering. We use multiple centroids

Method
Merge Only
Expected Entropy
Gravitational Force
Uncertainty
Random
Merge and Split
Expected Entropy
Gravitational Force
Uncertainty
Random
No Merge
Expected Entropy
Gravitational Force
Uncertainty
Random

Precision Recall

F1

73.72
63.10
64.95
63.97

76.19
64.10
66.56
66.45

91.46
91.53
87.01
86.96

87.92
92.37
87.83
89.46

58.56
53.06
54.45
50.47

38.46
37.84
41.91
43.77

72.37
64.55
63.54
64.23

60.90
53.56
55.32
52.27

51.06
50.47
52.70
54.03

Table 4: Area Under Curve for different Resource Bounded Infor-
mation Gathering criteria

and pick top 20% tightly connected vertices in each cluster.
We experiment with ordering these query candidates accord-
ing to the four criteria: expected entropy, gravitational force,
uncertainty-based and random. For each of the queries in the
proposed order, we issue a query to Google and incorporate
the result into the binary classiﬁer with an additional feature.
If the prediction from this classiﬁer is greater than a thresh-
old (t = 0.5), we force merge the two nodes together. If lower,
we have two choices. We can impose the force split, in ac-
cordance with the deﬁnition of expected entropy. We call this
approach “split and merge”. The second choice is to not im-
pose the force split, because, in practice, Google is not an
oracle and absence of co-occurence of two citations on the
web is not an evidence that they refer to different people. We
call this approach “merge only”. The third choice is to simply
incorporate the result of the query into the edge weight.

After each query, we rerun the stochastic partitioner and
note the precision, recall and F1. This gives us a plot for a
single dataset. Note that the number of proposed queries in
each dataset is different. We get an average plot by sampling
the result of each of the datasets for a ﬁxed number of points,
n (n = 100). We interpolate when queries fewer than n are
proposed. We then average across these datsets and calculate
the area under these curves, as shown in Table 4.

These curves measure the effectiveness of a criteria in
achieving maximum possible beneﬁt with least effort. Hence,
a curve that rises the fastest, and has the maximum area under
the curve is most desired. Expected entropy approach, gives
the best performance on F1 measure, as expected.

It is interesting to note that the gravitational-force-based
criteria does better than the expected entropy criteria on re-
call, but worse on the precision. This is because this ap-
proach captures the sizes of the two clusters and hence tends
to merge large clusters, without paying much attention to the
’purity’ of the resulting clusters. The expected entropy ap-
proach, on the other hand, takes this into account and hence
emerges as the best method. The force-based approach is a
much faster approach and it can be used as a heuristic for

IJCAI-07

433

Resource Bounded Use of Web Mentions

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

#Mentions
(Resources

Used)

Precision

Recall

F1

All Mentions

Selected Mentions

Figure 3: Using the web and selectively obtaining new mentions.

very large datasets.

Both the criteria work better than uncertainty-based and
random, except an occasional spike. All four methods are
sensitive to the noise in data labeling, result of the web
queries and sampling in stochastic graph partitioning, as re-
ﬂected by the spikes in the curves. However,
these re-
sults show that expected entropy approach is the best way
to achieve maximum returns on investment and proves to be
a promising approach to solve this class of problems, in gen-
eral.
6.5 Resource Bounded Querying for Additional

Web Mentions

We now present the results for efﬁciently querying the web
and adding new mentions to the graph. We start with initial
partitioning of citations for data sets in the DBLP corpus. We
then pick up to two or three tightly connected citations in each
cluster, clean their titles and remove stop words to form a
query. Fig. 3 shows the comparison of the result of these
queries with the result of performing all pairwise queries. By
adding only 14.86% of the nodes to the graph, we can achieve
91.25% of the original F1. In other words, we gain most of
the beneﬁt by using a small fraction of the queries. Note that
the resulting graph is smaller and hence is faster to process.
7 Conclusions and Future Work
We have formulated a new class of problems:
resource
bounded information gathering from the web in the context
of correlational clustering, and have proposed several meth-
ods to achieve this goal in the domain of entity resolution.
Our current approach yields positive results and can be ap-
plied for coreference of other object types, e.g. automatic
product categorization. We believe that this problem setting
has the potential to bring together ideas from the areas of ac-
tive learning, relational learning, decision theory and graph
theory, and apply them in a real world domain.

In future work we will explore alternative queries, (includ-
ing input from more than two citations), as well as various
new ways of efﬁciently selecting candidate queries. We are
interested in investigating more sophisticated querying crite-
ria in the case of web-as-a-mention. Additional theoretical
work in the form of new formulations and bound proofs for
these methods are also anticipated.

8 Acknowledgments
This work was supported in part by the Center for Intelligent Infor-
mation Retrieval, in part by The Central Intelligence Agency, the
National Security Agency and National Science Foundation under
NSF grant #IIS-0326249, and in part by the Defense Advanced Re-
search Projects Agency (DARPA), through the Department of the In-
terior, NBC, Acquisition Services Division, under contract number
NBCHD030010, and Microsoft Research under the Memex funding
program. Any opinions, ﬁndings and conclusions or recommenda-
tions expressed in this material are the authors’ and do not neces-
sarily reﬂect those of the sponsor. We thank Aron Culotta, Avrim
Blum, Sridhar Mahadevan, Katrina Ligett and Arnold Rosenberg for
interesting discussions.
References
[Bansal et al., 2002] N. Bansal, S. Chawla, and A. Blum. Correla-
tion clustering. In The 43rd Annual Symposium on Foundations
of Computer Science (FOCS), pages 238–247, 2002.

[Demaine and Immorlica, 2003] Erik D. Demaine and Nicole Im-
In

morlica. Correlation clustering with partial information.
RANDOM-APPROX, page 1, 2003.

[Dong et al., 2004] Xinyi Dong, Alon Y. Halevy, Ema Nemes, Ste-
fan B. Sigurdsson, and Pedro Domingos. Semex: Toward on-the-
ﬂy personal information integration. In Workshop on Information
Integration on the Web (IIWEB), 2004.

[Etzioni et al., 2004] O. Etzioni, M. Cafarella, D. Downey, S. Kok,
A. Popescu, T. Shaked, S. Soderland, D. Weld, and A. Yates.
Web-scale information extraction in knowitall. In Proceedings of
the International WWW Conference, New York. ACM, May 2004.
[Han et al., 2005] Hui Han, Hongyuan Zha, and Lee Giles. Name
disambiguation in author citations using a k-way spectral cluster-
ing method. In ACM/IEEE Joint Conference on Digital Libraries
(JCDL 2005), 2005.

[Kapoor and Greiner, 2005] Aloak Kapoor and Russell Greiner.
Learning and classifying under hard budgets. In ECML, pages
170–181, 2005.

[McCallum and Li, 2003] A. McCallum and W. Li. Early results for
named entity recognition with conditional random ﬁelds, feature
induction and web-enhanced lexicons. In Proceedings of CoNLL,
pages 188–191, 2003.

[McCallum and Wellner, 2003] Andrew McCallum and Ben Well-
ner.
Object consolidation by graph partitioning with a
conditionally-trained distance metric. KDD Workshop on Data
Cleaning, Record Linkage and Object Consolidation, 2003.

[McCallum and Wellner, 2004] A. McCallum and B. Wellner. Con-
ditional models of identity uncertainty with application to noun
coreference. In Neural Information Processing (NIPS), 2004.

[Roy and McCallum, 2001] Nicholas Roy and Andrew McCallum.
Toward optimal active learning through sampling estimation of
error reduction.
In Proc. 18th International Conf. on Machine
Learning, pages 441–448. Morgan Kaufmann, 2001.

[Thompson et al., 1999] C. A. Thompson, M. E. Califf, and R. J.
Mooney. Active learning for natural language parsing and infor-
mation extraction. In ICML, page 406, 1999.

[Zilberstein and Lesser, 1996] Shlomo Zilberstein

and Victor
Lesser.
Intelligent information gathering using decision mod-
els. Technical Report 96-35, Computer Science Department
University of Massachusetts at Amherst, 1996.

[Zilberstein, 1996] Shlomo Zilberstein. Resource-bounded reason-

ing in intelligent systems. ACM Comput. Surv, 28, 1996.

IJCAI-07

434

