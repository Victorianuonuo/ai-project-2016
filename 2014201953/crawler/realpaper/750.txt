A Theoretical Framework for Learning Bayesian Networks

with Parameter Inequality Constraints

Radu Stefan Niculescu

Tom M. Mitchell

R. Bharat Rao

Siemens Medical Solutions

Carnegie Mellon University

Siemens Medical Solutions

Malvern PA, USA

Pittsburgh PA, USA

Malvern PA, USA

stefan.niculescu@siemens.com

tom.mitchell@cs.cmu.edu

bharat.rao@siemens.com

Abstract

The task of learning models for many real-world
problems requires incorporating domain knowl-
edge into learning algorithms, to enable accurate
learning from a realistic volume of training data.
Domain knowledge can come in many forms. For
example, expert knowledge about the relevance of
variables relative to a certain problem can help per-
form better feature selection. Domain knowledge
about the conditional independence relationships
among variables can help learning of the Bayesian
Network structure.

This paper considers a different type of domain
knowledge for constraining parameter estimates
when learning Bayesian Networks.
In particular,
we consider domain knowledge that comes in the
form of inequality constraints among subsets of pa-
rameters in a Bayesian Network with known struc-
ture. These parameter constraints are incorporated
into learning procedures for Bayesian Networks, by
formulating this task as a constrained optimization
problem. The main contribution of this paper is the
derivation of closed form Maximum Likelihood pa-
rameter estimators in the above setting.

1 Introduction

Probabilistic models have become increasingly popular in
the last decade because of their ability to capture non-
deterministic relationships among variables describing many
real world domains. Among these models, Bayesian Net-
works [Heckerman, 1999] have received signiﬁcant attention
because of their ability to compactly encode conditional in-
dependence assumptions over random variables and because
of the development of effective algorithms for inference and
learning based on these representations. A Bayesian Network
consists of two components: a structure, which encodes the
assumption that a variable is conditionally independent of its
non-descendants in the network, given the value of its parents,
and a set of parameters, which describe how each variable
relates probabilistically to its parents. A Bayesian Network
encodes a unique joint probability distribution, which can be
easily computed using the chain rule.

When learning Bayesian Networks, the correctness of the
learned network of course depends on the amount of train-
ing data available. When training data is scarce, it is useful to
employ various forms of prior knowledge about the domain to
improve the accuracy of learned models. For example, a do-
main expert might provide prior knowledge specifying condi-
tional independencies among variables, constraining or even
fully specifying the network structure of the Bayesian Net-
work. In addition to helping specify the network structure,
the domain expert might also provide prior knowledge about
the values of certain parameters in the conditional probabil-
ity tables (CPTs) of the network, or knowledge in the form
of prior distributions over these parameters. While previous
research has examined a number of approaches to represent-
ing and utilizing prior knowledge about Bayesian Network
parameters, the type of prior knowledge that can be utilized
by current learning methods remains limited, and is insufﬁ-
cient to capture many types of knowledge that may be readily
available from experts.

The main contribution of our paper consists of deriving
closed form Maximum Likelihood estimators for the param-
eters in a Bayesian Network, in the setting that expert do-
main knowledge is available in the form of parameter inequal-
ity constraints, which current methods can not accommodate.
With our estimators comes a theorem that describes the per-
formance in the case when the domain knowledge represented
by the inequality constraints might not be entirely accurate.

The next section of the paper describes related research
on constraining parameter estimates for Bayesian Networks.
Section 3 presents the task of parameter estimation in the
presence of general parameter constraints and formulates it
as a constrained optimization problem. Section 4 details the
main contribution of this paper: closed form solutions for pa-
rameter estimates for several classes of parameter inequality
constraints. Some formal guarantees about our estimators are
discussed in section 5. We conclude with a brief summary of
this research along with several directions for future work.

2 Related Work

The main methods to represent relationships among param-
eters of a Bayesian Network fall into two main categories:
Dirichlet Priors and their variants (including smoothing tech-
niques) and Parameter Sharing of several kinds.

IJCAI-07

155

In [Geiger and Heckerman, 1997], it is shown that Dirich-
let Priors are the only possible priors for discrete Bayesian
Networks, provided certain assumptions hold. One can think
of a Dirichlet Prior as an expert’s guess for the parameters
in a discrete Bayesian Network, allowing room for some
variance around the guess. One of the main problems with
Dirichlet Priors and related models is that it is impossible
to represent even simple equality constraints between pa-
rameters (for example the constraint: θ111 = θ121 where
θijk = P (Xi = xij |P arents(Xi) = paik)) without us-
ing priors on the hyperparameters of the Dirichelet Prior, in
which case the marginal likelihood can no longer be com-
puted in closed form, and expensive approximate methods are
required to perform parameter estimation. A second problem
is that it is often beyond the expert’s ability to specify a full
Dirichlet Prior over the parameters of a Bayesian Network.

A widely used form of parameter constraints employed
by Bayesian Networks is Parameter Sharing. Models us-
ing different
types of Parameter Sharing include: Dy-
namic Bayesian Networks [Murphy, 2002] and their spe-
cial case Hidden Markov Models [Rabiner, 1989], Module
Networks [Segal et al., 2003], Context Speciﬁc Indepen-
dence models [Boutilier et al., 1996] such as Bayesian Multi-
networks, Recursive Multinetworks and Dynamic Multinet-
works [Geiger and Heckerman, 1996; Pena et al., 2002;
Bilmes, 2000], Probabilistic Relational Models [Friedman et
al., 1999], Object Oriented Bayes Nets [Koller and Pfeffer,
1997], Kalman Filters [Welch and Bishop, 1995] and Bilinear
Models [Tenenbaum and Freeman, 2000]. Parameter Sharing
methods constrain parameters to share the same value, but
do not capture more complicated constraints among parame-
ters such as inequality constraints or constraints on sums of
parameter values. The above methods are restricted to shar-
ing parameters at either the level of sharing a conditional
probability table (CPT) (Module Networks, HMMs), at the
level of sharing a conditional probability distribution within
a single CPT (Context Speciﬁc Independence), at the level
of sharing a state-to-state transition matrix (Kalman Filters)
or at the level of sharing a style matrix (Bilinear Models).
None of the above models allow sharing at the level of gran-
ularity of individual parameters. [Niculescu et al., 2005] in-
troduces a parameter equality constraint framework that de-
scribes many models that use parameter sharing: Module
Networks, Context Speciﬁc Independence models, HMMs
and Dynamic Bayesian Networks. Within this framework,
it is showed how efﬁcient parameter learning is performed
from both a frequentist and bayesian point of view, from both
observable and partially observable data.

All the models described so far can only take advantage of
certain types of parameter equality constraints. Only recently,
[Altendorf et al., 2005; Feelders and van der Gaag, 2006]
study the feasibility of incorporating simple inequality con-
straints in the learning of parameters of Bayesian Networks.
The constraints analyzed in these papers are somehow restric-
tive, in the sense that each constraint must involve all parame-
ters in a conditional probability table, whereas our framework
allows for constraints at individual distribution level of gran-
ularity. Additionally, in [Altendorf et al., 2005], the authors
employ an approximation algorithm, whereas we derive ex-

act estimators. Further, [Altendorf et al., 2005] assumes the
values of the variables can be totally ordered and [Feelders
and van der Gaag, 2006] assumes all variables are binary.
Our framework makes none of these assumptions. In the next
section we will place parameter learning with inequality con-
straints in a general constrained optimization framework and
we will show how closed form learning of the parameters of
Bayesian Networks can be performed when expert knowledge
is available in the form of either of two types of parameter in-
equality constraints.

3 Problem Deﬁnition and Approach

Here we deﬁne the problem and suggest a general optimiza-
tion based approach to solve it. This approach has serious
limitations when the constraints are arbitrary. However, it
constitutes the basis for computing the Maximum Likelihood
estimators for the classes of inequality constraints described
in section 4. We begin by describing the problem along with
several assumptions.

3.1 The Problem

Our task here is to perform parameter estimation in a
Bayesian Network where the structure is known in advance.
To accomplish this task, we assume a dataset of examples
is available. In addition, a set of parameter equality and/or
inequality constraints is provided by a domain expert. The
equality constraints are of the form gi(θ) = 0 for 1 ≤ i ≤ m
and the inequality constraints are of the form hj(θ) ≤ 0 for
1 ≤ j ≤ k, where θ represents the set of parameters of the
Bayesian Network.

Initially we will assume the domain knowledge provided
by the expert is correct. Later, we investigate what happens if
this knowledge is not completely accurate. Next we enumer-
ate several assumptions that must be satisﬁed for our meth-
ods to work. These are similar to common assumptions made
when learning parameters in standard Bayesian Networks.

First, we assume that the examples in the training dataset
are drawn independently from the underlying distribution. In
other words, examples are conditionally independent given
the parameters of the Bayesian Network. Second, we assume
that all the variables in the Bayesian Network can take on at
least two different values. This is a safe assumption since
there is no uncertainty in a random variable with only one
possible value. Any such variables in our Bayesian Network
can be deleted, along with all arcs into and out of the nodes
corresponding to those variables. Third, when computing pa-
rameter estimators, we additionally assume that all observed
counts corresponding to parameters in the Bayesian Network
are strictly positive. We enforce this condition in order to
avoid potential divisions by zero, which may impact infer-
ence negatively. In the real world it is expected there will be
observed counts which are zero. This problem can be solved
by using priors on parameters, that essentially have the ef-
fect of adding a positive quantity to the observed counts and
essentially create strictly positive virtual counts.

Finally, the functions g1, . . . , gm and h1, . . . , hk must be
twice differentiable, with continuous second derivatives. This
assumption justiﬁes the formulation of our problem as a con-

IJCAI-07

156

strained maximization problem that can be solved using stan-
dard optimization methods.

3.2 A General Approach

In order to solve the problem described above, here we brieﬂy
suggest an approach based on already existing optimization
techniques. The idea is to formulate our problem as a con-
strained maximization problem where the objective function
is the data log-likelihood log P (D|θ) and the constraints are
given by gi(θ) = 0 for 1 ≤ i ≤ m and hj(θ) ≤ 0 for
1 ≤ j ≤ k.
It is easy to see that, applying the Karush-
Kuhn-Tucker conditions theorem [Kuhn and Tucker, 1951],
the maximum must satisfy a system with the same number of
equations as variables. To solve this system, one can use any
of several already existing methods (for example the Newton-
Raphson method [Press et al., 1993]).

It is well known that ﬁnding a solution for the system given
by the KKT conditions is not enough to determine the opti-
mum point, but fortunately the objective function is concave
and most of the constraints we have encountered in real life
are linear equalities or inequalities. Therefore several well
known sufﬁciency criteria can guarantee optimality.

Unfortunately, the above methods have serious shortcom-
ings in the general case. With a large number of parameters in
the Bayesian Network, they can be extremely expensive be-
cause they involve potentially multiple runs of the Newton-
Raphson method and each such run requires several expen-
sive matrix inversions. Other methods for ﬁnding the solu-
tions of a system of equations can be employed, but, as noted
in [Press et al., 1993], all these methods have limitations in
the case when the constraints are arbitrary, non-linear func-
tions. The worst case happens when there exists a constraint
that explicitly uses all parameters in the Bayesian Network.

The above method should be regarded as a mere suggestion
and, because of its shortcomings, we believe it is not compu-
tationally feasible with arbitrary constraints. We mentioned it
here only to show how learning in the presence of parameter
constraints can be formulated as a general constrained max-
imization problem. This general approach also provides the
starting point for ﬁnding closed form Maximum Likelihood
estimators given the particular classes of parameter inequal-
ity constraints presented in the next section.

4 Learning with Inequality Constraints

In this section we derive closed form Maximum Likelihood
estimators for the parameters in a discrete Bayesian Network
with known structure when domain knowledge is provided as
either of the two types of inequality constraints.

4.1

Inequalities between Sums of Parameters

Brieﬂy, this type of Parameter Domain Knowledge states that
the sum of several parameters within one conditional prob-
ability distribution is bounded by the sum of other parame-
ters in the same distribution of the Bayesian Network. Intu-
itively, one can think of this constraint in terms of the parts
of speech of a language. Usually, an adverb comes along
with a verb and therefore it is reasonable to assume that a lan-
guage expert can specify that the aggregate probability mass

⎧⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩

IJCAI-07

157

of adverbs is no greater than the aggregate probability mass
of the verbs in a given language. Formally, in this type of
domain knowledge, the parameters of a conditional probabil-
ity distribution, denoted by θ1, . . . , θn, can be partitioned into
θ = ∪s
θi∈Bk θi
for all 1 ≤ k ≤ s. Let us denote by NAk the sum of the ob-
served counts corresponding to parameters in Ak. Similar
deﬁnitions hold for NBk and NC . Let N be the sum of all
observed counts Ni corresponding to parameters θ.

k=1 Bk ∪C such that

θi∈Ak θi ≤

k=1Ak ∪s

(cid:2)

(cid:2)

An expert can potentially specify different such con-
straints for several conditional probability distributions in the
Bayesian Network. Because of the decomposability of log-
likelihood, the problem of computing the Maximum Like-
lihood parameter estimators can be decomposed in a set of
independent optimization subproblems, one for each condi-
tional probability distribution in the network. We have the
following theorem:

Theorem 4.1. If all Ni are strictly positive, the Maximum
Likelihood Estimators of parameters θ are given by:

N

+NBk

2·NAk

· NAk
· NAk

a) ˆθi = Ni
b) ˆθi = Ni
c) ˆθi = Ni
d) ˆθi = Ni

if θi ∈ Ak and NAk
if θi ∈ Bk and NAk
N if θi ∈ Ak ∪ Bk and NAk < NBk
N if θi ∈ C

2·NBk

+NBk

N

≥ NBk
≥ NBk

(cid:2)

Proof. Finding Maximum Likelihood estimators is equiva-
i Ni · log θi subject to the
lent to maximizing l(θ) =
domain knowledge constraints, including the constraint that
i θi − 1 = 0. Since this problem contains in-
g(θ) =
equality constraints, we can attempt to solve it using Karush-
Kuhn-Tucker theorem. We introduce the Lagrange Multiplier
θi∈Ak θi−
(cid:2)
λ for g and μk for inequality constraint hk(θ) =
θi∈Bk θi ≤ 0. The optimum ˆθ can then be found among the

(cid:2)

solutions of the system:

∇θ l(ˆθ) − λ · ∇θ g(ˆθ) −

k μk · ∇θ hk(ˆθ) = 0

(cid:2)

(cid:2)

g(ˆθ) = 0

μk · hk(ˆθ) = 0

hk(ˆθ) ≤ 0

μk ≥ 0

From the ﬁrst equation we obtain:

⎧⎨
⎩

ˆθi =
(cid:2)

Ni
λ+μk if θi ∈ Ak
Ni
λ−μk if θi ∈ Bk
Ni
λ if θi ∈ C
(cid:2)

Therefore,

ˆθi =
Based on whether constraint k is tight or not we have:

ˆθi =

θi∈Ak

θi∈Bk

NAk
λ+μk and

NBk
λ−μk .

NAk

• If hk(ˆθ) = 0, then

+NBk
2λ

NAk
λ+μk =

NBk
λ−μk . This implies

NAk
λ+μk =
NBk
ˆθi =
λ−μk =
+NBk
NAk
−NBk ) =
λ
μk · (NAk + NBk ). Since μk ≥ 0, we also must have
NAk

≥ NBk in order for constraint k to be tight.

. In this case, we also have λ·(NAk

and therefore

θi∈Ak∪Bk

(cid:2)

(cid:2)

• If hk(ˆθ) < 0, then μk = 0 and therefore we again have
. In this case we also have
and since hk(ˆθ) < 0, we must also

ˆθi =
−NBk
λ

θi∈Ak∪Bk

+NBk
λ

NAk

NAk

hk(ˆθ) =
have NAk < NBk .

The above observations allow us to conclude that a con-
≥ NBk . Now, summing up
straint is tight if and only if NAk
over all parameters in the conditional probability distribution
we get:

(cid:2)

(cid:7)

1 =

i

ˆθi =

NC +

k(NAk + NBk )

λ

=

N
λ

This gives us: λ = N and therefore:

⎧⎨
⎩

ˆθi =

Assume now that NAk

Ni
N +μk if θi ∈ Ak
Ni
N −μk if θi ∈ Bk
Ni
N if θi ∈ C
≥ NBk . According to the obser-
vations above, it means constraint k is tight and we have:
NAk
N +μk =
. From this we immediately
derive: ˆθi = Ni
if θi ∈ Ak and NAk
≥ NBk
and ˆθi = Ni

if θi ∈ Bk and NAk

+NBk
2·N
+NBk

· NAk
+NBk

NBk
N −μk =

N
· NAk

≥ NBk .

2·NAk

NAk

N

2·NBk

If NAk < NBk , then, as discussed above, μk must be 0
and therefore ˆθi = Ni
N if θi ∈ Ak ∪ Bk and NAk < NBk .
Because the log-likelihood objective function is concave and
because the constraints are linear inequalities, it follows that ˆθ
is the set of Maximum Likelihood estimators. This concludes
the proof of our theorem.

4.2 Upper Bounds on Sums of Parameters

Here the domain expert provides upper bounds on the sum of
several parameters within one conditional probability distri-
bution in the Bayesian Network. Consider the same language
example described in the introduction of the previous subsec-
tion. Here the expert may state that the aggregate probability
of nouns is no greater than 0.4, the aggregate probability of
verbs is no greater than 0.4 and the aggregate probability of
adjectives is no greater than 0.3. Even though the combined
probability mass of all words equals one, the sum of the upper
bounds provided by the expert can be greater than one. For-
mally, in this type of domain knowledge, the parameters of
a conditional probability distribution, denoted by θ1, . . . , θn,
θi∈Ak θi ≤ αk
can be partitioned in θ = ∪s
for all 1 ≤ k ≤ s, where αk is a given positive constant.
Again, denote by NAk the sum of the observed counts cor-
responding to parameters in Ak and by N be the sum of all
observed counts Ni corresponding to parameters θ. If there
are parameters not involved in any of these constraints, then
we can consider they belong to their own set Ak with αk = 1.
In the previous subsection we found an easy way to de-
cide whether a constraint is tight at the optimum point. For
the type of constraints we deal with here, we are not able to
derive such a simple criterion. However, we show a simple,
linear algorithm that computes the set of tight constraints at

k=1Ak such that

(cid:2)

the optimum point. This algorithm starts with an empty set
and at each step adds one of the ﬁnal tight constraints.

Again, an expert can specify different sets of such con-
straints for different conditional probability distributions in
the network and, because of the decomposability of log-
likelihood, we can decompose the task of ﬁnding the Max-
imum Likelihood estimators into a set of independent opti-
mization subproblems:

Theorem 4.2. Assume all observed counts Ni are strictly
positive and also assume we know the set K = {k1, . . . , kl}
of constraints that are tight at the point given by the Maxi-
mum Likelihood estimators ˆθ. Then, we have:

a) ˆθi = αk · Ni
(cid:2)
NAk
b) ˆθi = (1 −

k (cid:7)∈ K

if θi ∈ Ak and k ∈ K
j∈K αj) ·

NiP

m(cid:2)∈K NAm

if θi ∈ Ak and

(cid:2)

(cid:2)

Proof. We can approach the problem of ﬁnding the Maxi-
mum Likelihood estimators in a similar fashion as in Theo-
i Ni ·
rem 4.1. The data log-likelihood is given by l(θ) =
log θi which we have to maximize with respect to the do-
main knowledge constraints, including the constraint that
i θi − 1 = 0. Again, we use Karush-Kuhn-Tucker
g(θ) =
theorem. We introduce the Lagrange Multiplier λ for g and
θi∈Ak θi − αk ≤ 0.
μk for inequality constraint hk(θ) =
The optimum ˆθ can then be found among the solutions of the
system:

(cid:2)

⎧⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩

∇θ l(ˆθ) − λ · ∇θ g(ˆθ) −

(cid:2)

k μk · ∇θ hk(ˆθ) = 0

g(ˆθ) = 0

μk · hk(ˆθ) = 0

hk(ˆθ) ≤ 0

μk ≥ 0

From the ﬁrst equation we obtain:

ˆθi =

(cid:2)

Therefore,

θi∈Ak

Ni

λ + μk
ˆθi =

if θi ∈ Ak

NAk
λ+μk . Based on whether con-

straint k is tight or not we have:

• If hk(ˆθ) = 0 i.e. k ∈ K, then

NAk
λ+μk = αk. This implies

ˆθi = Ni
λ+μk = αk · Ni
NAk
(cid:2)

.

have

θi∈Ak

ˆθi =

NAk
λ .

• If hk(ˆθ) < 0 i.e. k (cid:7)∈ K, then μk = 0 and therefore we

Summing up over all parameters not involved in the tight

constraints, we get:

(cid:7)

(cid:7)

(1 −

αj) =

θi =

j∈K

θi∈Ak,k(cid:4)∈K

(cid:2)

j(cid:4)∈K NAj

λ

(cid:2)

We obtain λ =
NiP
j∈K αj) ·

m(cid:2)∈K NAm

P

1−

m(cid:2)∈K NAm
P

j∈K αj and further: ˆθi = (1 −
if θi ∈ Ak and k (cid:7)∈ K. Because

IJCAI-07

158

the log-likelihood objective function is concave and because
the constraints are linear inequalities, it follows that ˆθ is the
set of Maximum Likelihood estimators. This concludes our
derivation of the Maximum Likelihood estimators when we
know in advance which constraints are satisﬁed by our esti-
mators.

Next we describe the algorithm that ﬁnds the set K of tight

j∈K

m(cid:4)∈K

(cid:2)

(1 −
is proved.

j∈K∪kl αj) > 0 and the ﬁrst part of the induction step
(cid:2)

If in both sides of inequality 1 we add the quantity (1 −
−

m(cid:4)∈K∪{kl} NAm , we obtain:

αkl

(cid:2)
(cid:7)

j∈K αj) ·
(cid:7)

(cid:7)

αj)·

(cid:7)

j∈K

m(cid:4)∈K∪{kl}

NAm

≥ (1−
(cid:2)

(1−αkl

−

αj)·

NAm

−

j∈K αj > 0, is equivalent to

which, given that 1 − αkl
λl ≥ λl+1. This concludes the proof of our lemma.
(cid:2)

Applying Lemma 4.2, it follows that, in the case when
(cid:7)= 1, the Algorithm 4.1 ends at a step l such that
j αj
≥ λj ≥ λl for all kj ∈ K and

NAkj
NAk
αk < λl for all
αkj
k (cid:7)∈ K. From Lemma 4.1 it follows that K is the set of tight
j αj (cid:7)= 1 and therefore Algo-
constraints in the case when
rithm 4.1 is correct. Another case is when all constraints are
processed and we are not left with a λl to compare with. This
situation can not happen, because, at the last step, we would
have:

(cid:2)

(cid:2)
NAks

1 −
(cid:2)

j(cid:4)=ks αj

≤ NAks
(cid:2)
αks

j αj = 1 or
(cid:2)

j αj < 1. In the second
and therefore either
case, the constraints are contradictory, which can not happen
because we assume the domain expert provides accurate do-
j αj = 1 (case which is not covered
main knowledge. If
by Algorithm 4.1), it is obvious that the all constraints must
be tight not only for the Maximum Likelihood estimators, but
for every feasible value of θ.

5 Formal Guarantees
Sometimes it may happen that the constraints provided by
an expert are not completely accurate.
In all our methods
so far, we assumed that the constraints are correct and there-
fore errors in domain knowledge can prove detrimental to the
performance of our learned models. In this section we investi-
gate the relationship between the true, underlying distribution
of the observed data and the distribution estimated using our
methods based on inequality constraints. Because of space
reasons, we omit the proofs for the theorem and the corollary
presented in this section.

∗

Suppose P is the true distribution from which data is sam-
be the the closest distribution to P (in terms of
pled. Let P
KL(P, ·)) that factorizes according to the given structure and
obeys the expert’s inequality constraints. We have:

Theorem 5.1. With an inﬁnite amount of data, the distribu-
tion ˆP given by the Maximum Likelihood estimators in Theo-
rem 4.1 converges to P

with probability 1.

∗

Corollary 5.1. If the true distribution P factorizes according
to the given structure and if the parameter inequality con-
straints provided by the expert are completely accurate, then
the distribution ˆP given by the estimators computed in Theo-
rem 4.1 converges to P with probability 1.

Similar results hold for the inequality constraints described

in subsection 4.2.

constraints:

(cid:2)

j αj (cid:7)= 1)

Algorithm 4.1. (Finding the set of tight constraints if

STEP 1. Start with K = ∅ and at each step add a constraint
to K.

STEP 2. If K = {k1, . . . , kl}, let λl =
above theorem.

P

1−

m(cid:2)∈K NAm
P

j∈K αj as in the

STEP 3. If there exists kl+1 (cid:7)∈ K such that
≥ λl, let
K = K ∪ {kl+1} and GO TO Step 2. Otherwise STOP and
declare K the set of tight constraints.

NAkl+1
αkl+1

Proof. (Correctness of Algorithm) We start by making the
following observation, based on the proof of Theorem 4.2:

• If hk tight, then
≥ λ.

have

NAk
αk

NAk
λ+μk = αk. Because μk ≥ 0, we must

NAk

• If hk not tight, then μk = 0 and therefore we have 0 >
NAk
αk <
It is obvious that λ ≥ 0 must hold, otherwise we

hk(ˆθ) =
λ.
would have negative parameters.

− αk and therefore we must have

λ

We have just developed a criterion to test if a set K of

constraints is the set of tight constraints:

Lemma 4.1. Given λ (which depends on K) computed as in
Theorem 4.2, K is the set of tight constraints if and only if
NAk
αk

NAk
αk < λ for all k (cid:7)∈ K.

≥ λ for all k ∈ K and

Before proving that our algorithm produces the set of tight

constraints, let us prove another useful result:

(cid:2)
(cid:2)
j αj (cid:7)= 1 then N = λ0 ≥ λ1 ≥ . . ., and
j∈K αj is always strictly positive.

Lemma 4.2. If
the quantity 1 −

(cid:2)

Proof. (of lemma) Since initially K = ∅, it is obvious that
j∈K αj ≥ 0. It is also obvious λ0 = N . Let us verify
1 −
the induction step.

(cid:2)

From

NAkl
αkl

≥ λl and because 1 −

NAkl

· (1 − αkl

αj ) ≥ αkl

·

(cid:7)

j∈K

−
(cid:2)

j∈K αj > 0 we get:
(cid:7)

NAm

(1)

m(cid:4)∈K∪{kl}

(cid:2)

It follows (1 −

j∈K∪kl αj) ≥ 0 with equality if and
only if we processed all constraints, in which case we have
1 =
j αj and it is obvious that all constraints must be
j αj (cid:7)= 1, we must have
tight. However, since we assumed

(cid:2)

IJCAI-07

159

6 Conclusions and Future Work

Building accurate models from limited training data is pos-
sible only by using some form of prior knowledge to aug-
ment the data. Prior knowledge in the form of parameter
equality constraints has been incorporated in learning of sev-
eral bayesian network models, including Module Networks,
HMMs and Context Speciﬁc Independence models.

In this paper we have demonstrated that the standard
methods for parameter estimation in Bayesian Networks can
be naturally extended to accommodate parameter inequality
constraints by formulating this as a constrained maximiza-
tion problem and deriving closed form Maximum Likelihood
parameter estimators.
It is also important to note that one
can combine the two types of parameter inequality constraints
presented in this paper as well as the parameter sharing con-
straints described in Section 2 when learning the parameters
of a Bayesian Network as long as the scopes of these con-
straints do not overlap.

We have proved that even when the asserted parameter con-
straints turn out to be incorrect, given an inﬁnite amount of
training data, our Maximum Likelihood estimators converge
to the best describable distribution; that is, the distribution
closest in terms of KL distance from the true distribution,
among all distributions that obey the parameter inequality
constraints and factor according to the given structure.

We see several useful directions for future work. First,
we would like to prove that by incorporating the inequality
constraints given by an expert we compute estimators with
lower variance than the ones obtained by simply learning the
Bayesian Network directly from the data. A second direction
to explore is to approach learning from a bayesian (as op-
posed to a frequentist) point of view. This might be achieved
by specifying Constrained Dirichlet Priors which assign zero
probability mass over the space where the constraints are not
satisﬁed. However, it is a challenge to compute the normal-
ization constant of such distributions in closed form.

Acknowledgments

We would like to thank John Lafferty, Andrew Moore, Russ
Greiner and Zoubin Ghahramani for their useful comments
and suggestions. As a student at Carnegie Mellon Univer-
sity, Radu Stefan Niculescu was sponsored by the NSF grants
CCR-0085982 and CCR-0122581, by the Darpa PAL pro-
gram under contract NBCD030010, and by a generous gift
from Siemens Medical Solutions.

References
[Altendorf et al., 2005] E. E. Altendorf, A. C. Restiﬁcar, and
T. G. Dietterich. Learning from sparse data by exploiting
monotonicity constraints. In Proceedings of the 21th An-
nual Conference on Uncertainty in Artiﬁcial Intelligence
(UAI-05), pages 18–26, Arlington, Virginia, 2005. AUAI
Press.

[Bilmes, 2000] J. Bilmes. Dynamic bayesian multinets. In

Proceedings of UAI, pages 38–45, 2000.

[Boutilier et al., 1996] C. Boutilier, N. Friedman, M. Gold-
szmidt, and D. Koller. Context-speciﬁc independence in

bayesian networks.
115–123, 1996.

In Proceedings of 12th UAI, pages

[Feelders and van der Gaag, 2006] A. J. Feelders and L. C.
van der Gaag. Learning bayesian network parameters un-
der order constraints.
International Journal of Approxi-
mate Reasoning, 42:37–53, 2006.

[Friedman et al., 1999] N. Friedman, L. Getoor, D. Koller,
and A. Pfeffer. Learning probabilistic relational models.
In Proceedings of 16th IJCAI, pages 1300–1307, 1999.

[Geiger and Heckerman, 1996] D. Geiger and D. Hecker-
man. Knowledge representation and inference in similarity
networks and bayesian multinets. Artiﬁcial Intelligence,
82:45–74, 1996.

[Geiger and Heckerman, 1997] D. Geiger and D. Hecker-
man. A characterization of the dirichlet distribution
through global and local parameter independence. The An-
nals of Statistics, 25:1344–1369, 1997.

[Heckerman, 1999] D. Heckerman. A tutorial on learning
with bayesian networks. In M. Jordan, editor, Learning in
Graphical Models. MIT Press, Cambridge, MA, 1999.

[Koller and Pfeffer, 1997] D. Koller and A. Pfeffer. Object
oriented bayesian networks. In Proceedings of 13th UAI,
pages 302–313, 1997.

[Kuhn and Tucker, 1951] H. W. Kuhn and A. W. Tucker.
Nonlinear programming.
In Proceedings of the Second
Berkeley Symposium on Mathematical Statistics and Prob-
ability, pages 481–492. University of California Press,
1951.

[Murphy, 2002] K. P. Murphy. Dynamic Bayesian Networks:
Representation, Inference and Learning. PhD thesis, UC
Berkeley, 2002.

[Niculescu et al., 2005] R. S. Niculescu, T. Mitchell, and
R. B. Rao. Parameter related domain knowledge for learn-
ing in graphical models.
In Proceedings of SIAM Data
Mining conference, 2005.

[Pena et al., 2002] J. M. Pena, J. A. Lozano, and P. Lar-
ranaga. Learning recursive bayesian multinets for data
clustering by means of constructive induction. Machine
Learning, 47(1):63–89, 2002.

[Press et al., 1993] W. H. Press, S. A. Teukolsky, and W. T.
Vetterling. Numerical Recipes in C: The Art of Scientiﬁc
Computing. Cambridge University Press, 1993.

[Rabiner, 1989] R. L. Rabiner. A tutorial on hidden markov
models and selected applications in speech recognition.
Proceedings of the IEEE, 77(2):257–286, 1989.

[Segal et al., 2003] E. Segal, D. Pe’er, A. Regev, D. Koller,
and N. Friedman. Learning module networks. In Proceed-
ings of 19th UAI, pages 525–534, 2003.

[Tenenbaum and Freeman, 2000] J. B. Tenenbaum and W. T.
Freeman. Separating style and content with bilinear mod-
els. Neural Computation, 12(6):1247–1283, 2000.

[Welch and Bishop, 1995] G. Welch and G. Bishop. An in-
troduction to the kalman ﬁlter. Technical Report TR 95-
041, University of North Carolina, 1995.

IJCAI-07

160

