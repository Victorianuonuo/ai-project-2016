Combining Two Local Search Approaches to Hypergraph Partitioning 

Arathi Ramani and Igor Markov 

Department of Electrical Engineering and Computer Science, 

University of Michigan,  Ann Arbor 48109-2122 

{ramania,imarkov} @eecs.umich.edu 

Abstract 
We study leading-edge  local  search heuristics for balanced hyper(cid:173)
graph partitioning and Boolean satisfiability, intending the general(cid:173)
ization of such heuristics beyond their original domains.  We adapt 
the Fiduccia Mattheyses (FM) hypergraph partitioning heuristic to 
Boolean  Satisfiability (SAT), and the  WalkSAT SAT solver to hy(cid:173)
pergraph partitioning.  Focusing on balanced hypergraph partition(cid:173)
ing,  we  propose  a  combination  of the  classical  FM  heuristic  and 
our "cross-over" heuristic WalkPart, and empirically show that it is 
more powerful than each component alone.  Empirically, we show 
a  15% improvement  in net cut and a 7% improvement  in runtime 
over a leading-edge implementation  of the FM heuristic. 

Introduction 

1 
The focus of our work is on search heuristics for balanced min-cut 
hypergraph partitioning, a well-known combinatorial optimization 
problem.  In general terms, the problem seeks to assign every ver(cid:173)
tex of a hypergraph to one of two subsets to minimize the number 
of connections between the two subsets, subject to having approx(cid:173)
imately  the  same  number  of vertices  in  each  subset.  Hypergraph 
partitioning is important in circuit layout because circuits arc often 
represented by hypergraphs,  e.g.  in placement by recursive bisec(cid:173)
tion.  Many efficient hypergraph partitioning algorithms have been 
developed  [3,4].  Here,  we  discuss  the  combination  of two  local 
search heuristics:  the Fiduccia-Mattheyses (FM) hypergraph parti(cid:173)
tioning heuristic [3], and the biased random walk heuristic, adapted 
from  the WalkSAT SAT solver [5]. 

Our work  is  motivated  by  attempts  to  generalize  well-known 
local search procedures  [5, 3] beyond their original domains.  We 
developed a SAT solver based on the FM algorithm  [3], and a hy(cid:173)
pergraph partitioner,  WalkPart,  based  on  the WalkSAT  algorithm 
from  [5].  The  WalkPart  algorithm  is  described  in  Section  3.  A 
detailed description  of the  SAT  solver is  beyond  the  scope  of this 
paper.  Our results show that WalkPart outperforms a highly tuned 
implementation  of FM  on  several  circuit  benchmarks.  The  algo(cid:173)
rithms  also  produce  very  different  solutions  and  appear  to  have 
different local  minima, suggesting that a hybrid strategy might be 
effective.  Empirical results show that the hybrid approach outper(cid:173)
forms  both  algorithms,  in  terms  of runtime  and  solution  quality. 
Our main contributions are summarized as follows. 

•  We  describe  the  balanced  min-cut  hypergraph  partitioning 
algorithm,  WalkPart,  based  on  the  WalkSAT  satisfiability 
solver  [5] 

•  We propose the combination of the FM and WalkPart heuris(cid:173)
tics  to  form  a  "hybrid"  heuristic,  and  perform  two  experi(cid:173)
ments 

•  Empirically, we show that a hybrid strategy achieves signifi(cid:173)

cantly better performance than either heuristic alone 

2  Background and Previous Work 

2.1  Hypergraph  Partitioning Problem: 
A hypergraph H(V,E)  is defined as a set,  V, of vertices, and a set, 
E,  of hyperedges,  where  each  edge e  E 
is a  set  of two or more 
vertices  from  V.  The  k-way  hypergraph  partitioning  problem  is 
stated as follows:  Let H(V,E)  be a hypergraph with weighted ver(cid:173)
tices and  edges.  The problem  asks  to  find  a minimum  cost parti(cid:173)
of the  vertices of // to k  disjoint subsets.  The  cost  function 
tion 
typically used is edge cut,  the sum of the weights of the hy(cid:173)
peredges  cut  by  the partition  (this  is  called  min-cut  partitioning). 
A hypcredgc is cut exactly when all of its vertices arc in more than 
one subset.  Constraints may be imposed on a partition e.g.  limiting 
the  total  vertex  weight  in each  subset  (balance,  constraints).  The 
balance-constrained  weighted  hypergraph  partitioning problem  is 
NP-hard. 
The  algorithms  in  this  work  deal  with  the  balanced 
min-cut hypergraph bi-partitioning problem, i.e., we consider only 
the case where k =  2.  In circuit  layout,  hypergraphs represent cir(cid:173)
cuits by mapping vertices to signal nodes, and hyperedges to signal 
nets.  In this context, we use the words "node" and "net" to mean 
"vertex"  and  "hyperedge"  when  referring  to  hypergraphs  in  this 
document. 

2.2  The  Fiduccia-Mattheyses  Heuristic 
The Fiduccia-Mattheyses (FM) [3] heuristic  for bi-partitioning cir(cid:173)
cuit hypergraphs is an iterative improvement algorithm.  FM starts 
with an arbitrary initial solution and changes the solution by a se(cid:173)
quence of moves, organized as passes.  At the beginning of a pass, 
all vertices are free to move (unlocked).  Each possible move is la(cid:173)
beled with the immediate change in total cost it would cause (called 
"gain").  Iteratively, a move with highest gain is selected and exe(cid:173)
cuted,  which may result in a  lower,  higher or unchanged  solution 
cost1. The moved vertex is locked, i.e., not allowed to move again 
during that pass.  Since  moving a  vertex  can  change  gains  of ad(cid:173)
jacent vertices, all affected gains are updated.  Selection and exe(cid:173)
cution of a best-gain move,  followed by gain update,  are repeated 
until every vertex is locked.  The best solution seen during the pass 
is adopted as the starting solution of the next pass.  The algorithm 
terminates when a pass fails to improve solution quality. 

The  FM  heuristic  is  now  used  as  a  component  in  multi-level 
partitioning  algorithms  [4]  which  create  a  series  of clustered  hy(cid:173)
pergraphs,  partition  the  most  clustered  with  "flat"  FM  and  then 
refine  unclustered  versions  of the  produced  partition by  applying 
FM  in  incremental  mode.  A  highly  optimized,  leading  edge  im(cid:173)
plementation  of FM  in this  context  is  available  in  [2].  This  work 
only  deals  with  "flat" partitioning  heuristics  in  the  hope  that  im(cid:173)
proved flat heuristics will  lead to  improved multi-level heuristics. 
This assumption will be verified in our future work. 

1 In a problem with balance constraints, moves should also not violate the  legality 

constraint 

1546 

POSTER PAPERS 

Table  1:  Results for  10 passes of a  Hybrid  Algorith m:  FM  is  run  once  to  com  ple-
tion, followed  by  100K  moves  of WalkPart alternated  with single  passes  of FM  . 

FMPart 

Hybrid 

Benchmark 
Benchmark 
Name 
Name 
ibm01 + 10 
ibm01+4 
ibm02+10 
ibm02+4 
ibm03+10 
ibm03+4 
ibm04+10 
ibm04+4 
ibm05+10 
ibm06+10 
ibm()7+IO 
ibm08+10 
ibm09+10 
ibm10+10 
ibm11+10 
ibml2+10 
Average 

Nodes 
Nodes 

Nets 
Nets 

12752 
12752 
19601 
19601 
23136 
23136 
27507 
27507 
29347 
32498 
45926 
51309 
53395 
69429 
70558 
71076 

14111 
14111 
19584 
19584 
27401 
27401 
31970 
31970 
28446 
34826 
48117 
50513 
60902 
75196 
81454 
77240 

Moves 

2M 
500K 
500K 
500K 
2M 
500K 
500K 
2M 
2M 
2M 
2M 
2M 
2M 
2M 
2M 
2M 

WalkPart 
Time 
9.16 
2.56 
3.61 
3.61 
14.15 
3.84 
4.50 
14.94 
17.34 
12.73 
18.07 
24.92 
19.60 
19.79 
21.61 
22.99 

Cut 

610.67 
506.00 
329.67 
654.33 
1603.33 
1175.00 
1589.00 
2121.00 
4804.67 
750.00 
2483.33 
1902.67 
2069.00 
3414.67 
2433.33 
3803.67 

Time 
1.54 
1.39 
2.15 
2.14 
3.84 
3.14 
5.30 
3.52 
9.54 
5.63 
9.63 
11.76 
14.38 
15.36 
19.78 
23.03 

Cut 

477.00 
464.33 
402.00 
386.00 
1487.67 
2488.00 
718.67 
2505.00 
2793.33 
1683.00 
1347.33 
3076.00 
1936.00 
2200.33 
4203.33 
4200.67 

Time  | 
2.0 
2.667 
3.8 
3.7 
5.0 
5.86 
9.0 
5.0 
14.75 
10.5 
13.98 
25.5 
29.0 
30.22 
34.13 
36 

Cut 

284.00 
413.33 
290.67 
523.33 
1157.33 
1093.33 
606.66 
1089.33 
1869.66 
1117.00 
1190.67 
1574.66 
1365.33 
1440.33 
2992.00 
4525.33 

Cut 
Cut 
Ratio 
Ratio 
0.59 
0.89 
0.72 
1.35 
0.77 
0.43 
0.84 
0.43 
0.66 
0.66 
0.88 
0.51 
0.70 
0.65 
0.71 
1.07 
0.7 

Time  1 
Time  1 
Ratio 
Ratio 
1.29 
1.91 
1.76 
1.72 
1.30 
1.86 
1.69 
1.41 
1.54 
1.86 
1.45 
2.16 
2.01 
1.96 
1.72 
1.56 
1.7 

2.3  The WalkSAT Satisfiability Solver 
The  WalkSAT algorithm  [5]  is  a  stochastic  local  search  heuristic 
for Boolean  Satisfiability.  WalkSAT is an  improvement on GSAT 
(Sclman et al.,  1992), a greedy algorithm that starts with a random 
assignment and flips variables one at a time.  The variable chosen 
for  flipping  is  always  the  one  that  would  cause  the  greatest  im(cid:173)
mediate reduction in the number of violated clauses.  WalkSAT [5] 
improves on GSAT by using a biased random walk to avoid getting 
stuck in local minima. 

To select the  next  variable  to flip,  WalkSAT picks  a clause  at 
random  from the  unsatisfied clauses.  With probability p, it flips a 
variable picked randomly from this clause.  With probability  1  - p 
it flips the variable that would cause the least number of clauses to 
be violated when flipped. 

3  The WalkPart Algorithm 
The WalkPart algorithm is  a stochastic  local  search  algorithm  for 
balance-constrained hypergraph bisection.  It performs a sequence 
of moves, until a preset maximum number of moves is reached.  A 
"move"  moves  a  vertex  from  one  partition  to  another,  if balance 
constraints arc not violated.  Moves are chosen using criteria sim(cid:173)
ilar to WalkSAT: with probability p, a vertex  is picked at random, 
and with probability  1 — p,  a vertex  is chosen to minimize some 
cost function.  The selected vertex  is then moved to the other par(cid:173)
tition  (if balance  constraints  allow).  After  a  move,  the  costs  of 
vertices  adjacent  to  the  moved  vertex  will  change,  and  these  are 
updated. 

The  move  selection  procedure  is  explained  in  more  detail  as 
follows.  A net from among the cut nets is chosen at random.  With 
probability p, a vertex is chosen from that net at random, and with 
probability 1 — p, the vertex that minimizes the cost function under 
the  decision  heuristic  in  use  is  chosen  from  the  net.  If a  chosen 
move is illegal, the selection process is repeated until a legal move 
is found. 

Due to space constraints, we describe only the decision heuris(cid:173)
tic  that performed  best  on  the benchmarks  in  this paper,  the  nor(cid:173)
malized node  score  heuristic. 

Normalized  Score Heuristic:  The FM heuristic is concerned 
with the  "gain"  of a node,  determined by  the  number of nets  that 
can  be  "cut"  or "uncut"  by  moving  the  node.  Therefore,  it  only 
considers "critical" nets that can be cut or uncut in a single move. 
It  is  mentioned  in  [4]  that  a  more  thorough  measure  would  also 
estimate  the  effort  required  to  uncut  the  net.  We  propose  a  new 
measure,  the  "score"  of a node,  defined  as  the  number of moves 
required  to  uncut  the  net  if the  node  in  question  was  moved. 
In 
practice, scores are normalized to avoid bias due to net sizes.  We 

and 

can  quickly  approximate  the  score  for a  given  node  for a  partic(cid:173)
ular net  as  follows.  Consider  a  node,  ni,  presently  in  partition  j 
(j  — O/I).  Let e/c  be a hyperedge containing  n i,  dk  be the degree 
of 
be the number of nodes from edge e k in partition 7, 
including ni,. Then  the normalized  score  of ni, due to eK is 
The  total  node  score  is  the  sum  of the  scores  due  to  all  nets  in 
which the node occurs.  The  idea of using a score comes  from the 
work  in  [6], which discusses an adaptation  of WalkSAT to formu(cid:173)
las with pseudo-boolean constraints.  In WalkPart, with probability 
I  — p the  algorithm  picks  the  node  from  the  chosen  net  with  the 
minimum  score.  For the benchmarks  in  this paper,  our empirical 
results are strongest when this heuristic is used, and when /; — 0.1. 
4  Hybrid  Partitioner 
Through empirical evaluation, we observe that WalkPart often out(cid:173)
performs  a  leading-edge  implementation  of FM  [2],  on  standard 
industry  circuit  benchmarks  [1].  Also,  WalkPart  frequently  does 
well on benchmarks where FM does not,  implying that both algo(cid:173)
rithms do not find similar solutions or search  in the  same areas of 
the search  space.  These observations  suggest that a hybrid algo(cid:173)
rithm might be able to exploit the strengths of both. 

The hybrid approach  alternates runs of FMPart (the FM imple(cid:173)
mentation available in  [2]) and WalkPart.  It is known that FMPart 
reduces the net cut greatly in the first few passes, and then spends 
time  performing  more  passes  for  relatively  small  improvements. 
The  hybrid  algorithm  starts by performing  one  or more passes  of 
FMPart,  and  then  performs  moves  of WalkPart  to  improve  FM-
Part's solution.  Control then switches back to FMPart, and so on. 
A combined FMPart-WalkPart pass constitutes one pass of the hy(cid:173)
brid  algorithm.  A  preset  number  of hybrid  passes  are  run  before 
the algorithm  terminates.  The use of a WalkSAT-like randomized 
component  makes  it difficult to find obvious  convergence  criteria. 
We  hope  to  address  this  issue  in  future  works. 
In  practice,  we 
observe  that  the  tendency  of FM  to  converge  rapidly  causes  con(cid:173)
siderable  reductions  in net  cut  in  a  fairly small  number of passes. 
This  can  be  seen  from  our results  in  Section  5.  Many  stochastic 
local  search  approaches  use  such  preset  limits because of the un(cid:173)
predictable nature of the search. 
5  Results 
In  this  section,  we  discuss  the  empirical  performance  of our  al(cid:173)
gorithms.  We  cannot  include  the  results  of all  our  experiments 
with different  tuning and parameter settings due  to  limited space. 
We present results of two relatively simple  experiments that illus(cid:173)
trate  the  utility  of the  hybrid  technique.  The  benchmarks  used 
are  standard  IBM  circuit  partitioning  benchmarks  [1].  Although 

POSTER PAPERS 

1547 

Table  2:  Results  for  10  passes  of o ur  H y b r id  A l g o r i t h m.  At  each  pass,  t wo  passes 
of  FM  are 
Nodes 
Nodes 

followed  by  5 0K  moves  of  W a l k P a r t. 

FMPart 

Nets 
Nets 

Hybrid 

Time 
1.54 
1.39 
2.15 
2.14 
3.84 
3.14 
5.30 
3.52 
9.54 
5.63 
9.63 
11.76 
14.38 
15.36 
19.78 
23.03 

Cut 

477.00 
464.33 
402.00 
386.00 
1487.67 
2488.00 
718.67 
2505.00 
2793.33 
1683.00 
1347.33 
3076.00 
1936.00 
2200.33 
4203.33 
4200.67 

Time 
1.42 
1.53 
1.9 
2.0 
2.62 
3.25 
2.9 
2.76 
7.6 
4.1 
9.3 
10.1 
11.98 
21.33 
26.67 
30.01 

Cut 

391.66 
439.67 
306.33 
344.67 
1244.33 
1351.33 
1131.33 

1071 
2612.33 
1160.33 

1687 
1501.33 
1676.33 
1520.66 
4072.33 

3781 

Cut 
Cut 
Ratio 
Ratio 
0.82 
0.94 
0.76 
0.89 
0.83 
0.54 
1.57 
0.42 
0.93 
0.68 
1.25 
0.48 
0.86 
0.69 
0.96 
0.90 
0.84 

Time 
Time 
Ratio 
Ratio 
0.92 
1.1 
0.88 
0.93 
0.68 
1.03 
0.54 
0.78 
0.79 
0.72 
0.96 
0.85 
0.83 
1.38 
1.34 
1.30 
0.93 

|  Benchmark 
|  Benchmark 
|  Name 
|  Name 

ibm01+10 
ibm01+4 
ibm02+10 
ibm02+4 
ibm03+10 
ibm03+4 
ibm04+10 
ibm()4 + 4 
ibm05+10 
ibm06+IO 
ibm07+10 
ibm08+10 
ibm09+10 
ibm10+10 
ibm11+10 
ibml2+10 
Average 

12752 
12752 
19601 
19601 
23136 
23136 
27507 
27507 
29347 
32498 
45926 
51309 
53395 
69429 
70558 
71076 

14111 
14111 
19584 
19584 
27401 
27401 
31970 
31970 
28446 
34826 
48117 
50513 
60902 
75196 
81454 
77240 

Moves 

2M 
500K 
500K 
500K 
2M 
500K 
500K 
2M 
2M 
2M 
2M 
2M 
2M 
2M 
2M 
2M 

WalkPart 
Time 
9.16 
2.56 
3.61 
3.61 
14.15 
3.84 
4.50 
14.94 
17.34 
12.73 
18.07 
24.92 
19.60 
19.79 
21.61 
22.99 

cut 
610.67 
506.00 
329.67 
654.33 
1603.33 
1175.00 
1589.00 
2121.00 
4804.67 
750.00 
2483.33 
1902.67 
2069.00 
3414.67 
2433.33 
3803.67 

the  benchmarks  arc  chosen  from  the  VLSI  domain,  all  the  algo(cid:173)
rithms  discussed  here  are  general  and  can  be  used  on  instances 
from any application.  In the experiments,  WalkPart  uses the nor(cid:173)
malized score heuristic, and randomness quotient p — 0.1.  2  We 
use the FM partitioning package  by Caldwell  ct.  al.,  available  at 
[2], for the FM component.  WalkPart is written in C++. 

In the first experiment, we run  10 hybrid passes after first run(cid:173)
ning FM once to completion.  Each  hybrid pass performs  100,000 
WalkPart moves  followed  by a  single  FMPart pass.  The  solution 
after a pass is used as the starting solution for the next pass.  Results 
for this experiment arc shown in Table  1. 

The  hybrid  algorithm  is compared  against  FMPart  and  Walk-
Part, run individually.  WalkPart uses the normalized score heuris(cid:173)
tic  and  p  —  0.1,  with  two  different  move  limits:  500,000  and 
2,000,000.  Because  some  moves  are  picked  randomly,  increas(cid:173)
ing  the  move  limit docs  not  always  produce  better solutions.  Wc 
show results  for the move  limit where net cut was lower.  For each 
benchmark  we  report  average  solution  quality  and  runtime  over 
three independent starts on a  1.2 GHz AMD Athlon processor with 
1-2GB, running Linux. 

In  the  tabic,  columns  1-3  describe  benchmark  statistics.  The 
benchmarks  are  named  ibmno+t%,  where  ibm  indicates  an  IBM 
benchmark,  no  is  the  serial  number,  /  indicates  the  balance  con(cid:173)
straint.  Tolerances  specify  the  maximum  legal  disparity  between 
subset  weights  as  a  percentage  of total  vertex  weight.  The  next 
three columns give WalkParf s number of moves, runtime and re(cid:173)
sulting net cut.  The next four columns show runtimes and net cuts 
for FM and  the  hybrid algorithm.  The  lowest  net  cut out  of the 3 
algorithms  is  boldfaced.  The  last  two  columns  show  the  ratio of 
net cut and runtime of the hybrid algorithm to net cut  and runtime 
of FMPart. Averages are shown at the bottom. 

We  observe  that  the  hybrid  algorithm  achieves  smaller  cuts 
than  both  FMPart  and  WalkPart on  most benchmarks.  This  is to 
be expected, since hybrid passes are run on a solution produced by 
FMPart. Nevertheless, we can make some important observations. 
First,  FMPart  frequently  converges  when  a  much  better  solution 
is  achievable.  Second,  it  is  possible  to  achieve  a  better  solution 
by introducing a randomized  component with a different decision 
heuristic (normalized score).  WalkPart can be used to lead FMPart 
out of local minima by performing random moves, after which FM(cid:173)
Part can be run again to find a better solution.  However, this exper(cid:173)
iment has a runtime cost.  On  average, this strategy improves run 
time by 30% over FMPart, but is  1.7 times slower. 

Our second experiment improves runtime by avoiding  the  ini-

2 Parameter settings were not chosen arbitrarily  After testing, we chose the values 

that gave best overall  performance. 

tial  run  of FMPart.  This  experiment  also uses  10  hybrid  passes. 
Each  pass  consists  of  2  passes  of  FMPart  followed  by  50,000 
moves of WalkPart.  Results for this experiment are in Table 3. 

It  is  clear  that  the  second  hybrid  configuration  is  competitive 
with FMPart and WalkPart in terms of runtime, and frequently pro(cid:173)
duces better solutions.  Also, while either FMPart or WalkPart may 
achieve lower net cut than the hybrid algorithm, it is very rare that 
both  of them  do  so.  The  hybrid  approach  is usually  close  to  the 
best  solution  achieved  by  either.  On  average,  the  second  hybrid 
configuration improves net cut by  15% and is about 7% faster than 
FMPart alone. 
6  Conclusions and Future Work 
In this work, wc introduce our "crossover" hypergraph partitioning 
algorithm,  WalkPart.  Wc  combine  WalkPart with the well-known 
Fiduccia-Mattheyses  (FM) heuristic  for hypergraph partitioning to 
produce a hybrid heuristic that draws on the strengths of both tech(cid:173)
niques.  Wc  achieve  substantial  improvement  over FMPart with  a 
very simple approach that requires almost no tuning. 

Our  first  experiment  shows  that  net  cuts  achieved  by  FM,  a 
widely used algorithm for this application, can be significantly im(cid:173)
proved (by 30%), albeit with a runtime cost.  However, our second 
experiment reduces net cuts by an average of 15%, and runtime by 
7%  over FM.  Our  results  show  that  combining  these  two  heuris(cid:173)
tics results in a search procedure that is more powerful than either 
heuristic used alone.  Strong empirical results for the proposed hy(cid:173)
brid algorithm motivate further research.  We are incorporating our 
flat partitioning algorithms into the multilevel framework [4,2] and 
plan to make it available for use in CAD tools.  We are also continu(cid:173)
ing our investigation of effective search procedures for partitioning 
and looking for new techniques that can be hybridized with exist(cid:173)
ing ones. 
References 

[1]  C. J. Alpert, "The 1SPD98 Circuit Benchmark Suite", Proc. ISPD 

1997, pp. 80-85 

[2]  A. 

and 
E. 
Markov, 
Tools 
http://nexus6.cs.ucla.edu/software/PDtools/tar.gz/ 

Caldwell, 
UCLA 

Physical 

Design 

Kahng 

A. 

B. 

I. 
L. 
Release: 

[3]  C. M. Fiduccia and R. M. Mattheyses, "A linear time heuristic  for 
improving network partitions", Proc. ACM/IEEE Design Automation 
Conference, 1982, pp. 175-181. 
[4]  G. Karypis,  R. Aggarwal,  V.  Kumar, and S. Shekhar, "Multilevel 
Hypergraph  Partitioning:  Applications in  VLSI  Design",  in Proc. 
ACM/IEEE Design Automation Conference, 1997, pp. 526-529. 

[5]  B. Selman, H. Kautz, and B. Cohen, "Noise strategies for improving 

local search", AAAI '94, pp. 337-343. 

[6]  J. P. Walser, "Solving Linear Pseudo-Boolean Constraint Problems 

with Local Search", AAAI '97. 

1548 

POSTER  PAPERS 

