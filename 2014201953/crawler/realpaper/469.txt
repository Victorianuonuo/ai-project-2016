Scenario-based  Stochastic  Constraint Programming 

Suresh Manandhar  and  Armagan Tarim 

Department of Computer Science 

University of York, England 

email:  {suresh,at}@cs.york.ac.uk 

Toby  Walsh 

Cork Constraint Computation Centre 

University College Cork, Ireland. 

email: tw@4c.ucc.ie. 

Abstract 

To model combinatorial decision problems involv(cid:173)
ing  uncertainty  and  probability,  we  extend  the 
stochastic constraint programming framework pro(cid:173)
posed in  iWalsh,  2002]  along  a number of impor(cid:173)
tant dimensions (e.g.  to multiple chance constraints 
and to a range of new objectives). We also provide a 
new (but equivalent) semantics based on scenarios. 
Using  this  semantics,  we  can  compile  stochastic 
constraint  programs down  into conventional  (non-
stochastic) constraint programs.  This allows us to 
exploit the full power of existing constraint solvers. 
We have implemented this  framework for decision 
making under uncertainty in stochastic OPL, a lan(cid:173)
guage which is based on the OPL constraint mod(cid:173)
elling  language  [Hentenryck  et a/.,  1999].  To  il(cid:173)
lustrate the potential  of this framework,  we model 
a wide range of problems in areas as diverse as fi(cid:173)
nance, agriculture and production. 

Introduction 

1 
Many  decision  problems  contain  uncertainty.  Data  about 
events in the past may not be known exactly due to errors in 
measuring or difficulties in sampling, whilst data about events 
in the future may simply not be known with certainty.  For ex(cid:173)
ample, when scheduling power stations, we need to cope with 
uncertainty in future energy demands.  As a second example, 
nurse rostering in an accident and emergency department re(cid:173)
quires us to anticipate variability in workload.  As a final ex(cid:173)
ample, when constructing a balanced bond portfolio, we must 
deal  with  uncertainty  in  the  future  price  of bonds.  To  deal 
with such situations,  [Walsh,  20021  has proposed an exten(cid:173)
sion  of constraint programming,  called stochastic constraint 
programming, in which we distinguish between decision vari(cid:173)
ables, which we are free to set,  and stochastic (or observed) 
variables,  which  follow  some  probability  distribution.  This 
framework  combines  together  some  of  the  best  features  of 
traditional constraint satisfaction, stochastic integer program(cid:173)
ming, and stochastic satisfiability. 

In this paper, we extend the expressivity of this framework 
considerably by adding multiple chance constraints,  as  well 
as a range of objective functions like maximizing the down(cid:173)
side.  We show how such stochastic constraint programs can 

be  compiled  down  into  conventional  (non-stochastic)  con(cid:173)
straint programs  using a scenario-based interpretation.  This 
compilation allows us to use existing constraint solvers with(cid:173)
out any modification, as well as call upon the power of hybrid 
solvers  which  combine  constraint  solving  and  integer  pro(cid:173)
gramming  techniques.  We  also  propose  a  number of tech(cid:173)
niques to reduce the number of scenarios and to generate ro(cid:173)
bust solutions.  We have implemented this framework for de(cid:173)
cision making under uncertainty in a language called stochas(cid:173)
tic OPL. This is an extension of the OPL constraint modelling 
language  iHentenryck  et  al,  1999].  Finally,  we  describe  a 
wide range of problems that we have modelled in  stochastic 
OPL that illustrate some of its potential. 

2  Stochastic constraint programs 
In  a  one  stage  stochastic  constraint  satisfaction  problem 
(stochastic  CSP),  the  decision  variables  are  set  before  the 
stochastic  variables.  The  stochastic  variables,  independent 
of the decision variables, take values with probabilities given 
by  a probability  distribution.  This  models  situations  where 
we  act now  and observe  later.  For example,  we have to de(cid:173)
cide  now  which  nurses  to  have  on  duty  and  will  only  later 
discover the actual workload. We can easily invert the instan(cid:173)
tiation  order  if the  application  demands,  with  the  stochastic 
variables  set  before  the  decision  variables.  Constraints  are 
defined (as  in  traditional  constraint satisfaction) by  relations 
of allowed tuples of values. Constraints can, however, be im(cid:173)
plemented with specialized and efficient algorithms for con(cid:173)
sistency checking. 

We allow  for both  hard constraints  which  are  always  sat(cid:173)
isfied and  "chance constraints" which  may only be satisfied 
in some of the possible worlds.  Each chance constraint has a 
threshold, 6 and the constraint must be satisfied in at least a 
fraction 0 of the worlds.  A one stage stochastic CSP is satis-
fiable iff there exists values for the decision variables so that, 
given  random  values  for  the  stochastic  variables,  the  hard 
constraints are always satisfied and the chance constraints are 
satisfied  in  at  least  the  given  fraction  of worlds.  Note  that 
IWalsh, 2002] only allowed for one (global) chance constraint 
so the definition here of stochastic constraint programming is 
strictly more general. 

CONSTRAINTS 

257 

so that given  random values  for  Vsl,  we can  find  values  for 
Vd2,  so that given random values for VS2, the hard constraints 
are always satisfied and the chance constraints are again sat(cid:173)
isfied  in  at  least the  given  fraction  of worlds.  Note  that the 
values chosen for the second set of decision variables  Vd2  are 
conditioned on both the values chosen for the  first  set of de(cid:173)
cision  variables  Vd1  and  on  the  random  values  given  to  the 
first set of stochastic variables  Vs1  This can model situations 
in which items are produced and can be consumed or put in 
stock for later consumption.  Future production then depends 
both  on  previous  production  (earlier decision  variables)  and 
on previous demand (earlier stochastic variables). 

An m stage stochastic CSP is defined in an analogous way 
to  one  and  two  stage  stochastic  CSPs.  Note  that  [Walsh, 
2002]  insisted  that the stochastic  variables  take values inde(cid:173)
pendently of each other. This prevents us representing a num(cid:173)
ber of common  situations.  For example,  if the  market  goes 
down in the first quarter, it is probably more likely to go down 
in  the  second  quarter.  A  second  stage  stochastic  variable 
representing  the  market  index  is  therefore  dependent on  the 
first stage  stochastic  variable  representing  the  maiket  index. 
There is, however, nothing in the semantics given for stochas(cid:173)
tic constraint programs nor in the solution methods proposed 
in [Walsh, 2002] that used this assumption.  We therefore al(cid:173)
low  later stage  stochastic  variables  to take  values  which  are 
conditioned by the earlier stage stochastic variables. 

A  stochastic  constraint  optimization  problem  (stochastic 
COP)  is  a  stochastic  CSP plus  a cost function  defined  over 
the decision and stochastic  variables.  In  [Walsh,  2002],  the 
only  goal  considered  was to  find  a solution  that satisfies the 
stochastic  CSP which  minimizes  or maximizes the expected 
value of the objective function. We now extend this to a much 
wider range of goals.  For example, we might wish to limit the 
downside (i.e.  maximize the least value of the cost function), 
or to minimize  the  spread  (i.e.  minimize  the  difference  be(cid:173)
tween the least and the largest value of the cost function). 

3  Scenario-based semantics 
In  [Walsh,  2002],  a  semantics  for stochastic  constraint  pro(cid:173)
grams  is  given  based  on  policies.  A  policy  is  a  tree  of de(cid:173)
cisions.  Each  path  in  a  policy  represents  a  different  possi(cid:173)
ble  scenario  (set  of values  for the  stochastic  variables),  and 
the values assigned to decision variables in this scenario.  To 
find satisfying policies,  [Walsh,  2002] presents backtracking 
and forward checking algorithms which explores the implicit 
AND/OR graph.  Stochastic variables give AND nodes as we 
must  find  a policy  that satisfies  all  their values,  whilst deci(cid:173)
sion variables give OR nodes as we only need find one satis(cid:173)
fying value. 

An alternative semantics, which suggests an alternative so(cid:173)
lution method, comes from a scenario-based view [Birge and 
Louveaux,  1997].  A scenario is any possible set of values for 
the stochastic  variables.  Thus,  a scenario is  associated  with 
each path in the policy. Within each scenario, we have a con(cid:173)
ventional  (non-stochastic)  constraint  program  to  solve.  We 
simply  replace  the  stochastic  variables  by  the  values  taken 
in the scenario,  and ensure that the values found for the de(cid:173)
cision  variables  are  consistent  across  scenarios.  Note  that 

certain  decision  variables  are  shared  across  scenarios.  The 
first stage  decisions  are,  for example,  shared  by  all  scenar(cid:173)
ios.  The great advantage of this approach  is that we can use 
conventional  constraint  solvers  to  solve stochastic  constraint 
programs.  We do not need to implement specialized solvers. 
Of course,  there  is  a  price  to  pay  as  the  number of scenar(cid:173)
ios grows exponentially with the number of stages.  However, 
our  results  show  that  a  scenario-based  approach  is  feasible 
for many  problems.  Indeed,  we observe much better perfor(cid:173)
mance using this approach on the production planning exam(cid:173)
ple  introduced  in  [Walsh,  2002].  In  addition,  as we discuss 
later,  we  have  developed  a  number  of techniques  like  Latin 
hypercube  sampling  to  reduce  the  number of scenarios con(cid:173)
sidered. 

4  Stochastic OPL 
We have implemented this framework on top of the OPL con(cid:173)
straint  modelling  language  [Hentenryck  et  al,  1999].  An 
OPL  model  consists  of  two  parts:  a  set  of  declarations, 
followed  by  an  instruction.  Declarations  define  the  data 
types,  (input) data and the (decision) variables.  An  OPL in(cid:173)
struction  is  either  to  satisfy  a  set  of constraints  or  to  maxi(cid:173)
mize/minimize an  objective function  subject to a set of con(cid:173)
straints.  We  have  extended  the  declarations  to  include  the 
declaration of stochastic variables, and the instructions to in(cid:173)
clude chance constraints, and a range of new goals like max(cid:173)
imizing the expectation of an objective function. 

4.1  Variable  declaration 
We  now  declare  both  decision  and  stochastic  variables. 
Stochastic  variables are set according to a probability distri(cid:173)
bution using a command of the form: 
stoch  <Type>  <Id>  <Dist>; 

Where  <Type>  is  (as  with  decision  variables)  a  data  type 
(e.g.  a  range  of  values,  or  an  enumerated  list  of  values), 
< I d>  is (as  with decision  variables) the variable name,  and 
< D i s t>  defines  the  probability  distribution  of the  stochas(cid:173)
tic  variable(s).  Probability  distributions  include  u n i f o r m, 
p o i s s on (lambda), and user defined via a list of (not nec(cid:173)
essarily  normalized)  values.  Other types  of distribution  can 
be supported as  needed.  We  insist that  stochastic  variables 
are arrays, with the last index describing the stage.  Here are 
some examples: 

s t o ch  0 . .1  m a r k e t [ Y e a r s]  u n i f o r m; 
s t o ch  1 0 0 . . 1 02  d e m a n d [ Q u a r t e r] 

{ 1 , 2 , 3 }; 

In the  first,  we have a 0/1  variable in each year which takes 
either value with equal probability.  In the last, we have a de(cid:173)
mand variable for each quarter, which takes the value 100 in 1 
out of 6 cases,  101  in 2 out 6 cases, and  102 in the remaining 
3 cases. 
4.2  Constraint posting 
We  can  post  both  hard  constraints  (as  in  OPL)  and  chance 
constraints.  Chance constraints hold in some but not neces(cid:173)
sarily all scenarios.  They are posted using a command of the 
form: 
prob(<Constraint>)  <ArithOp>  <Expr>; 

258 

CONSTRAINTS 

is 

any  OPL 

< C o n s t r a i n t> 
is  any  of 

constraint, 
Where 
< A r i t h O p> 
the  arithmetically  comparison 
operations  (=,<>,<,>,  <=, or  >=) and  <Expr>  is any arith(cid:173)
metic  expression  (it  may  contain  decision  variables  or  may 
just be a rational or a float in the range 0 to  1).  For example, 
the  following  command  specifies  the  chance  constraint  that 
in  each  quarter the  demand  (a  stochastic  variable)  does  not 
exceed  the  production  (a  decision  variable)  plus  the  stock 
carried  forward  in  each  quarter  (this  auxiliary  is  modelled, 
as  in  conventional  constraint  programming,  by  a  decision 
variable) with 80% probability: 
f o r a l l (i 

in  1..n) 

prob(demand[i ] < = 

p r o d u c t i o n [ i ] + s t o c k [ i ]) 

>=  0.80; 

Constraints  which  are  not  chance  constraints  are  hard  and 
have to hold in all possible scenarios.  For example, the stock 
carried forwards is computed via the hard constraint: 

f o r a l l (i 

in  1 . . n) 

s t o c k [ i + 1]  =  s t o c k [ i]  +  p r o d u c t i o n [ i] 

-  demand[i]; 

4.3  Optimization 
Stochastic  OPL  supports  both  stochastic  constraint  satisfac(cid:173)
tion and optimization  problems.  We can  maximize or mini(cid:173)
mize  the expectation of an  objective  function.  For example, 
in  the  book  production  example  of  [Walsh,  2002],  we  can 
minimize  the  expected  cost  of storing  surplus  books.  Each 
book costs $1  per quarter to store.  This can be specified by 
the following (partial) model: 
minimize  expected(cost) 
subject 

to 

cost  = 
sum(i 
f o r a l l (i 

in 
in  1..n) 

l . . n)  m a x ( s t o c k [ i + 1 ] , 0 ); 

s t o c k [ i + 1]  =  s t o c k [ i]  +  p r o d u c t i o n [ i] 

-  demand[i]; 

Stochastic OPL also supports a number of other optimization 
goals.  For example: 
minimize  s p r e a d ( p r o f i t) 
maximize  d o w n s i d e ( p r o f i t) 
minimize  upside(cost) 
The spread is the difference between the value of the objective 
function in the best and worst scenarios, whilst the downside 
(upside) is the minimum (maximum) objective function value 
a possible scenario may take. 

5  Compilation of stochastic OPL 
These stochastic extensions are compiled down into conven(cid:173)
tional (non-stochastic) OPL models automatically by exploit(cid:173)
ing  the  scenario-based  semantics.  The  compiler  is  written 
in  Lex  and  Yacc,  with  a  graphical  interface  in  Visual  C++. 
Compilation  involves  replacing  stochastic  variables  by  their 
possible  values,  and decision  variables by a ragged array of 
decision variables,  one for each possible scenario.  Consider 
again the chance constraint: 

prob( 

demand[i]  <=  p r o d u c t i o n [ i ] + s t o c k [ i]  ) 

>=  0.80; 

This is compiled into a sum constraint of the form: 

sum(j 

in  S c e n a r i o s)  p [ j ]* 

( d e m a n d [ i , j]  <= 

p r o d u c t i o n [ i , j ] + s t o c k [ i,  j]  ) 

>=  0 . 8 0; 

Where S c e n a r i os is the set of scenarios, p [ j ]  is the prob(cid:173)
ability  of scenario  j,  demand [ i,  j ]  is  the  demand  in  sce(cid:173)
nario  j  and  quarter  i,  etc.  Note  that  the  bracketing  of the 
inequality reifies the constraint so that it takes the value  1  if 
satisfied and 0 otherwise. 

Hard constraints are also transformed. Consider, for exam(cid:173)

ple, the hard constraint: 
w e a l t h [ t]  =  bonds[t]  +  stocks [ t]  ; 
This is compiled into a forall constraint of the form: 

f o r a l l (j 

in  Scenarios) 

w e a l t h [ t , j]  =  b o n d s [ t , j]  +  s t o c k s [ t , j] 
Where  w e a l th [ t, j] 
is  the  wealth  at  time  t  in  scenario 
j,  etc.  Maximization  and  minimization  instructions  are  also 
transformed. Consider, for example, the optimization instruc(cid:173)
tion: 
maximize  expected(wealth[n]) 
subject 

. .. 

to 

This is compiled into an instruction of the form: 
maximize  sum(j 

in  Scenarios) 

p [ j]  * w e a l t h [ n,  t] 

s u b j e ct 

to 

. .. 

The rest of the stochastic OPL model is transformed in a sim(cid:173)
ilar manner. 

6  Value of information and stochastic 

solutions 

For stochastic optimization problems, we compute two statis(cid:173)
tics which quantify the importance of randomness.  The value 
of a stochastic  solution  (VSS)  is the difference  in  the objec(cid:173)
tive  function  for  the  stochastic  problem  (call  it  the  stochas(cid:173)
tic  solution,  SS)  and  the  objective  value  for the  determinis(cid:173)
tic  problem  computed  by  replacing  stochastic  variables  by 
their expectations (call  it the expected  value solution,  EVS): 
VSS  =  SS  -  EVS.  This  computes  the  benefit  of  know(cid:173)
ing the distributions of the stochastic variables.  Clearly, VSS 
is non-negative.  We also compute  the expected value of the 
wait-and-see  solution  (WSS).  To calculate  this,  we  give the 
stochastic  variables values according to their probability dis(cid:173)
tributions, and then find the best values for the decision vari(cid:173)
ables.  The difference between WSS and SS  is the expected 
value  of  perfect  information  (EVPI):  EVPI  =  WSS  -  SS. 
This measures how  much more you can expect to win if you 
have perfect information about the stochastic components of 
the  problem. 
In  other  words,  EVPI  measures  the  value  of 
knowing the future with certainty.  This is therefore the most 
that should be spent in gathering information about the uncer(cid:173)
tain world. 

CONSTRAINTS 

259 

8.1  Production  planning 
This problem comes from [Walsh, 20021. The results in Table 
1 show that a scenario-based approach offers much better per(cid:173)
formance on this problem than the forward checking or back(cid:173)
tracking tree search algorithms also introduced in this paper. 
The  problem  involves  planning  production  over  m  quarters. 
In each quarter, we expect to sell between  100 and  105 copies 
of a book.  To keep customers happy,  we want to satisfy de(cid:173)
mand over all  m  quarters  with  80%  probability.  This  prob(cid:173)
lem  is modelled by an  m stage stochastic  CSP  There are m 
decision  variables,  xi  representing  production  in  each quar(cid:173)
ter.  There  are  also  m  stochastic  variables,  y1  representing 
demand  in each quarter.  To  limit stock carried  forward,  we 
use a simple heuristic which picks the smallest possible val(cid:173)
ues  for  the  decision  variables.  An  alternative  is  to  convert 
the problem into an optimization problem with a cost to keep 
books  in  store.  We  do  not explore  this option  here,  though 
it is very easy to implement in stochastic OPL, as we cannot 
then compare our results  with  those of the  forward checking 
or backtracking algorithms from [Walsh, 2002]. 
8.2  Portfolio management 
This portfolio management problem of [Birge and Louveaux, 
1997] can be modelled as a stochastic COP. Suppose we have 
$P  to invest in any of / investments and wc wish to exceed a 
wealth of $G after t investment periods.  To calculate the util(cid:173)
ity, we suppose that exceeding $G is equivalent to an income 
of q% of the excess while not meeting the goal  is equivalent 
to borrowing  at a cost r%  of the  amount  short.  This defines 
a concave  utility  function  for r  >  q.  The  uncertainty  in  this 
problem is the rate of return, which is a random variable, on 
each  investment  in  each  period.  The  objective  is  to  deter(cid:173)
mine  the  optimal  investment  strategy,  which  maximizes  the 
investor's expected utility. 

The  problem  has  8  stages  and  5760  scenarios.  To  com(cid:173)
pare  the  effectiveness  of the  different  scenario  reduction  al(cid:173)
gorithms, we adopt a two step procedure. In the first step, the 
scenario reduced problem  is solved and the first period's de(cid:173)
cision is observed.  We then solve the full-size (non scenario 
reduced) problem to optimality with this first decision fixed. 
The difference between the objective values of these two so(cid:173)
lutions is normalized by the range [optimal solution, observed 
worst solution]  to give  a normalized error for committing  to 
the  scenario  reduced  first  decision.  In  Fig.  1,  we  see  that 
Dupacova  et  al's  algorithm  is  very  effective,  that  Latin  hy-
percube  sampling  is  a  small  distance  behind,  and  both  are 
far ahead of the most likely scenario method (which requires 
approximately  half the  scenarios  before  the  first  decision  is 
made correctly). 

8.3  Yield  management 
Farmers must deal with uncertainty since weather and many 
other factors  affect crop  yields.  In  this  example  (also  taken 
from  [Birge and Louveaux,  1997]),  we must decide on  how 
many acres of his fields to devote to various crops before the 
planting season.  A certain amount of each crop is required for 
cattle feed, which can be purchased from a wholesaler if not 
raised on the farm.  Any crop in excess of cattle feed can be 
sold up to the EU quota;  any amount in excess of this quota 

Finally, we implemented a scenario reduction method used in 
stochastic programming due to Dupacova, Growe-Kuska and 
Romisch  [Dupacova  et  al,  2003].  They  report  power  pro(cid:173)
duction planning problems on which this method offers 90% 
accuracy  sampling  50%  of the  scenarios  and  50%  accuracy 
sampling just 2% of the scenarios.  The method heuristically 
deletes  scenarios  to  approximate  as  closely  as  possible  the 
original scenarios according to a Fortet-Mourier metric on the 
stochastic parameter space. 

8  Some examples 
To illustrate the potential of this framework for decision mak(cid:173)
ing under uncertainty, we now describe a wide range of prob(cid:173)
lems that we have modelled. In the first problem, we compare 
a scenario-based approach to the previous tree search meth(cid:173)
ods for solving stochastic constraint satisfaction problems.  In 
the next three problems, we illustrate the effectiveness of the 
different scenario reduction techniques. 

260 

CONSTRAINTS 

production capacity constraints and stochastic demand.  The 
objective  is  to  find  the  minimum expected cost policy.  The 
cost components take into account holding costs, backlogging 
costs,  fixed  replenishment  (or setup)  costs  and  unit produc(cid:173)
tion costs.  The optimal policy gives the timing of the replen(cid:173)
ishments as well as the ordcr-up-to-levels.  Hence, the exact 
order quantity can be known only after the realization of the 
demand, using the scenario dependent order-up-to-level deci(cid:173)
sions. This problem has 5 stages and 1,024 scenarios. In Fig. 
3, we again see that Dupacova et al's algorithm and Latin hy-
percube sampling are very effective, but both are now only a 
small distance ahead of the most likely scenario method. 

9  Robust solutions 
Inspired  by  robust  optimization  methods  in  operations  re(cid:173)
search  [Kouvelis and Yu,  1996], stochastic OPL also allows 
us to  find  robust solutions to stochastic constraint programs. 
That is, solutions in which similar decisions are made in the 
different scenarios.  It will often be impossible or undesirable 
for all decision variables to be robust.  We therefore identify 
those decision variables whose values we wish to be identical 
across scenarios using commands of the form: 

robust  <Var>; 
For  example,  in  production/inventory  problem  of Sec.8.4 
the  decision  variables  "order-up-to-Ievels"  and  "replenish(cid:173)
ment periods" can be declared as robust variables. The values 
of these  two  sets  of decision  variables  are  then  fixed  at  the 
beginning of the planning  horizon.  A robust solution damp(cid:173)
ens the nervousness of the solution, an area of very active re-

will  be  sold  at  a  low  price.  Crop  yields  are  uncertain,  de(cid:173)
pending upon weather conditions during the growing season. 
This problem has 4 stages and  10,000 scenarios.  In Fig.  2, 
we again see that Dupacova et al's algorithm and Latin hyper-
cube sampling are very effective, and both are far ahead of the 
most  likely  scenario  method  (which  requires  approximately 
one third the scenarios before the  first  decision is made cor(cid:173)
rectly). 
8.4  Production/Inventory control 
Uncertainty  plays  a  major role  in  production  and  inventory 
planning. 
In  this  simplified  production/inventory  planning 
example,  there  is  a single product,  a single  stocking  point, 

CONSTRAINTS 

261 

search in production/inventory management.  As the expected 
cost of the  robust  solution  is  always  higher,  the  tradeoff be(cid:173)
tween  nervousness  and  cost  may  have  to  be  taken  into  ac(cid:173)
count. 

10  Related and future work 
Stochastic constraint programs are closely related to Markov 
decision  problems  (MDPs)  [Puterman,  1994J.  Stochastic 
constraint  programs  can,  however,  model  problems  which 
lack the  Markov property  that the next state  and reward de(cid:173)
pend only on the previous state and action taken. The current 
decision in a stochastic constraint program will often depend 
on all earlier decisions.  To model this as an MDP, we would 
need  an  exponential  number  of  states.  Another  significant 
difference  is  that  stochastic  constraint  programs  by  using  a 
scenario-based interpretation can immediately call upon com(cid:173)
plex and powerful constraint propagation techniques. 

Stochastic  constraint  programming  was  inspired  by  both 
stochastic  integer  programming  and  stochastic  satisfiability 
[Littman  et  al,  20001. 
It  is  designed  to  take  advantage  of 
some  of the  best  features  of each  framework.  For example, 
we are able to write expressive models using non-linear and 
global constraints, and to exploit efficient constraint propaga(cid:173)
tion algorithms.  In operations research, scenarios are used in 
stochastic programming. Indeed, the scenario reduction tech(cid:173)
niques of Dupacova,  Growe-Kuska and Romisch  [Dupacova 
et al.,  2003]  implemented  here  are  borrowed  directly  from 
stochastic programming. 

There  are  a  number  of  extensions  of  conventional  con(cid:173)
straint satisfaction problem to model constraints that are un(cid:173)
certain,  probabilistic or not necessarily  satisfied.  For exam(cid:173)
ple, in probabilistic constraint satisfaction each constraint has 
a certain probability  independent of all  other probabilities of 
being part of the problem  [Fargier and Lang,  1993]  whilst in 
semi-ring constraint satisfaction each tuple in a constraint has 
a value  associated  with  it  [Bistarelli  et al,  1996].  However, 
none  of these  extensions  deal  with  variables  that  may  have 
uncertain  or probabilistic  values.  Stochastic  constraint  pro(cid:173)
gramming could, however, easily be combined with most of 
these techniques. 

11  Conclusions 
To model  combinatorial  decision  problems  involving  uncer(cid:173)
tainty and probability,  we have extended the stochastic con(cid:173)
straint  programming  framework  proposed  in  [Walsh,  2002J 
along  a  number  of important  dimensions.  In  particular,  we 
have relaxed the assumption that stochastic variables are in(cid:173)
dependent, and added multiple chance constraints as well as 
a  range  of  objective  functions  like  maximizing  the  down(cid:173)
side.  We have also provided a new (but equivalent) seman(cid:173)
tics  for  stochastic  constraint  programs  based  on  scenarios. 
Based on this semantics, we can compile stochastic constraint 
programs down into conventional  (non-stochastic) constraint 
programs.  The advantage of this compilation  is that we can 
use the full  power of existing constraint solvers  without any 
modification. We have also proposed a number of techniques 
to reduce the number of scenarios, and to generate robust so(cid:173)
lutions. 

We have implemented this framework for decision making 
under uncertainty  in  a language called  stochastic  OPL.  This 
is  an  extension  of  the  OPL  constraint  modelling  language 
[Hentenryck et al.,  1999].  To  illustrate  the  potential  of this 
framework,  we  have  modelled  a  wide  range  of problems  in 
areas as diverse as finance, agriculture and production. There 
are  many directions  for future  work.  For example,  we  want 
to allow  the  user to define a limited  set of scenarios that are 
representative of the whole.  As a second example,  we want 
to explore  more  sophisticated  notions  of solution  robustness 
(e.g. limiting the range of values used by a decision variable). 
Acknowledgements 
This  project  was  funded  by  EPSRC  under GR/R30792,  and 
the  Science  Foundation  Ireland.  We  thank  the  members  of 
the APES Research Group and 4C Lab for their feedback. 

References 
[Birge and Louveaux,  1997]  J. R. Birge and F. Louveaux. In(cid:173)
troduction  to  Stochastic  Programming.  Springer-Verlag, 
New York,  1997. 

[Bistarelli e/ al,  1996]  S.  Bistarelli,  H.  Fargier,  U.  Monta-
nari,  F.  Rossi,  T.  Schiex,  and  G.  Verfaillie.  Semi-ring 
based CSPs and valued CSPs:  Basic properties and com(cid:173)
parison.  In M. Jample, E. Freuder, and M. Maher, editors, 
Over-Constrained Systems,  LNCS  1106,  pages  111-150. 
Springer-Verlag, 1996. 

[Dupacova et al, 2003]  J.  Dupacova,  N.  Growe-Kuska,  and 
W.  Romisch.  Scenario  reduction  in  stochastic  program(cid:173)
ming:  an approach using probability metrics.  Mathemati(cid:173)
cal Programming, Series A 95:493-511, 2003. 

[Fargier and Lang,  1993]  H.  Fargier  and  J.  Lang.  Uncer(cid:173)
tainty  in  constraint  satisfaction  problems:  a  probabilis-
tic  approach. 
In  Proceedings  of ECSQARU,  LNCS  747. 
Springer-Verlag, 1993. 

[Hentenryck et al,  1999]  P.  Van  Hentenryck,  L.  Michel, 
L.  Perron,  and  J-C.  Regin.  Constraint  programming  in 
OPL. 
In  G.  Nadathur,  editor,  Principles  and  Practice 
of Declarative  Programming,  LNCS  1702,  pages  97-116. 
Springer-Verlag, 1999. 

[Kouvelis and Yu,  1996]  P. Kouvelis and G. Yu. Robust Dis(cid:173)
crete  Optimization  and Its Applications.  Nonconvex  opti(cid:173)
mization and its applications:  volume  14. Kluwer,  1996. 
[Littman et al, 2000]  M.  L.  Littman,  S.  M.  Majercik,  and 
T. Pitassi. Stochastic boolean satisfiability. Journal of Au(cid:173)
tomated Reasoning, 2000. 

[McKay  et  al,  1979]  M.  D.  McKay,  R.  J.  Beckman,  and 
W. J. Conover.  A comparison of three methods for select(cid:173)
ing values of input variables in the analysis of output from 
a computer code.  Technometrics, 21(2):239-245,  1979. 

[Puterman,  1994]  M.  L.  Puterman.  Markov  Decision  Pro(cid:173)
cess:  Discrete  Stochastic  Dynamic  Programming.  John 
Wiley and Sons, 1994. 

[Walsh, 2002]  Toby  Walsh.  Stochastic  constraint  program(cid:173)
ming. In Proceedings of the 15th ECAl, European Confer(cid:173)
ence on Artificial Intelligence. 10S Press, 2002. 

262 

CONSTRAINTS 

