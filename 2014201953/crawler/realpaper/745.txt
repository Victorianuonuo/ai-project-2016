A Study of Residual Supports in Arc Consistency

Christophe Lecoutre and Fred Hemery

CRIL−CNRS FRE 2499

Universit´e d’Artois

Lens, France

{lecoutre, hemery}@cril.univ-artois.fr

Abstract

In an Arc Consistency (AC) algorithm, a residual
support, or residue, is a support that has been stored
during a previous execution of the procedure which
determines if a value is supported by a constraint.
The point is that a residue is not guaranteed to rep-
resent a lower bound of the smallest current sup-
port of a value. In this paper, we study the theoreti-
cal impact of exploiting residues with respect to the
basic algorithm AC3. First, we prove that AC3rm
(AC3 with multi-directional residues) is optimal for
low and high constraint tightness. Second, we show
that when AC has to be maintained during a back-
tracking search, MAC2001 presents, with respect
to MAC3rm, an overhead in O(μed) per branch of
the binary tree built by MAC, where μ denotes the
number of refutations of the branch, e the num-
ber of constraints and d the greatest domain size
of the constraint network. One consequence is that
MAC3rm admits a better worst-case time complex-
ity than MAC2001 for a branch involving μ refuta-
tions when either μ > d2
or μ > d and the tightness
of any constraint is either low or high. Our experi-
mental results clearly show that exploiting residues
allows enhancing MAC and SAC algorithms.

1 Introduction
It is well-known that Arc Consistency (AC) plays a central
role in solving instances of the Constraint Satisfaction Prob-
lem (CSP). Indeed, the MAC algorithm, i.e., the algorithm
which maintains arc consistency during the search of a so-
lution, is still considered as the most efﬁcient generic ap-
proach to cope with large and hard problem instances. Fur-
thermore, AC is at the heart of a stronger consistency called
Singleton Arc Consistency (SAC) which has recently at-
tracted a lot of attention (e.g., [Bessi`ere and Debruyne, 2005;
Lecoutre and Cardon, 2005]).

For more that two decades, many algorithms have been
proposed to establish arc consistency. Today, the most ref-
erenced algorithms are AC3 [Mackworth, 1977] because of
its simplicity and AC2001/3.1 [Bessi`ere et al., 2005] because
of its optimality (while being not too complex). The worst-
case time complexities of AC3 and AC2001 are respectively

) and O(ed2

O(ed3
) where e denotes the number of constraints
and d the greatest domain size. The interest of an optimal al-
gorithm such as AC2001 resides in its robustness. It means
that AC2001 does not suffer from some pathological cases as
AC3 does. This situation occurs when the tightness of the
constraints is high, as it is the case for the equality constraint
(i.e. constraint of the form X = Y ). Indeed, as naturally
expected and demonstrated later, AC3 admits then a practical
behaviour which is close to the worst-case, and the difference
by a factor d between the two theoretical worst-case complex-
ities becomes a reality.

In this paper, we are interested in residues for AC algo-
rithms. A residue is a support that has been stored during
a previous execution of the procedure which determines if a
value is supported by a constraint. The point is that a residue
is not guaranteed to represent a lower bound of the smallest
current support of a value. The basic algorithm AC3 can be
reﬁned by exploiting residues as follows: before searching a
support for a value from scratch, the validity of the residue
associated with this value is checked. We then obtain an al-
gorithm denoted AC3r, and when multi-directionality is ex-
ploited, an algorithm denoted AC3rm.

In fact, AC3r is an algorithm which can be advantageously
replaced by AC2001 when AC must be established stand-
alone on a given constraint network. However, when AC has
to be maintained during search, MAC3r which corresponds
to mac3.1residue [Likitvivatanavong et al., 2004] becomes
quite competitive. On the other hand, AC3rm is interesting
of its own as it exploits multi-directional residues just like
AC3.2 [Lecoutre et al., 2003]. But, let us see the interest of
exploiting residues.

First, we prove in this paper that AC3rm, contrary to AC3,
admits an optimal behaviour when the tightness of the con-
straints is high. To illustrate this, let us consider the Domino
problem introduced in [Bessi`ere et al., 2005]. All but one
constraints of this problem correspond to equality constraints.
The results that we obtain when running AC3, AC2001,
AC3.2 and the new algorithm AC3rm on some instances of
this problem are depicted in Table 1. The time in seconds
(cpu) and the number of constraint checks (ccks) is given for
each instance of the form domino-n-d where n corresponds
to the number of variables and d the number of values in each
domain. Clearly, AC3rm largely compensates the weakness
of the basic AC3.

IJCAI-07

125

Instances

domino-100-100

domino-300-300

domino-500-500

domino-800-800

AC3

1.81
18M
134
1377M
951
10542M
6144
68778M

AC3rm
0.16
990K
3.40
27M
15.0
125M
60
511M

AC2001
0.23
1485K
6.01
40M
21.4
187M
87
767M

AC3.2
0.18
990K
3.59
27M
15.2
125M
59
511M

cpu
ccks
cpu
ccks
cpu
ccks
cpu
ccks

Table 1: Establishing Arc Consistency on Domino instances

Next, we analyse the cost of managing data structures with
respect to backtracking. On the one hand, it is easy to embed
AC3rm in MAC and SAC algorithms as these algorithms do
not require any maintenance of data structures during MAC
search and SAC inference. On the other hand, embedding
an optimal algorithm such as AC2001 entails an extra devel-
opment effort, with, in addition, an overhead at the execu-
tion. For MAC2001, this overhead is O(μed) per branch of
the binary tree built by MAC as we have to take into account
the reinitialization of a structure (called last) which contains
smallest found supports. Here, μ denotes the number of refu-
tations of the branch, e denotes the number of constraints and
d the greatest domain size.

2 Constraint Networks
A Constraint Network (CN) P is a pair (X , C ) where X is
a set of n variables and C a set of e constraints. Each vari-
able x ∈ X has an associated domain, denoted by dom(x),
which contains the set of values allowed for x. Each con-
straint C ∈ C involves a subset of variables of X , called
scope and denoted scp(C), and has an associated relation,
denoted rel(C), which contains the set of tuples allowed for
the variables of its scope. The initial (resp. current) domain
of a variable X is denoted dominit(X) (resp. dom(X)). For
each r-ary constraint C such that scp(C) = {X1, . . . , Xr},
we have: rel(C) ⊆
denotes the
Cartesian product. Also, for any element t = (a1, . . . , ar),
(cid:2)
i=1 dominit(Xi), t[Xi] denotes the value
r
called tuple, of
ai. It is also important to note that, assuming a total order on
domains, tuples can be ordered using a lexicographic order
≺. To simplify the presentation of some algorithms, we will
use two special values ⊥ and (cid:6) such that any tuple t is such
that ⊥ ≺ t ≺ (cid:6).

i=1 dominit(Xi) where

(cid:2)
r

(cid:2)

(cid:2)
r

Deﬁnition 1 Let C be a r-ary constraint such that scp(C) =
{X1, . . . , Xr}, a r-tuple t of
i=1 dominit(Xi) is said to be
allowed by C iff t ∈ rel(C), valid iff ∀Xi ∈ scp(C), t[Xi] ∈
dom(Xi), and a support in C iff it is allowed by C and valid.
A tuple t will be said to be a support of (Xi, a) in C when
t is a support in C such that t[Xi] = a. Determining if a tuple
is allowed is called a constraint check. A solution to a CN is
an assignment of values to all the variables such that all the
constraints are satisﬁed. A CN is said to be satisﬁable iff it ad-
mits at least one solution. The Constraint Satisfaction Prob-
lem (CSP) is the NP-complete task of determining whether a
given CN is satisﬁable. A CSP instance is then deﬁned by a
CN, and solving it involves either ﬁnding one (or more) solu-
tion or determining its unsatisﬁability. Arc Consistency (AC)
remains the central property of CNs and establishing AC on

a given network P involves removing all values that are not
arc consistent.
Deﬁnition 2 Let P = (X , C ) be a CN. A pair (X, a), with
X ∈ X and a ∈ dom(X), is arc consistent (AC) iff ∀C ∈ C
| X ∈ scp(C), there exists a support of (X, a) in C. P is AC
iff ∀X ∈ X , dom(X) (cid:8)= ∅ and ∀a ∈ dom(X), (X, a) is AC.

The following deﬁnitions will be useful later to analyze the

worst-case time complexity of some algorithms.

Deﬁnition 3 A cn-value is a triplet of the form (C,X,a)
where C ∈ C , X ∈ scp(C) and a ∈ dom(X).
Deﬁnition 4 Let (C,X,a) be a cn-value such that scp(C) =
{X, Y }.

• The number of supports of (X, a) in C, denoted
the set {b ∈

s(C,X,a), corresponds to the size of
dom(Y ) | (a, b) ∈ rel(C)}.

• The number of conﬂicts of (X, a) in C, denoted c(C,X,a),
corresponds to the size of the set {b ∈ dom(Y ) |
(a, b) /∈ rel(C)}.

Note that the number of cn-values that can be built from a
binary constraint network is O(ed). To sum up all evaluations
of an expression Expr(C, X, a) wrt all the cn-values of a
given CN, we will write:

Expr(C, X, a).

(cid:3)

C,X,a

3 AC3rm

In this section, we introduce AC3rm, and we propose a de-
tailed analysis of its complexity. It is important to remark that
our algorithm is given in the general case (i.e. it can be ap-
plied to instances involving constraints of any arity). Hence,
strictly speaking,
its description corresponds to GAC3rm
since for non binary constraints, one usually talks about Gen-
eralized Arc Consistency (GAC). However, to simplify, theo-
retical complexities will be given for binary instances. More
precisely, for all theoretical results, we will consider given a
binary CN P = (X , C ) such that, to simplify and without
any loss of generality, each domain exactly contains d values.
To establish (generalized) arc consistency on a given CN,
doAC (Algorithm 1) can be called. It returns true when the
given CN can be made arc-consistent and it is described in
the context of a coarse-grained algorithm. Initially, all pairs
(C, X), called arcs, are put in a set Q. Once Q has been
initialized, each arc is revised in turn (line 4), and when a
revision is effective (at least one value has been removed), the
set Q has to be updated (line 6). A revision is performed by a
call to the function revise, and entails removing values that
have become inconsistent with respect to C. This function

Algorithm 1 doAC (P = (X , C ) : CN): Boolean
1: Q ← {(C, X) | C ∈ C ∧ X ∈ scp(C)}
2: while Q (cid:5)= ∅ do
3:
4:
5:
6:
7: return true

pick and delete (C, X) from Q
if revise(C,X) then

if dom(X) = ∅ then return false
Q ← Q ∪ {(C (cid:2), Y )|C (cid:2) (cid:5)= C, Y (cid:5)= X, {X, Y } ⊆ scp(C (cid:2))

IJCAI-07

126

Algorithm 2 revise(C : Constraint, X : Variable) : Boolean
1: nbElements ← | dom(X) |
2: for each a ∈ dom(X) do
3:
4:
5:
6:
7: return nbElements (cid:5)= | dom(X) |

if supp[C, X, a] is valid then continue
t ← seekSupport(C, X, a)
if t = (cid:9) then remove a from dom(X)
else for each Y ∈ scp(C) do supp[C, Y, t[Y ]] ← t

Algorithm 3 seekSupport(C, X, a) : Tuple
1: t ← ⊥
2: while t (cid:5)= (cid:9) do
3:
4:
5: return (cid:9)

if C(t) then return t
t ← setN extT uple(C, X, a, t)

returns true when the revision is effective. The algorithm is
stopped when a domain wipe-out occurs (line 5) or the set Q
becomes empty.

Following the principle used in AC3.2 [Lecoutre et al.,
2003], we propose a mechanism to partially beneﬁt from
(positive) multi-directionality. The idea is that, when a sup-
port t is found, it can be recorded for all values occurring in t.
For example, let us consider a binary constraint C such that
scp(C) = {X, Y }. If (a, b) is found in C when looking for
a support of either (X, a) or (Y, b), in both cases, it can be
recorded as being the last found support of (X, a) in C and
the last found support of (Y, b) in C. In fact, one can sim-
ply record for any cn-value (C,X,a) the last found support
of (X,a) in C. However, here, unlike AC2001, by exploit-
ing multi-directionality, we cannot beneﬁt anymore from uni-
directionality. It means that, when the last found support is no
more valid, one has to search for a new support from scratch.
Indeed, by using multi-directionality, we have no guarantee
that the last found support corresponds to the last smallest
support. This new algorithm requires the introduction of a
three-dimensional array, denoted supp. This data structure is
used to store for any cn-value (C,X,a) the last found support
of (X,a) in C. Initially, any element of the structure supp
must be set to ⊥. Each revision (see Algorithm 2) involves
testing for any value the validity of the last found support (line
3) and if, it fails, a search for a new support is started from
scratch (see Algorithm 3). It uses setN extT uple which re-
turns either the smallest valid tuple t(cid:2)
built from C such that
t ≺ t(cid:2)
and t(cid:2)[X] = a, or (cid:6) if it does not exist. Without any
loss of generality, we assume that any call to setN extT uple
is performed in constant time. Note that C(t) must be under-
stood as a constraint check and that C(⊥) returns false. If
this search succeeds, structures corresponding to last found
supports are updated (line 6).

To summarize, the structure supp allows to record what
we call multi-directional residues. Of course, it is possible
to exploit simpler residues [Likitvivatanavong et al., 2004],
called here uni-directional residues, by not exploiting multi-
directionality. We can then derive a new algorithm, denoted
AC3r, by replacing line 6 of Algorithm 2 with:

else supp[C, X, a] ← t

alone, rather than searching a new support from scratch when
the residue is no more valid, it is more natural and more efﬁ-
cient to perform the search using the value of the residue as
a resumption point. This is exactly what is done by AC2001.
It means that, in practice, AC3r is interesting only when it is
embedded in MAC [Likitvivatanavong et al., 2004] or a SAC
algorithm.

AC3rm has a space complexity of O(ed) and a non-optimal
worst-case time complexity of O(ed3). However, it is possi-
ble to reﬁne this result as follows:

Proposition 1 In AC3rm,
the worst-case cumulated time
complexity of seekSupport for a cn-value (C,X,a) is O(cs +
d) with c = c(C,X,a) and s = s(C,X,a).

Proof. The worst-case in terms of constraint checks is when:
1) only one value is removed from dominit(Y ) between two
calls to revise(C,X), 2) values of dominit(Y ) are ordered
in such a way that the c ﬁrst values correspond to values
which do not support a and the s last values correspond to
values which support a, 3) the ﬁrst s values removed from
dominit(Y ) systematically correspond to the last found sup-
ports recorded by AC3rm (until a domain wipe-out is en-
countered). For these s + 1 calls (note the initial call) to
seekSupport(C, X, a), we obtain s ∗ (c + 1) + c constraint
checks. On the other hand, the number of other operations
(validity checks and updates of the supp structure) in revise
performed with respect to a is bounded by d. Then, we have
a worst-case cumulated complexity in O(sc + s + c + d) =
O(cs + d). 2

What is interesting with AC3rm is that, even if this al-
gorithm is not optimal, it is adapted to instances involving
constraints of low or high tightness. Indeed, when the con-
straint tightness is low (more precisely, when c is O(1)) or
high (when s is O(1)), the worst-case cumulated time com-
plexity becomes O(d), what is optimal. On the other hand,
sc is maximized when c = s = d/2, what corresponds to
a medium constraint tightness. However, AC3rm can also
be expected to have a good (practical) behavior for medium
constraint tightness since, on average (i.e. asymptotically),
considering random constraints, 2 constraint checks are nec-
essary to ﬁnd a support when the tightness is 0.5. We can
deduce the following result.

Proposition 2 The worst-case time complexity of AC3rm is:
O(ed2 +

c(C,X,a) ∗ s(C,X,a)).

(cid:3)

C,X,a

Table 2 indicates the overall worst-case complexities1
to establish arc consistency with algorithms AC3, AC3rm,
AC2001 and AC3.2. It is also interesting to look at worst-
case cumulated time complexities to seek successive supports
for a given cn-value (C,X,a). Even if it has not been intro-
duced earlier, it is easy to show that optimal algorithms admit
a cumulated complexity in O(d). By observing Table 3, we
do learn that AC3 and AC3rm are optimal when the tightness
is low (i.e. c is O(1)), and that, unlike AC3, AC3rm is also
optimal when the tightness is high (i.e. s is O(1)).

1Due to lack of space, we do not provide the detailed proof of

However, with AC3r, when AC must be established stand-

the original complexities given for AC3.

IJCAI-07

127

Space

(cid:3)

AC3

O(e + nd)

O(d ∗

Time
c(C,X,a) +
(cid:3)

(cid:3)

C,X,a

s(C,X,a) )

c(C,X,a) ∗ s(C,X,a) )

C,X,a
2 +

O(ed

AC3rm

AC2001

AC3.2

O(ed)

O(ed)
O(ed)

C,X,a

O(ed
O(ed

2)
2)

Time (per branch)

(cid:3)

Space

O(e + nd)

O(ed

O(ed)

2 +

O(ed

2 + d ∗
(cid:3)

c(C,X,a) )

C,X,a
c(C,X,a) ∗ s(C,X,a) )

O(min(n, d)ed)
O(min(n, d)ed)

C,X,a

O(ed(d + μ))
O(ed(d + μ))

MAC3

MAC3rm

MAC2001

MAC3.2

Table 2: Worst-case complexities to establish AC.

Tightness

AC3

AC3rm

AC2001

AC3.2

Any

O(cd + s)
O(cs + d)

O(d)
O(d)

Low
O(d)
O(d)
O(d)
O(d)

Medium
2)
O(d
2)
O(d
O(d)
O(d)

High
2)
O(d
O(d)
O(d)
O(d)

Table 3: Cumulated worst-case time complexities to seek suc-
cessive supports for a cn-value (C,X,a). We have c + s = d.

Remark that the complexities given for AC3rm also hold
for AC3r. The advantage of AC3rm is the fact that as we
always record the most recent found supports (by exploit-
ing multi-directionality), there is a greater probability that a
residue be valid. Finally, note that it should be possible to
extend the AC-* framework [R´egin, 2005] in order to include
the concept of residues.

4 Maintaining arc consistency

In this section, we focus on maintaining arc consistency dur-
ing search. More precisely, we study the impact, in terms of
time and space, of embedding some AC algorithms in MAC.
The MAC algorithm aims at solving a CSP instance and per-
forms a depth-ﬁrst search with backtracking while maintain-
ing arc consistency. At each step of the search, a variable
assignment is performed followed by a ﬁltering process that
corresponds to enforcing arc-consistency. MAC is based on
a binary branching scheme.
It means that, at each step of
the search, a pair (X,a) is selected where X is an unassigned
variable and a a value in dom(X), and two cases are consid-
ered: the ﬁrst one corresponds to the assignment X = a and
the second one to the refutation X (cid:8)= a.

On the other hand, it is important to remark that all known
AC algorithms (including AC3rm) are incremental. An arc-
consistency algorithm is incremental if its worst-case time
complexity is the same when it is applied one time on a
given network P and when it is applied up to nd times on P
where between two consecutive executions at least one value
has been deleted. By exploiting incrementality, one can get
the same complexity, in terms of constraint checks, for any
branch of the search tree as for only one establishment of AC.
For AC3 and AC3rm, the (non optimal) worst-case time
complexity for any branch of the search tree is guaranteed
(by incrementality) even if, meanwhile, sub-trees have been
explored and then backtracking has occurred. However, for
optimal algorithms AC2001 and AC3.2, it is important to
manage the data structure, denoted last, in order to restart
search, after exploring a sub-tree, as if backtracking never
occurred. In this paper, MAC2001 and MAC3.2 correspond
to the algorithms that record the smallest supports that have
been successively found all along the current branch. Note

Table 4: Worst-case complexities to run MAC. Time com-
plexity is given for a branch involving μ refutations.

that it is at the price of a space complexity in O(min(n,d)ed)
[van Dongen, 2004].

Proposition 3 In MAC2001 and MAC3.2, the worst-case cu-
mulated time complexity of reinitializing the structure last is
O(μed) for any branch involving μ refutations.

Proof. For any refutation occurring in a branch, we need
to restore the data structure last. In the worst-case, we have
at most e ∗ 2 ∗ d operations since for each cn-value (C,X,a),
we have to reinitialize last[C, X, a] to a stacked value (or, for
variants, to ⊥ or a new recomputed value). Hence, we obtain
(μed). 2

If μ = 0, it means that a solution has been found with-
out any backtracking. In this case, there is no need to restore
the structure last as the instance is solved. At the opposite,
we know that the longest branch that can be built contains
nd edges as follows: for each variable X, there are exactly
d − 1 edges that correspond to refutations and only one edge
that corresponds to an assignment. Then, we obtain a worst-
case cumulated time complexities of reinitializing the struc-
ture last in O(end2
) and although it is omitted here, we can
also show that it is Ω(end2

).

One nice feature of AC3rm is that, when they are em-
bedded in MAC, no initialization is necessary at each step
since the principle of this algorithm is to record the last found
support which does not systematically correspond to the last
smallest one. In fact, it was reported in [Lecoutre et al., 2003]
that it is worthwhile to leave unchanged last found supports
(using AC3.2) while backtracking, having the beneﬁt of a so-
called memorization effect. It means that a support found at a
given depth of the search has the opportunity to be still valid
at a weaker depth of the search (after backtracking). In other
words, it is worthwhile to exploit residues during search. The
importance of limiting in MAC the overhead of maintain-
ing the data structures employed by the embedded AC al-
gorithm was pointed out in [Likitvivatanavong et al., 2004]
(but no complexity result was given). In fact, MAC3r corre-
sponds to the algorithm mac3.1residue introduced in [Likit-
vivatanavong et al., 2004].

By taking into account Proposition 3 and Table 2, we ob-
It appears that, for the
tain the results given in Table 4.
longest branch, when μ > d2
, MAC3 and MAC3rm have
a better worst-case time complexity than other MAC algo-
rithms based on optimal AC algorithms since we know that,
for any branch, due to incrementality, MAC3 and MAC3rm
are O(ed3
). Also, if the tightness of any constraint is either
low or high (more precisely, if for any cn-value (C,X,a), ei-
ther c(C,X,a) is O(1) or s(C,X,a) is O(1)), then MAC3rm ad-
mits an optimal worst-case time complexity in O(ed2
) per

IJCAI-07

128

AC3

M AC embedding
AC2001

AC3rm

AC3.2

AC3

SAC − 1 embedding
AC3rm
AC2001

AC3.2

Classes of random instances (mean results for 100 instances)

(cid:4)40-8-753-0.1(cid:5)

(cid:4)40-11-414-0.2(cid:5)

(cid:4)40-16-250-0.35(cid:5)

(cid:4)40-25-180-0.5(cid:5)

(cid:4)40-40-135-0.65(cid:5)

(cid:4)40-80-103-0.8(cid:5)

(cid:4)40-180-84-0.9(cid:5)

Academic instances

ehi-85-12

geo-50-20-19

qa-5

qcp-819

Real-world instances

f app01-0200-9

js-enddr2-3

scen-11

graph-10

cpu
ccks

cpu
ccks

cpu
ccks

cpu
ccks

cpu
ccks
cpu
ccks

cpu
ccks

cpu
ccks

cpu
ccks

cpu
ccks

cpu
ccks

cpu
ccks
cpu
ccks

cpu
ccks

cpu
ccks

22.68
81M
21.19
97M
21.86
121M
37.35
233M
37.62
344M
89.01
1072M
166.12
2540M

394
642M
194
1117M
31.60
130M
139
116M

0.54
6905K
53.66
596M
15.67
92M
0.64
4842K

22.96
17M
19.23
22M
18.31
28M
25.53
56M
26.62
83M
51.62
240M
76.99
506M

377
60M
157
244M
28.31
36M
143
21M

0.37
3080K
29.08
104M
11.88
18M
0.54
2216K

34.38
24M
27.91
28M
25.18
33M
35.30
60M
35.98
82M
67.74
225M
98.69
479M

557
190M
278
284M
37.49
38M
215
41M

0.60
3018K
39.24
88M
16.26
15M
0.69
2228K

33.35
16M
26.34
19M
23.38
24M
32.27
45M
34.45
64M
61.48
180M
87.50
381M

511
83M
263
199M
36.02
27M
208
25M

0.60
2778K
29.60
48M
14.58
10M
0.68
1925K

Table 5: Cost of running MAC

branch.
In this case, MAC3rm outperforms MAC2001 as
soon as μ > d. These observations suggest that MAC3rm
should be very competitive.

5 Experiments
To compare the different algorithms mentioned in this paper,
we have performed a vast experimentation (run on a PC Pen-
tium IV 2.4GHz 512MB under Linux) with respect to ran-
dom, academic and real-world problems. Performances have
been measured in terms of the CPU time in seconds (cpu) and
the number of constraint checks (ccks).

To start, we have tested MAC (equipped with dom/deg)
by considering 7 classes of binary random instances situated
at the phase transition of search. For each class (cid:12)n,d,e,t(cid:13),
deﬁned as usually, 100 instances have been generated. The
tightness t denotes the probability that a pair of values is al-
lowed by a relation. What is interesting here is that a signiﬁ-
cant sampling of domain sizes, densities and tightnesses is in-
troduced. In Table 5, we can observe the results obtained with
MAC embedding the various AC algorithms. As expected,
the best embedded algorithms are AC3 and AC3rm when the
tightness is low (here 0.1) and AC3rm when the tightness is
high (here, 0.9). Also, AC3rm is the best when the tight-
ness is medium (here 0.5) as expected on random instances.
All these results are conﬁrmed for some representative se-
lected academic and real-world instances. Clearly, MAC3rm
outperform all other MAC algorithms in terms of cpu while
MAC3.2 is the best (although beaten on a few instances by

Academic instances

domino-300-300

domino-500-100

geo-50-20-19

qa-5

Real-world instances

f app01-0200-9

js-enddr2-3

graph-10

scen-11

cpu
ccks
cpu
ccks
cpu
ccks
cpu
ccks

cpu
ccks
cpu
ccks
cpu
ccks
cpu
ccks

446.32
1376M
4.37
88M
1.18
9525K
1.22
10M

637
10047M
58.95
980M
980
12036M
44.89
479M

9.56
26M
0.53
4950K
0.74
1165K
0.89
3104K

158
905M
12.35
54M
439
1307M
21.07
33M

14.40
40M
0.71
7425K
1.49
2671K
1.91
5001K

312
1795M
24.66
128M
836
2467M
56.03
52M

9.67
26M
0.57
4950K
1.24
1157K
1.34
3085K

192
904M
14.38
55M
581
1303M
53.21
37M

Table 6: Cost of establishing SAC-1

MAC3rm) in terms of constraint checks. Interestingly, in an
overall analysis, we can remark that MAC3rm and MAC2001
roughly perform the same number of constraint checks. As,
on the other hand, MAC3rm do not require any data struc-
ture to be maintained, it explains why it is the quickest ap-
proach. These results conﬁrm the results obtained for MAC3r
(mac3.1residue) in [Likitvivatanavong et al., 2004] which has
a behaviour similar to MAC3rm (due to lack of space, results
for MAC3r are not presented).

We have then embedded AC algorithms in SAC-1. In Ta-
ble 6, one can observe that, for domino instances which in-
volve constraints of high tightness, AC3rm clearly shows its
superiority to AC3. For real-world instances, the gap be-
tween AC3rm and the other algorithms increases. For exam-
ple, SAC-1 embedding AC3rm is about 3 times more efﬁcient
than SAC-1 embedding AC2001 on scen11 and 4 times more
efﬁcient than SAC-1 embedding AC3 on f app01-0200-9.

6 Residues for Non Binary Constraints

One can wonder what is the behaviour of an algorithm that
exploits residues when applied to non binary instances. First,
it is important to remark that seeking a support of a cn-value
from scratch requires iterating O(dr−1
) tuples in the worst-
case for a constraint of arity r. We then obtain a worst-case
cumulated time complexity of seeking a support of a given
cn-value in O(r2dr) for GAC3 and O(rdr−1
) for GAC2001
[Bessi`ere et al., 2005] since we consider that a constraint
check is O(r) and since there are O(rd) potential calls to the
speciﬁc seekSupport function. Then, we can observe that
there is a difference by a factor dr. It means that the differ-
ence between the two algorithms grows linearly with r.

On the other hand, if we assume that c > 0 and s > 0
respectively denote the number of forbidden and allowed tu-
ples of the constraint, then we obtain, by generalizing our
results of Section 3, a complexity in O(crdr−1
) for GAC3
and in O(cs) for GAC3rm. We can then deduce that the
worst-case cumulated time complexity of seeking a support is
O(min(c, rd).rdr−1
) for GAC3 and O(min(csr, r2dr)) for
GAC3rm. If c = O(1) or s = O(1), we obtain O(rdr−1
) for
GAC3rm as c + s = dr−1
, that is to say optimality. However,

IJCAI-07

129

Instance

GAC3

M GAC embedding
GAC3r

GAC3rm

GAC2001

Random instances (mean results for 10 instances - constraints are of arity 6)
(cid:3)20-6-36-0.55(cid:4)

(cid:3)20-8-24-0.75(cid:4)

(cid:3)20-10-14-0.95(cid:4)

(cid:3)20-20-15-0.99(cid:4)

Structured instances

tsp-20-366

gr-44-9-a3

gr-44-10-a3

series-14

renault

cpu
ccks
cpu
ccks
cpu
ccks
cpu
ccks

cpu
ccks
cpu
ccks
cpu
ccks
cpu
ccks
cpu
ccks

13.1
8.7
12M 6481K
31.8
51.7
26M
48M
220
135
151M
249M
489
869
2255M 1289M

8.0
4997K
27.7
20M
102
108M
301
785M

10.2
6825K
34.6
26M
135
149M
351
887M

387
607M
73.1
166M
2945

243
364M
38.4
41M
1465
6819M 1513M 1527M
217
490M
16.2
42M

233
1135M
25.0
68M

242
370
37.2
44M
1401

218
531M
25.4
66M

266
387M
56.3
74M
2129
2914M
312
618M
25.2
66M

Table 7: Cost of running MGAC

in practice, the likelihood of having small (bounded) values
of c or s when dealing with non binary constraints is weak.

We have performed a preliminary experimentation by
maintaining GAC algorithms during search on series of ran-
dom non binary instances. Here, we chose constraints of arity
6 and studied the behaviour of the algorithm for a tightness
t ∈ {0.55, 0, 75, 0.95, 0.99}. For small values of t, we ob-
served (as in the binary case) that the difference between all
algorithms was limited. On these random instances, one can
observe in Table 7 that GAC3rm and GAC3.2 are the most
efﬁcient embedded algorithms. Of course, when the tightness
is high, GAC3 is penalized and GAC3r is less efﬁcient then
GAC3rm as exploiting multi-directionality pays off. On non
binary structured instances of the 2005 CSP solver competi-
tion, one can see the good behaviour of GAC3r and GAC3rm.

7 Conclusion

In this paper, we have introduced some theoretical results
about the use of residual supports, or residues, in Arc Consis-
tency algorithms. The concept of residue has been introduced
under its multi-directional form in [Lecoutre et al., 2003]
and under its uni-directional form in [Likitvivatanavong et
al., 2004]. We have ﬁrst proved that the basic algorithm
AC3 which is optimal for low constraint tightness, also be-
comes optimal for high constraint tightness when it is ex-
tended to exploit uni-directional or multi-directional residues.
Furthermore, these extensions to AC3, respectively called
AC3r and AC3rm, can be expected to have a good (prac-
tical) behavior for medium tightness as asymptotically, for
random constraints, 2 constraint checks are necessary to ﬁnd
a support when the tightness is 0.5. Then, we have shown
that MAC3rm admit a better worst-case time complexity than
MAC2001 for a branch of the binary search tree when either
μ > d2
or μ > d and the tightness of any constraint is low or
high, with μ denoting the number of refutations of the branch.
On the practical side, we have run a vast experimentation
including MAC and SAC-1 algorithms on binary and non
binary instances. The results that we have obtained clearly

show the interest of exploiting residues as AC3rm (embed-
ded in MAC or SAC-1) were almost always the quickest
algorithms (only beaten by AC3.2 on some non binary in-
stances). It conﬁrms for MAC3r (mac3.1residue) the results
presented in [Likitvivatanavong et al., 2004]. In terms of con-
straint checks, it appears that AC3rm is quite close to AC2001
(but usually beaten by AC3.2). We also noted that AC3rm
was more robust than AC3r on non binary instances and con-
straints of high tightness.

Finally, residues can be seen as a lazy structure related to
the concept of watched literals [Moskewicz et al., 2001]. In
both cases, no maintenance of data structures upon backtrack-
ing is required. We also want to emphasize that implementing
(G)AC3rm (and embedding it in MAC or SAC) is a quite easy
task. It should be compared with the intricacy of ﬁne-grained
algorithms which requires a clever use of data structures, in
particular when applied to non binary instances. The simplic-
ity of AC3rm offers another scientiﬁc advantage:
the easy
reproducibility of the experimentation by other researchers.

Acknowledgments
We would like to thank Christian Bessi`ere and Romuald De-
bruyne for their useful comments. This paper has been sup-
ported by the CNRS and the ANR “Planevo” project.

References
[Bessi`ere and Debruyne, 2005] C. Bessi`ere and R. Debru-
yne. Optimal and suboptimal singleton arc consistency
algorithms. In Proc. of IJCAI’05, pages 54–59, 2005.

[Bessi`ere et al., 2005] C. Bessi`ere, J.C. R´egin, R.H.C. Yap,
and Y. Zhang. An optimal coarse-grained arc consistency
algorithm. Artiﬁcial Intelligence, 165(2):165–185, 2005.

[Lecoutre and Cardon, 2005] C. Lecoutre and S. Cardon. A
greedy approach to establish singleton arc consistency. In
Proceedings of IJCAI’05, pages 199–204, 2005.

[Lecoutre et al., 2003] C. Lecoutre, F. Boussemart, and
Exploiting multidirectionality in coarse-
In Proceedings of

F. Hemery.
grained arc consistency algorithms.
CP’03, pages 480–494, 2003.

[Likitvivatanavong et al., 2004] C.

Likitvivatanavong,
Y. Zhang, J. Bowen, and E.C. Freuder. Arc consistency
in MAC: a new perspective. In Proceedings of CPAI’04
workshop held with CP’04, pages 93–107, 2004.

[Mackworth, 1977] A.K. Mackworth. Consistency in net-
works of relations. Artiﬁcial Intelligence, 8(1):99–118,
1977.

[Moskewicz et al., 2001] M. W. Moskewicz, C. F. Madigan,
Y. Zhao, L. Zhang, and S. Malik. Chaff: Engineering an
Efﬁcient SAT Solver. In Proceedings of DAC’01, pages
530–535, 2001.

[R´egin, 2005] J.C. R´egin. AC-*: a conﬁgurable, generic
In Proceedings

and adaptive arc consistency algorithm.
of CP’05, pages 505–519, 2005.

[van Dongen, 2004] M.R.C. van Dongen. Saving support-
checks does not always save time. Artiﬁcial Intelligence
Review, 21(3-4):317–334, 2004.

IJCAI-07

130

