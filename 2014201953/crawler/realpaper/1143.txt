Logical Circuit Filtering

Dafna Shahaf

and Eyal Amir

Computer Science Department

University of Illinois, Urbana-Champaign

Urbana, IL 61801, USA

{dshahaf2,eyal}@uiuc.edu

Abstract

Logical Filtering is the problem of tracking the pos-
sible states of a world (belief state) after a sequence
of actions and observations. It is fundamental to
applications in partially observable dynamic do-
mains. This paper presents the Ô¨Årst exact logical
Ô¨Åltering algorithm that is tractable for all determin-
istic domains. Our tractability result is interesting
because it contrasts sharply with intractability re-
sults for structured stochastic domains. The key to
this advance lies in using logical circuits to repre-
sent belief states. We prove that both Ô¨Åltering time
and representation size are linear in the sequence
length and the input size. They are independent of
the domain size if the actions have compact repre-
sentations. The number of variables in the result-
ing formula is at most the number of state features.
We also report on a reasoning algorithm (answer-
ing propositional questions) for our circuits, which
can handle questions about past time steps (smooth-
ing). We evaluate our algorithms extensively on AI-
planning domains. Our method outperforms com-
peting methods, sometimes by orders of magnitude.

1 Introduction
Much work in AI applies system models whose state changes
over time. Applications use these dynamic-system models to
diagnose past observations, predict future behavior, and make
decisions. Those applications must consider multiple possi-
ble states when the initial state of the system is not known,
and when the state is not observed fully at every time step.
One fundamental reasoning task in such domains is Logical
Filtering [Amir and Russell, 2003]. It is the task of Ô¨Ånding
the set of states possible (belief state) after a sequence of ob-
servations and actions, starting from an initial belief state.

Logical Filtering in large deterministic domains is impor-
tant and difÔ¨Åcult. Planning, monitoring, diagnosis, and others
in partially observable deterministic domains estimate the be-
lief state (e.g., [Biere et al., 1999; Cimatti and Roveri, 2000;
Bertoli et al., 2001; Petrick and Bacchus, 2004]) as part of
performing other computations. This estimation is difÔ¨Åcult
because the number of states in a belief state is exponential in
the number of propositional features deÔ¨Åning the domain.

Several approaches were developed that represent belief
states compactly in logic (e.g., BDDs [Bryant, 1992], Log-
ical Filter, and database progression [Winslett, 1990; Lin and
Reiter, 1997]) and update this representation. However, none
of them guarantees compact representation, even for simple
domains. [Amir and Russell, 2003], for instance, guarantees
compactness and tractability only for sequences of STRIPS
actions whose preconditions are known to hold. Most impor-
tantly, the straightforward approach to Logical Filtering (de-
ciding if a clause should be in the belief state representation
of time t + 1, based on the belief state of time t) was shown
to be coNP-complete [Liberatore, 1997].

In this paper we show that solving the update problem in
its entirety is easier (done in poly-time) than creating the new
belief state piecemeal. We present C-Filter‚Äì the Ô¨Årst exact,
tractable Logical Filtering algorithm that can handle any de-
terministic domain. Importantly, both time (to compute a be-
lief state) and space (to represent it) do not depend on the do-
main size. Furthermore, the number of variables in the result-
ing formula is at most n, the number of state features (com-
pare this with n ¬∑ t, the number of variables used in Bounded
Model Checking [Clarke et al., 2001]).

We extend C-Filter to NNF Circuits (no internal negation
nodes), and show that similar space and time bounds hold for
this more restricted representation. We further show how to
reason with an output circuit, including smoothing (queries
about the past). Our results are also useful from the perspec-
tive of representation-space complexity; they sidestep previ-
ous negative results about belief-state representation (Section
5.4) and intractability results for stochastic domains.

The key to our advance lies in using logical circuits to rep-
resent belief states instead of traditional formulas. We show
that updating a logical circuit formula amounts to adding a
few internal connectives to the original formula. We take ad-
vantage of determinism: a feature is true after an action iff
the action made it true or it was already true and the action
did not change that. Interestingly, our empirical examination
suggests that other graphical representations (e.g., BDDs) do
not maintain compact representation with such updates.

C-Filter applies to many problems that require belief-state
update, such as Bounded Model Checking and planning with
partial observability. The attractive nature of this approach is
that we can apply standard planning techniques without fear
of reaching belief states that are too large to represent.

IJCAI-07

2611

2 Logical Filtering

We now describe the problem of Logical Filtering (tracking
the state of the world), hereby referred to as Filtering. Imag-
ine an assembly robot that can put items together in order to
construct some machine. The parts are randomly oriented,
and they must be brought to goal orientations for assembly.
At the beginning, the parts are located on a conveyor belt.
Each part drifts until it hits a fence perpendicular to the belt,
and then rotates so one of its edges is aligned against the fence
(see Figure 1). A sensor measures that edge, providing par-
tial information about the part‚Äôs orientation (partial, because
the part can have some edges of equal length, and the sensor
might be noisy). The robot can then rotate a part (by a certain,
discrete amount) and place it back on the belt, or pick it up
and try assembling it. We now deÔ¨Åne the problem formally.

DeÔ¨Ånition 2.1 (Deterministic Transition System) A transi-

tion system is a tuple (cid:2)P, S, A, R(cid:3). P is a Ô¨Ånite set of propo-
sitional Ô¨Çuents, S ‚äÜ Pow(P ) is the set of world states. A state
contains exactly the Ô¨Çuents that are true in it. A is a Ô¨Ånite set
of actions, and R : S √ó A ‚Üí S is the transition function.
Executing action a in state s results in state R(s, a). R may be
partial. In our example, P = { OnBelt(part1), PartOfAssem-
bly(part1), Touch(part1-e1), Touch(part1-e2), ... }, A = {
PickUp(part1), Assemble(part1), Rotate(part1,90), ... }

In the sequel we assume an implicit transition system.

Figure 1: A conveyor belt: the triangle drifts down, hits the fence
and rotates. The edge touching the fence is then measured.

Our robot tries to keep track of the state of the world, but
it cannot observe it completely. One possible solution is to
maintain a belief state‚Äì a set of possible world states. Every

œÅ ‚äÜ S is a belief state. The robot updates its belief state as

the result of performing actions and receiving observations.
We now deÔ¨Åne the semantics of Filtering.

DeÔ¨Ånition 2.2 (Filtering Semantics [Amir and Russell, 2003])

œÅ ‚äÜ S, the states that the robot considers possible, ai ‚àà A.
We assume that observations oi are logical sentences over P .
1. Filter[](œÅ) = œÅ (: an empty sequence)
2. Filter[a](œÅ) = {s(cid:2) | s(cid:2) = R(s, a), s ‚àà œÅ}
3. Filter[o](œÅ) = {s ‚àà œÅ | o is true in s}
4. Filter[(cid:2)aj , oj(cid:3)i‚â§j‚â§t](œÅ) =

Filter[(cid:2)aj, oj(cid:3)i<j‚â§t] (Filter[oi](Filter[ai](œÅ)))

We call step 2 progression with a and step 3 Ô¨Åltering with o.
Every state s in œÅ becomes s(cid:2) = R(s, a) after performing
action a. After receiving an observation, we eliminate every
state that is not consistent with it.

‚àö
Figure 2 illustrates a belief-state update. Imagine that the
2),
robot has an isosceles right triangle (edges of size 1,1,
and one of the 1-edges is currently touching the fence. There

are two possible orientations ((a) and (b), left part). After
rotating the triangle 90 degrees, each possible state is updated
‚àö
(middle part). If the world state was (a), we should see a 1-
2-edge. After
edge again. Otherwise, we expect to see the
observing a 1-edge (right part), the robot eliminates (b) from
his belief state, leaving him only with (a). That is, the robot
knows the orientation of the triangle.


 















	







‚àö

2 triangle. Left: Pos-
Figure 2: A belief-state update with a 1,1,
sible initial states. Middle: Progressing with Rotate(90)‚Äì rotating
‚ó¶
and putting it on the belt again. Right: After
the triangle by 90
observing length=1, state (b) is eliminated.

3 Circuit Filtering

|P |

Filtering is a hard problem. There are 22
belief states, so
na¬®ƒ±ve methods (such as enumeration) are intractable for large
domains. Following [Amir and Russell, 2003], we represent
belief states in logic. Their solution provides the foundations
for our research, but it guarantees an exact and compact rep-
resentation only for a few classes of models (e.g. restricted
action models, belief-states in a canonical form). We use log-
ical circuits (not Ô¨Çat formulas) in order to extend their results
to all deterministic domains. In this section we describe our
representation and explain how to update it with an action-
observation sequence, and how to reason with the result.

3.1 Representation
A belief-state œÅ can be represented as a logical formula œï
over some P (cid:2) ‚äá P : a state s is in œÅ iff it satisÔ¨Åes œï (s ‚àß œï
is satisÔ¨Åable). We call œï a belief-state formula. We represent
our belief state formulas as circuits.

DeÔ¨Ånition 3.1 (Logical Circuits) Logical Circuits are di-
rected acyclic graphs. The leaves represent variables, and
the internal nodes are assigned a logical connective. Each
node represents a formula‚Äì the one that we get by applying
the connective to the node‚Äôs children.

We allow the connectives ‚àß,‚à®,¬¨. ¬¨ nodes should have
exactly one child, while ‚àß,‚à® can have many. In Corollary
5.6 we explain how to avoid internal ¬¨ nodes (for NNF).

We use logic to represent R, too: a domain description is
a Ô¨Ånite set of effect rules of the form ‚Äúa causes F if G‚Äù, for
a an action, F and G propositional formulas over P . W.l.g.,
F is a conjunction of literals. The semantics of these rules
is as follows: after performing a in state s, iterate through
its rules. If the rule‚Äôs precondition G holds in s, its effect F

IJCAI-07

2612

will hold in R(s, a). If this leads to a contradiction, a is not
possible to execute. The rest of the Ô¨Çuents stay the same; if
no preconditions hold, the state does not change (we can also
make action failure lead to a sink state).

Consider the triangle in Figure 2. If the triangle is on the
belt, action a = Rotate(90) will rotate it, so the touching edge
will change: e1 to e2, e2 to e3, e3 to e1. a‚Äôs effect rules are:
‚Äúa causes Touch(e2) ‚àß ¬¨Touch(e1) if OnBelt() ‚àß Touch(e1)‚Äù
‚Äúa causes Touch(e3) ‚àß ¬¨Touch(e2) if OnBelt() ‚àß Touch(e2)‚Äù
‚Äúa causes Touch(e1) ‚àß ¬¨Touch(e3) if OnBelt() ‚àß Touch(e3)‚Äù

3.2 C-Filter

We described how domains and belief-states are represented;
we can now present our Circuit-Filtering algorithm, C-Filter.
PROCEDURE C-Filter((cid:3)ai, oi(cid:4)0<i‚â§t, œï, D)
{ai actions, oi observations, œï an initial belief state over P ,
D domain description}
1: ProcessDomain(D, (cid:3)ai(cid:4)0<i‚â§t)
2: for f ‚àà P do explf := a new proposition f0
3: cb := Time0(œï )

Preprocess D, œï

Process sequence

4: for i = 1 to t do
5:
6:

ProgressAction(ai)
FilterObservation(oi)

(f ‚Üî explf )

7: return cb ‚àß V
PROCEDURE ProgressAction(a)
{a an action}

f ‚ààP

(cid:5)

expl

(cid:5)
f

2:
3:

Get f ‚Äôs next-value explanation:

1: for f ‚àà Effects(a) do

Update cb: a executed, thus was possible.
a caused f , or f held and a did not cause ¬¨f
cb := cb ‚àß Time0( Poss(a,f) )
f := Time0( NextVal(a,f) )
4: for f ‚àà Effects(a) do explf := expl
PROCEDURE FilterObservation(o)
{o an observation over P}
1: cb := cb ‚àß Time0(o)
PROCEDURE Time0(œà)
{œà a formula}
1: for f ‚àà P in œà do replace f with the node pointed by explf
2: return œà
PROCEDURE ProcessDomain(D, (cid:3)ai(cid:4)0<i‚â§t)
{D a domain description, ai actions}
1: for f ‚àà P, a ‚àà (cid:3)ai(cid:4) do

Extract ‚ÄùNext Value‚Äù and ‚ÄùPossible‚Äù Formulas

Return an equivalent circuit over time 0

NextVal(a,f) := Cause(a,f) ‚à® (f ‚àß ¬¨Cause(a,¬¨f)) 1
Poss(a,f) := ¬¨(Cause(a,f) ‚àß Cause(a,¬¨f))

2:
3:
4:

(optional: Simplify Formulas)

Figure 3: C-Filter Algorithm

Algorithm Overview
C-Filter is presented in Figure 3 and demonstrated in Section
4. It receives an action-observation sequence, an initial belief

state formula, œï, over P , and a domain description D.
outputs the Ô¨Åltered belief state as a logical circuit.

It

The algorithm maintains a circuit data structure, and point-
ers to some of its nodes. A pointer to a node represents the
formula which is rooted in that node (and they will be used
interchangeably). We maintain pointers to the following for-
mulas: (1) A formula cb (constraint base) ‚Äì the knowledge
obtained so far from the sequence (receiving observations and
knowing that actions were possible to execute constrains our

belief state). (2) For every Ô¨Çuent f‚ààP , a formula explf ; this

formula explains why f should be true now (in Figure 4, the
node marked e(Tch1) is the explanation formula of Touch(e1)
at time t, and the root node is the explanation at time t + 1).
We keep the number of variables in our representation
small (|P|) by allowing those formulas to involve only Ô¨Çu-
ents of time 0. In a way, this is similar to regression: explf
expresses the value of Ô¨Çuent f as a function of the ini-
tial world state, and cb gives the constraints on the initial
state.

The belief state is always cb‚àß(cid:2)

f ‚ààP (f ‚Üî explf ). In other

words, a possible model should satisfy cb, and each Ô¨Çuent f
can be replaced with the formula explf .

In the preprocessing phase, we extract data from the do-
main description (Procedure C-Filter, line 1). We then cre-
ate a node for each Ô¨Çuent, and initialize the explf pointers to
them. We also create a circuit for the initial belief-state, œï
(using the explf nodes), and set the cb pointer to it (lines 2-
3). Then we iterate through the sequence, update the circuit
and the pointers with every time step (lines 4-6, see below),
and Ô¨Ånally return the updated belief state.

A Closer Look
The circuit is constructed as follows.
In the preprocessing
stage, we extract some useful formulas from the domain de-
scription. Let Effects(a) be the set of Ô¨Çuents that action a
might affect. For each f in this set, we need to know how a
can affect f . Let Cause(a,f) be a formula describing when a
causes f to be true. It is simply the precondition of the rule of
a causing f to hold (if there are several, take the disjunction;
if there are none, set it to FALSE). That is, if s |= Cause(a,f)
and a is possible to execute, f will hold after it. Cause(a,¬¨f)

is deÔ¨Åned similarly.

For example,

take a = Rotate(90)

Effects(a)={Touch(e1), Touch(e2), Touch(e3)} , and
Cause(a,Touch(e1)) = OnBelt() ‚àß Touch(e3)
Cause(a,¬¨ Touch(e1)) = OnBelt() ‚àß Touch(e1)

(*)

(Section 3.1).

Procedure ProgressDomain then constructs the formula
NextVal(a,f), which evaluates to TRUE iff f holds after a
(given the previous state). Intuitively, either a caused it to
hold, or it already held and a did not affect it. Similarly, the
formula Poss(a,f) states that a was possible to execute regard-
ing f , i.e. did not cause it to be true and false at the same
time.

After preprocessing, we iterate through the sequence. Pro-
cedure ProgressAction uses those formulas to update the be-
lief state: First, it constructs a circuit asserting the action was

1Cause(a,f) represents the conditions for a to cause f , extracted

from the domain description (See (*))

IJCAI-07

2613

possible (corresponding to the Poss formula) and adds it to
cb (line 2). Then, it builds a circuit for the NextVal formula.
Procedure Time0 ensures the circuit uses only time-0 Ô¨Çuents.
When we construct a new Poss or NextVal circuit, its leafs
represent Ô¨Çuents of the previous time step; Time0 replaces
them by their equivalent explanation nodes. Our circuit im-
plementation is crucial for the efÔ¨Åciency of this replacement.
Instead of copying the whole formula, we only need to up-
date edges in the graph (using the pointers). This way, we
can share formulas recursively, and maintain compactness.

After all the new circuits were built, the explanation point-
ers are updated (line 4); the new explanation is the root of the
corresponding NextVal circuit, built earlier (line 3; see also
Section 5.1). Then we deal with the observation (Procedure
FilterObservation): similarly, we use Time0 to get a time-0
formula, and simply add it to cb.






‚àß

‚à®






‚àß






‚àß


  	





Figure 4: Updating the explanation of Touch(e1) after Rotate(90)

Example:

Figure 4 shows an update of the explanation
of Touch(e1) after the action Rotate(90). Rectangles (on the
bottom nodes) represent the explanation pointers of time t
(before the action). The circuit in the image is the NextVal
formula, after Procedure Time0 replaced its Ô¨Çuents by the cor-
responding explanation nodes.

The ‚à® node is the root of the graph representing state of

Touch(e1) after the action: the right branch describes the case
that the action caused it to hold, and the left branch is the
case that it held, and the action did not falsify it. In the next
iteration, the pointer of Touch(e1) will point at this node.

Note the re-use of some time-t explanation nodes; they are

internal nodes, possibly representing large subformulas.

3.3 Query Answering with the End Formula
C-Filter returns an updated belief state œït, represented as
a logical circuit. We are interested in satisÔ¨Åability queries
(œït ‚àß œà satisÔ¨Åable) and entailment queries (œït
|= œà, or
œït‚àß¬¨œà unsatisÔ¨Åable). In the following, we construct a circuit

corresponding to the query and run inference on it.

Query Circuits
Let œà be an arbitrary propositional query formula; we want to
check whether œït‚àßœà is satisÔ¨Åable. Very similarly to an obser-
vation, we add œà to cb, and replace the Ô¨Çuents for their expla-
nations. The new cb is our query circuit. Queries are usually
about time t, but the circuit structure allows more interesting
queries, in particular smoothing‚Äì queries that refer to the past
(e.g., did f change its value in the last 5 steps? Could the

initial value of g be TRUE?). Note that every Ô¨Çuent in every
time step has a corresponding node. If we keep track of those
nodes, we can replace Ô¨Çuents from any time step by their ex-
planations. If the queries are given in advance, this does not
change the complexity. Otherwise, Ô¨Ånding a past-explanation
node might take O(log t) time. Note that the same mecha-
nism (tracking previous explanations) has many interesting
applications, such as Ô¨Åltering in non-Markovian domains.

SAT for Circuits
After building a query circuit, we check satisÔ¨Åability. Tradi-
tional approaches check circuit-SAT by converting the circuit
into a CNF formula. The approaches for doing so either grow
the representation exponentially (duplicating shared subfor-
mulas) or grow the number of variables signiÔ¨Åcantly.

Instead, we run inference on the circuit itself. A number of
works show that the structural information lost in a CNF en-
coding can be used to give SAT procedures a signiÔ¨Åcant per-
formance improvement. Using circuit SAT solvers, we can
solve the problem more efÔ¨Åciently and effectively in its origi-
nal non-clausal encoding. Several such algorithms have been
proposed recently, taking advantage of the circuit structure
[Ganai et al., 2002; Thiffault et al., 2004]. We use those, and
a simple algorithm of our own, C-DPLL.

C-DPLL is a generalization of DPLL. Every iteration, an
uninstantiated variable f is chosen, and set to TRUE. The
truth value is then propagated as far as possible, resulting in
a smaller circuit (for example, if f had an OR parent, it will
be set to TRUE as well). Then, C-DPLL is called recursively.
If no satisfying assignment was found, it backtracks and tries
f =FALSE. If no assignment is found again, return UNSAT.
C-DPLL takes O(|E|¬∑ 2l) time and O(|E|) space for a circuit
with |E| edges and l leaves.

4 Extended Example

We now give a detailed example of the whole process. Inter-
estingly, this example demonstrates how logical circuits can
represent compactly a belief state that one cannot represent
compactly using CNF formulas over the same variables.

Our domain includes Ô¨Çuents {p1, ..., pn, odd}. The follow-
ing sequence of actions makes odd equal to p1 ‚äï p2 ‚äï ...pn,
the parity of the other Ô¨Çuents. Our actions a1, ..., an‚àí1 are
deÔ¨Åned such that a1 sets odd := p1 ‚äï p2, and any other ai
sets odd := odd ‚äï pi+1. Formally:

‚Äúa1 causes odd if (p1 ‚àß ¬¨p2) ‚à® (¬¨p1 ‚àß p2)‚Äù
‚Äúa1 causes ¬¨odd if ¬¨[(p1 ‚àß ¬¨p2) ‚à® (¬¨p1 ‚àß p2)]‚Äù
‚Äúai causes odd if (odd ‚àß ¬¨pi+1) ‚à® (¬¨odd ‚àß pi+1)‚Äù
‚Äúai causes ¬¨odd if ¬¨[(odd ‚àß ¬¨pi+1) ‚à® (¬¨odd ‚àß pi+1)]‚Äù
Applying the sequence a1, ..., an‚àí1 sets odd = p1 ‚äï ...pn.

We now show how our algorithm maintains the belief state
throughout the sequence.

Preprocessing the Domain:
In this phase we extract the Poss and NextVal formulas. We
examine the action speciÔ¨Åcations:
the only Ô¨Çuent which is
affected is odd. a1 is executable when it does not cause both
odd,¬¨odd.

Cause(a1,odd) = (p1 ‚àß ¬¨p2) ‚à® (¬¨p1 ‚àß p2)

IJCAI-07

2614

Cause(a1,¬¨odd) = ¬¨[(p1 ‚àß ¬¨p2) ‚à® (¬¨p1 ‚àß p2)]
Poss(a1,odd) = ¬¨[Cause(a1,odd) ‚àß Cause(a1,¬¨odd)]

It is easy to see that both cannot hold simultaneously, and
the formula can be simpliÔ¨Åed to TRUE: indeed, a1 is always
executable. Similarly, all of our actions are always possible
to execute, so the Poss formulas are all equal TRUE.

Now, the NextVal formulas. After executing a1, odd will

be set to Cause(a1,odd) ‚à® [odd ‚àß ¬¨Cause(a1,¬¨odd)].
will be set to p1 ‚äï p2. Similarly, after action ai odd will
be set to pi+1 ‚äï odd. Note, simplifying the formulas is not

This is equivalent to Cause(a1,odd). In other words, odd

mandatory; the representation will be compact without it, too.

Executing the Actions:
Imagine

that we

receive

the

a1, a2, ..., an‚àí1, odd ‚àß ¬¨pn (performing n actions and

(arbitrary)

sequence

receiving an observation).
Figure 5 describes how the
algorithm updates the belief-state with this sequence. At
time 0 (5a) we create a node for every Ô¨Çuent, and another for
TRUE. The nodes represent the value of the Ô¨Çuent at time 0.
We set a pointer (the rectangles) for each formula that we
want to maintain: the formula for cb (constraints) is set to
TRUE because we do not have any initial knowledge. The
explanation formula of each Ô¨Çuent is set to the corresponding
node.

We then execute a1, arriving at time 1 (5b). No constraint
was added to cb, since the action is always executable. No
explanation formula of pi changed, since a1 does not affect
them. The only thing that changed is the state of odd: its new
explanation is p1 ‚äï p2. We construct the graph for this for-

mula, and update the explanation pointer to its root node.
NOTE: the image shows xor gates just for the sake of clar-
ity. In fact, each of them should be replaced by Ô¨Åve gates, as
depicted in 5b.

Executing a2 is similar (time 2, 5c). We construct the graph
for odd‚Äôs new value, odd ‚äï p3. Note that we substitute the
Ô¨Çuents in this formula (odd, p3) by their explanations in time
1, i.e. the pointers of the previous time step.

This is just an example observation; alternatively, you can

We execute a3, ..., an‚àí1, and then observe odd ‚àß ¬¨pn (5d.
think of it as querying whether it is possible that odd ‚àß ¬¨pn
planation of odd. Then we add odd ‚àß ¬¨pn to our constraints,

holds now). First, we process the actions and update the ex-

	





 

















	


(a) At time t=0: initial belief state œï = TRUE

‚â°

‚äï





	


	

	



‚äï



 











‚à®

‚àß

‚àß













	


(b) Time t=1: after performing a1

	


	

	



‚äï

‚äï



 

















	


(c) Time t=2: after performing a1, a2

	

	

‚äï


‚äï

	


	

‚äï

	



‚äï



‚àß























	


(d) Time t=(n-1): after performing a1, .., an‚àí1 and observing

(odd ‚àß ¬¨pn)

creating a new cb circuit and updating the pointer. Finally, we
return the circuit in 5d, along with the pointers. This is our
updated belief state.

Answering Queries:
In 5e we show an example of truth-value propagation: if we
assume that at time 0 p1=TRUE and the rest are set to FALSE,
those values are propagated up and result in cb=TRUE. That
is, this assignment is consistent with our sequence.

	

‚äï

	

‚äï
‚äï

	

	

‚äï

	



‚àß

	



5 Analysis and Complexity
5.1 Correctness
Theorem 5.1 C-Filter is correct. For any formula œï and a

sequence of actions and observations (cid:2)ai, oi(cid:3)0<i‚â§t,
Filter[(cid:2)ai, oi(cid:3)0<i‚â§t]({s ‚àà S that satisfy œï}).

{ s ‚àà S that satisfy C-Filter((cid:2)ai, oi(cid:3)0<i‚â§t, œï)} =

IJCAI-07

2615

	



















	


Figure 5: (e) Propagating truth-values

Recall that a state s satisÔ¨Åes formula œï if s‚àßœï is satisÔ¨Åable

(Section 3.1). s is used as a formula and as a state.

PROOF SKETCH We present an effect model, and show
how to update a belief-state (Ô¨Çat) formula with this model.
We show that the Filtering deÔ¨Ånition in Section 2 can be re-
duced to consequence Ô¨Ånding (in a restricted language) with
this formula. Then, we show that C-Filter computes exactly
those consequences.

DeÔ¨Ånition 5.2 Effect Model:
For an action a, deÔ¨Åne the effect model of a at time t to be:

(cid:2)

Teff(a, t) = at ‚Üí
Poss(a, f, t) = ¬¨(Cause(a,f)t ‚àß Cause(a,¬¨f)t)
NextVal(a, f, t) = Cause(a,f)t

f ‚ààP Poss(a, f, t) ‚àß (ft+1 ‚Üî NextVal(a, f, t))
‚à® (ft ‚àß ¬¨Cause(a,¬¨f)t)

at asserts that action a occurred at time t, and ft+1 means
that f after performing a. œàt is the result of adding a sub-
script t to every Ô¨Çuent in formula œà (see Section 3.2 for deÔ¨Å-
nition of Cause(a,f)). The effect model corresponds to effect
axioms and explanation closure axioms from Situation Cal-
culus [Reiter, 1991]. If the robot can recognize an impossible
action, we can drop the assumption that actions are possible,
and adopt a slightly different effect model.

Recall that Filter[](¬∑) was deÔ¨Åned over a set of states. We

now deÔ¨Åne its analogue L-Filter, which handles belief-state
logical formulas.

DeÔ¨Ånition 5.3 (L-Filter) Let œï a belief-state formula.

‚Ä¢ L-Filter[a](œï) = CnLt+1(œït ‚àß at ‚àß Teff(a, t))
‚Ä¢ L-Filter[o](œï) = œï ‚àß o
where CnL(œà) are the consequences of œà in vocabulary L.
Lt+1 = (L(œït) ‚à™ Pt+1) \ Pt , for Pt = {ft | f ‚àà P} and
L(œït) the language of œït; i.e., Lt+1 does not allow Ô¨Çuents
with subscript t.
Lemma 5.4 The result of applying L-Filter[a] for a ‚àà A is a
formula representing exactly the set of states Filter[a].

More formally, let œï be a belief state formula.
Filter[a]({s ‚àà S | s satisÔ¨Åes œï}) =
{s ‚àà S | s satisÔ¨Åes L-Filter[a](œï)}

That is, both deÔ¨Ånitions are equivalent (for lack of space,
we do not present the proof here). As a result, we can com-
pute Filter using a consequence Ô¨Ånder in a restricted lan-
guage. However, this does not guarantee tractability. Instead
of using a consequence-Ô¨Ånder, we show that C-Filter com-
putes exactly those consequences.

Let œà := œït ‚àß at ‚àß Teff(a, t). According to our deÔ¨Ånition,
L-Filter[a](œï) = CnLt+1(œà). We now observe that conse-
quence Ô¨Ånding is easy if we keep œït in the following form:

œït = cb ‚àß (cid:2)

f ‚ààP (ft ‚Üî explf )

cb and explf do not involve any Ô¨Çuent of time t.

We now show how to compute the consequences of such
formulas. Furthermore, we show that the resulting formula
maintains this form, so we only need to check the form of the
initial belief-state. Luckily, this is not a problem; every ini-
tial belief-state can be converted to this form (in linear time)
using new proposition symbols.

Let œà be a formula in this form. œà states that (ft ‚Üî explf )
for every ft ‚àà Pt: we construct an equivalent formula, œà(cid:2), by
replacing every ft ‚àà Pt in Teff(a, t) with the formula explf .
Notation: œà(cid:2) := œït ‚àß at ‚àß Teff(a, t)[explf /ft].
œà ‚â° œà(cid:2) ‚áí CnLt+1(œà) ‚â° CnLt+1(œà(cid:2))

Therefore, we can Ô¨Ånd the consequences of œà(cid:2) instead.
Note that consequence Ô¨Ånding in Lt+1 is the same as using
the Resolution algorithm to resolve Ô¨Çuents of Pt. We use this
to compute CnLt+1(œà(cid:2)):
CnLt+1(œà(cid:2)) ‚â° cb ‚àß (cid:2)

f ‚ààP (Poss(a, t, f )[explg/gt]) ‚àß
f ‚ààP (ft+1 ‚Üî NextVal(a, t, f )[explg/gt])

(cid:2)

(cid:2) := cb ‚àß (cid:2)

cb

Let

f ‚ààP (Poss(a, t, f )[explg/gt])

(cid:2)
f := NextVal(a, t, f )[explg/gt]).
expl

The last formula can be re-written as

(cid:2) ‚àß (cid:2)

f ‚ààP (ft+1 ‚Üî expl
(cid:2)
f )

cb

Now note that C-Filter maintains the belief-state for-

mula exactly in that easy-to-compute form, namely cb ‚àß
(cid:2)
f ‚ààP (ft ‚Üî explf ) , cb and explf involve only special propo-

Also, cb

sitions, representing time-0 (to avoid confusion, you might
think of the new propositions in line 2 as finit, not f0).

(cid:2)
f are exactly the constraint-base and expla-
nation formulas after C-Filter‚Äôs ProgressAction. That is, C-
Filter correctly progresses the belief-state with actions. The
proof for handling observations is similar.

(cid:2), expl

vations in the sequence. Let ActDesc be the longest descrip-

5.2 C-Filter Complexity
Let œï0 be the initial belief state, t the length of the action-
observation sequence, and |Obs| the total length of the obser-
tion of an action a ‚àà A (preconditions + effects).
Theorem 5.5 Allowing preprocessing of O(|P|) time and
time O(|œï0| + |Obs| + t ¬∑ ActDesc) . Its output is a circuit of

space (or, alternatively, using a hash table), C-Filter takes

the same size.

If the observations are always conjunctions of literals, we

can drop |Obs| from space complexity. If there are no precon-
does not depend on the domain size, |P|. ActDesc is usually

ditions, we can maintain a Ô¨Çat formula instead. Note that this

small‚Äì especially if the actions in the domain affect a small
number of Ô¨Çuents, and have simple preconditions.

PROOF SKETCH: Initializing cb takes O(|œï0|) time. Han-
dling each action adds at most O(ActDesc) nodes and edges
to the graph, and takes the same time: in the worst case, as-
suming no simpliÔ¨Åcations were done, we need to construct a
graph for each of the action‚Äôs Causes formulas. Finally, each

time we receive an observation o we add at most O(|o|) nodes
and edges, resulting in total O(|Obs|).

Corollary 5.6 We can maintain an NNF-Circuit (no negation
nodes) with the same complexity.

PROOF SKETCH

The circuit‚Äôs leaves represent literals
(instead of propositions). We maintain explanation formulas

for them. Since (f ‚Üî explf ) ‚áí (¬¨f ‚Üî ¬¨explf ), we can
deÔ¨Åne expl¬¨f := ¬¨explf . We take the NNF-form of every

IJCAI-07

2616

Figure 6: Left: Filtering time (sec) for C-Filter, applied to Block-World and Grid domains of different sizes. The time is linear, and does
not depend on the domain size (slight differences in the graph are due to hash-table implementation). Right: Comparison of Filtering time
(msec) for several methods (numbers represent domain size). Note that this is log-scale.

formula we use (observations, explanations, etc.), and replace
every literal by its explanation. Converting to NNF takes time
linear in the formula‚Äôs size; therefore, time and space com-
plexities will not change (modulo a small constant).

sibly nondeterministic) domain, an initial belief state, and a
sequence of actions after which our belief state representation
is exponential in the initial belief state size. Our results show
that this does not hold for deterministic systems.

5.3 Projection
Projection is the problem of checking that a property holds
after t action steps of an action system, starting from a belief
state. Generalizations allow additional observations.

Our results from previous sections show that projection is
doable by applying C-Filter (generating the belief state at
time t, œït, adding the query and running our C-DPLL solver).
Let m be maximal length of a single observation plus
ActDesc. Usually m = O(1). Since œït includes O(n) vari-
ables, and has overall size O(n + mt), checking if a variable
assignment is a model of œït takes time O(n+mt). Thus, test-
ing satisÔ¨Åability is NP-Complete in n, instead of n + mt (the
size of the formula) or n¬∑ t (the number of propositional vari-
ables that appear in an unrolling of the system over t steps;
used in Bounded Model Checking). We need to guess n vari-
able assignments, and then apply a linear algorithm to check
it. The following result reÔ¨Ånes earlier complexity results.
Theorem 5.7 (Projection) Let D be a domain with deter-
ministic actions. The problem of answering whether all the
states in F ilter[œÄ](œï) satisfy Q, for belief state formula œï,
sequence of actions œÄ and query Q, is coNP-complete in the
number of state variables, n. We assume œÄ, œï, ActDesc and
Q are polynomial in n.

5.4 Representation Complexity
Our results have implications for the theory of representation-
space complexity. A simple combinatorial argument shows
that there are belief states of n Ô¨Çuents that cannot be described
using logical circuit of size o(2n), i.e., strictly smaller than
some linear function of 2n. Nevertheless, our results for C-
Filter show that those belief states that are reachable within a
polynomial number of actions from an initial belief state are
of size linear in t and the input size (initial belief state size,
and longest action description).

Also, [Amir and Russell, 2003] showed that for every
general-purpose representation of belief states there is a (pos-

5.5 A Note on Non-Determinism
C-Filter can handle non-determinism in observations, but not
in transition models. However, many real-life environments
are inherently non-deterministic. One natural solution is to
treat each non-deterministic action as a choice between sev-
eral deterministic ones. For example, coin-Ô¨Çipping:
Ô¨Çipt

‚Üí [ExactlyOneCase ‚àß

(case1 ‚Üí headst+1) ‚àß (case2 ‚Üí ¬¨headst+1)]

where formula ExactlyOneCase speciÔ¨Åes that exactly one of
case1, case2 holds (we can use a binary encoding). Unfortu-
nately, the number of propositions grows linearly with t.

We can handle another (very limited) non-deterministic
class without adding propositions (speciÔ¨Åcally, ‚Äúa causes
p ‚à® q if G‚Äù, G deterministic). The idea is to maintain a belief
state in a different form, with (l ‚Üí expll) for every literal l .

6 Experimental Evaluation
Our Filtering algorithm was implemented in C++. Our im-
plementation could also handle parametrized domain descrip-
tions, such as STRIPS. We tested it on AI-Planning domains
(Figure 7 lists several) of various sizes and observation mod-
els. We generated long action-observation sequences with a
random sequence generator (implemented in Lisp), and ran
inference on the results using our own C-DPLL and NoClause
([Thiffault et al., 2004]). circuit SAT solver.

Blocks: 108/124
Gripper: 110/6
Movie: 47/13

Ferry: 163/17
Hanoi: 259/16 Logistics: 176/16
Tsp: 98/15

Grid: 251/53

Figure 7: Overview of C-Filter experiments: AI-Planning domains
(2000+ Ô¨Çuents, 10000 steps). Results presented as Filtering time/
Model Ô¨Ånding time (both in msec).

Figures 6, 7, 8 present some of the results. Figure 6 (left)
shows that C-Filter is linear in the sequence length; note that

IJCAI-07

2617





#




#








!















	


	





	
























 !"





Figure 8: Total time for Ô¨Ånding a model (msec), for Block-Worlds
of different size and number of observations per step.

time depends on the domain but not on the domain size. In
both Block-World and Grid-World, Ô¨Åltering time almost does
not change, even when the number of Ô¨Çuents grows 100 times
larger (slight difference in the graph is due to hash-table im-
plementation, instead of an array; the circuit size does not
depend on this implementation and was the same).

The right part of Figure 6 shows a comparison to other
Ô¨Åltering methods. We compared our algorithm to (1) Filter
[Amir and Russell, 2003] (in Lisp), (2) Filtering by unrolling
the system over t steps (using |P|t propositions), (3) BDD-
based Filtering, based on the BuDDy package [Lind-Nielsen,
1999]. C-Filter outperformed them all, sometimes by orders
of magnitude; note that the graph is log-scale.

Comparison Analysis:

BDD sizes depend highly on
variable ordering. Even for some very simple circuits, the
representation can have either linear or exponential size de-
pending on the order (Ô¨Ånding an optimal ordering is known
to be NP-complete). The long processing time at the begin-
ning is due to heuristic methods that try to achieve a good
ordering; after a while, a good ordering was reached, mak-
ing processing faster. Even with those heuristics, we could
not process large (> 300) domains. Filter and Unroll were
also slower, and could not process long sequences or large
domains (also, Filter can handle only a limited class of do-
mains). Unroll suffers from the frame problem, i.e. needs to

explicitly state the Ô¨Çuents that do not change (ft ‚Üî ft+1),

and therefore depends on the domain size. C-Filter, however,
managed to handle large domains (hundreds of thousands of
Ô¨Çuents), taking a few milliseconds per step.

Figure 8 shows the time to Ô¨Ånd a model for the resulting
circuits using a modiÔ¨Åed version of NoClause. SigniÔ¨Åcantly,
reasoning time grows only linearly with t. This allows prac-
tical logical Ô¨Åltering over temporal sequences of unbounded
length. Note that the more observations an agent gets, the
more constrained his belief state is. Therefore, it takes longer
to Ô¨Ånd a satisfying model (also, the formula is larger).

7 Conclusions

A straightforward approach to Ô¨Åltering is to create all the
prime implicates (or all consequences) at time t + 1 from the
belief state representation of time t. Previous work (e.g. [Lib-
eratore, 1997]) showed that deciding if a clause belongs to the
new belief state is coNP-complete, even for deterministic do-
mains. This discouraged further research on the problem.

Nevertheless,

in this work we presented an exact and

tractable Ô¨Åltering algorithm for all deterministic domains.
Our result is surprising because it shows that creating a rep-
resentation of all of the consequences at time t + 1 is easier
(poly-time) than creating the new belief state piecemeal.

Several approaches were developed in the past to repre-
sent belief states in logic (e.g., BDDs, [Amir and Russell,
2003]), but none of them guaranteed compactness. The key
to our advance was our logical circuits representation. We
also showed how to maintain NNF-Circuits.

The results obtained here have implications in many impor-
tant AI-related Ô¨Åelds. We expect our algorithms to apply to
planning, monitoring and controlling, and perhaps stochastic
Ô¨Åltering. We plan to explore these directions in the future.

Acknowledgements This work was supported by the Na-
tional Science Foundation CAREER award grant IIS 05-
46663. We thank the anonymous reviewers for their helpful
comments.

References
[Amir and Russell, 2003] E. Amir and S. Russell. Logical Ô¨Åltering.

In IJCAI ‚Äô03. MK, 2003.

[Bertoli et al., 2001] P. Bertoli, A. Cimatti, and M. Roveri. Heuris-
tic search + symbolic model checking = efÔ¨Åcient conformant
planning. In IJCAI ‚Äô01. MK, 2001.

[Biere et al., 1999] A. Biere, A. Cimatti, E.M. Clarke, M. Fujita,
and Y. Zhu. Symbolic model checking using SAT procedures
instead of BDDs. In DAC‚Äô99, 1999.

[Bryant, 1992] R. E. Bryant. Symbolic Boolean manipulation with
ordered binary-decision diagrams. ACM Computing Surveys,
1992.

[Cimatti and Roveri, 2000] A. Cimatti and M. Roveri. Conformant

planning via symbolic model checking. JAIR, 2000.

[Clarke et al., 2001] E.M. Clarke, A. Biere, R. Raimi, and Y. Zhu.
Bounded model checking using satisÔ¨Åability solving. Formal
Methods in System Design, 2001.

[Ganai et al., 2002] M. K. Ganai, P. Ashar, A. Gupta, L. Zhang, and
S. Malik. Combining strengths of circuit-based and cnf-based
algorithms for a high-performance sat solver. In DAC, 2002.

[Liberatore, 1997] P. Liberatore. The complexity of the language

A. ETAI, 1997.

[Lin and Reiter, 1997] F. Lin and R. Reiter. How to progress a

database. AIJ, 1997.

[Lind-Nielsen, 1999] J. Lind-Nielsen. Buddy - a binary decision di-
agram package. Technical report, Institute of Information Tech-
nology, Technical University of Denmark, 1999.

[Petrick and Bacchus, 2004] R.P.A. Petrick and F. Bacchus. Ex-
tending the knowledge-based approach to planning with incom-
plete information and sensing. In ICAPS-04. AAAI Press, 2004.
[Reiter, 1991] R. Reiter. The frame problem in the situation cal-
culus: A simple solution (sometimes) and a completeness result
for goal regression. In ArtiÔ¨Åcial Intelligence and Mathematical
Theory of Computation. Academic Press, 1991.

[Thiffault et al., 2004] C. Thiffault, F. Bacchus, and T. Walsh. Solv-
In Principles and

ing non-clausal formulas with dpll search.
Practice of Constraint Programming, 2004.

[Winslett, 1990] M.A. Winslett. Updating Logical Databases.

Cambridge U. Press, 1990.

IJCAI-07

2618

