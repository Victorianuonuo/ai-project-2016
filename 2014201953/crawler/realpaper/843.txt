Permanents, Transportation Polytopes

and Positive Deﬁnite Kernels on Histograms

Marco Cuturi

Institute of Statistical Mathematics, Tokyo, Japan

cuturi@ism.ac.jp

Abstract

For two integral histograms r = (r1, . . . , rd) and
c = (c1, . . . , cd) of equal sum N , the Monge-
Kantorovich distance dMK(r, c) between r and c
parameterized by a d × d distance matrix T is the
minimum of all costs < F, T > taken over matrices
F of the transportation polytope U (r, c). Recent re-
sults suggest that this distance is not negative deﬁ-
nite, and hence, through Schoenberg’s well-known
result, exp(− 1
dMK) may not be a positive deﬁnite
t
kernel for all t > 0. Rather than using directly
dMK to deﬁne a similarity between r and c, we pro-
pose in this paper to investigate kernels on r and c
based on the whole transportation polytope U (r, c).
We prove that when r and c have binary counts,
which is equivalent to stating that r and c represent
clouds of points of equal size, the permanent of an
adequate Gram matrix induced by the distance ma-
trix T is a positive deﬁnite kernel under favorable
conditions on T . We also show that the volume
of the polytope U (r, c), that is the number of inte-
gral transportation plans, is a positive deﬁnite quan-
tity in r and c through the Robinson-Schensted-
Knuth correspondence between transportation ma-
trices and Young Tableaux. We follow by propos-
ing a family of positive deﬁnite kernels related to
the generating function of the polytope through re-
cent results obtained separately by A. Barvinok on
the one hand, and C.Berg and A.J. Duran on the
other hand. We ﬁnally present preliminary results
led on a subset of the MNIST database to compare
clouds of points through the permanent kernel.

1 Introduction
Deﬁning meaningful kernels on histograms and clouds of
points – and more generally positive measures on an arbitrary
space X – is an important topic in the ﬁeld of kernel methods,
as it is directly related to the deﬁnition of kernels for struc-
tured objects seen as bags-of-components. Since the latter
representations are frequently used by practitioners in appli-
cations, notably images seen as histograms of colors, texts as
bags-of-words or sequences as groups of subsequences, re-
search has been active in this ﬁeld recently.

In the early applications of kernel methods to complex
data structures, histograms were often treated as vectors, and
used as such with the standard Gaussian or polynomial ker-
nels [Joachims, 2002]. More adequate positive deﬁnite ker-
nels which exploit their speciﬁcity have been proposed since.
Namely, kernels which take into account the fact that his-
tograms are vectors with nonnegative coordinates [Hein and
Bousquet, 2005], and whose sum may be normalized to one,
that is cast as discrete probability measures and treated un-
der the light of information geometry [Lafferty and Lebanon,
2005; Lebanon, 2006]. Since such histograms are usually
deﬁned on bins which are not equally dissimilar, as is for
instance the case with color or amino-acid histograms, fur-
ther kernels which may take into account an a priori inter-bin
similarity where subsequently proposed [Kondor and Jebara,
2003; Cuturi et al., 2005; Hein and Bousquet, 2005].

In this context, a well-known distance for probability mea-
sures on a space X which takes explicitly into account the
geometry of X is the optimal transportation distance [Villani,
2001], which is usually known as the Monge-Kantorovich
(MK) or Wasserstein distance. This distance is also popu-
lar in the computer vision community [Rubner et al., 2000]
under the name of the earth movers’ distance. However, pre-
liminary ﬁndings [Naor and Schechtman, 2005] suggest that
the MK distance is not negative deﬁnite, and cannot thus
be used directly to deﬁne positive deﬁnite kernels, through
the Schoenberg theorem1 and negative exponentiation for in-
stance. Although some approximations of the distance have
been used so far to deﬁne positive deﬁnite kernels in vision
applications [Grauman and Darrell, 2004], we propose in this
paper to consider not only the optimal transport plan, but the
whole of the transportation polytope to characterize the simi-
larity of two histograms r and c.

This idea is rooted in the approach of [Vert et al., 2004]
to deﬁne a positive deﬁnite kernel for strings derived from
a set of string manipulations which may map a string m1
to another string m2, namely sequences of deletions, substi-
tutions and insertions of tokens, known as alignments. Vert

1The Schoenberg theorem[Berg et al., 1984, Theorem 3.2.2],
states that if a function ψ is a negative deﬁnite kernel, equivalently
that −ψ is conditionally positive deﬁnite [Sch¨olkopf and Smola,
2002], then for all t > 0, exp(−tψ) is a positive deﬁnite kernel.
The Gaussian kernel is for instance based on the fact that for two
vectors x, y, (cid:2)x − y(cid:2)2 is negative deﬁnite.

IJCAI-07

732

(cid:2)

et al. [2004] consider all possible alignments π between m1
and m2 and associate to each of these alignments π a score
S(π) which quantiﬁes how efﬁciently the sequence π aligns
successive tokens of m1 and m2. Rather than consider-
ing the score S(π(cid:2)) of the optimal alignment π(cid:2), known as
the Smith-Waterman score in the context of biological se-
quences, Vert et al. [2004] propose to deﬁne a positive def-
π eβS(π),
inite kernel between m1 and m2 through the sum
β > 0, which in their experimental setting provides a much
better performance. Intuitively, the latter sum can be inter-
preted as the generating function of the set of all alignments
π, which may give it more discriminative power than the sim-
ple use of the extremum S(π(cid:2)).

In the context of this paper, the set of all alignments π is
played by the set of all d × d transportation matrices F ∈
U (r, c) between two discrete histograms r = (r1, . . . , rd)
and c = (c1, . . . , cd) of equal sum N ; the analog of the BLO-
SUM distance matrices between amino-acids used in Vert et
al. [2004] is an arbitrary d × d negative deﬁnite distance ma-
trix T between the bins of the histograms, and ﬁnally, the cost
π(σ) becomes simply the Frobenius dot-product < F, T >.
As is also the case in [Vert et al., 2004], the family of con-
volution kernels introduced by Haussler [1999] plays an im-
portant role in our proofs, notably for the permanent kernel
for clouds of points introduced in Section 2. We then propose
in Section 3 a kernel between histograms by only taking into
account the volume of U (r, c), and we show that this result is
a natural consequence of the Robinson-Schensted-Knuth cor-
respondence between transportation matrices and generalized
Young tableaux. Finally, inspired by a recent construction ob-
tained by Barvinok [2005] and through a lemma by Berg and
Duran [2004], we show in Section 4 that a weighted version
of the generating function of U (r, c) can be used to deﬁne
positive deﬁnite kernels. We close the paper with Section 5 by
discussing implementation and computational issues brought
forward by these kernels, as well as preliminary experimental
results led on a subset of the MNIST database of handwritten
digits.

2 Permanent kernel for clouds of points
We deﬁne in this section a kernel for two clouds of points
x = {x1, . . . , xn} and y = {y1, . . . , yn} in a space X en-
dowed with a kernel κ, through a kernel on arbitrary sequence
representations x = (x1, . . . , xn) and y = (y1, . . . , yn),
which is by deﬁnition invariant under reordering of these
terms. Recall that for a n × n matrix M = [mij], the per-
manent of M , per M is deﬁned as the quantity

(cid:3)

n(cid:4)

per M =

miσ(i)

σ∈Sn

i=1

where σ spans the symmetric group Sn, that is the set of all
permutations of {1, . . . , n}. Note that the deﬁnition of the
permanent of a matrix differs from that of its determinant in
that the signatures of the permutations are not taken into ac-
count. The permanent of a matrix is also invariant under any
permutation of columns or rows of this matrix, a fact that we
use in the proof of Proposition 1 below.

Proposition 1 Let X be a set endowed with a kernel κ and
Xn the set of clouds of points of X of cardinal n, that is {X =
{x1, . . . , xn}, xi ∈ X }. Let X = {x1, . . . , xn} and Y =
{y1, . . . , yn} ∈ Xn. Then

kper : (X, Y ) (cid:3)→ per([κ(xi, yj)]1≤i,j≤n)

(1)

is a positive deﬁnite kernel on Xn × Xn.
Proof. We ﬁrst prove the result for two sequences x =
(x1, . . . , xn), y = (y1, . . . , yn). Given a permutation σ we
write xσ for the sequence (xσ(1)
, . . . , xσ(n)). The proof now
follows from the work of Haussler [1999] on convolution ker-
nels. Namely, we consider the equivalence relation R be-
tween two sequences x, y where xRy if and only if there ex-
ists a permutation σ ∈ Sn such that xσ = y. Consider now
the kernel k for two sequences

k((x1, . . . , xn), (y1, . . . , yn)) =

κ(xi, yi).

(cid:4)

1≤i≤n

which we use to deﬁne the convolution kernel K, which is
positive deﬁnite by deﬁnition,
(cid:3)

(cid:3)

K(x, y) =

k(u, v)

u∈R−1x

(cid:3)

v∈R−1y

(cid:3)

σu∈Sn

(cid:3)

σv ∈Sn

(cid:3)

k(xσu , yσv )
(cid:4)

κ(xσu (i)

, yσv (i))

1≤i≤n

σv ∈Sn
per[κ(xi, yj)] = n! per[κ(xi, yj)],

=

=

=

σu∈Sn

(cid:3)

σu∈Sn

hence the positive deﬁniteness of kper used on clouds of
points X, Y represented through any arbitrary pair of se-
quences x, y.

Suppose for interpretation purposes that the kernel k can
be written as k(x, y) = e−d(x,y) where d is an Hilbertian
metric [Hein and Bousquet, 2005] on X , that is there exists
a mapping φ from X to an arbitrary Hilbert space H such
that d(x, y) = (cid:5)φ(x) − φ(y)(cid:5). In that case the permanent
can be interpreted as the sum over all possible matchings
σ of the weight of each total transport scheme e−dσ where
dσ =
i d(xi, yσ(i)). The quantity dσ stands for the to-
tal transport cost between the two clouds-of-points given the
transport plan σ is selected, taken in a feature space H, as
illustrated in Figure 1.

(cid:2)

Note ﬁnally that a possible way to deﬁne kernels for two
clouds X and Y of sizes n and m respectively is to consider
the sum of the pairwise kernels of all their respective subsets
of size d ≤ min(n, m), that is
(cid:3)

(cid:3)

kper(X, Y ) =

kper(xd
1

, yd
1).

xd

1

∈x

yd

1

∈y

3 The volume of the transport polytope as a

kernel for marginals

We write N = {0, 1, . . .} for the set of nonnegative integers,
and consider now integral histograms (or margins as in the

IJCAI-07

733

Optimal permutation σ(cid:7)
Other permutation σ ∈ Sn

Figure 1: By considering the permanent of the matrix e−tij
where tij = d(xi, yj), the pairwise distances between white
and dark points, the permanent kernel explicitly considers the
costs of all possible matchings between the points of x and y,
and not only the optimal permutation σ(cid:2).

corresponding statistical literature [Diaconis and Gangolli,
1995]) with identical overall sum and dimension, that is el-
ements of the simplex lattice

d(cid:3)

i=1

For two partitions u, v of an integer n, a semi-standard
Young tableau of shape u and weight v is a diagram of shape
u containing v1 ones, v2 twos, etc., arranged to be weakly
right increasing in rows and strictly increasing down columns.
Consider for instance for n = 15, the semi-standard tableau

4

7

1
3
4

1
3
6

2
5
6

1
2
3
6

of shape u = (6, 4, 4, 1) and weights v = (3, 2, 3, 2, 1, 3, 1).
Given two partitions u and v, the Kostka number Ku,v is
equal to the number of semi-standard Young tableaux of
shape u and weight v.
Proposition 2 The kernel kvol on Σd,N deﬁned as

kvol(r, c) = |U (r, c)|

is symmetric positive deﬁnite.
Proof. The proof can be derived either from the theory of
symmetric functions or from the Robinson-Schensted-Knuth
(RSK) correspondence [Knuth, 1970], with both approaches
mentionned in [Diaconis and Gangolli, 1995]. We recall
brieﬂy the second proof. The RSK bijective correspondence
states that to every matrix M ∈ U (r, c) corresponds one and
only pair of semi-standard Young tableaux of identical shape
and weights r and c respectively. We hence have that, sum-
ming over all possible partitions η of N used as shapes for
the Young tableaux,

|U (r, c)| =

Kη, rKη, c ,

(cid:3)

η

Σd,N

def= {r = (ri) ∈ N

d,

ri = N }.

which is sufﬁcient to prove that the volume |U (r, c)| satisﬁes
Mercer’s condition.

We consider the polytope of transport matrices between r

and c, restricted to integral matrices, that is

U (r, c) = {F ∈ Nd×d | F 1d = r, F (cid:4)1d = c},

where 1d is the d-dimensional vector of ones. We recall that
the optimal transportation cost from r to c is a symmetric
function in r and c which is deﬁned as the result of the opti-
mization

dMK(r, c) def= min

< F, T >,

F ∈U (r,c)

where T ∈ Rd,d is an arbitrary distance matrix between bins,
and for two square matrices U and V we use the Frobenius
dot-product < U, V >= tr(U V (cid:4)). Note that the optimal
plan

F (cid:2) def= argminF ∈U (r,c)

< F, T >

can be computed through standard linear-programming meth-
ods in polynomial time in d and it is known that F (cid:2) is a ver-
tex of the polytope. We will reconsider the cost parameter T
in the next section, and focus for the rest of this section on
the volume |U (r, c)| of the polytope U (r, c), that is the total
number of integral transportation plans. We introduce ﬁrst
the concept of semi-standard Young tableaux.

4 Weighted generating functions
The volume of the transportation polytope is a special case of
the evaluation of the generating function f of U (r, c) [Barvi-
nok, 2006] on a given cost matrix T , in that case the null
matrix, where f is more generally deﬁned as

(cid:3)

f (T ) =

e−<F,T >.

F ∈U(r,c)

The computation of f for general polytopes, notably the
transportation one, is a subject of extensive research, with sig-
niﬁcative developments carried out in recent years and sum-
marized in [Loera et al., 2004]. The generating function can
also be expressed as the total weight of U (r, c) if we use
the terminology of [Barvinok, 2005] by setting wij = e−tij .
Note that for binary histograms, that is marginals which may
either take 1 or 0 values, U (r, c) is known as the Birkhoff
polytope and f (T ) corresponds in this case to the permanent
kernel deﬁned in Proposition 1 with κ set to e−T . In the gen-
eral case where r and c may not have binary counts, the vol-
ume |U (r, c)| can thus be regarded as a similarity between r
and c based exclusively on combinatorial properties, regard-
less of any prior knowledge T on the distance between the d

IJCAI-07

734

F (cid:3)

U (r, c)

where each block Ai,j is the ri × cj rectangular matrix with
all coefﬁcients set to the constant γiγje−ti,j . Then

kγ,T : (r, c) (cid:3)→

per A

r1! · · · rd!c1! · · · cn!

is a positive deﬁnite kernel on Σd,N × Σd,N .
Proof. we ﬁrst map each marginal r and c to the correspond-
ing sequences

(cid:5) (cid:6)(cid:7) (cid:8)
˜r = (1, . . . , 1

(cid:5) (cid:6)(cid:7) (cid:8)
, 2, . . . , 2

(cid:5) (cid:6)(cid:7) (cid:8)
, . . . , d, . . . , d
)

Figure 2: Rather than only consider the minimal value for
< F, T > reached on the vertex F (cid:2), we propose to use the
same cost criterion evaluated on the whole polytope U (r, c).

r1 times

r2 times

rd times

and ˜c, and deﬁne the positive deﬁnite kernel

κ(i, j) = γiγje−ti,j ,

bins. On the other hand, the optimal plan F (cid:2) corresponding
to the Monge-Kantorovich distance dMK =< F (cid:2), T > takes
into account such an information but does not reﬂect the in-
formation carried out by the distribution of the costs found in
the whole polytope. Hence, having in mind Figure 2 we pro-
pose to deﬁne valid kernels kϕ which consider both criteri-
ons, that is we consider the distribution of the cost < F, T >
over the whole polytope U (r, c). We do so by introducing
weighted versions of the generating function through a func-
tion ϕ : U (r, c) → R, deﬁning
(cid:3)

kϕ : (r, c) (cid:3)→

ϕ(F )e−<T,F >.

F ∈U (r,c)

Note that the generating functionis recovered when ϕ = 1.
Although the generating function might be a good candidate
for a kernel between r and c, we do not know at this moment
whether its evaluations on arbitrary matrices T are positive
deﬁnite functions of r and c. We provide instead a family of
functions ϕ which ensures this condition:
Proposition 3 Given that T is such that [e−tij ] is positive
semideﬁnite, and having deﬁned for 0 ≤ a < 2 the weight
function ϕa : Nd×d → R as
(cid:4)

(cid:4)

ϕa(F ) =

(2fii)!a

fii!

i

i(cid:5)=j

fij !2a−1,

we have that kϕa is a positive deﬁnite kernel on Σd,N .

The symmetry of kϕa is ensured by the symmetry of T and

ϕa since U (c, r) = U (r, c)(cid:4) and we have that

ϕa(F )e−<F,T > = ϕa(F (cid:4))e−<F (cid:2),T >.

We prove the positive-deﬁniteness of kϕa using the following
3 lemmas, which are motivated by a recent characterization
carried out by Barvinok [2005] of the generating function of
the transport polytope in terms of random permanents.
Lemma 4 Let T be a d × d cost matrix such that
[e−tij ]1≤i,j≤d is positive semideﬁnite and γ = (γ1, . . . , γd)
a sequence of nonnegative real numbers. For r, c ∈ Σd,N
deﬁne the N × N block matrix A as

A = [Ai,j]1≤i,j≤d

for the kernel indexed on {1, . . . , d} × {1, . . . , d}. We then
have using Proposition 1 that:

kγ,T (r, c) = kper(˜r, ˜c) ·

1

r1! · · · rd!c1! · · · cd!

.

(cid:3)→

Since (r, c)

is trivially positive
deﬁnite, so is kγ,T as the product of two positive deﬁnite
kernels.

r1!···rd!

c1!···cd!

1

×

1

0

(cid:9) ∞

xnμα(x) = (n!)α for n ∈ N.

We use the following lemma to turn the randomized setting
proposed in [Barvinok, 2005] into a sum of positive deﬁnite
kernels:
Lemma 5 (Berg, Duran) For each 0 < α ≤ 2, the sequence
(n!)α, n ∈ N is a determinate Stieltjes moment sequence, that
is there exists a unique nonnegative measure μα on [0, ∞[
such that
We refer to [Berg and Duran, 2004] for a proof of this result,
and more generally to the reference [Berg et al., 1984] for
the exposition of the moment problems and their relationship
with harmonic analysis on semigroups. Note that in the case
where α = 1, μ1 is the standard exponential density, and for
α = 0 the measure μ0 can be simply deﬁned as the dirac mass
on 1.
Lemma 6 (Barvinok) Let 0 ≤ a < 2 and suppose γ =
(γ1, . . . , γd) is distributed as a sequence of independent ran-
dom variables with identical law μa. Through the identity

kϕa = E[kγ,T (r, c)]

we have that kϕa is positive deﬁnite.
Proof. E[kγ,T (r, c)] is trivially positive deﬁnite as a sum of
positive deﬁnite kernels. We follow Barvinok’s proof to prove
the equality, with a slight modiﬁcation: Barvinok considers
standard exponential variable γij arranged in a d × d matrix,
while we consider here a sequence of independent random
variables γ = (γ1, . . . , γd) which all follow law μa.

Let us consider matrix A deﬁned in Lemma 4. For every

permutation σ of SN let

hσ =

N(cid:4)

k=1

akσ(k)

IJCAI-07

735

be the corresponding term in per A. Hence

E[per A] =

E[hσ].

(cid:3)

σ∈SN

Following Barvinok, with every permutation σ we associate
a transport plan D = D(σ) of U (r, c) called the pattern of σ,
as follows. Namely D = [dij]1≤i,j≤d where

dij =

1(˜rk = i)1(˜cσ(k) = j),

N(cid:3)

k=1

that is dij is the number of indices k ∈ {1, . . . , N } such that
(k, σ(k)) is in the (i, j) block of A. Note that D : σ (cid:3)→
D(σ) ∈ U (r, c) is surjective, but not bijective as we see be-
low. For hσ, we thus have, through Lemma 5 that

(cid:4)

E[hσ] = E[
(cid:4)

i,j

(cid:4)

(cid:4)

i,j

(cid:4)

(e−tij γiγj)di,j ] =

e−tij dij E[γdi,j

i

γdi,j
j

]

=

e−tij dij

(2dii)!a

(dij !)2a.

i,j

i

i(cid:5)=j

At this point we follow exactly Barvinok’s proof. Barvinok
proves that the number of permutations σ of SN which admit
D as a pattern is

Cr,c,D =

r1! · · · rd!c1! · · · cd!

(cid:10)

i,j dij !

,

yielding

E[per A] =

(cid:3)

D∈U (r,c)

and hence

E[kγ,T (r, c)] =

Cr,c,D

(cid:3)

D∈U(r,c)

(cid:3)

D∈U (r,c)

=

which concludes the proof.

(cid:4)

i,j

e−tij dij

(cid:4)

(2dii)!a

i

(cid:4)

i(cid:5)=j

dij!2a,

ϕa(D)

(cid:4)

i,j

e−tij dij

ϕa(D)e−<T,D> = kϕa(r, c),

Note that when a = 0 we obtain the Fisher-Yates dis-
tribution on transportation matrices [Diaconis and Gangolli,
1995], that is

ϕ0(F ) =

(cid:4)

i,j

1
fij!

,

whereas the case a = 1
on the diagonal elements of the transport plan,

2 yields a weight which only depends

(cid:11)

(cid:4)

ϕ 1

2

(F ) =

i

(2fii)!
fii!

.

5 Discussion and Experiments
We discuss in this section complexity issues which may arise
when trying to compute the kernels presented above, and
we present preliminary results on a pattern recognition task
which involves comparing clouds of points.

5.1 Computational issues
To handle clouds of points through Proposition 1 requires the
computation of the permanent of a n × n matrix, which is
a notoriously difﬁcult problem in combinatorics. Millions
of computations of such kernel evaluations, which are usu-
ally required to ﬁll in Gram matrices, may not be tractable at
the moment when the number n of points exceeds twenty to
thirty points. However, and in the case where the kernel κ is
bounded between 0 and 1, recent advances2 in the computa-
tion of approximations of the permanent through Sequential
Monte Carlo (SMC) techniques [Jerrum et al., 2004] yield a
complexity of the order of n7 log4 n. This is still problematic
for large n, but we believe that for clouds of points of small
size the permanent might be a useful kernel, with the abil-
ity of quantifying complex relationships through the power
of combinatorics. We propose below in our experiments to
compare 2000 images of handwritten digits by sampling arti-
ﬁcially 20 black pixels among each image, and compare these
clouds of points through the permanent of the pairwise ker-
nels for the points in each cloud. Another issue in that case
arises from the numerical stability of the computation of the
permanent when the values for κ might be too small, and we
do not have an adequate answer to this problem other than
simple cross-validation to obtain reasonable entries.

In the more general case of histograms, both the computa-
tion of the volume |U (r, c)| and the integration of kϕ0, which
corresponds to the Fisher-Yates distribution, as well as that
of kϕ1/2, may be computed through SMC sampling method-
ologies presented in recent works [Chen et al., 2006]. For
the volume only, exact calculations through toolboxes such
as LattE [Loera et al., 2004] are possible, but only tractable
for very low dimensions. Diaconis and Gangolli [1995] pro-
pose ad-hoc numerical approximations when d is small and
N is large,

Γ(dk)(N + 1
2

d2)(d−1)2

Γ(d)dkd

d(cid:4)

(¯ri)d−1(¯ci)k−1

i=1

|U (r, c)| =

where

w =

1

1 − w

1 + d2/2N
wri
N

d +

¯ri =

(cid:2)
d + 1
d
¯r2
i
1 − w

, k =

,

¯cj =

d +

,

− 1
d
wcj
N

.

Although these expressions might be symmetrized by aver-
2 (|U (r, c)| + |U (c, r)|), their positive deﬁniteness may
aging 1
not be guaranteed and has yet to be tested on datasets.

5.2 Experiments
Following the previous work of Kondor and Jebara [2003],
we have conducted experiments on the ﬁrst 2000 images
(28 × 28 pixels) of the MNIST database of handwritten dig-
its, with approximately 200 images for each digit. For each
image X i, we randomly sample a set {xi
} of 20
1
distinct black points in the image, that is pixels with an in-
tensity superior to 190 represented as points of the square

, . . . , xi

20

2which we have not used in our experiments.

IJCAI-07

736

[0, 1] × [0, 1], and perform a multiclass classiﬁcation to clas-
sify any new image as one of the 10 digits. We do so by ap-
plying a simple one-vs-all strategy on 10 classiﬁers, namely
support vector machines, using the Spider toolbox. This set-
ting makes it particularly difﬁcult for most common kernels
to compare the images and we consider here two different
approaches: ﬁrst the permanent kernel of Equation (1), sec-
ond a Gaussian kernel taken between the two images seen as
28 × 28 dimensional vectors, preliminarily smoothed through
a smoothing-kernel κ on the pixels, which yields actually a
simple summation over Gram matrices as described for in-
stance in [Borgwardt et al., 2006]. The kernel κ used to com-
pute both the permanent as in Equation (1), and to smooth the
image in the second case was set to be the Gaussian kernel be-
tween pixels κ(x, y) = exp(−(cid:5)x − y(cid:5)2/σ2) with a width σ
spanning values 0.1, 0.2 and 0.3. The considered kernels are
thus

kper(X i, X j) = per[κ(xi
r, xj
(cid:3)

kgaussian(X i, X j) = exp(−

s)]r,s,
κ(xi

r, xj

s)),

r,s

(cid:11)

that

is using
and we use their normalized counterpart,
˜k(x, y) = k(x, y)/
k(x, x)k(y, y) instead of k in our ex-
periments. We report the cross-validation errors for these
settings for σ taken over 5-fold cross validations in Table 1,
which show that the permanent kernels appear as a robust al-
though costly alternative to the smoothed kernel in this pre-
liminary experiment.

σ
.1
.2
.3

Gaussian

34.3 (± 1.4)
33.45 (± 1.0)
37.3 (± 1.0)

Permanent
32.3 (± 1.2)
31.3 (± 1.3)
33.2 (± 1.2)

Table 1: Misclassiﬁcation rate expressed in percents for the 2
considered kernels along with their standard errors averaged
over cross-validation folds.

Yuguo Chen, Ian H. Dinwoodie, and Seth Sullivant. Sequen-
tial importance sampling for multiway tables. The Annals
of Statistics, (34):523–545, 2006.

Marco Cuturi, Kenji Fukumizu, and Jean-Philippe Vert.
JMLR, 6:1169–1198,

Semigroup kernels on measures.
2005.

Persi Diaconis and Anil Gangolli. Rectangular arrays with
ﬁxed margins. In D. Aldous, P. Diaconis, J. Spencer, and
J.M. Steele, editors, Discrete Probability and Algorithms,
volume 72 of The IMA Volumes in Mathematics and Its
Applications, pages 15–41. Springer-Verlag, 1995.

Kristen Grauman and Trevor Darrell. Fast contour matching
using approximate earth mover’s distance. In IEEE Conf.
Vision and Patt. Recog., pages 220–227, 2004.

David Haussler. Convolution kernels on discrete structures.

Technical report, UC Santa Cruz, 1999. CRL-99-10.

M. Hein and O. Bousquet. Hilbertian metrics and positive
deﬁnite kernels on probability measures. In Proceedings
of AISTATS, January 2005.

Mark Jerrum, Alistair Sinclair, and Eric Vigoda.

A
polynomial-time approximation algorithm for the perma-
nent of a matrix with nonnegative entries.
J. ACM,
51(4):671–697, 2004.

Thorsten Joachims. Learning to Classify Text Using Sup-
port Vector Machines: Methods, Theory, and Algorithms.
Kluwer Academic Publishers, 2002.

Donald E. Knuth. Permutations, matrices, and generalized

Young tableaux. Paciﬁc J. Math., 34:709–727, 1970.

Risi Kondor and Tony Jebara. A kernel between sets of
In T. Faucett and N. Mishra, editors, Proc. of

vectors.
ICML’03, pages 361–368, 2003.

John Lafferty and Guy Lebanon. Diffusion kernels on statis-

tical manifolds. JMLR, 6:129–163, January 2005.
Guy Lebanon. Metric learning for text documents.

IEEE
Transactions on Pattern Analysis and Machine Intelli-
gence, 28(4):497–508, 2006.

References
Alexander Barvinok. Enumerating contingency tables via

random permanents, 2005. arXiv.org:math/0511596.

Alexander Barvinok. The complexity of generating functions
for integer points in polyhedra and beyond. In Proceedings
of the International Congress of Mathematicians, Madrid,
2006. to appear.

Christian Berg and Antonio J. Duran. A transformation from
hausdorff to Stieltjes moment sequences. Arkiv f¨or matem-
atik, 42:239–257, 2004.

Christian Berg, Jens Peter Reus Christensen, and Paul Res-
sel. Harmonic Analysis on Semigroups. Number 100 in
Graduate Texts in Mathematics. Springer Verlag, 1984.

Karsten M. Borgwardt, Arthur Gretton, Malte J. Rasch,
Hans-Peter Kriegel, Bernhard Sch¨olkopf, and Alexander J.
Smola.
Integrating structured biological data by kernel
maximum mean discrepancy.
In ISMB (Supplement of
Bioinformatics), volume 22, pages 49–57, 2006.

Jes´us A. De Loera, Raymond Hemmecke, Jeremiah Tauzer,
and Ruriko Yoshida. Effective lattice point counting in ra-
tional convex polytopes. Journal of Symbolic Computa-
tion, 38(4):1273–1302, October 2004.

Assaf Naor and Gideon Schechtman. Planar earthmover is

not in l1, 2005. arXiv:cs/0509074.

Y. Rubner, C. Tomasi, and L.J. Guibas. The earth mover’s dis-
tance as a metric for image retrieval. IJCV: International
Journal of Computer Vision, 40, 2000.

Bernhard Sch¨olkopf and Alexander J. Smola. Learning with
Kernels: Support Vector Machines, Regularization , Opti-
mization, and Beyond. MIT Press, 2002.

Jean-Philippe Vert, Hiroto Saigo, and Tatsuya Akutsu. Local
alignment kernels for protein sequences. In B. Sch¨olkopf,
K. Tsuda, and J.-P. Vert, editors, Kernel Methods in Com-
putational Biology. MIT Press, 2004.

C´edric Villani. Topics in Optimal Transportation, volume 58.

AMS Graduate Studies in Mathematics, 2001.

IJCAI-07

737

